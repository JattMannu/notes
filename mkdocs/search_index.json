{
    "docs": [
        {
            "location": "/", 
            "text": "Shichao's Notes\n\n\nThis site documents reading and learning notes. See \nRoadmap\n for the current progress.\n\n\n\n  \n\n    \n\n      (function() {\n        var cx = '000491777875727507539:_gc3mx7cstg';\n        var gcse = document.createElement('script');\n        gcse.type = 'text/javascript';\n        gcse.async = true;\n        gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +\n            '//cse.google.com/cse.js?cx=' + cx;\n        var s = document.getElementsByTagName('script')[0];\n        s.parentNode.insertBefore(gcse, s);\n      })();\n    \n\n    \n\n  \n\n\n\n\n\nBooks\n\n\nThe following is the primary reading list of books. Each chapter is organized as a single page; the included sections are noted with major concepts, along with personal doubts (with possible solutions figured out afterwards) and summary.\n\n\nAPUE\n\n\n\n\nAdvanced Programming in the UNIX Environment, 3rd Edition\n\n\nby W. Richard Stevens and Stephen A. Rago\n\n\nLKD\n\n\n\n\nLinux Kernel Development (3rd Edition)\n\n\nby Robert Love\n\n\nUTLK\n\n\n\n\nUnderstanding the Linux Kernel, Third Edition\n\n\nby Daniel P. Bovet and Marco Cesati\n\n\nUNP\n\n\n\n\nUnix Network Programming, Volume 1: The Sockets Networking API (3rd Edition)\n\n\nby W. Richard Stevens and Bill Fenner\n\n\nTCPv1\n\n\n\n\nTCP/IP Illustrated, Volume 1: The Protocols (2nd Edition)\n\n\nby Kevin R. Fall and W. Richard Stevens\n\n\nTCPIP\n\n\n\n\nThe TCP/IP Guide: A Comprehensive, Illustrated Internet Protocols Reference\n\n\nby Charles M. Kozierok\n\n\nLSP\n\n\n\n\nLinux System Programming: Talking Directly to the Kernel and C Library (Second Edition)\n\n\nby Robert Love\n\n\nTLPI\n\n\n\n\nThe Linux Programming Interface\n\n\nby Michael Kerrisk\n\n\nGOPL\n\n\n\n\nThe Go Programming Language\n\n\nby Alan A. A. Donovan and Brian W. Kernighan\n\n\nTWGR\n\n\n\n\nThe Well-Grounded Rubyist, Second Edition\n\n\nby David A. Black\n\n\nDevOps\n\n\n\n\nDevOps: A Software Architect's Perspective\n\n\nby Len Bass, Ingo Weber, Liming Zhu\n\n\nICND1\n\n\nCCENT/CCNA ICND1 640-822 Official Cert Guide, Third Edition\n\n\nICND2\n\n\nCCNA ICND2 Official Exam Certification Guide, Second Edition\n\n\nSPEC\n\n\n\n\nSystems Performance: Enterprise and the Cloud\n\n\nby Brendan Gregg\n\n\nCNAPP\n\n\nContent Networking: Architecture, Protocols, and Practice\n\n\nby Markus Hofmann\n\n\nBD\n\n\n\n\nBig Data: Principles and Best Practices of Scalable Realtime Data Systems\n\n\nby Nathan Marz, James Warren\n\n\nHTAE\n\n\n\n\nHacking: The Art of Exploitation, 2nd Edition\n\n\nby Jon Erickson\n\n\nMaterials\n\n\nThe following is the supplementary books and materials. Each topic, which may have one or more primary references listed, is included in a single page.\n\n\nBash\n\n\n\n\nThe GNU Bash Reference Manual\n\n\n\n\nC\n\n\n\n\nPatterns in C\n\n\n\n\nGo\n\n\n\n\nThe Way To Go: A Thorough Introduction To The Go Programming Language\n\n\nThe Go Documentation\n\n\nThe Go Programming Language Specification\n\n\n\n\nPython\n\n\n\n\nPython Essential Reference (4th Edition)\n\n\n\n\nRuby\n\n\n\n\nProgramming Ruby 1.9 \n 2.0: The Pragmatic Programmers' Guide (4th Edition)\n\n\n\n\nx86 Assembly\n\n\n\n\nWikibooks\n\n\n\n\niptables\n\n\n\n\nIptables Tutorial 1.2.2\n\n\n\n\nNginx\n\n\n\n\nnginx documentation\n\n\nNGINX and NGINX Plus Tutorial and Admin Guide\n\n\n\n\nVim\n\n\n\n\nLearning the vi and Vim Editors, 7th Edition\n\n\nLearn Vimscript the Hard Way", 
            "title": "Home"
        }, 
        {
            "location": "/apue/", 
            "text": "APUE\n\n\n\n\nChapter 1. UNIX System Overview\n\n\nChapter 2. UNIX Standardization and Implementations\n\n\nChapter 3. File I/O\n\n\nChapter 4. Files and Directories\n\n\nChapter 5. Standard I/O Library\n\n\nChapter 6. System Data Files and Information\n\n\nChapter 7. Process Environment\n\n\nChapter 8. Process Control\n\n\nChapter 9. Process Relationships\n\n\nChapter 10. Signals\n\n\nChapter 11. Threads\n\n\nChapter 12. Thread Control\n\n\nChapter 13. Daemon Processes\n\n\nChapter 14. Advanced I/O\n\n\nChapter 15. Interprocess Communication\n\n\nChapter 16. Network IPC: Sockets\n\n\nChapter 17. Advanced IPC", 
            "title": "Contents"
        }, 
        {
            "location": "/apue/ch1/", 
            "text": "Chapter 1. UNIX System Overview\n\n\nIntroduction\n\n\nThis chapter gives basic Unix system concepts that are familiar to system administrators, from a programmer's perspective.\n\n\nUNIX Architecture\n\n\nAn operating system can be defined as the software that controls the hardware resources of the computer and provides an environment under which programs can run. This software is generally called the \nkernel\n, since it is relatively small and resides at the core of the environment. The figure below shows a diagram of the UNIX System architecture.\n\n\n\n\n\n\nThe interface to the kernel is a layer of software called the \nsystem calls\n.\n\n\nLibraries of common functions are built on top of the system call interface, but applications are free to use both.\n\n\nThe shell is a special application that provides an interface for running other applications.\n\n\n\n\nLinux is the kernel used by the GNU operating system. Some people refer to this combination as the GNU/Linux operating system, but it is more commonly referred to as simply Linux. Although this usage may not be correct in a strict sense, it is understandable, given the dual meaning of the phrase \noperating system\n.\n\n\nLogging In\n\n\nShells\n\n\nA \nshell\n is a command-line interpreter that reads user input and executes commands. The user input to a shell is normally from the terminal (an interactive shell) or sometimes from a file (called a \nshell script\n).\n\n\nFiles and Directories\n\n\nFile system\n\n\nThe UNIX file system is a hierarchical arrangement of directories and files. Everything starts in the directory called root, whose name is the single character \n/\n.\n\n\nFilename\n\n\nThe names in a directory are called filenames. The only two characters that cannot appear in a filename are the slash character (/) and the null character. The slash separates the filenames that form a pathname (described next) and the null character terminates a pathname. For portability, POSIX.1 recommends restricting filenames to consist of the following characters: letters (\na-z\n, \nA-Z\n), numbers (\n0-9\n), period (\n.\n), dash (\n-\n), and underscore (\n_\n).\n\n\nPathname\n\n\nA sequence of one or more filenames, separated by slashes and optionally starting with a slash, forms a \npathname\n. A pathname that begins with a slash is called an \nabsolute pathname\n; otherwise, it\u2019s called a \nrelative pathname\n.\n\n\nWorking Directory\n\n\nEvery process has a working directory, sometimes called the \ncurrent working directory\n. This is the directory from which all relative pathnames are interpreted. A process can change its working directory with the \nchdir\n function.\n\n\nHome Directory\n\n\nThe working directory is set to our home directory, which is obtained from our entry in the password file.\n\n\nInput and Output\n\n\nFile Descriptors\n\n\nFile descriptors are normally small non-negative integers that the kernel uses to identify the files accessed by a process. Whenever it opens an existing file or creates a new file, the kernel returns a file descriptor that we use when we want to read or write the file\n\n\nStandard Input, Standard Output, and Standard Error\n\n\nBy convention, all shells open three descriptors whenever a new program is run: standard input, standard output, and standard error.\n\n\nPrograms and Processes\n\n\nProgram\n\n\nA \nprogram\n is an executable file residing on disk in a directory.\n\n\nProcesses and Process ID\n\n\nAn executing instance of a program is called a \nprocess\n.\n\n\nThe UNIX System guarantees that every process has a unique numeric identifier called the \nprocess ID\n. The process ID is always a non-negative integer.\n\n\nProcess Control\n\n\nThreads and Thread IDs\n\n\nThreads are identified by IDs. Thread IDs are local to a process. A thread ID from one process has no meaning in another process. We use thread IDs to refer to specific threads as we manipulate the threads within a process.\n\n\nError Handling\n\n\nWhen an error occurs in one of the UNIX System functions, a negative value is often returned, and the integer \nerrno\n is usually set to a value that tells why.  Some functions use a convention other than returning a negative value. For example:\n\n\n\n\nThe \nopen\n function returns either a non-negative file descriptor if all is OK or \u22121 if an error occurs.\n\n\nMost functions that return a pointer to an object return a null pointer to indicate an error.\n\n\n\n\nThe file \nerrno.h\n defines the symbol errno and constants for each value that errno can assume. Each of these constants begins with the character \nE\n. On Linux, the error constants are listed in the \nerrno(3)\n manual page\n\n\nPOSIX and ISO C define \nerrno\n as a symbol expanding into a modifiable lvalue of type integer. This can be either an integer that contains the error number or a function that returns a pointer to the error number. The historical definition is:\n\n\nextern\n \nint\n \nerrno\n;\n\n\n\n\n\n\nBut in an environment that supports threads, the process address space is shared among multiple threads, and each thread needs its own local copy of errno to prevent one thread from interfering with another. Linux supports multithreaded access to \nerrno\n by defining it as:\n\n\nextern\n \nint\n \n*\n_\n \n_errno_location\n(\nvoid\n);\n\n\n#define errno (*_ _errno_location())\n\n\n\n\n\n\nThere are two rules to be aware of with respect to \nerrno\n:\n\n\n\n\nThe value of \nerrno\n is never cleared by a routine if an error does not occur. Therefore, we should examine its value only when the return value from a function indicates that an error occurred.\n\n\nThe value of \nerrno\n is never set to 0 by any of the functions, and none of the constants defined in \nerrno.h\n has a value of 0.\n\n\n\n\nThe following functions are defined by the C standard to help with printing error messages.\n\n\nThe \nstrerror\n function maps errnum, which is typically the \nerrno\n value, into an error message string and returns a pointer to the string.\n\n\n#include \nstring.h\n\n\n\nchar\n \n*\nstrerror\n(\nint\n \nerrnum\n);\n\n\n\n/* Returns: pointer to message string */\n\n\n\n\n\n\nThe \nperror\n function produces an error message on the standard error, based on the current value of \nerrno\n, and returns. It outputs the string pointed to by msg, followed by a colon and a space, followed by the error message corresponding to the value of \nerrno\n, followed by a newline.\n\n\n#include \nstdio.h\n\n\n\nvoid\n \nperror\n(\nconst\n \nchar\n \n*\nmsg\n);\n\n\n\n\n\n\nThe following code shows the use of these two error functions.\n\n\n#include \napue.h\n\n\n#include \nerrno.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n      \nfprintf\n(\nstderr\n,\n \nEACCES: %s\n\\n\n,\n \nstrerror\n(\nEACCES\n));\n\n      \nerrno\n \n=\n \nENOENT\n;\n\n      \nperror\n(\nargv\n[\n0\n]);\n\n      \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nIf this program is compiled into the file \na.out\n, we have:\n\n\n$ ./a.out\n\n\nEACCES: Permission denied\n\n\n./a.out: No such file or directory\n\n\n\n\n\n\nUser Identification\n\n\nSignals\n\n\nTime Values\n\n\nSystem Calls and Library Functions\n\n\n\n\nLinux 3.2.0 has 380 system calls and FreeBSD 8.0 has over 450\n\n\nEach system call has a function of the same name in the standard C library\n\n\nAn application can either make a system call or call a library routine", 
            "title": "Chapter 1. UNIX System Overview"
        }, 
        {
            "location": "/apue/ch2/", 
            "text": "Chapter 2. UNIX Standardization and Implementations\n\n\nThis chapter discusses Unix standards, specifications and implementations.\n\n\nUNIX Standardization\n\n\n\n\nISO C\n\n\nIEEE POSIX\n\n\nSingle UNIX Specification (SUS): superset of the POSIX.1 standard\n\n\n\n\nLimits\n\n\n\n\nCompile-time limits\n\n\nRuntime limits", 
            "title": "Chapter 2. UNIX Standardization and Implementations"
        }, 
        {
            "location": "/apue/ch3/", 
            "text": "Chapter 3. File I/O\n\n\nThis chapter discusses unbuffered I/O, which are not part of ISO C but are part of POSIX.1 and the Single UNIX Specification.\n\n\nFile Descriptors\n\n\n\n\nAll open files are referred to by file descriptors\n\n\nNon-negative integer\n\n\nRange from 0 to \nOPEN_MAX - 1\n. With FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10, the limit is essentially infinite, bounded by the amount of memory on the system, the size of an integer, and any hard and soft limits configured by the system administrator.\n\n\n\n\nopen\n and \nopenat\n Functions\n\n\napue_open.h\n\n\n#include \nfcntl.h\n\n\n\nint\n \nopen\n(\nconst\n \nchar\n \n*\npath\n,\n \nint\n \noflag\n,\n \n...\n \n/* mode_t mode */\n \n);\n\n\nint\n \nopenat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npath\n,\n \nint\n \noflag\n,\n \n...\n \n/* mode_t mode */\n \n);\n\n\n\n/* Both return: file descriptor if OK, \u22121 on error */\n\n\n\n\n\n\noflag\n argument is formed by ORing one or more of the following constants from \nfcntl.h\n [p62]:\n\n\nRequired:\n\n\n\n\nO_RDONLY\n\n\nO_WRONLY\n\n\nO_RDWR\n\n\nO_EXEC\n\n\nO_SEARCH\n: Open for search only (applies to directories).\n\n\n\n\nOptional:\n\n\n\n\nO_APPEND\n\n\nO_CLOEXEC\n: Set the \nFD_CLOEXEC\n file descriptor flag\n\n\nO_CREAT\n: Create the file if it doesn\u2019t exist\n\n\nO_DIRECTORY\n: Generate an error if \nO_CREAT\n is also specified and the file already exists. This test for whether the file already exists and the creation of the file if it doesn\u2019t exist is an atomic operation\n\n\nO_EXCL\n\n\nO_NOCTTY\n\n\nO_NOFOLLOW\n\n\nO_NONBLOCK\n\n\nO_SYNC\n: Have each \nwrite\n wait for physical I/O to complete\n\n\nO_TRUNC\n\n\nO_TTY_INIT\n\n\nO_DSYNC\n\n\nO_RSYNC\n\n\n\n\nTOCTTOU\n\n\nopenat\n, for example, provides a way to avoid \ntime-of-check-to-time-of-use\n (TOCTTOU) errors. A program is vulnerable if it makes two file-based function calls where the second call depends on the results of the first call (two calls are not atomic).\n\n\nFilename and Pathname Truncation\n\n\nMost modern file systems support a maximum of 255 characters for filenames.\n\n\ncreat\n Function\n\n\napue_creat.h\n\n\n#include \nfcntl.h\n\n\n\nint\n \ncreat\n(\nconst\n \nchar\n \n*\npath\n,\n \nmode_t\n \nmode\n);\n\n\n\n/* Returns: file descriptor opened for write-only if OK, \u22121 on error */\n\n\n\n\n\n\nThis function is equivalent to:\n\n\nopen\n(\npath\n,\n \nO_WRONLY\n \n|\n \nO_CREAT\n \n|\n \nO_TRUNC\n,\n \nmode\n);\n\n\n\n\n\n\nWith \ncreat\n, the file is opened only for writing. To read and write a file, use [p66]:\n\n\nopen\n(\npath\n,\n \nO_RDWR\n \n|\n \nO_CREAT\n \n|\n \nO_TRUNC\n,\n \nmode\n);\n\n\n\n\n\n\nclose\n Function\n\n\napue_close.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nclose\n(\nint\n \nfd\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nWhen a process terminates, all of its open files are closed automatically by the kernel. Many programs take advantage of this fact and don\u2019t explicitly close open files.\n\n\nlseek\n Function\n\n\nEvery open file has a \"current file offset\", normally a non-negative integer that measures the number of bytes from the beginning of the file.\n\n\napue_lseek.h\n\n\n#include \nunistd.h\n\n\n\noff_t\n \nlseek\n(\nint\n \nfd\n,\n \noff_t\n \noffset\n,\n \nint\n \nwhence\n);\n\n\n\n/* Returns: new file offset if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nwhence\n argument can be:\n\n\n\n\nSEEK_SET\n: the file\u2019s offset is set to \noffset\n bytes from the beginning of the file\n\n\nSEEK_CUR\n: the file\u2019s offset is set to its current value plus the \noffset\n. The \noffset\n can be positive or negative.\n\n\nSEEK_END\n: the file\u2019s offset is set to the size of the file plus the \noffset\n. The \noffset\n can be positive or negative.\n\n\n\n\nTo determine the current offset, \nseek zero bytes from the current position\n:\n\n\noff_t\n \ncurrpos\n;\n\n\ncurrpos\n \n=\n \nlseek\n(\nfd\n,\n \n0\n,\n \nSEEK_CUR\n);\n\n\n\n\n\n\nThis technique (above code) can also be used to determine if a file is capable of seeking. If the file descriptor refers to a pipe, FIFO, or socket, \nlseek\n sets \nerrno\n to \nESPIPE\n and returns \u22121.\n\n\n\n\nNegative offsets are possible for certain devices, but for regular files, the offset must be non-negative.\n\n\nlseek\n only records the current file offset within the kernel and does not cause any I/O to take place. This offset is then used by the next read or write operation.\n\n\nHole in a file: file\u2019s offset can be greater than the file\u2019s current size, in which case the next \nwrite\n to the file will extend the file. This creates a hole in the file.\n\n\nBytes in the hole (bytes that have not been writen) are read back as 0.\n\n\nA hole in a file isn\u2019t required to have storage backing it on disk.\n\n\n\n\n\n\n\n\nread\n Function\n\n\napue_read.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \nread\n(\nint\n \nfd\n,\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: number of bytes read, 0 if end of file, \u22121 on error */\n\n\n\n\n\n\n\n\nbuf\n: type \nvoid *\n is used for generic pointers.\n\n\nReturn value is required to be a signed integer (\nssize_t\n) to return a positive byte count, 0 (for end of file), or \u22121 (for an error).\n\n\n\n\nSeveral cases in which the number of bytes actually read is less than the amount requested:\n\n\n\n\nRegular file: if the end of file is reached before the requested number of bytes has been read.\n\n\nTerminal device: up to one line is read at a time\n\n\nNetwork: buffering within the network may cause less than the requested amount to be returned\n\n\nPipe or FIFO: if the pipe contains fewer bytes than requested, \nread\n will return only what is available\n\n\nRecord-oriented device\n\n\nInterrupted by a signal and a partial amount of data has already been read\n\n\n\n\nwrite\n Function\n\n\napue_write.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \nwrite\n(\nint\n \nfd\n,\n \nconst\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: number of bytes written if OK, \u22121 on error */\n\n\n\n\n\n\nThe return value is usually equal to the \nnbytes\n argument; otherwise, an error has occurred.\n\n\nCommon causes for a \nwrite\n error:\n\n\n\n\nFilling up a disk\n\n\nExceeding the file size limit for a given process\n\n\n\n\nFor a regular file, the write operation starts at the file\u2019s current offset. If the \nO_APPEND\n option was specified when the file was opened, the file\u2019s offset is set to the current end of file before each write operation. After a successful write, the file\u2019s offset is incremented by the number of bytes actually written.\n\n\nI/O Efficiency\n\n\n\n\nmycat.c\n\n\n\n\n#include \napue.h\n\n\n\n#define BUFFSIZE 4096\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nn\n;\n\n    \nchar\n \nbuf\n[\nBUFFSIZE\n];\n\n\n    \nwhile\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nbuf\n,\n \nBUFFSIZE\n))\n \n \n0\n)\n\n    \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \nbuf\n,\n \nn\n)\n \n!=\n \nn\n)\n\n        \nerr_sys\n(\nwrite error\n);\n\n\n    \nif\n \n(\nn\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nCaveats of the above program:\n\n\n\n\nIt reads from standard input and writes to standard output, assuming that these have been set up by the shell before this program is executed.\n\n\nIt doesn\u2019t close the input file or output file. Instead, the program uses the feature of the \nUNIX kernel that closes all open file descriptors in a process when that process terminates.\n\n\nThis example works for both text files and binary files, since there is no difference between the two to the UNIX kernel.\n\n\n\n\nTiming results for reading with different buffer sizes (\nBUFFSIZE\n) on Linux:\n\n\n\n\nThe file was read using the program shown above, with standard output redirected to \n/dev/null\n. The file system used for this test was the Linux ext4 file system with 4,096-byte blocks (the \nst_blksize\n value is 4,096). This accounts for the minimum in the system time occurring at the few timing measurements starting around a \nBUFFSIZE\n of 4,096. Increasing the buffer size beyond this limit has little positive effect.\n\n\nMost file systems support some kind of read-ahead to improve performance. When sequential reads are detected, the system tries to read in more data than an application requests, assuming that the application will read it shortly. The effect of read-ahead can be seen in Figure 3.6, where the elapsed time for buffer sizes as small as 32 bytes is as good as the elapsed time for larger buffer sizes. [p73]\n\n\nFile Sharing\n\n\nThe UNIX System supports the sharing of open files among different processes.\n\n\n\n\nThe kernel uses three data structures to represent an open file, and the relationships among them determine the effect one process has on another with regard to file sharing.\n\n\n\n\nProcess table entry\n: every process has an entry in the process table. Each process table entry has a table of open file descriptors. Associated with each file descriptor are:\n\n\nFile descriptor flags\n (close-on-exec)\n\n\nPointer to a file table entry:\n\n\n\n\n\n\nFile table entry\n: the kernel maintains a file table for all open files. Each file table entry contains:\n\n\nFile status flags\n\n\nCurrent file offset\n\n\nPointer to the v-node table entry for the file\n\n\n\n\n\n\nv-node\n structure: contains information about the type of file and pointers to functions that operate on the file\n\n\nThis information is read from disk when the file is opened, so that all the pertinent information about the file is readily available\n\n\nv-node also contains the \ni-node\n for the file\n\n\nLinux has no v-node. Instead, a generic i-node structure is used. [p75] Instead of splitting the data structures into a v-node and an i-node, Linux uses a file system\u2013independent i-node and a file system\u2013dependent i-node. [p76]\n\n\n\n\n\n\n\n\nFigure 3.7\n shows a pictorial arrangement of these three tables for a single process that has two different files open: one file is open on standard input (file descriptor 0), and the other is open on standard output (file descriptor 1).\n\n\nIf two independent processes have the same file open, we could have the arrangement shown in Figure 3.8 (below).\n\n\n\n\nEach process that opens the file gets its own file table entry, but only a single v-node table entry is required for a given file. One reason \neach process gets its own file table entry is so that each process has its own current offset for the file.\n\n\nSpecific operations\n\n\n\n\nFile offset: After each \nwrite\n is complete, the current file offset in the file table entry is incremented by the number of bytes written. If this causes the current file offset to exceed the current file size, the current file size in the i-node table entry is set to the current file offset (the file is extended).\n\n\nO_APPEND\n: If a file is opened with the \nO_APPEND\n flag, a corresponding flag is set in the file status flags of the file table entry. Each time a \nwrite\n is performed for a file with this append flag set, the current file offset in the file table entry is first set to the current file size from the i-node table entry. Th is forces every \nwrite\n to be appended to the current end of file.\n\n\nlseek\n\n\nIf a file is positioned to its current end of file using \nlseek\n, all that happens is the current file offset in the file table entry is set to the current file size from the i-node table entry. \nThis is not the same as if the file was opened with the \nO_APPEND\n flag.\n\n\nThe \nlseek\n function modifies only the current file offset in the file table entry. No I/O takes place.\n\n\n\n\n\n\n\n\nIt is possible for more than one file descriptor entry to point to the same file table entry:\n\n\n\n\ndup\n\n\nfork\n: the parent and the child share the same file table entry for each open descriptor\n\n\n\n\nFile descriptor flags vs. the file status flags\n\n\n\n\nFile descriptor flags: apply only to a single descriptor in a single process\n\n\nFile status flags: apply to all descriptors in any process that point to the given file table entry\n\n\nfcntl\n is used to fetch and modify both of them\n\n\n\n\nAtomic Operations\n\n\nOlder versions of the UNIX System didn\u2019t support the \nO_APPEND\n option if a single process wants to append to the end of a file. The program would be:\n\n\nif\n \n(\nlseek\n(\nfd\n,\n \n0L\n,\n \n2\n)\n \n \n0\n)\n \n/* position to EOF, 2 means SEEK_END */\n\n    \nerr_sys\n(\nlseek error\n);\n\n\nif\n \n(\nwrite\n(\nfd\n,\n \nbuf\n,\n \n100\n)\n \n!=\n \n100\n)\n \n/* and write */\n\n    \nerr_sys\n(\nwrite error\n);\n\n\n\n\n\n\nThis works fine for a single process, but problems arise if multiple processes (or multiple instances of the same program) use this technique to append to the same file. The problem here is that our logical operation of \"position to the end of file and write\" requires two separate function calls. The solution is to have the positioning to the current end of file and the write be an atomic operation with regard to other processes. Any operation that requires more than one function call cannot be atomic, as there is always the possibility that the kernel might temporarily suspend the process between the two function calls. The UNIX System provides an atomic way to do this operation if we set the \nO_APPEND\n flag when a file is opened. This causes the kernel to position the file to its current end of file before each \nwrite\n. We no longer have to call lseek before each \nwrite\n.\n\n\npread\n and \npwrite\n Functions\n\n\nThe Single UNIX Specification includes two functions that allow applications to seek and perform I/O atomically:\n\n\napue_pread.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \npread\n(\nint\n \nfd\n,\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n,\n \noff_t\n \noffset\n);\n\n\n/* Returns: number of bytes read, 0 if end of file, \u22121 on error */\n\n\n\nssize_t\n \npwrite\n(\nint\n \nfd\n,\n \nconst\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n,\n \noff_t\n \noffset\n);\n\n\n/* Returns: number of bytes written if OK, \u22121 on error */\n\n\n\n\n\n\n\n\npread\n: equivalent to calling \nlseek\n followed by a call to \nread\n, with the following exceptions:\n\n\nThere is no way to interrupt the two operations that occur calling \npread\n.\n\n\nThe current file offset is not updated.\n\n\n\n\n\n\npwrite\n:  equivalent to calling lseek followed by a call to write, with similar exceptions to \npread\n.\n\n\n\n\nCreating a File\n\n\nAtomic operation\n\n\nWhen both of \nO_CREAT\n and \nO_EXCL\n options are specified, the \nopen\n will fail if the file already exists. The check for the existence of the file and the creation of the file was performed as an atomic operation.\n\n\nNon-atomic operation\n\n\nIf we didn\u2019t have this atomic operation, we might try:\n\n\nif\n \n((\nfd\n \n=\n \nopen\n(\npath\n,\n \nO_WRONLY\n))\n \n \n0\n)\n \n{\n\n    \nif\n \n(\nerrno\n \n==\n \nENOENT\n)\n \n{\n\n        \nif\n \n((\nfd\n \n=\n \ncreat\n(\npath\n,\n \nmode\n))\n \n \n0\n)\n\n            \nerr_sys\n(\ncreat error\n);\n\n    \n}\n \nelse\n \n{\n\n        \nerr_sys\n(\nopen error\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe problem occurs if the file is created by another process between the \nopen\n and the \ncreat\n. If the file is created by another process between these two function calls, and if that other process writes something to the file, that data is erased when this \ncreat\n is executed. Combining the test for existence and the creation into a single atomic operation avoids this problem.\n\n\nAtomic operation\n refers to an operation that might be composed of multiple steps. \nIf the operation is performed atomically, either all the steps are performed (on success) or none are performed (on failure). It must not be possible for only a subset of the steps to be performed.\n\n\ndup\n and \ndup2\n Functions\n\n\nAn existing file descriptor is duplicated by either of the following functions:\n\n\napue_dup.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ndup\n(\nint\n \nfd\n);\n\n\nint\n \ndup2\n(\nint\n \nfd\n,\n \nint\n \nfd2\n);\n\n\n\n/* Both return: new file descriptor if OK, \u22121 on error */\n\n\n\n\n\n\n\n\ndup\n: return the new file descriptor, which is guaranteed to be the lowest-numbered available file descriptor\n\n\ndup2\n: \nfd2\n argument is the new file descriptor we specifiy.\n\n\nIf \nfd2\n is already open, it is first closed\n\n\nIf \nfd\n equals \nfd2\n, then \ndup2\n returns \nfd2\n without closing it. Otherwise, the \nFD_CLOEXEC\n file descriptor flag is cleared for \nfd2\n, so that \nfd2\n is left open if the process calls \nexec\n.\n\n\n\n\n\n\n\n\nKernel data structures after \ndup(1)\n:\n\n\n\n\nIn the above figure, we assume the process executes:\n\n\nnewfd\n \n=\n \ndup\n(\n1\n);\n\n\n\n\n\n\n\n\nBecause both descriptors point to the same file table entry, they share the same file status flags (e.g. read, write, append) and the same current file offset.\n\n\nEach descriptor has its own set of file descriptor flags\n\n\n\n\nAnother way to duplicate a descriptor is with the \nfcntl\n function:\n\n\ndup\n(\nfd\n);\n\n\n\n\n\n\nis equivalent to\n\n\nfcntl\n(\nfd\n,\n \nF_DUPFD\n,\n \n0\n);\n\n\n\n\n\n\nSimilarly, the call\n\n\ndup2\n(\nfd\n,\n \nfd2\n);\n\n\n\n\n\n\nis equivalent to\n\n\nclose\n(\nfd2\n);\n\n\nfcntl\n(\nfd\n,\n \nF_DUPFD\n,\n \nfd2\n);\n\n\n\n\n\n\nIn this last case (above), the \ndup2\n is not exactly the same as a \nclose\n followed by an \nfcntl\n:\n\n\n\n\ndup2\n is an atomic operation, whereas the alternate form involves two function calls. It is possible in the latter case to have a signal catcher called between the \nclose\n and the \nfcntl\n that could modify the file descriptors. The same problem could occur if a different thread changes the file descriptors.\n\n\nThere are some \nerrno\n differences between \ndup2\n and \nfcntl\n.\n\n\n\n\nsync\n, \nfsync\n, and \nfdatasync\n Functions\n\n\nTraditional implementations of the UNIX System have a buffer cache or page cache in the kernel through which most disk I/O passes.\n\n\n\n\nDelayed write\n: when we write data to a file, the data is normally copied by the kernel into one of its buffers and queued for writing to disk at some later time\n\n\n\n\nThe kernel eventually writes all the delayed-write blocks to disk, normally when it needs to reuse the buffer for some other disk block. To ensure consistency of the file system on disk with the contents of the buffer cache, the \nsync\n, \nfsync\n, and \nfdatasync\n functions are provided.\n\n\napue_fsync.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nfsync\n(\nint\n \nfd\n);\n\n\nint\n \nfdatasync\n(\nint\n \nfd\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nvoid\n \nsync\n(\nvoid\n);\n\n\n\n\n\n\n\n\nsync\n: queues all the modified block buffers for writing and returns. It does not wait for the disk writes to take place\n\n\nsync\n is normally called periodically (usually every 30 seconds) from a system daemon, often called \nupdate\n, which guarantees regular flushing of the kernel\u2019s block buffers. The command \nsync(1)\n also calls the \nsync\n function.\n\n\n\n\n\n\nfsync\n: applies to a single file specified by the file descriptor \nfd\n, and waits for the disk writes to complete before returning.\n\n\nfsync\n also updates the file's attributes synchronously\n\n\n\n\n\n\nfdatasync\n: similar to \nfsync\n, but it affects only the data portions of a file.\n\n\n\n\nfcntl\n Function\n\n\nThe \nfcntl\n function can change the properties of a file that is already open.\n\n\napue_fcntl.h\n\n\n#include \nfcntl.h\n\n\n\nint\n \nfcntl\n(\nint\n \nfd\n,\n \nint\n \ncmd\n,\n \n...\n \n/* int arg */\n \n);\n\n\n\n/* Returns: depends on cmd if OK (see following), \u22121 on error */\n\n\n\n\n\n\nIn this section, the third argument of \nfcntl\n is always an integer, corresponding to the comment in the function prototype just shown.\n\n\nThe \nfcntl\n function is used for five different purposes:\n\n\n\n\nDuplicate an existing descriptor (\ncmd\n = \nF_DUPFD\n or \nF_DUPFD_CLOEXEC\n)\n\n\nGet/set file descriptor flags (\ncmd\n = \nF_GETFD\n or \nF_SETFD\n)\n\n\nGet/set file status flags (\ncmd\n = \nF_GETFL\n or \nF_SETFL\n)\n\n\nGet/set asynchronous I/O ownership (\ncmd\n = \nF_GETOWN\n or \nF_SETOWN\n)\n\n\nGet/set record locks (\ncmd\n = \nF_GETLK\n, \nF_SETLK\n, or \nF_SETLKW\n)\n\n\n\n\nThe following text discusses both the file descriptor flags associated with each file descriptor in the process table entry and the file status flags associated with each file table entry.\n\n\n\n\nF_DUPFD\n: Duplicate the file descriptor \nfd\n. The new file descriptor, which is the lowest-numbered descriptor that is not already open and is greater than or equal to the third argument (integer), is returned as the value of the function. The new descriptor has its own set of file descriptor flags with \nFD_CLOEXEC\n cleared.\ncleared.\n\n\nF_DUPFD_CLOEXEC\n: Duplicate the file descriptor and set the \nFD_CLOEXEC\n file descriptor flag associated with the new descriptor.\n\n\nF_GETFD\n: Return the file descriptor flags for \nfd\n. Currently, only one file descriptor flag (\nFD_CLOEXEC\n) is defined.\n\n\nF_SETFD\n: Set the file descriptor flags for \nfd\n. The new flag value is set from the third argument.\n\n\nSome existing programs don\u2019t use constant \nFD_CLOEXEC\n. Instead, these programs set the flag to either 0 (don\u2019t close-on-exec, the default) or 1 (do close-on-exec).\n\n\n\n\n\n\n\n\nF_GETFL\n: Return the file status flags for \nfd\n. The file status flags were described with the \nopen\n function.\n\n\n\n\nThe five access-mode flags (\nO_RDONLY\n, \nO_WRONLY\n, \nO_RDWR\n, \nO_EXEC\n, and \nO_SEARCH\n) are not separate bits that can be tested.\n\n\nO_RDONLY\n, \nO_WRONLY\n, \nO_RDWR\n often have the values 0, 1, and 2, respectively\n\n\nThe five access-mode flags are mutually exclusive: this means a file can have only one of them enabled.\n\n\nWe must first use the \nO_ACCMODE\n mask to obtain the access-mode bits and then compare the result against any of the five values.\n\n\n\n\n\n\n\n\n\n\nFile status flag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nO_RDONLY\n\n\nopen for reading only\n\n\n\n\n\n\nO_WRONLY\n\n\nopen for writing only\n\n\n\n\n\n\nO_RDWR\n\n\nopen for reading and writing\n\n\n\n\n\n\nO_EXEC\n\n\nopen for execute only\n\n\n\n\n\n\nO_SEARCH\n\n\nopen directory for searching only\n\n\n\n\n\n\nO_APPEND\n\n\nappend on each write\n\n\n\n\n\n\nO_NONBLOCK\n\n\nnonblocking mode\n\n\n\n\n\n\nO_SYNC\n\n\nwait for writes to complete (data and attributes)\n\n\n\n\n\n\nO_DSYNC\n\n\nwait for writes to complete (data only)\n\n\n\n\n\n\nO_RSYNC\n\n\nsynchronize reads and writes\n\n\n\n\n\n\nO_FSYNC\n\n\nwait for writes to complete (FreeBSD and Mac OS X only)\n\n\n\n\n\n\nO_ASYNC\n\n\nasynchronous I/O (FreeBSD and Mac OS X only)\n\n\n\n\n\n\n\n\n\n\n\n\nF_SETFL\n: Set the file status flags to the value of the third argument (integer). The only flags that can be changed are:\n\n\n\n\nO_APPEND\n\n\nO_NONBLOCK\n\n\nO_SYNC\n\n\nO_DSYNC\n\n\nO_RSYNC\n\n\nO_FSYNC\n\n\nO_ASYNC\n\n\n\n\n\n\nF_GETOWN\n: Get the process ID or process group ID currently receiving the \nSIGIO\n and \nSIGURG\n signals.\n\n\nF_SETOWN\n: Set the process ID or process group ID to receive the \nSIGIO\n and \nSIGURG\n signals.\n\n\n\n\nThe return value from \nfcntl\n depends on the command. All commands return \u22121 on an error or some other value if OK. The following four commands have special return values:\n\n\n\n\nF_DUPFD\n: returns the new file descriptor\n\n\nF_GETFD\n: returns the file descriptor flags\n\n\nF_GETFL\n: returns the file status flags\n\n\nF_GETOWN\n: returns a positive process ID or a negative process group ID\n\n\n\n\nGetting file flags\n\n\nExample:\n\n\n\n\nfileflags.c\n\n\n\n\n#include \napue.h\n\n\n#include \nfcntl.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nint\n \nval\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: a.out \ndescriptor#\n);\n\n    \nif\n \n((\nval\n \n=\n \nfcntl\n(\natoi\n(\nargv\n[\n1\n]),\n \nF_GETFL\n,\n \n0\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nfcntl error for fd %d\n,\n \natoi\n(\nargv\n[\n1\n]));\n\n\n    \nswitch\n \n(\nval\n \n \nO_ACCMODE\n)\n \n{\n\n    \ncase\n \nO_RDONLY\n:\n\n        \nprintf\n(\nread only\n);\n\n        \nbreak\n;\n\n    \ncase\n \nO_WRONLY\n:\n\n        \nprintf\n(\nwrite only\n);\n\n        \nbreak\n;\n\n    \ncase\n \nO_RDWR\n:\n\n        \nprintf\n(\nread write\n);\n\n        \nbreak\n;\n\n    \ndefault\n:\n\n        \nerr_dump\n(\nunknown access mode\n);\n\n    \n}\n\n\n    \nif\n \n(\nval\n \n \nO_APPEND\n)\n\n        \nprintf\n(\n, append\n);\n\n    \nif\n \n(\nval\n \n \nO_NONBLOCK\n)\n\n        \nprintf\n(\n, nonblocking\n);\n\n    \nif\n \n(\nval\n \n \nO_SYNC\n)\n\n        \nprintf\n(\n, synchronous writes\n);\n\n\n\n#if !defined(_POSIX_C_SOURCE) \n defined(O_FSYNC) \n (O_FSYNC != O_SYNC)\n\n    \nif\n \n(\nval\n \n \nO_FSYNC\n)\n\n        \nprintf\n(\n, synchronous writes\n);\n\n\n#endif\n\n\n    \nputchar\n(\n\\n\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ \n./a.out \n0\n \n /dev/tty\n\nread \nonly\n\n$ \n./a.out \n1\n \n temp.foo\n\n$ \ncat temp.foo\nwrite only\n\n$ \n./a.out \n2\n 2\ntemp.foo\nwrite only, append\n\n$ \n./a.out \n5\n 5\ntemp.foo\n\nread \nwrite\n\n\n\n\n\nModifying file flags\n\n\nTo modify either the file descriptor flags or the file status flags, we must be careful to fetch the existing flag value, modify it as desired, and then set the new flag value. We can\u2019t simply issue an \nF_SETFD\n or an \nF_SETFL\n command, as this could turn off flag bits that were previously set.\n\n\nExample:\n\n\n#include \napue.h\n\n\n#include \nfcntl.h\n\n\n\nvoid\n\n\nset_fl\n(\nint\n \nfd\n,\n \nint\n \nflags\n)\n \n/* flags are file status flags to turn on */\n\n\n{\n\n    \nint\n \nval\n;\n\n    \nif\n \n((\nval\n \n=\n \nfcntl\n(\nfd\n,\n \nF_GETFL\n,\n \n0\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nfcntl F_GETFL error\n);\n\n    \nval\n \n|=\n \nflags\n;\n \n/* turn on flags */\n\n    \nif\n \n(\nfcntl\n(\nfd\n,\n \nF_SETFL\n,\n \nval\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nfcntl F_SETFL error\n);\n\n\n}\n\n\n\n\n\n\nIf we change the middle statement to\n\n\nval\n \n=\n \n~\nflags\n;\n \n/* turn flags off */\n\n\n\n\n\n\nwe have a function named \nclr_fl\n,  logically ANDs the one\u2019s complement of \nflags\n with the current \nval\n.\n\n\nSynchronous-write flag\n\n\nIf we add the line\n\n\nset_fl\n(\nSTDOUT_FILENO\n,\n \nO_SYNC\n);\n\n\n\n\n\n\nto the beginning of the program shown in \nI/O Efficiency section\n, we\u2019ll turn on the synchronous-write flag. This causes each write to wait for the data to be written to disk before returning. Normally in the UNIX System, \na \nwrite\n only queues the data for writing; the actual disk write operation can take place sometime later.\n A database system is a likely candidate for using \nO_SYNC\n, so that it knows on return from a write that the data is actually on the disk, in case of an abnormal system failure.\n\n\nLinux ext4 timing results using various synchronization mechanisms [p86]\n\n\nMac OS X HFS timing results using various synchronization mechanisms [p87]\n\n\nThe \nabove program\n operates on a descriptor (standard output), never knowing the name of the file that was opened on that descriptor. We can\u2019t set the \nO_SYNC\n flag when the file is opened, since the shell opened the file. With \nfcntl\n, we can modify the properties of a descriptor, knowing only the descriptor for the open file.\n\n\nioctl\n Function\n\n\napue_ioctl.h\n\n\n#include \nunistd.h\n \n/* System V */\n\n\n#include \nsys/ioctl.h\n \n/* BSD and Linux */\n\n\n\nint\n \nioctl\n(\nint\n \nfd\n,\n \nint\n \nrequest\n,\n \n...);\n\n\n\n/* Returns: \u22121 on error, something else if OK */\n\n\n\n\n\n\nThe \nioctl\n function has always been the catchall for I/O operations. Anything that couldn\u2019t be expressed using one of the other functions in this chapter usually ended up being specified with an \nioctl\n. Terminal I/O was the biggest user of this function.\n\n\nFor the ISO C prototype, an ellipsis is used for the remaining arguments. Normally, however, there is only one more argument, and it\u2019s usually a pointer to a variable or a structure.\n\n\nEach device driver can define its own set of \nioctl\n commands. The system, however, provides generic ioctl commands for different classes of devices.\n\n\nWe use the \nioctl\n function in Section 18.12 to fetch and set the size of a terminal\u2019s window, and in Section 19.7 when we access the advanced features of pseudo terminals.\n\n\n/dev/fd\n\n\nNewer systems provide a directory named \n/dev/fd\n whose entries are files named 0, 1, 2, and so on. Opening the file \n/dev/fd/n\n is equivalent to duplicating descriptor \nn\n, assuming that descriptor \nn\n is open. \n/dev/fd\n is not part of POSIX.1.\n\n\nThe following are equivalent:\n\n\nfd\n \n=\n \nopen\n(\n/dev/fd/0\n,\n \nmode\n);\n\n\nfd\n \n=\n \ndup\n(\n0\n);\n\n\n\n\n\n\nMost systems ignore the specified \nmode\n, whereas others require that it be a subset of the mode used when the referenced file (standard input, in this case) was originally opened. The descriptors 0 and \nfd\n \nshare the same file table entry\n.\n\n\nThe Linux implementation of \n/dev/fd\n is an exception. It maps file descriptors into symbolic links pointing to the underlying physical files. When you open \n/dev/fd/0\n, for example, you are really opening the file associated with your standard input. Thus the mode of the new file descriptor returned is unrelated to the mode of the \n/dev/fd\n file descriptor.\n\n\nWe can also call \ncreat\n with a \n/dev/fd\n pathname argument as well as specify \nO_CREAT\n in a call to open. This allows a program that calls \ncreat\n to still work if the pathname argument is \n/dev/fd/1\n, for example.\n\n\nSome systems provide the pathnames \n/dev/stdin\n, \n/dev/stdout\n, and \n/dev/stderr\n. These pathnames are equivalent to \n/dev/fd/0\n, \n/dev/fd/1\n, and \n/dev/fd/2\n, respectively.\n\n\nThe main use of the \n/dev/fd\n files is from the shell. It allows programs that use pathname arguments to handle standard input and standard output in the same manner as other pathnames.\n\n\nThe following are equivalent:\n\n\nfilter file2 \n|\n cat file1 - file3 \n|\n lpr\nfilter file2 \n|\n cat file1 /dev/fd/0 file3 \n|\n lpr", 
            "title": "Chapter 3. File I/O"
        }, 
        {
            "location": "/apue/ch4/", 
            "text": "Chapter 4. Files and Directories\n\n\nThis chapter centers on I/O for regular files.\n\n\nrestrict\n keyword\n\n\nAdded in C99, \nrestrict\n keyword is used to tell the compiler which pointer references can be optimized, by indicating that the object to which the pointer refers is accessed in the function only via that pointer. [p26]\n\n\nstat\n, \nfstat\n, \nfstatat\n, and \nlstat\n Functions\n\n\napue_stat.h\n\n\n#include \nsys/stat.h\n\n\n\nint\n \nstat\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nstruct\n \nstat\n \n*\nrestrict\n \nbuf\n);\n\n\nint\n \nfstat\n(\nint\n \nfd\n,\n \nstruct\n \nstat\n \n*\nbuf\n);\n\n\nint\n \nlstat\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nstruct\n \nstat\n \n*\nrestrict\n \nbuf\n);\n\n\nint\n \nfstatat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nstruct\n \nstat\n \n*\nrestrict\n \nbuf\n,\n \nint\n \nflag\n);\n\n\n\n/* All four return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nstat\n: returns a structure of information about the named file\n\n\nfstat\n: returns a structure of information about the given file descriptor\n\n\nlstat\n: similar to \nstat\n, returns information about the symbolic link, not the file referenced by the symbolic link\n\n\nfstatat\n:  return the file statistics for a pathname relative to an open directory represented by the fd argument; the flag argument controls whether symbolic links are followed\n\n\n\n\nThe \nbuf\n argument is a pointer to a \nstructure\n that we must supply. The functions fill in the structure.\n\n\nstruct\n \nstat\n \n{\n\n    \nmode_t\n    \nst_mode\n;\n\n    \nino_t\n    \nst_ino\n;\n\n    \ndev_t\n    \nst_dev\n;\n\n    \ndev_t\n    \nst_rdev\n;\n\n    \nnlink_t\n    \nst_nlink\n;\n\n    \nuid_t\n    \nst_uid\n;\n\n    \ngid_t\n    \nst_gid\n;\n\n    \noff_t\n    \nst_size\n;\n\n    \nstruct\n \ntimespec\n    \nst_atim\n;\n\n    \nstruct\n \ntimespec\n    \nst_mtim\n;\n\n    \nstruct\n \ntimespec\n    \nst_ctim\n;\n\n    \nblksize_t\n    \nst_blksize\n;\n\n    \nblkcnt_t\n    \nst_blocks\n;\n\n\n};\n\n\n\n\n\n\ntimespec\n structure\n\n\nThe \ntimespec\n structure type defines time in terms of seconds and nanoseconds. It includes at least the following fields:\n\n\ntime_t\n \ntv_sec\n;\n\n\nlong\n \ntv_nsec\n;\n\n\n\n\n\n\nFile Types\n\n\n\n\nRegular file. All binary executable files conform to a format that allows the kernel to identify where to load a program\u2019s text and data.\n\n\nDirectory file. A file that contains the names of other files and pointers to information on these files. Any process that has read permission for a directory file can read the contents of the directory, but only the kernel can write directly to a directory file.\n\n\nBlock special file\n\n\nCharacter special file\n\n\nFIFO\n\n\nSocket\n\n\nSymbolic link\n\n\n\n\nThis program prints the type of file for each command-line argument.\n\n\n\n\nfiletype.c\n\n\n\n\nSet-User-ID and Set-Group-ID\n\n\nEvery process has six or more IDs associated with it:\n\n\n\n\nThe \nreal user ID\n and \nreal group ID\n: who we really are.\n\n\nThese two fields are taken from our entry in the password file when we log in.\n\n\nNormally, these values don\u2019t change during a login session, although there are ways for a superuser process to change them. (\nSection 8.11\n)\n\n\n\n\n\n\nThe \neffective user ID\n, \neffective group ID\n and \nsupplementary group IDs\n: used for file access permission checks.\n\n\nThe \nsaved set-user-ID\n and \nsaved set-group-ID\n: saved by \nexec\n functions. They contain copies of the effective user ID and the effective group ID, when a program is executed. (\nSection 8.11\n)\n\n\n\n\nEvery file has an owner and a group owner:\n\n\n\n\nThe owner is specified by the \nst_uid\n member of the \nstat\n structure;\n\n\nThe group owner is specified by the \nst_gid\n member of the \nstat\n structure.\n\n\n\n\nWhen we execute a program file, the effective user ID of the process is usually the real user ID, and the effective group ID is usually the real group ID. However, we can also set special flags in the file\u2019s mode word (\nst_mode\n) that says:\n\n\n\n\nWhen this file is executed, set the effective user ID of the process to be the owner of the file (\nst_uid\n).\n\n\nWhen this file is executed, set the effective group ID of the process to be the group owner of the file (\nst_gid\n).\n\n\n\n\nThese two bits in the file\u2019s mode word are called the \nset-user-ID\n (setuid) bit and the \nset-group-ID\n (setgid) bit.\n\n\nFor example:\n\n\n\n\nIf the owner of the file is the superuser and if the file\u2019s set-user-ID bit is set, then while that program file is running as a process, it has superuser privileges, regardless of the real user ID of the process that executes the file.\n\n\npasswd(1)\n is a set-user-ID program, so that the program can write the new password to the password file, typically either \n/etc/passwd\n or \n/etc/shadow\n, files that should be writable only by the superuser.\n\n\n\n\nBecause a process that is running set-user-ID to some other user usually assumes extra permissions, it must be written carefully.\n\n\n[p99]\n\n\nFile Access Permissions\n\n\n\n\nWhenever we want to open any type of file by name, we must have execute permission in each directory mentioned in the name, including the current directory, if it is implied. Read permission for a directory and execute permission for a directory mean different things. Read permission lets us read the directory, obtaining a list of all the filenames in the directory. Execute permission lets us pass through the directory when it is a component of a pathname that we are trying to access. [p100]\n\n\nWe cannot create a new file in a directory unless we have write permission and execute permission in the directory.\n\n\n\n\nOwnership of New Files and Directories\n\n\n\n\nThe user ID of a new file is set to the effective user ID of the process\n\n\nThe group ID of a new file can be the effective group ID of the process; or group ID of the directory in which the file is being created.\n\n\n\n\nFreeBSD 8.0 and Mac OS X 10.6.8 always copy the new file\u2019s group ID from the directory.\n\n\naccess\n and \nfaccessat\n Functions\n\n\napue_access.h\n\n\n#include \nunistd.h\n\n\n\nint\n \naccess\n(\nconst\n \nchar\n \n*\npathname\n,\n \nint\n \nmode\n);\n\n\nint\n \nfaccessat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npathname\n,\n \nint\n \nmode\n,\n \nint\n \nflag\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThese functions test accessibility based on the real user and group IDs.\n\n\nThe \nflag\n argument can be used to change the behavior of \nfaccessat\n. If the \nAT_EACCESS\n flag is set, the access checks are made using the effective user and group IDs.\n\n\n\n\naccess.c\n\n\n\n\numask\n Function\n\n\nThe Single UNIX Specification requires that the \numask\n command support a symbolic mode of operation. Unlike the octal format, the symbolic format specifies which permissions are to be allowed instead of which ones are to be denied.\n\n\n$ \numask\n  \n# first print the current file mode creation mask\n\n002\n\n$ \numask\n -S  \n# print the symbolic form\n\n\nu\n=\nrwx,g\n=\nrwx,o\n=\nrx\n\n$ \numask \n027\n  \n# print the symbolic form\n\n\n$ \numask\n -S  \n# print the symbolic form\n\n\nu\n=\nrwx,g\n=\nrx,o\n=\n\n\n\n\n\n\nchmod\n, \nfchmod\n, and \nfchmodat\n Functions\n\n\napue_chmod.h\n\n\n#include \nsys/stat.h\n\n\n\nint\n \nchmod\n(\nconst\n \nchar\n \n*\npathname\n,\n \nmode_t\n \nmode\n);\n\n\nint\n \nfchmod\n(\nint\n \nfd\n,\n \nmode_t\n \nmode\n);\n\n\nint\n \nfchmodat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npathname\n,\n \nmode_t\n \nmode\n,\n \nint\n \nflag\n);\n\n\n\n/* All three return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nchmod\n automatically clears the following permission bits under the following conditions:\n\n\n\n\nSetting sticky bit on a regular file without superuser privileges (Solaris)\n\n\nIf the group ID of the new file does not equal either the effective group ID of the process or one of the process\u2019s supplementary group IDs and if the process does not have superuser privileges, then the set-group-ID bit is automatically turned off. On FreeBSD 8.0, Linux 3.2.0 and Mac OS X 10.6.8, if a process that does not have superuser privileges writes to a file, the set-user-ID and set-group-ID bits are automatically turned off.\n\n\n\n\nSticky Bit\n\n\nSticky Bit (\nS_ISVTX\n), or saved-text bit in the later versions of the UNIX System.\n\n\n\n\nOn file: only on a minority of systems\n\n\nOn directory: \n/tmp\n and \n/var/tmp\n\n\n\n\nchown\n, \nfchown\n, \nfchownat\n, and \nlchown\n Functions\n\n\napue_chown.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nchown\n(\nconst\n \nchar\n \n*\npathname\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n);\n\n\nint\n \nfchown\n(\nint\n \nfd\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n);\n\n\nint\n \nfchownat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npathname\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n,\n \nint\n \nflag\n);\n\n\nint\n \nlchown\n(\nconst\n \nchar\n \n*\npathname\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n);\n\n\n\n/* All four return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nlchown\n and \nfchownat\n (with the \nAT_SYMLINK_NOFOLLOW\n flag set) change the owners of the symbolic link itself.\n\n\nfchown\n operates on a open file, it can\u2019t be used to change the ownership of a symbolic link.\n\n\n\n\nOnly the superuser can change the ownership of a file (FreeBSD 8.0, Linux 3.2.0, and Mac OS X 10.6.8)\n\n\nWhen \n_POSIX_CHOWN_RESTRICTED\n is in effect, a non-superuser can\u2019t change the user ID of your files; A nonsuperuser can change the group ID of files that he owns, but only to groups that he belongs to.\n\n\nFile Size\n\n\nThe \nst_size\n member of the stat structure contains the size of the file in bytes. This field is meaningful only for regular files, directories, and symbolic links.\n\n\nFreeBSD 8.0, Mac OS X 10.6.8, and Solaris 10 also define the file size for a pipe as the number of bytes that are available for reading from the pipe.\n\n\n\n\nFor a regular file, a file size of 0 is allowed. We\u2019ll get an end-of-file indication on the first read of the file.\n\n\nFor a directory, the file size is usually a multiple of a number, such as 16 or 512.\n\n\nFor a symbolic link, the file size is the number of bytes in the filename.\n\n\n\n\nMost contemporary UNIX systems provide two fields:\n\n\n\n\nst_blksize\n: preferred block size for I/O for the file\n\n\nst_blocks\n: actual number of 512-byte blocks that are allocated\n\n\n\n\nBe aware that different versions of the UNIX System use units other than 512-byte blocks for \nst_blocks\n. Use of this value is \nnonportable\n.\n\n\nHoles in a File\n\n\n$ \nls -l core\n-rw-r--r-- \n1\n sar \n8483248\n Nov \n18\n 12:18 core\n\n$ \ndu -s core\n\n272\n core\n\n\n\n\n\nFile Truncation\n\n\napue_truncate.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ntruncate\n(\nconst\n \nchar\n \n*\npathname\n,\n \noff_t\n \nlength\n);\n\n\nint\n \nftruncate\n(\nint\n \nfd\n,\n \noff_t\n \nlength\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThese two functions truncate an existing file to \nlength\n bytes. If the previous size of the file was greater than \nlength\n, the data beyond \nlength\n is no longer accessible. Otherwise, if the previous size was less than \nlength\n, the file size will increase and the data between the old end of file and the new end of file will read as 0 (a hole is probably created in the file).\n\n\nFile Systems\n\n\nMost UNIX file systems support \ncase-sensitive\n filenames. On Mac OS X, however, the HFS file system is \ncase-preserving\n with \ncase-insensitive\n comparisons.\n\n\n\n\n\n\nEvery i-node has a link count that contains the number of directory entries that point to it. Only when the link count (\nst_nlink\n) goes to 0 can the file be deleted.\n\n\nWith a symbolic link (file type \nS_IFLNK\n), the actual contents of the file (the data blocks) store the name of the file that the symbolic link points to.\n\n\nThe i-node contains all the information about the file: the file type, the file\u2019s access permission bits, the size of the file, pointers to the file\u2019s data blocks, and so on.\n\n\nOnly two items are stored in the directory entry: the filename and the i-node number. The data type for the i-node number is \nino_t\n.\n\n\n\n\nlink\n, \nlinkat\n, \nunlink\n, \nunlinkat\n, and \nremove\n Functions\n\n\napue_link.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nlink\n(\nconst\n \nchar\n \n*\nexistingpath\n,\n \nconst\n \nchar\n \n*\nnewpath\n);\n\n\nint\n \nlinkat\n(\nint\n \nefd\n,\n \nconst\n \nchar\n \n*\nexistingpath\n,\n \nint\n \nnfd\n,\n \nconst\n \nchar\n \n*\nnewpath\n,\n\n           \nint\n \nflag\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nWhen a file is closed, the kernel first checks the count of the number of processes that have the file open. If this count has reached 0, the kernel then checks the link count; if it is 0, the file\u2019s contents are deleted.\n\n\nWhen the \nAT_REMOVEDIR\n flag is set, then the \nunlinkat\n function can be used to remove a directory, similar to using \nrmdir\n.\n\n\napue_remove.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nremove\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nrename\n and \nrenameat\n Functions\n\n\napue_rename.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nrename\n(\nconst\n \nchar\n \n*\noldname\n,\n \nconst\n \nchar\n \n*\nnewname\n);\n\n\nint\n \nrenameat\n(\nint\n \noldfd\n,\n \nconst\n \nchar\n \n*\noldname\n,\n \nint\n \nnewfd\n,\n \nconst\n \nchar\n \n*\nnewname\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nSymbolic Links\n\n\nIt is possible to introduce loops into the file system by using symbolic links. Most functions that look up a pathname return an \nerrno\n of \nELOOP\n when this occurs.\n\n\nOn Linux, the \nftw\n and \nnftw\n functions record all directories seen and avoid processing a directory more than once, so they don\u2019t display this behavior.\n\n\n\n\nls -l\n\n\nls -F\n\n\n\n\napue_symlink.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsymlink\n(\nconst\n \nchar\n \n*\nactualpath\n,\n \nconst\n \nchar\n \n*\nsympath\n);\n\n\nint\n \nsymlinkat\n(\nconst\n \nchar\n \n*\nactualpath\n,\n \nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nsympath\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nBecause the open function follows a symbolic link, we need a way to open the link itself and read the name in the link.\n\n\napue_readlink.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \nreadlink\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nchar\n \n*\nrestrict\n \nbuf\n,\n\n                 \nsize_t\n \nbufsize\n);\n\n\n\nssize_t\n \nreadlinkat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n\n                   \nchar\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nbufsize\n);\n\n\n\n/* Both return: number of bytes read if OK, \u22121 on error */\n\n\n\n\n\n\nThese functions combine the actions of \nopen\n, \nread\n, and \nclose\n.\n\n\nFile Times\n\n\n\n\n\n\n\n\nField\n\n\nDescription\n\n\nExample\n\n\nls(1) option\n\n\n\n\n\n\n\n\n\n\nst_atim\n\n\nlast-access time of file data\n\n\nread\n\n\n-u\n\n\n\n\n\n\nst_mtim\n\n\nlast-modification time of file data\n\n\nwrite\n\n\ndefault\n\n\n\n\n\n\nst_ctim\n\n\nlast-change time of i-node status\n\n\nchmod\n, \nchown\n\n\n-c\n\n\n\n\n\n\n\n\nThe system does not maintain the last-access time for an i-node. The functions \naccess\n and \nstat\n don\u2019t change any of the three times.\n\n\nfutimens\n, \nutimensat\n, and \nutimes\n Functions\n\n\napue_futimens.h\n\n\n#include \nsys/stat.h\n\n\n\nint\n \nfutimens\n(\nint\n \nfd\n,\n \nconst\n \nstruct\n \ntimespec\n \ntimes\n[\n2\n]);\n\n\nint\n \nutimensat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npath\n,\n \nconst\n \nstruct\n \ntimespec\n \ntimes\n[\n2\n],\n \nint\n \nflag\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nIn both functions, the first element of the times array argument contains the \naccess time\n, and the second element contains the \nmodification time\n.\n\n\n\n\napue_utimes\n\n\n\n\n#include \nsys/time.h\n\n\n\nint\n \nutimes\n(\nconst\n \nchar\n \n*\npathname\n,\n \nconst\n \nstruct\n \ntimeval\n \ntimes\n[\n2\n]);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nWe are unable to specify a value for the \nchanged-status time\n, \nst_ctim\n (the time the i-node was last changed), as this field is automatically updated when the \nutime\n function is called.\n\n\nmkdir\n, \nmkdirat\n, and \nrmdir\n Functions\n\n\napue_rmdir.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nrmdir\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nFor a directory, we normally want at least one of the execute bits enabled, to allow access to filenames within the directory.\n\n\nSolaris 10 and Linux 3.2.0 also have the new directory inherit the set-group-ID bit from the parent directory. Files created in the new directory will then inherit the group ID of that directory. With Linux, the file system implementation determines whether this behavior is supported. For example, the ext2, ext3, and ext4 file systems allow this behavior to be controlled by an option to the mount(1) command.\n\n\nReading Directories\n\n\napue_opendir.h\n\n\n#include \ndirent.h\n\n\n\nDIR\n \n*\nopendir\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\nDIR\n \n*\nfdopendir\n(\nint\n \nfd\n);\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\nstruct\n \ndirent\n \n*\nreaddir\n(\nDIR\n \n*\ndp\n);\n\n\n/* Returns: pointer if OK, NULL at end of directory or error */\n\n\n\nvoid\n \nrewinddir\n(\nDIR\n \n*\ndp\n);\n\n\nint\n \nclosedir\n(\nDIR\n \n*\ndp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nlong\n \ntelldir\n(\nDIR\n \n*\ndp\n);\n\n\n/* Returns: current location in directory associated with dp */\n\n\n\nvoid\n \nseekdir\n(\nDIR\n \n*\ndp\n,\n \nlong\n \nloc\n);\n\n\n\n\n\n\nThe \ndirent\n structure defined in \n is implementation dependent, with at least the following two members:\n\n\n    \nino_t\n  \nd_ino\n;\n                 \n/* i-node number */\n\n    \nchar\n   \nd_name\n[];\n              \n/* null-terminated filename */\n\n\n\n\n\n\nThe \nDIR\n structure is an internal structure used by these seven functions to maintain information about the directory being read. The purpose of the DIR structure is similar to that of the \nFILE\n structure maintained by the standard I/O library,\n\n\n\n\nftw8.c\n\n\n\n\nchdir\n, \nfchdir\n, and \ngetcwd\n Functions\n\n\napue_chdir.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nchdir\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\nint\n \nfchdir\n(\nint\n \nfd\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\napue_getcwd.h\n\n\n#include \nunistd.h\n\n\n\nchar\n \n*\ngetcwd\n(\nchar\n \n*\nbuf\n,\n \nsize_t\n \nsize\n);\n\n\n\n/* Returns: buf if OK, NULL on error */\n\n\n\n\n\n\nDevice Special Files\n\n\n\n\nEvery file system is known by its \nmajor\n and \nminor\n device numbers, which are encoded in the primitive system data type \ndev_t\n.\n\n\nWe can usually access the major and minor device numbers through two macros defined by most implementations: \nmajor\n and \nminor\n.\n\n\n\n\nOn Linux 3.2.0, \ndev_t\n is a 64-bit integer, only 12 bits are used for the major number and 20 bits are used for the minor number. Linux defines these macros in \nsys/sysmacros.h\n, which is included by \nsys/types.h\n.\n\n\nThe \nst_dev\n value for every filename on a system is the device number of the file system containing that filename and its corresponding i-node.\n\n\nOnly character special files and block special files have an \nst_rdev\n value. This value contains the device number for the actual device.\n\n\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\nSection 4.21 on \nrmdir\n [p130]:\n\n\n\n\nIf the link count of the directory becomes 0 with this call, and if no other process has the directory open, then the space occupied by the directory is freed. If one or more processes have the directory open when the link count reaches 0, the last link is removed and the dot and dot-dot entries are removed before this function returns. Additionally, no new files can be created in the directory.\n\n\n\n\nDoes \"link count\" here mean number of entries (except dot and dot-dot)? Otherwise, this contradicts  \"any leaf directory (a directory that does not contain any other directories) always has a link count of 2\" in section 4.14 on page 115.", 
            "title": "Chapter 4. Files and Directories"
        }, 
        {
            "location": "/apue/ch5/", 
            "text": "Chapter 5. Standard I/O Library\n\n\nThe standard I/O library handles such details as buffer allocation and performing I/O in optimal-sized chunks.\n\n\nStreams and \nFILE\n Objects\n\n\nStandard I/O file streams can be used with both \nsingle-byte\n and \nmultibyte\n (\"wide\") character sets. A stream\u2019s orientation determines whether the characters that are read and written are single byte or multibyte.\n\n\n\n\nThis book deals only with \nbyte-oriented\n (single byte) streams.\n\n\nThis book refers to a pointer to a \nFILE\n object, the type \nFILE *\n, as a \nfile pointer\n.\n\n\n\n\nStandard Input, Standard Output, and Standard Error\n\n\nThree streams are predefined and automatically available to a process. They refer to file descriptors \nSTDIN_FILENO\n, \nSTDOUT_FILENO\n, and \nSTDERR_FILENO\n (defined in \nunistd.h\n) [p9]. These three standard I/O streams are referenced through the predefined file pointers \nstdin\n, \nstdout\n,and \nstderr\n(defined in \nstdio.h\n).\n\n\nBuffering\n\n\n\n\nFully buffered\n\n\nLine buffered\n\n\nUnbuffered\n\n\n\n\nMost implementations default to the following types of buffering:\n\n\n\n\nStandard error is always unbuffered.\n\n\nAll other streams are line buffered if they refer to a terminal device; otherwise, they are fully buffered.\n\n\n\n\napue_setbuf.h\n\n\n#include \nstdio.h\n\n\n\nvoid\n \nsetbuf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nchar\n \n*\nrestrict\n \nbuf\n \n);\n\n\nint\n \nsetvbuf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nchar\n \n*\nrestrict\n \nbuf\n,\n \nint\n \nmode\n,\n \nsize_t\n \nsize\n);\n\n\n\n/* Returns: 0 if OK, nonzero on error */\n\n\n\n\n\n\n\n\nsetbuf\n: \nbuf\n must point to a buffer of length \nBUFSIZ\n, a constant defined in \nstdio.h\n\n\nsetvbuf\n: type of buffering is specified with \n_IOFBF\n, \n_IOLBF\n, \n_IONBF\n.\n\n\n\n\nThe GNU C librarys use the value from the \nst_blksize\n member of the \nstat\n structure to determine the optimal standard I/O buffer size.\n\n\nThe \nfflush\n function causes any unwritten data for the stream to be passed to the kernel. If \nfp\n is \nNULL\n, \nfflush\n causes all output streams to be flushed.\n\n\nOpening a Stream\n\n\napue_fopen.h\n\n\n#include \nstdio.h\n\n\n\nFILE\n \n*\nfopen\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nconst\n \nchar\n \n*\nrestrict\n \ntype\n);\n\n\nFILE\n \n*\nfreopen\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n\n              \nconst\n \nchar\n \n*\nrestrict\n \ntype\n,\n\n              \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nFILE\n \n*\nfdopen\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\ntype\n);\n\n\n\n/* All three return: file pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\nfdopen\n function is often used with descriptors returned by the functions that create pipes and network communication channels, because these special types of files cannot be opened with the \nfopen\n function.\n\n\n\n\ntype\n argument has 15 values as specifed by ISO C:\n\n\n\n\n\n\n\n\ntype\n\n\nDescription\n\n\nopen\n(2) Flags\n\n\n\n\n\n\n\n\n\n\nr\n, \nrb\n\n\nopen for reading\n\n\nO_RDONLY\n\n\n\n\n\n\nw\n, \nwb\n\n\ntruncate to 0 length or create for writing\n\n\nO_WRONLY\nO_CREAT\nO_TRUNC\n\n\n\n\n\n\na\n, \nab\n\n\nappend; open for writing at end of file, or create for writing\n\n\nO_WRONLY\nO_CREAT\nO_APPEND\n\n\n\n\n\n\nr+\n, \nr+b\n, \nrb+\n\n\nopen for reading and writing\n\n\nO_RDWR\n\n\n\n\n\n\nw+\n, \nw+b\n, \nwb+\n\n\ntruncate to 0 length or create for reading and writing\n\n\nO_RDWR\nO_CREAT\nO_TRUNC\n\n\n\n\n\n\na+\n, \na+b\n, \nab+\n\n\nopen or create for reading and writing at end of file\n\n\nO_RDWR\nO_CREAT\nO_APPEND\n\n\n\n\n\n\n\n\nCharacter \nb\n allows the standard I/O system to differentiate between a text file and a binary file. The UNIX kernel doesn\u2019t differentiate between these types of files, thus character \nb\n has no effect.\n\n\n\n\nWrite\n: The \nfdopen\n function cannot truncate any file it opens for writing\n\n\nAppend\n: each write will take place at the then current end of file. If multiple processes open the same file with the standard I/O append mode, the data from each process will be correctly written to the file\n\n\nRead and write\n (\n+\n sign in type): Output cannot be directly followed by input without an intervening \nfflush\n, \nfseek\n, \nfsetpos\n, or \nrewind\n. Input cannot be directly followed by output without an intervening \nfseek\n, \nfsetpos\n, or \nrewind\n, or an input operation that encounters an end of file.\n\n\n\n\napue_fclose.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfclose\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: 0 if OK, EOF on error */\n\n\n\n\n\n\nAn open stream is closed by calling \nfclose\n:\n\n\n\n\nAny buffered output data is flushed before the file is closed\n\n\nAny input data that may be buffered is discarded\n\n\n\n\nWhen a process terminates normally, either by calling the exit function directly or by returning from the main function, all standard I/O streams with unwritten buffered data are flushed and all open standard I/O streams are closed.\n\n\nReading and Writing a Stream\n\n\nUnformatted I/O:\n\n\n\n\nCharacter-at-a-time I/O\n\n\nLine-at-a-time I/O: \nfgets\n and \nfputs\n. Each line is terminated with a newline character.\n\n\nDirect I/O (binary I/O, object-at-a-time I/O, record-oriented I/O, or structure-oriented I/O): \nfread\n and \nfwrite\n. For each I/O operation, we read or write some number of objects, where each object is of a specified size\n\n\n\n\nInput Functions\n\n\napue_getc.h\n\n\n#include \nstdio.h\n\n\n\nint\n \ngetc\n(\nFILE\n \n*\nfp\n);\n\n\nint\n \nfgetc\n(\nFILE\n \n*\nfp\n);\n\n\nint\n \ngetchar\n(\nvoid\n);\n\n\n\n/* All three return: next character if OK, EOF on end of file or error */\n\n\n\n\n\n\n\n\nThe function \ngetchar\n is defined to be equivalent to \ngetc(stdin)\n.\n\n\ngetc\n can be implemented as a macro, whereas \nfgetc\n cannot be implemented as a macro.\n\n\nThese three functions return the next character as an \nunsigned char\n converted to an \nint\n. Thus, all possible character values can be returned, along with an indication that either an error occurred or the end of file has been encountered. The constant EOF in \nstdio.h\n is required to be a negative value. Its value is often \u22121.\n\n\n\n\nThese functions return the same value whether an error occurs or the end of file is reached. To distinguish between the two, we must call either \nferror\n or \nfeof\n:\n\n\napue_ferror.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nferror\n(\nFILE\n \n*\nfp\n);\n\n\nint\n \nfeof\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Both return: nonzero (true) if condition is true, 0 (false) otherwise */\n\n\n\nvoid\n \nclearerr\n(\nFILE\n \n*\nfp\n);\n\n\n\n\n\n\nIn most implementations, two flags are maintained for each stream in the \nFILE\n object:\n\n\n\n\nAn error flag\n\n\nAn end-of-file flag\n\n\n\n\nBoth flags are cleared by calling \nclearerr\n.\n\n\nPushback\n\n\nAfter reading from a stream, we can push back characters by calling \nungetc\n.\n\n\napue_ungetc.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nungetc\n(\nint\n \nc\n,\n \nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: c if OK, EOF on error */\n\n\n\n\n\n\n\n\nThe characters that are pushed back are returned by subsequent reads on the stream in reverse order of their pushing.\n\n\nThe character that is pushed back does not have to be the same character that was read.\n\n\nWhen characters are pushed back with \nungetc\n, they are not written back to the underlying file or device. Instead, they are kept incore in the standard I/O library\u2019s buffer for the stream. EOF cannot be pushed back.\n\n\nUsed for peeking characters.\n\n\n\n\nOutput Functions\n\n\napue_putc.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nputc\n(\nint\n \nc\n,\n \nFILE\n \n*\nfp\n);\n\n\nint\n \nfputc\n(\nint\n \nc\n,\n \nFILE\n \n*\nfp\n);\n\n\nint\n \nputchar\n(\nint\n \nc\n);\n\n\n\n/* All three return: c if OK, EOF on error */\n\n\n\n\n\n\n\n\nputchar(c)\n is equivalent to \nputc(c, stdout)\n\n\nputc\n can be implemented as a macro, whereas \nfputc\n cannot be implemented as a macro.\n\n\n\n\nLine-at-a-Time I/O\n\n\napue_fgets.h\n\n\n#include \nstdio.h\n\n\n\nchar\n \n*\nfgets\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nint\n \nn\n,\n \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nchar\n \n*\ngets\n(\nchar\n \n*\nbuf\n);\n\n\n\n/* Both return: buf if OK, NULL on end of file or error */\n\n\n\n\n\n\n\n\ngets\n function reads from standard input, whereas \nfgets\n reads from the specified stream.\n\n\nfgets\n: reads \nn - 1\n characters (including the newline) or partial line if longer than \nn - 1\n into the buffer, then the buffer is (always) null terminated.\n\n\ngets\n: should never be used. Without specifying buffer size, this may cause buffer to overflow if the line is longer than the buffer, writing over whatever happens to follow the buffer in memory. \ngets\n is marked as an obsolescent interface in SUSv4 and has been omitted from the latest version of the ISO C standard\n\n\n\n\napue_fputs.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfputs\n(\nconst\n \nchar\n \n*\nrestrict\n \nstr\n,\n \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nint\n \nputs\n(\nconst\n \nchar\n \n*\nstr\n);\n\n\n\n/* Both return: non-negative value if OK, EOF on error */\n\n\n\n\n\n\n\n\nfputs\n: writes the null-terminated string to the specified stream without writing the null byte\n\n\nputs\n: writes the null-terminated string to the standard output without writing the null byte, and then writes a newline character to the standard output. \nputs\n should be avoided being used to prevent having to remember whether it appends a newline.\n\n\n\n\nStandard I/O Efficiency\n\n\n\n\n\n\n\n\nFunction\n\n\nUser CPU (seconds)\n\n\nSystem CPU (seconds)\n\n\nClock time (seconds)\n\n\nBytes of program text\n\n\n\n\n\n\n\n\n\n\nbest time from Figure 3.6\n\n\n0.05\n\n\n0.29\n\n\n3.18\n\n\n\n\n\n\n\n\nfgets\n, \nfputs\n\n\n2.27\n\n\n0.30\n\n\n3.49\n\n\n143\n\n\n\n\n\n\ngetc\n, \nputc\n\n\n8.45\n\n\n0.29\n\n\n10.33\n\n\n114\n\n\n\n\n\n\nfgetc\n, \nfputc\n\n\n8.16\n\n\n0.40\n\n\n10.18\n\n\n114\n\n\n\n\n\n\nsingle byte time from Figure 3.6\n\n\n134.61\n\n\n249.94\n\n\n394.95\n\n\n\n\n\n\n\n\n\n\n\n\nOne advantage of using the standard I/O routines is that we don\u2019t have to worry about buffering or choosing the optimal I/O size.\n\n\nUsually, \ngetc\n and \nputc\n are implemented as macros, but in the GNU C library implementation the macro simply expands to a function call.\n\n\nThe line-at-a-time functions are implemented using \nmemccpy(3)\n. Often, the memccpy function is implemented in assembly language instead of C, for efficiency.\n\n\n\n\nBinary I/O\n\n\nIf doing binary I/O, we often want to read or write an entire structure at a time. There are problems with the previous functions:\n\n\n\n\ngetc\n, \nputc\n: we have to loop through the entire structure one byte a time\n\n\nfputs\n: stops writing when it hits a null byte\n\n\nfgets\n: won't work correctly on input if any data bytes are null or newlines\n\n\n\n\napue_fread.h\n\n\n#include \nstdio.h\n\n\n\nsize_t\n \nfread\n(\nvoid\n \n*\nrestrict\n \nptr\n,\n \nsize_t\n \nsize\n,\n \nsize_t\n \nnobj\n,\n\n             \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nsize_t\n \nfwrite\n(\nconst\n \nvoid\n \n*\nrestrict\n \nptr\n,\n \nsize_t\n \nsize\n,\n \nsize_t\n \nnobj\n,\n\n              \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\n\n/* Both return: number of objects read or written */\n\n\n\n\n\n\nThese functions have two common uses:\n\n\nRead or write a binary array (e.g write elements 2 through 5 of a floating-point array):\n\n\nfloat\n   \ndata\n[\n10\n];\n\n\n\nif\n \n(\nfwrite\n(\ndata\n[\n2\n],\n \nsizeof\n(\nfloat\n),\n \n4\n,\n \nfp\n)\n \n!=\n \n4\n)\n\n    \nerr_sys\n(\nfwrite error\n);\n\n\n\n\n\n\nRead or write a structure:\n\n\nstruct\n \n{\n\n    \nshort\n  \ncount\n;\n\n    \nlong\n   \ntotal\n;\n\n    \nchar\n   \nname\n[\nNAMESIZE\n];\n\n\n}\n \nitem\n;\n\n\n\nif\n \n(\nfwrite\n(\nitem\n,\n \nsizeof\n(\nitem\n),\n \n1\n,\n \nfp\n)\n \n!=\n \n1\n)\n\n    \nerr_sys\n(\nfwrite error\n);\n\n\n\n\n\n\n\n\nfread\n: return value can be less than \nnobj\n if an error occurs or if the end of file is encountered\n\n\nfwrite\n: if the return value is less than the requested \nnobj\n, an error has occurred\n\n\n\n\nThese two functions won't work on different systems (sometimes even on the same system):\n\n\n\n\nThe offset of a member within a structure can differ between compilers and systems because of different \nalignment requirements\n. Even on a single system, the binary layout of a structure can differ, depending on compiler options. [p157]\n\n\nThe binary formats used to store multibyte integers and floating-point values differ among machine architectures\n\n\n\n\nPositioning a Stream\n\n\napue_ftell.h\n\n\n#include \nstdio.h\n\n\n\nlong\n \nftell\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: current file position indicator if OK, \u22121L on error */\n\n\n\nint\n \nfseek\n(\nFILE\n \n*\nfp\n,\n \nlong\n \noffset\n,\n \nint\n \nwhence\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nvoid\n \nrewind\n(\nFILE\n \n*\nfp\n);\n\n\n\n\n\n\n\n\nftell\n: return file's position indicator (bytes from the beginning of the file)\n\n\nfseek\n:\n\n\nBinary file: \nwhence\n can be \nSEEK_SET\n, \nSEEK_CUR\n, and \nSEEK_END\n\n\nText file: \nwhence\n has to be \nSEEK_SET\n; \noffset\n can only be 0 (rewind the file to its beginning) or a value that was returned by \nftell\n for that file.\n\n\n\n\n\n\nrewind\n: set the stream to the beginning of the file\n\n\n\n\napue_ftello.h\n\n\n#include \nstdio.h\n\n\n\noff_t\n \nftello\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: current file position indicator if OK, (off_t)\u22121 on error */\n\n\n\nint\n \nfseeko\n(\nFILE\n \n*\nfp\n,\n \noff_t\n \noffset\n,\n \nint\n \nwhence\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\napue_fgetpos.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfgetpos\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nfpos_t\n \n*\nrestrict\n \npos\n);\n\n\nint\n \nfsetpos\n(\nFILE\n \n*\nfp\n,\n \nconst\n \nfpos_t\n \n*\npos\n);\n\n\n\n/* Both return: 0 if OK, nonzero on error */\n\n\n\n\n\n\nFormatted I/O\n\n\nFormatted Output\n\n\napue_printf.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nprintf\n(\nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \nfprintf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \ndprintf\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n\n/* All three return: number of characters output if OK, negative value if output error */\n\n\n\nint\n \nsprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n/* Returns: number of characters stored in array if OK, negative value if encoding error */\n\n\n\nint\n \nsnprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nn\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n/* Returns: number of characters that would have been stored in array if buffer was\n\n\n   large enough, negative value if encoding error */\n\n\n\n\n\n\n\n\nsprintf\n: automatically appends a null byte at the end of the array, but this null byte is not included in the return value. \nsprintf\n is possible to overflow the buffer.\n\n\nsnprintf\n: returns the number of characters that would have been written to the buffer had it been big enough. If \nsnprintf\n returns a positive value less than the buffer size n, then the output was not truncated.\n\n\n\n\nConversion specification\n\n\n%[flags][fldwidth][precision][lenmodifier]convtype\n\n\n\n\n\n\n\n\n\n\nFlag\n\n\n\n\n\n\n\n\nFlag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n\u2019\n\n\n(apostrophe) format integer with thousands grouping characters\n\n\n\n\n\n\n-\n\n\nleft-justify the output in the field\n\n\n\n\n\n\n+\n\n\nalways display sign of a signed conversion\n\n\n\n\n\n\n(space)\n\n\nprefix by a space if no sign is generated\n\n\n\n\n\n\n#\n\n\nconvert using alternative form (include 0x prefix for hexadecimal format, for example)\n\n\n\n\n\n\n0\n\n\nprefix with leading zeros instead of padding with spaces\n\n\n\n\n\n\n\n\n\n\n\n\nfldwidth\n specifies a minimum field width for the conversion\n\n\n\n\nprecision\n specifies the minimum number of digits to appear for integer conversions, the minimum number of digits to appear to the right of the decimal point for floating-point conversions, or the maximum number of bytes for string conversions\n\n\n\n\nlenmodifier\n pecifies the size of the argument\n\n\n\n\n\n\n\n\nLength modifier\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nhh\n\n\nsigned or unsigned \nchar\n\n\n\n\n\n\nh\n\n\nsigned or unsigned \nshort\n\n\n\n\n\n\nl\n\n\nsigned or unsigned \nlong\n or wide character\n\n\n\n\n\n\nll\n\n\nsigned or unsigned \nlong\n \nlong\n\n\n\n\n\n\nj\n\n\nintmax_t\n or \nuintmax_t\n\n\n\n\n\n\nz\n\n\nsize_t\n\n\n\n\n\n\nt\n\n\nptrdiff_t\n\n\n\n\n\n\nL\n\n\nlong double\n\n\n\n\n\n\n\n\n\n\n\n\nconvtype\n is required.\n\n\n\n\n\n\n\n\n\n\n\n\nConversion type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nd\n,\ni\n\n\nsigned decimal\n\n\n\n\n\n\no\n\n\nunsigned octal\n\n\n\n\n\n\nu\n\n\nunsigned decimal\n\n\n\n\n\n\nx\n,\nX\n\n\nunsigned hexadecimal\n\n\n\n\n\n\nf\n,\nF\n\n\ndouble floating-point number\n\n\n\n\n\n\ne\n,\nE\n\n\ndouble floating-point number in exponential format\n\n\n\n\n\n\ng\n,\nG\n\n\ninterpreted as \nf\n, \nF\n, \ne\n, or \nE\n, depending on value converted\n\n\n\n\n\n\na\n,\nA\n\n\ndouble floating-point number in hexadecimal exponential format\n\n\n\n\n\n\nc\n\n\ncharacter (with \nl\n length modifier, wide character)\n\n\n\n\n\n\ns\n\n\nstring (with \nl\n length modifier, wide character string)\n\n\n\n\n\n\np\n\n\npointer to a void\n\n\n\n\n\n\nn\n\n\npointer to a signed integer into which is written the number of characters written so far\n\n\n\n\n\n\n%\n\n\na \n%\n character\n\n\n\n\n\n\nC\n\n\nwide character (XSI option, equivalent to \nlc\n)\n\n\n\n\n\n\nS\n\n\nwide character string (XSI option, equivalent to \nls\n)\n\n\n\n\n\n\n\n\nWith the normal conversion specification, conversions are applied to the arguments in the order they appear after the format argument. An alternative conversion specification syntax allows the arguments to be named explicitly with the sequence \n%n$\n representing the \nn\nth argument.\n\n\nThe following five variants of the printf family are similar to the previous five, but the variable argument list (\n...\n) is replaced with \narg\n.\n\n\napue_vprintf.h\n\n\n#include \nstdarg.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nvprintf\n(\nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\nint\n \nvfprintf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n\n             \nva_list\n \narg\n);\n\n\nint\n \nvdprintf\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\n\n/* All three return: number of characters output if OK, negative value if output error */\n\n\n\nint\n \nvsprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\n\n/* Returns: number of characters stored in array if OK, negative value if encoding error */\n\n\n\nint\n \nvsnprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nn\n,\n\n              \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\n\n/* Returns: number of characters that would have been stored in array if buffer was\n\n\n   large enough, negative value if encoding error */\n\n\n\n\n\n\nFormatted Output\n\n\napue_scanf.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nscanf\n(\nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \nfscanf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \nsscanf\n(\nconst\n \nchar\n \n*\nrestrict\n \nbuf\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n\n/* All three return: number of input items assigned, EOF if input error\n\n\n   or end of file before any conversion */\n\n\n\n\n\n\nExcept for the conversion specifications and white space, other characters in the format have to match the input. If a character doesn\u2019t match, processing stops, leaving the remainder of the input unread.\n\n\nConversion specification\n\n\n%[*][fldwidth][m][lenmodifier]convtype\n\n\n\n\n\n\n\n\n*\n (leading asterisk) causes the result not stored in an argument\n\n\n\n\nm\n: \nassignment-allocation character\n, used with the \n%c\n, \n%s\n, and \n%[\n to force a memory  buffer to be allocated to hold the converted string. The caller is responsible for freeing the buffer.\n\n\n\n\n\n\nconvtype\n\n\n\n\n\n\n\n\n\n\n\n\nConversion type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nd\n\n\nsigned decimal, base 10\n\n\n\n\n\n\ni\n\n\nsigned decimal, base determined by format of input\n\n\n\n\n\n\no\n\n\nunsigned octal (input optionally signed)\n\n\n\n\n\n\nu\n\n\nunsigned decimal, base 10 (input optionally signed)\n\n\n\n\n\n\nx\n,\nX\n\n\nunsigned hexadecimal (input optionally signed)\n\n\n\n\n\n\na\n,\nA\n,\ne\n,\nE\n,\nf\n,\nF\n,\ng\n,\nG\n\n\nfloating-point number\n\n\n\n\n\n\nc\n\n\ncharacter (with \nl\n length modifier, wide character)\n\n\n\n\n\n\ns\n\n\nstring (with \nl\n length modifier, wide character string)\n\n\n\n\n\n\n[\n\n\nmatches a sequence of listed characters, ending with \n]\n\n\n\n\n\n\n[\u02c6\n\n\nmatches all characters except the ones listed, ending with \n]\n\n\n\n\n\n\np\n\n\npointer to a void\n\n\n\n\n\n\nn\n\n\npointer to a signed integer into which is written the number of characters read so far\n\n\n\n\n\n\n%\n\n\na \n%\n character\n\n\n\n\n\n\nC\n\n\nwide character (XSI option, equivalent to \nlc\n)\n\n\n\n\n\n\nS\n\n\nwide character string (XSI option, equivalent to \nls\n)\n\n\n\n\n\n\n\n\nImplementation Details\n\n\napue_fileno.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfileno\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: the file descriptor associated with the stream */\n\n\n\n\n\n\nEach standard I/O stream has an associated file descriptor, and we can obtain the descriptor for a stream by calling \nfileno\n.\n\n\n\n\nFILE\n implementaion in GNU C.\n\n\nbuf.c\n (Figure 5.11): print buffering for various standard I/O streams\n\n\n\n\nResult on OS X 10.10:\n\n\n$ ./buf\nenter any character\n\none line to standard error\nstream = stdin, line buffered, buffer size = 4096\nstream = stdout, line buffered, buffer size = 4096\nstream = stderr, unbuffered, buffer size = 1\nstream = /etc/passwd, fully buffered, buffer size = 4096\n\n$ ./buf \n /etc/group \n std.out 2\n std.err\n$ cat std.out\nenter any character\nstream = stdin, fully buffered, buffer size = 4096\nstream = stdout, fully buffered, buffer size = 4096\nstream = stderr, unbuffered, buffer size = 1\nstream = /etc/passwd, fully buffered, buffer size = 4096\n$ cat std.err\none line to standard error\n\n\n\n\n\nTemporary Files\n\n\napue_tmpnam.h\n\n\n#include \nstdio.h\n\n\n\nchar\n \n*\ntmpnam\n(\nchar\n \n*\nptr\n);\n\n\nFILE\n \n*\ntmpfile\n(\nvoid\n);\n\n\n\n/* Returns: pointer to unique pathname Returns: file pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\ntmpnam\n: generates a string that is a valid pathname that does not match any existing file. This function generates a different pathname each time it is called, up to \nTMP_MAX\n times.\n\n\nWhen \nptr\n is \nNULL\n: pathname is stored in a static area\n\n\nWhen \nptr\n is not \nNULL\n: it is assumed that it points to an array of at least \nL_tmpnam\n characters. The generated pathname is stored in this array, and \nptr\n is returned as the value of the function.\n\n\n\n\n\n\ntmpfile\n: creates a temporary binary file (type \nwb+\n) that is automatically removed when it is closed or on program termination.\n\n\n\n\napue_mkdtemp.h\n\n\n#include \nstdlib.h\n\n\n\nchar\n \n*\nmkdtemp\n(\nchar\n \n*\ntemplate\n);\n\n\n\n/* Returns: pointer to directory name if OK, NULL on error */\n\n\n\nint\n \nmkstemp\n(\nchar\n \n*\ntemplate\n);\n\n\n\n/* Returns: file descriptor if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nmkdtemp\n: creates a uniquely named directory\n\n\nmkstemp\n: creates a uniquely named regular file\n\n\ntemplate\n: a pathname whose last six characters are set to \nXXXXXX\n (\n/tmp/dirXXXXXX\n)\n\n\n\n\nUnlike \ntmpfile\n, the temporary file created by \nmkstemp\n is not removed automatically for us.\n\n\nThe \ntmpfile\n and \nmkstemp\n functions should be used instead of \ntmpnam\n. [p169]\n\n\nExample:\n\n\n\n\napue_stdio_mkstemp.c\n: the array variable is allocated on the stacl. For a pointer to a string literal, only the pointer itself resides on the stack; the (constant) string is stored in the read-only segment of the program.\n\n\n\n\nMemory Streams\n\n\nMemory streams\n are standard I/O streams for which there are no underlying files, although they are still accessed with \nFILE\n pointers. All I/O is done by transferring bytes to and from buffers in main memory.\n\n\napue_fmemopen.h\n\n\n#include \nstdio.h\n\n\n\nFILE\n \n*\nfmemopen\n(\nvoid\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nsize\n,\n\n               \nconst\n \nchar\n \n*\nrestrict\n \ntype\n);\n\n\n\n/* Returns: stream pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\nbuf\n: points to the beginning of the user-allocated buffer and the size argument specifies the size of the buffer in bytes. If the buf argument is null, then the fmemopen function allocates a buffer of \nsize\n bytes.\n\n\ntype\n: controls how the stream can be used [p171]\n\n\n\n\nNote:\n\n\n\n\nUnder append mode, the current file position is set to the first null byte in the buffer. If the buffer contains no null bytes, then the current position is set to one byte past the end of the buffer. Under non-append mode, the current position is set to the beginning of the buffer. Thus, memory streams aren\u2019t well suited for storing binary data (which might contain null bytes before the end of the data).\n\n\nIf the \nbuf\n argument is a null pointer, it makes no sense to open the stream for only reading or only writing. Because the buffer is allocated by \nfmemopen\n in this case, there is no way to find the buffer's address\n\n\nA null byte is written at the current position in the stream whenever we increase the amount of data in the stream\u2019s buffer and call \nfclose\n, \nfflush\n, \nfseek\n, \nfseeko\n, or \nfsetpos\n.\n\n\n\n\nAlternatives to Standard I/O\n\n\nWhen we use the line-at-a-time functions, \nfgets\n and \nfputs\n, the data is usually copied twice: once between the kernel and the standard I/O buffer (when the corresponding read or write is issued) and again between the standard I/O buffer and our line buffer.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\nSection 5.4 on line buffering [p145]\n\n\n\n\nSecond, whenever input is requested through the standard I/O library from either (a) an unbuffered stream or (b) a line-buffered stream (that requires data to be requested from the kernel), all line-buffered output streams are flushed. The reason for the qualifier on (b) is that the requested data may already be in the buffer, which doesn\u2019t require data to be read from the kernel. Obviously, any input from an unbuffered stream, item (a), requires data to be obtained from the kernel.\n\n\n\n\nSection 5.8 Standard I/O Efficiency [p155]\n\n\n\n\nThe version using line-at-a-time I/O is almost twice as fast as the version using character-at-a-time I/O. If the fgets and fputs functions are implemented using getc and putc, then we would expect the timing to be similar to the getc version. Actually, we might expect the line-at-a-time version to take longer, since we would be adding the overhead of 200 million extra function calls to the existing 6 million ones.\n\n\n\n\nSection 5.14 on Memory Stream [p172]\n\n\n\n\nThird, a null byte is written at the current position in the stream whenever we increase the amount of data in the stream\u2019s buffer and call fclose, fflush, fseek, fseeko, or fsetpos.", 
            "title": "Chapter 5. Standard I/O Library"
        }, 
        {
            "location": "/apue/ch6/", 
            "text": "Chapter 6. System Data Files and Information\n\n\nThis chapter covers portable interfaces to data files, system identification functions and the time and date functions.\n\n\nPassword File\n\n\nThe UNIX System's password file, called the user database by POSIX.1, contains the following fields:\n\n\n\n\nHistorically, the password file has been stored in \n/etc/passwd\n and has been an ASCII file.\n\n\n\n\nroot\n has a user ID of 0 (superuser)\n\n\nThe encrypted password field contains a single character as a placeholder (\nx\n)\n\n\nSome fields can be empty\n\n\nThe shell field contains the user's login shell. The default value for an empty shell field is usually \n/bin/sh\n. Other executable that prevents a user from loggin in to a system:\n\n\n/dev/null\n\n\n/bin/false\n: exits with an unsuccessful (nonzero) status\n\n\n/bin/true\n: exits with a successful (zero) status\n\n\nnologin\n: prints a customizable error message and exits with a nonzero exit status\n\n\n\n\n\n\nnobody\n user name can be used to allow people to log in to a system, but with a user ID (65534) and group ID (65534) that provide no privileges.\n\n\nSome systems that provide the \nfinger(1)\n command support additional information in the comment field\n\n\n\n\nSome systems provide the \nvipw\n command to allow administrators to edit the password file.\n\n\napue_getpwuid.h\n\n\n#include \npwd.h\n\n\n\nstruct\n \npasswd\n \n*\ngetpwuid\n(\nuid_t\n \nuid\n);\n\n\nstruct\n \npasswd\n \n*\ngetpwnam\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\ngetpwuid\n: used by the \nls(1)\n program to map the numerical user ID contained in an i-node into a user's login name.\n\n\ngetpwnam\n: used by the \nlogin(1)\n program when we enter our login name\n\n\n\n\nBoth functions return a pointer to a passwd structure that the functions fill in. \nThis structure is usually a static variable within the function, so its contents are overwritten each time we call either of these functions.\n\n\napue_getpwent.h\n\n\n#include \npwd.h\n\n\n\nstruct\n \npasswd\n \n*\ngetpwent\n(\nvoid\n);\n\n\n\n/* Returns: pointer if OK, NULL on error or end of file */\n\n\n\nvoid\n \nsetpwent\n(\nvoid\n);\n\n\nvoid\n \nendpwent\n(\nvoid\n);\n\n\n\n\n\n\n\n\ngetpwent\n: returns the next entry (a pointer to a structure that it has filled in, this structure is overwritten each time we call this function) in the password file.\n\n\nsetpwent\n: rewinds files\n\n\nendpwent\n: closes files\n\n\n\n\nExample:\n\n\n\n\ngetpwnam.c\n\n\n\n\nsetpwent\n at the beginning of this function is self-defense: we ensure that the files are rewound, in case the caller has already opened them by calling getpwent.\n\n\nShadow Passwords\n\n\nSystems store the encrypted password in another file, often called the \nshadow password file\n. Minimally, this file has to contain the user name and the encrypted password.\n\n\n\n\nThe shadow password file should not be readable by the world. Only a few programs need to access encrypted passwords, e.g. \nlogin(1)\n and \npasswd(1)\n, and these programs are often set-user-ID root. With shadow passwords, the regular password file, \n/etc/passwd\n, can be left readable by the world.\n\n\napue_getspnam.h\n\n\n#include \nshadow.h\n\n\n\nstruct\n \nspwd\n \n*\ngetspnam\n(\nconst\n \nchar\n \n*\nname\n);\n\n\nstruct\n \nspwd\n \n*\ngetspent\n(\nvoid\n);\n\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\nvoid\n \nsetspent\n(\nvoid\n);\n\n\nvoid\n \nendspent\n(\nvoid\n);\n\n\n\n\n\n\nGroup File\n\n\nThe UNIX System\u2019s group file, called the group database by POSIX.1, contains the following fields:\n\n\n\n\nThe field \ngr_mem\n is an array of pointers to the user names that belong to this group. This array is terminated by a null pointer.\n\n\napue_getgrgid.h\n\n\n#include \ngrp.h\n\n\n\nstruct\n \ngroup\n \n*\ngetgrgid\n(\ngid_t\n \ngid\n);\n\n\nstruct\n \ngroup\n \n*\ngetgrnam\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\n\n\n\nLike the password file functions, both of these functions normally return pointers to a static variable, which is overwritten on each call.\n\n\napue_getgrent.h\n\n\n#include \ngrp.h\n\n\n\nstruct\n \ngroup\n \n*\ngetgrent\n(\nvoid\n);\n\n\n\n/* Returns: pointer if OK, NULL on error or end of file */\n\n\n\nvoid\n \nsetgrent\n(\nvoid\n);\n\n\nvoid\n \nendgrent\n(\nvoid\n);\n\n\n\n\n\n\n\n\ngetgrent\n: reads the next entry from the group file, opening the file first, if it\u2019s not already open\n\n\n\n\nSupplementary Group IDs\n\n\nnewgrp(1)\n can be used to change the real group ID to the new group\u2019s ID. We could always go back to our original group (as listed in \n/etc/passwd\n) by executing \nnewgrp\n without any arguments.\n\n\nWith 4.2BSD, the concept of \nsupplementary group IDs\n was introduced. The file access permission checks were modified so that in addition to comparing the the file\u2019s group ID to the process effective group ID, it was also compared to all the supplementary group IDs.\n\n\nThe constant \nNGROUPS_MAX\n specifies the number of supplementary group IDs.\n\n\napue_getgroups.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ngetgroups\n(\nint\n \ngidsetsize\n,\n \ngid_t\n \ngrouplist\n[]);\n\n\n\n/* Returns: number of supplementary group IDs if OK, \u22121 on error */\n\n\n\n#include \ngrp.h\n \n/* on Linux */\n\n\n#include \nunistd.h\n \n/* on FreeBSD, Mac OS X, and Solaris */\n\n\n\nint\n \nsetgroups\n(\nint\n \nngroups\n,\n \nconst\n \ngid_t\n \ngrouplist\n[]);\n\n\n\n#include \ngrp.h\n \n/* on Linux and Solaris */\n\n\n#include \nunistd.h\n \n/* on FreeBSD and Mac OS X */\n\n\n\nint\n \ninitgroups\n(\nconst\n \nchar\n \n*\nusername\n,\n \ngid_t\n \nbasegid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\ngetgroups\n\n\ngidsetsize\n \n 0: the function fills in the array up to \ngidsetsize\n supplementary group IDs\n\n\ngidsetsize\n = 0: the function returns only the number of supplementary group IDs; \ngrouplist\n is not modified\n\n\n\n\n\n\nsetgroups\n: called by the superuser to set the supplementary group ID list for the calling process\n\n\ninitgroups\n: reads the entire group file with the functions \ngetgrent\n, \nsetgrent\n, and \nendgrent\n and determines the group membership for username.  It then calls setgroups to initialize the supplementary group ID list for the user. It includes \nbasegid\n in the supplementary group ID list; basegid is the group ID from the password file for username. See \nSetting the Group IDs\n\n\n\n\nImplementation Differences\n\n\n[p184-185]\n\n\nOther Data Files\n\n\nNumerous other files are used by UNIX systems in normal day-to-day operation.\n\n\nServices and networks:\n\n\n\n\n/etc/services\n\n\n/etc/protocols\n\n\n/etc/networks\n\n\n\n\nThe general principle is that every data file has at least three functions:\n\n\n\n\nget\n: reads the next record, opening the file\n\n\nset\n: opens the file, if not already open, and rewinds the file\n\n\nend\n: closes the data file\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nData file\n\n\nHeader\n\n\nStructure\n\n\nAdditional keyed lookup functions\n\n\n\n\n\n\n\n\n\n\npasswords\n\n\n/etc/passwd\n\n\npwd.h\n\n\npasswd\n\n\ngetpwnam\n, \ngetpwuid\n\n\n\n\n\n\ngroups\n\n\n/etc/group\n\n\ngrp.h\n\n\ngroup\n\n\ngetgrnam\n, \ngetgrgid\n\n\n\n\n\n\nshadow\n\n\n/etc/shadow\n\n\nshadow.h\n\n\nspwd\n\n\ngetspnam\n\n\n\n\n\n\nhosts\n\n\n/etc/hosts\n\n\nnetdb.h\n\n\nhostent\n\n\ngetnameinfo\n, \ngetaddrinfo\n\n\n\n\n\n\nnetworks\n\n\n/etc/networks\n\n\nnetdb.h\n\n\nnetent\n\n\ngetnetbyname\n, \ngetnetbyaddr\n\n\n\n\n\n\nprotocols\n\n\n/etc/protocols\n\n\nnetdb.h\n\n\nprotoent\n\n\ngetprotobyname\n, \ngetprotobynumber\n\n\n\n\n\n\nservices\n\n\n/etc/services\n\n\nnetdb.h\n\n\nservent\n\n\ngetservbyname\n, \ngetservbyport\n\n\n\n\n\n\n\n\nLogin Accounting\n\n\nTwo data files provided with most UNIX systems:\n\n\n\n\nutmp\n: keeps track of all the users currently logged in\n\n\nwtmp\n: keeps track of all logins and logouts\n\n\n\n\nstruct\n \nutmp\n \n{\n\n    \nchar\n \nut_line\n[\n8\n];\n \n/* tty line: \nttyh0\n, \nttyd0\n, \nttyp0\n, ... */\n\n    \nchar\n \nut_name\n[\n8\n];\n \n/* login name */\n\n    \nlong\n \nut_time\n;\n \n/* seconds since Epoch */\n\n\n};\n\n\n\n\n\n\nOn login, the \nlogin\n program fills one of these structures, and writes it to the \nutmp\n and \nwtmp\n file. On logout, the \ninit\n process erases this entry (fills with null bytes) in \nutmp\n file and appends a new logout entry. This logout entry in the \nwtmp\n file had the \nut_name\n field zeroed out. Special entries were appended to the \nwtmp\n file to indicate when the system was rebooted and right before and after the system\u2019s time and date was changed.\n\n\nThe \nwho(1)\n program read the \nutmp\n file and printed its contents in a readable form\n\n\nSystem Identification\n\n\napue_uname.h\n\n\n#include \nsys/utsname.h\n\n\n\nint\n \nuname\n(\nstruct\n \nutsname\n \n*\nname\n);\n\n\n\n/* Returns: non-negative value if OK, \u22121 on error */\n\n\n\n\n\n\nstruct\n \nutsname\n \n{\n\n    \nchar\n \nsysname\n[];\n \n/* name of the operating system */\n\n    \nchar\n \nnodename\n[];\n \n/* name of this node */\n\n    \nchar\n \nrelease\n[];\n \n/* current release of operating system */\n\n    \nchar\n \nversion\n[];\n \n/* current version of this release */\n\n    \nchar\n \nmachine\n[];\n \n/* name of hardware type */\n\n\n};\n\n\n\n\n\n\napue_gethostname.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ngethostname\n(\nchar\n \n*\nname\n,\n \nint\n \nnamelen\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\ngethostname\n (now defined as part of POSIX.1) specifies that the maximum host name length is \nHOST_NAME_MAX\n.\n\n\n\n\n\n\n\n\nInterface\n\n\nFreeBSD 8.0\n\n\nLinux 3.2.0\n\n\nMac OS X 10.6.8\n\n\nSolaris 10\n\n\n\n\n\n\n\n\n\n\nuname\n\n\n256\n\n\n65\n\n\n256\n\n\n257\n\n\n\n\n\n\ngethostname\n\n\n256\n\n\n64\n\n\n256\n\n\n256\n\n\n\n\n\n\n\n\nIf the host is connected to a TCP/IP network, the \nhost name is normally the fully qualified domain name of the host.\n\n\nThere is also a \nhostname(1)\n command that can fetch or set the host name. (The host name is set by the superuser using a similar function, \nsethostname\n.) The host name is normally set at bootstrap time from one of the start-up files invoked by \n/etc/rc\n or \ninit\n.\n\n\nTime and Date Routines\n\n\nCalendar times\n: number of seconds (represented in a \ntime_t\n data type) that have passed since the \nEpoch\n: 00:00:00 January 1, 1970, Coordinated Universal Time (UTC). These calendar times represent both the time and the date. The UNIX System has always differed from other operating systems in:\n\n\n\n\nkeeping time in UTC instead of the local time\n\n\nautomatically handling conversions, such as daylight saving time\n\n\nkeeping the time and date as a single quantity\n\n\n\n\nThe \ntime\n function returns the current time and date.\n\n\napue_time.h\n\n\n#include \ntime.h\n\n\n\ntime_t\n \ntime\n(\ntime_t\n \n*\ncalptr\n);\n\n\n\n/* Returns: value of time if OK, \u22121 on error */\n\n\n\n\n\n\nThe time value is always returned as the value of the function. If the argument is non-null, the time value is also stored at the location pointed to by \ncalptr\n.\n\n\nClock type identifiers\n\n\nThe real-time extensions to POSIX.1 added support for multiple system clocks. A clock is identified by the \nclockid_t\n type.\n\n\n\n\n\n\n\n\nIdentifier\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCLOCK_REALTIME\n\n\n\n\nreal system time\n\n\n\n\n\n\nCLOCK_MONOTONIC\n\n\n_POSIX_MONOTONIC_CLOCK\n\n\nreal system time with no negative jumps\n\n\n\n\n\n\nCLOCK_PROCESS_CPUTIME_ID\n\n\n_POSIX_CPUTIME\n\n\nCPU time for calling process\n\n\n\n\n\n\nCLOCK_THREAD_CPUTIME_ID\n\n\n_POSIX_THREAD_CPUTIME\n\n\nCPU time for calling thread\n\n\n\n\n\n\n\n\napue_clock_gettime.h\n\n\n#include \nsys/time.h\n\n\n\nint\n \nclock_gettime\n(\nclockid_t\n \nclock_id\n,\n \nstruct\n \ntimespec\n \n*\ntsp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nint\n \nclock_getres\n(\nclockid_t\n \nclock_id\n,\n \nstruct\n \ntimespec\n \n*\ntsp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nint\n \nclock_settime\n(\nclockid_t\n \nclock_id\n,\n \nconst\n \nstruct\n \ntimespec\n \n*\ntsp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nint\n \ngettimeofday\n(\nstruct\n \ntimeval\n \n*\nrestrict\n \ntp\n,\n \nvoid\n \n*\nrestrict\n \ntzp\n);\n\n\n/* Returns: 0 always */\n\n\n\n\n\n\n\n\nclock_gettime\n: gets the time of the specified clock. The time is returned in a \ntimespec\n structure\n\n\nclock_getres\n: determines the resolution of a given system clock. It initializes the \ntimespec\n structure pointed to by the \ntsp\n\n\nclock_settime\n: sets the time for a particular clock.\n\n\ngettimeofday\n: now obsolescent. The only legal value for \ntzp\n is \nNULL\n.\n\n\n\n\nOnce we have the integer value that counts the number of seconds since the Epoch, we normally call a function to convert it to a broken-down time structure, and then call another function to generate a human-readable time and date.\n\n\n\n\nThe two functions \nlocaltime\n and \ngmtime\n convert a calendar time into a broken-down time, a \ntm\n structure.\n\n\nstruct\n \ntm\n \n{\n \n/* a broken-down time */\n\n    \nint\n \ntm_sec\n;\n \n/* seconds after the minute: [0 - 60] */\n\n    \nint\n \ntm_min\n;\n \n/* minutes after the hour: [0 - 59] */\n\n    \nint\n \ntm_hour\n;\n \n/* hours after midnight: [0 - 23] */\n\n    \nint\n \ntm_mday\n;\n \n/* day of the month: [1 - 31] */\n\n    \nint\n \ntm_mon\n;\n \n/* months since January: [0 - 11] */\n\n    \nint\n \ntm_year\n;\n \n/* years since 1900 */\n\n    \nint\n \ntm_wday\n;\n \n/* days since Sunday: [0 - 6] */\n\n    \nint\n \ntm_yday\n;\n \n/* days since January 1: [0 - 365] */\n\n    \nint\n \ntm_isdst\n;\n \n/* daylight saving time flag: \n0, 0, \n0 */\n\n\n};\n\n\n\n\n\n\nThe reason that the seconds can be greater than 59 is to allow for a \nleap second\n.\n\n\napue_gmtime.h\n\n\n#include \ntime.h\n\n\n\nstruct\n \ntm\n \n*\ngmtime\n(\nconst\n \ntime_t\n \n*\ncalptr\n);\n\n\nstruct\n \ntm\n \n*\nlocaltime\n(\nconst\n \ntime_t\n \n*\ncalptr\n);\n\n\n\n/* Both return: pointer to broken-down time, NULL on error */\n\n\n\n\n\n\n\n\ngmtime\n: converts the calendar time to UTC time (broken time)\n\n\nlocaltime\n: converts the calendar time to local time (broken time)\n\n\nmktime\n: takes a broken-down time, expressed as a local time, and converts it into a \ntime_t\n value\n\n\nThe \nstrftime\n and \nstrftime_l\n functions are the same, except that the \nstrftime_l\n function allows the caller to specify the locale as an argument. The strftime function uses the locale specified by the \nTZ\n environment variable\n\n\ntmptr\n argument is the time value to format, specified by a pointer to a broken-down time value. [p192]\n\n\nformat\n argument controls the formatting of the time value\n\n\n\n\n\n\n\n\nConversion specifiers for \nstrftime\n\n\n\n\n\n\n\n\nFormat\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n%a\n\n\nabbreviated weekday name\n\n\nThu\n\n\n\n\n\n\n%A\n\n\nfull weekday name\n\n\nThursday\n\n\n\n\n\n\n%b\n\n\nabbreviated month name\n\n\nJan\n\n\n\n\n\n\n%B\n\n\nfull month name\n\n\nJanuary\n\n\n\n\n\n\n%c\n\n\ndate and time\n\n\nThu Jan 19 21:24:52 2012\n\n\n\n\n\n\n%C\n\n\nyear/100: [00\u201399]\n\n\n20\n\n\n\n\n\n\n%d\n\n\nday of the month: [01\u201331]\n\n\n19\n\n\n\n\n\n\n%D\n\n\ndate [MM/DD/YY]\n\n\n01/19/12\n\n\n\n\n\n\n%e\n\n\nday of month (single digit preceded by space) [1\u201331]\n\n\n19\n\n\n\n\n\n\n%F\n\n\nISO 8601 date format [YYYY\u2013MM\u2013DD]\n\n\n2012-01-19\n\n\n\n\n\n\n%g\n\n\nlast two digits of ISO 8601 week-based year [00\u201399]\n\n\n12\n\n\n\n\n\n\n%G\n\n\nISO 8601 week-based year\n\n\n2012\n\n\n\n\n\n\n%h\n\n\nsame as \n%b\n\n\nJan\n\n\n\n\n\n\n%H\n\n\nhour of the day (24-hour format): [00\u201323]\n\n\n21\n\n\n\n\n\n\n%I\n\n\nhour of the day (12-hour format): [01\u201312]\n\n\n09\n\n\n\n\n\n\n%j\n\n\nday of the year: [001\u2013366]\n\n\n019\n\n\n\n\n\n\n%m\n\n\nmonth: [01\u201312]\n\n\n01\n\n\n\n\n\n\n%M\n\n\nminute: [00\u201359]\n\n\n24\n\n\n\n\n\n\n%n\n\n\nnewline character\n\n\n\n\n\n\n\n\n%p\n\n\nAM/PM\n\n\nPM\n\n\n\n\n\n\n%r\n\n\nlocale\u2019s time (12-hour format)\n\n\n09:24:52 PM\n\n\n\n\n\n\n%R\n\n\nsame as \n%H:%M\n\n\n21:24\n\n\n\n\n\n\n%S\n\n\nsecond: [00\u201360]\n\n\n52\n\n\n\n\n\n\n%t\n\n\nhorizontal tab character\n\n\n\n\n\n\n\n\n%T\n\n\nsame as \n%H:%M:%S\n\n\n21:24:52\n\n\n\n\n\n\n%u\n\n\nISO 8601 weekday [Monday = 1, 1\u20137]\n\n\n4\n\n\n\n\n\n\n%U\n\n\nSunday week number: [00\u201353]\n\n\n03\n\n\n\n\n\n\n%V\n\n\nISO 8601 week number: [01\u201353]\n\n\n03\n\n\n\n\n\n\n%w\n\n\nweekday: [0 = Sunday, 0\u20136]\n\n\n4\n\n\n\n\n\n\n%W\n\n\nMonday week number: [00\u201353]\n\n\n03\n\n\n\n\n\n\n%x\n\n\nlocale\u2019s date 01/19/\n\n\n12\n\n\n\n\n\n\n%X\n\n\nlocale\u2019s time 21:24:\n\n\n52\n\n\n\n\n\n\n%y\n\n\nlast two digits of year: [00\u201399]\n\n\n12\n\n\n\n\n\n\n%Y\n\n\nyear\n\n\n2012\n\n\n\n\n\n\n%z\n\n\noffset from UTC in ISO 8601 format\n\n\n-0500\n\n\n\n\n\n\n%Z\n\n\ntime zone name\n\n\nEST\n\n\n\n\n\n\n%%\n\n\ntranslates to a percent sign\n\n\n%\n\n\n\n\n\n\n\n\n\n\nstrftime\n example: \nstrftime.c\n\n\n\n\nConversion specifiers for \nstrptime\n\n\n\n\n\n\n\n\nFormat\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n%a\n\n\nabbreviated or full weekday name\n\n\n\n\n\n\n%A\n\n\nsame as \n%a\n\n\n\n\n\n\n%b\n\n\nabbreviated or full month name\n\n\n\n\n\n\n%B\n\n\nsame as \n%b\n\n\n\n\n\n\n%c\n\n\ndate and time\n\n\n\n\n\n\n%C\n\n\nall but the last two digits of the year\n\n\n\n\n\n\n%d\n\n\nday of the month: [01\u201331]\n\n\n\n\n\n\n%D\n\n\ndate [MM/DD/YY]\n\n\n\n\n\n\n%e\n\n\nsame as \n%d\n\n\n\n\n\n\n%h\n\n\nsame as \n%b\n\n\n\n\n\n\n%H\n\n\nhour of the day (24-hour format): [00\u201323]\n\n\n\n\n\n\n%I\n\n\nhour of the day (12-hour format): [01\u201312]\n\n\n\n\n\n\n%j\n\n\nday of the year: [001\u2013366]\n\n\n\n\n\n\n%m\n\n\nmonth: [01\u201312]\n\n\n\n\n\n\n%M\n\n\nminute: [00\u201359]\n\n\n\n\n\n\n%n\n\n\nany white space\n\n\n\n\n\n\n%p\n\n\nAM/PM\n\n\n\n\n\n\n%r\n\n\nlocale\u2019s time (12-hour format, AM/PM notation)\n\n\n\n\n\n\n%R\n\n\ntime as \n%H:%M\n\n\n\n\n\n\n%S\n\n\nsecond: [00\u201360]\n\n\n\n\n\n\n%t\n\n\nany white space\n\n\n\n\n\n\n%T\n\n\ntime as \n%H:%M:%S\n\n\n\n\n\n\n%U\n\n\nSunday week number: [00\u201353]\n\n\n\n\n\n\n%w\n\n\nweekday: [0 = Sunday, 0\u20136]\n\n\n\n\n\n\n%W\n\n\nMonday week number: [00\u201353]\n\n\n\n\n\n\n%x\n\n\nlocale\u2019s date\n\n\n\n\n\n\n%X\n\n\nlocale\u2019s time\n\n\n\n\n\n\n%y\n\n\nlast two digits of year: [00\u201399]\n\n\n\n\n\n\n%Y\n\n\nyear\n\n\n\n\n\n\n%%\n\n\ntranslates to a percent sign\n\n\n\n\n\n\n\n\nFunctions that are affected by \nTZ\n environment variable. If defined, the value of this environment variable is used by these functions instead of the default time zone:\n\n\n\n\nlocaltime\n\n\nmktime\n\n\nstrftime", 
            "title": "Chapter 6. System Data Files and Information"
        }, 
        {
            "location": "/apue/ch7/", 
            "text": "Chapter 7. Process Environment\n\n\nIntroduction\n\n\nmain\n Function\n\n\nA C program starts execution with a function called \nmain\n:\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[]);\n\n\n\n\n\n\n\n\nargc\n: number of command-line arguments\n\n\nargv\n: an array of pointers to the arguments\n\n\n\n\nWhen a C program is executed by the kernel (by one of the \nexec\n functions), a special start-up routine is called before the \nmain\n function is called. The executable program file specifies this routine as the starting address for the program; this is set up by the link editor (linker) when it is invoked by the C compiler. This start-up routine takes values from the kernel (the command-line arguments and the environment) and sets things up so that the \nmain\n function is called as shown earlier.\n\n\nProcess Termination\n\n\nThere are eight ways for a process to terminate.\n\n\n\n\n\n\nNormal termination occurs in five ways:\n\n\n\n\nReturn from \nmain\n\n\nCalling \nexit\n\n\nCalling \n_exit\n or \n_Exit\n\n\nReturn of the last thread from its start routine (Section 11.5)\n\n\nCalling \npthread_exit\n (Section 11.5) from the last thread\n\n\n\n\n\n\n\n\nAbnormal termination occurs in three ways:\n\n\n\n\nCalling \nabort\n (Section 10.17)\n\n\nReceipt of a signal (Section 10.2)\n\n\nResponse of the last thread to a cancellation request (Sections 11.5 and 12.7)\n\n\n\n\n\n\n\n\nExit Functions\n\n\nThree functions terminate a program normally:\n\n\napue_exit.h\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \nexit\n(\nint\n \nstatus\n);\n\n\nvoid\n \n_Exit\n(\nint\n \nstatus\n);\n\n\n\n#include \nunistd.h\n\n\n\nvoid\n \n_exit\n(\nint\n \nstatus\n);\n\n\n\n\n\n\n\n\n_exit\n: returns to the kernel immediately\n\n\n_Exit\n: same as \n_exit\n\n\nexit\n: performs certain cleanup processing and then returns to the kernel. Historically, it has always performed a clean shutdown of the standard I/O library: the \nfclose\n function is called for all open streams\n\n\n\n\nAll three exit functions expect a single integer argument (\nexit status\n).\n\n\nThe \nexit status of the process is undefined\n, if any of the following occurs:\n\n\n\n\nAny of these functions is called without an exit status\n\n\nmain\n does a return without a return value\n\n\nmain\n function is not declared to return an integer\n\n\n\n\nIf the return type of main is an integer and main \"falls off the end\" (an implicit return), the exit status of the process is 0.\n\n\nReturning an integer value from the main function is equivalent to calling exit with the same value:\n\n\nexit(0);\n is same as \nreturn(0);\n from the \nmain\n function.\n\n\natexit\n Function\n\n\nWith ISO C, a process can register at least 32 functions that are automatically called by \nexit\n. These are called \nexit handlers\n and are registered by calling the \natexit\n function.\n\n\napue_atexit.h\n\n\n#include \nstdlib.h\n\n\n\nint\n \natexit\n(\nvoid\n \n(\n*\nfunc\n)(\nvoid\n));\n\n\n\n/* Returns: 0 if OK, nonzero on error */\n\n\n\n\n\n\n\n\nfunc\n argument is the address of the function to be called by \nexit\n. When this function is called, it is not passed any arguments and is not expected to return a value. The \nexit\n function calls these functions in reverse order of their registration. Each function is called as many times as it was registered.\n\n\n\n\nWith ISO C and POSIX.1, \nexit\n first calls the exit handlers and then closes (via \nfclose\n) all open streams. POSIX.1 extends the ISO C standard by specifying that any exit handlers installed will be cleared if the program calls any of the \nexec\n family of functions.\n\n\nThe only way a program can be executed by the kernel is if one of the \nexec\n functions is called. \nThe only way a process can voluntarily terminate is if \n_exit\n or \n_Exit\n is called\n, either explicitly or implicitly (by calling \nexit\n). A process can also be involuntarily terminated by a signal.\n\n\nCommand-Line Arguments\n\n\nWhen a program is executed, the process that does the \nexec\n can pass command-line arguments to the new program. This is part of the normal operation of the UNIX system shells.\n\n\nExample:\n\n\n#include \napue.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nint\n \ni\n;\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nargc\n;\n \ni\n++\n)\n \n/* echo all command-line args */\n\n        \nprintf\n(\nargv[%d]: %s\n\\n\n,\n \ni\n,\n \nargv\n[\ni\n]);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWe are guaranteed by both ISO C and POSIX.1 that argv[argc] is a null pointer. This lets us alternatively code the argument-processing loop as:\n\n\nfor\n \n(\ni\n \n=\n \n0\n;\n \nargv\n[\ni\n]\n \n!=\n \nNULL\n;\n \ni\n++\n)\n\n\n\n\n\n\nEnvironment List\n\n\nEach program is also passed an environment list, which is an array of character pointers, with each pointer containing the address of a null-terminated C string. It is contained in the global variable environ:\n\n\nextern\n \nchar\n \n**\nenviron\n;\n\n\n\n\n\n\n\n\n\n\nenviron\n is called the \nenvironment pointer\n, the array of pointers the environment list, and the strings they point to the \nenvironment strings\n, which by convention is \nname=value\n strings. By convetion, predefined names are entirely uppercase.\n\n\n\n\nMemory Layout of a C Program\n\n\nHistorically, a C program has been composed of the following pieces:\n\n\n\n\nText segment: consists of the machine instructions that the CPU executes\n\n\nInitialized data segment (or simply data segment): contains variables that are specifically initialized in the program\n\n\nUninitialized data segment (often called the \"bss\" segment, which is named after \"block started by symbol\"): data in this segment is initialized by the kernel to arithmetic 0 or null pointers before the program starts executing\n\n\nStack: stores automatic variables, along with information that is saved each time a function is called\n\n\nHeap is where dynamic memory allocation usually takes place\n\n\n\n\n\n\nWith Linux on a 32-bit Intel x86 processor, the text segment starts at location \n0x08048000\n, and the bottom of the stack starts just below \n0xC0000000\n. \nThe stack grows from higher-numbered addresses to lower-numbered addresses on this particular architecture.\n The unused virtual address space between the top of the heap and the top of the stack is large\n\n\nThe \nsize(1)\n command reports the sizes (in bytes) of the text, data, and bss segments:\n\n\n$ \nsize /usr/bin/cc /bin/sh\ntext data bss dec hex filename\n\n346919\n \n3576\n \n6680\n \n357175\n \n57337\n /usr/bin/cc\n\n102134\n \n1776\n \n11272\n \n115182\n 1c1ee /bin/sh\n\n\n\n\n\nShared Libraries\n\n\nShared libraries remove the common library routines from the executable file and maintains a single copy of the library routine somewhere in memory that all processes reference:\n\n\n\n\nPros: reduces the size of each executable file; library functions can be replaced with new versions without having to relink edit every program that uses the library\n\n\nCons: adds some runtime overhead, either when the program is first executed or the first time each shared library function is called\n\n\n\n\nMemory Allocation\n\n\napue_malloc.h\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \n*\nmalloc\n(\nsize_t\n \nsize\n);\n\n\nvoid\n \n*\ncalloc\n(\nsize_t\n \nnobj\n,\n \nsize_t\n \nsize\n);\n\n\nvoid\n \n*\nrealloc\n(\nvoid\n \n*\nptr\n,\n \nsize_t\n \nnewsize\n);\n\n\n\n/* All three return: non-null pointer if OK, NULL on error */\n\n\n\nvoid\n \nfree\n(\nvoid\n \n*\nptr\n);\n\n\n\n\n\n\n\n\nmalloc\n: allocates a specified number of bytes of memory\n\n\ncalloc\n: allocates space for a specified number of objects of a specified size\n\n\nrealloc\n: increases or decreases the size of a previously allocated area. The final argument to realloc is the new size of the region, not the\ndifference between the old and new sizes\n\n\n\n\nThe pointer returned by the three allocation functions is guaranteed to be suitably aligned so that it can be used for any data object.\n\n\nBecause the three \nalloc\n functions return a generic \nvoid *\n pointer, if we \n#include \nstdlib.h\n (to obtain the function prototypes), we do not explicitly have to cast the pointer returned by these functions when we assign it to a pointer of a different type. \nThe default return value for undeclared functions is int, so using a cast without the proper function declaration could hide an error on systems where the size of type int differs from the size of a function\u2019s return value (a pointer in this case).\n\n\n\n\nfree\n: causes the space pointed to by \nptr\n to be deallocated. This freed space is usually put into a pool of available memory and can be allocated in a later call to one of the three \nalloc\n functions.\n\n\n\n\nThe allocation routines are usually implemented with the \nsbrk(2)\n system call. This system call expands (or contracts) the heap of the process. Although \nsbrk\n can expand or contract the memory of a process, most versions of \nmalloc\n and free never decrease their memory size. \nThe space that we free is available for a later allocation, but the freed space is not usually returned to the kernel; instead, that space is kept in the \nmalloc\n pool.\n\n\nAlternate Memory Allocators\n\n\n[p209]\n\n\n\n\nlibmalloc\n\n\nvmalloc\n\n\nquick-fit\n\n\njemalloc\n\n\nTCMalloc\n\n\nalloca\n Function: has the same calling sequence as \nmalloc\n; however, instead of allocating memory from the heap, the memory is allocated from the stack frame of the current function\n\n\n\n\nEnvironment Variables\n\n\nThe environment strings are usually of the form:\n\n\nname=value\n\n\n\n\n\nThe UNIX kernel never looks at these strings; their interpretation is up to the various applications.\n\n\napue_getenv.h\n\n\n#include \nstdlib.h\n\n\n\nchar\n \n*\ngetenv\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n/* Returns: pointer to value associated with name, NULL if not found */\n\n\n\nint\n \nputenv\n(\nchar\n \n*\nstr\n);\n\n\n/* Returns: 0 if OK, nonzero on error */\n\n\n\nint\n \nsetenv\n(\nconst\n \nchar\n \n*\nname\n,\n \nconst\n \nchar\n \n*\nvalue\n,\n \nint\n \nrewrite\n);\n\n\nint\n \nunsetenv\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\ngetenv\n: returns a pointer to the value of a \nname=value\n string. We should always use \ngetenv\n to fetch a specific value from the environment, instead of accessing \nenviron\n directly\n\n\n\n\n\n\n\n\nputenv\n: takes a string of the form \nname=value\n and places it in the environment list. If name already exists, its old definition is first removed.\n\n\nsetenv\n: sets \nname\n to \nvalue\n. If name already exists in the environment, then:\n\n\nIf \nrewrite\n is nonzero, the existing definition for \nname\n is first removed\n\n\nIf \nrewrite\n is 0, the existing definition for \nname\n is not removed, \nname\n is not set to the new value, and no error occurs\n\n\n\n\n\n\nunsetenv\n: removes any definition of name. It is not an error if such a definition does not exist.\n\n\n\n\nNote the difference between \nputenv\n and \nsetenv\n. Whereas \nsetenv\n must allocate memory to create the \nname=value\n string from its arguments, \nputenv\n is free to place the string passed to it directly into the environment. Indeed, many implementations do exactly this, so \nit would be an error to pass putenv a string allocated on the stack, since the memory would be reused after we return from the current function.\n\n\n\n\nDeleting a string: we just find the pointer in the environment list and move all subsequent pointers down one.\n\n\nModifying a existing \nname\n:\n\n\nIf new \nvalue\n is smaller than or equal to old: we just copy the string\n\n\nIf new \nvalue\n is larger than old: we must \nmalloc\n and replace the old pointer in the environment list for \nname\n with the pointer to this allocated area\n\n\n\n\n\n\nAdding a new \nname\n:\n\n\nFirst time: we call \nmalloc\n, copy the old environment list to this new area and store a pointer to the \nname=value\n string at the end of\nthis list of pointers. We also store a null pointer at the end of this list, of course. Finally, we set \nenviron\n to point to this new list of pointers. \nIf the original environment list was contained above the top of the stack, as is common, then we have moved this list of pointers to the heap. But most of the pointers in this list still point to \nname=value\n strings above the top of the stack.\n\n\nNot first time: we call \nrealloc\n to allocate room for one more pointer. The pointer to the new \nname=value\n string is stored at the end of the list (on top of the previous null pointer), followed by a null pointer.\n\n\n\n\n\n\n\n\nsetjmp\n and \nlongjmp\n Functions\n\n\nIn C, we can't \ngoto\n a label that\u2019s in another function. Instead, we must use the \nsetjmp\n and \nlongjmp\n functions to perform this type of branching. These two functions are useful for handling error conditions that occur in a deeply nested function call.\n\n\napue_setjmp.h\n\n\n#include \nsetjmp.h\n\n\n\nint\n \nsetjmp\n(\njmp_buf\n \nenv\n);\n\n\n/* Returns: 0 if called directly, nonzero if returning from a call to longjmp */\n\n\n\nvoid\n \nlongjmp\n(\njmp_buf\n \nenv\n,\n \nint\n \nval\n);\n\n\n\n\n\n\nExamples:\n\n\n\n\ncmd1.c\n\n\ncmd2.c\n\n\n\n\nAutomatic, Register, and Volatile Variables\n\n\nWhen we return to \nmain\n as a result of the \nlongjmp\n, implementations do not try to roll back these automatic variables and register variables (in \nmain\n), though standards say only that their values are indeterminate.\n\n\nExample:\n\n\n\n\ntestjmp.c\n\n\n\n\nCompile the above program, with and without compiler optimizations, the results are different:\n\n\n$ gcc testjmp.c compile without any optimization\n$ ./a.out\nin f1():\nglobval = 95, autoval = 96, regival = 97, volaval = 98, statval = 99\nafter longjmp:\nglobval = 95, autoval = 96, regival = 97, volaval = 98, statval = 99\n$ gcc -O testjmp.c compile with full optimization\n$ ./a.out\nin f1():\nglobval = 95, autoval = 96, regival = 97, volaval = 98, statval = 99\nafter longjmp:\nglobval = 95, autoval = 2, regival = 3, volaval = 98, statval = 99\n\n\n\n\n\nThe optimizations don\u2019t affect the global, static, and volatile variables. The \nsetjmp(3)\n manual page on one system states that variables stored in memory will have values as of the time of the \nlongjmp\n, whereas variables in the CPU and floating-point registers are restored to their values when \nsetjmp\n was called. Without optimization, all five variables are stored in memory. When we enable optimization, both \nautoval\n and \nregival\n go into registers, even though the former wasn't declared \nregister\n, and the \nvolatile\n variable stays in memory.\n\n\nPotential Problem with Automatic Variables\n\n\nAn automatic variable can never be referenced after the function that declared it returns.\n\n\nIncorrect usage of an automatic variable:\n\n\n#include \nstdio.h\n\n\nFILE\n \n*\n\n\nopen_data\n(\nvoid\n)\n\n\n{\n\n    \nFILE\n \n*\nfp\n;\n\n    \nchar\n \ndatabuf\n[\nBUFSIZ\n];\n \n/* setvbuf makes this the stdio buffer */\n\n    \nif\n \n((\nfp\n \n=\n \nfopen\n(\ndatafile\n,\n \nr\n))\n \n==\n \nNULL\n)\n\n        \nreturn\n(\nNULL\n);\n\n    \nif\n \n(\nsetvbuf\n(\nfp\n,\n \ndatabuf\n,\n \n_IOLBF\n,\n \nBUFSIZ\n)\n \n!=\n \n0\n)\n\n        \nreturn\n(\nNULL\n);\n\n    \nreturn\n(\nfp\n);\n \n/* error */\n\n\n}\n\n\n\n\n\n\nThe problem is that when \nopen_data\n returns, the space it used on the stack will be used by the stack frame for the next function that is called. But the standard I/O library will still be using that portion of memory for its stream buffer. Chaos is sure to result. To correct this problem, the array \ndatabuf\n needs to be allocated from global memory, either statically (\nstatic\n or \nextern\n) or dynamically (one of the \nalloc\n functions).\n\n\ngetrlimit\n and \nsetrlimit\n Functions\n\n\nEvery process has a set of resource limits, some of which can be queried and changed by the \ngetrlimit\n and \nsetrlimit\n functions.\n\n\napue_getrlimit.h\n\n\n#include \nsys/resource.h\n\n\n\nint\n \ngetrlimit\n(\nint\n \nresource\n,\n \nstruct\n \nrlimit\n \n*\nrlptr\n);\n\n\nint\n \nsetrlimit\n(\nint\n \nresource\n,\n \nconst\n \nstruct\n \nrlimit\n \n*\nrlptr\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThese two functions are defined in the XSI option in the Single UNIX Specification. The resource limits for a process are normally established by process 0 when the system is initialized and then inherited by each successive process. Each implementation has its own way of tuning the various limits.\n\n\n\n\nrlptr\n: a pointer to the following structure:\n\n\n\n\nstruct\n \nrlimit\n \n{\n\n    \nrlim_t\n \nrlim_cur\n;\n \n/* soft limit: current limit */\n\n    \nrlim_t\n \nrlim_max\n;\n \n/* hard limit: maximum value for rlim_cur */\n\n\n};\n\n\n\n\n\n\n\n\n\n\nresource\n argument takes on one of the following values:\n\n\n\n\nRLIMIT_AS\n: The maximum size in bytes of a process\u2019s total available memory. This affects the \nsbrk\n function and the \nmmap\n function.\n\n\nRLIMIT_CORE\n: The maximum size in bytes of a core file. A limit of 0 prevents the creation of a core file.\n\n\nRLIMIT_CPU\n: The maximum amount of CPU time in seconds. When the soft limit is exceeded, the SIGXCPU signal is sent to the process.\n\n\nRLIMIT_DATA\n: The maximum size in bytes of the data segment: the sum of the initialized data, uninitialized data, and heap from \nFigure 7.6\n.\n\n\nRLIMIT_FSIZE\n: The maximum size in bytes of a file that may be created.  When the soft limit is exceeded, the process is sent the \nSIGXFSZ\n signal.\n\n\nRLIMIT_MEMLOCK\n: The maximum amount of memory in bytes that a process can lock into memory using \nmlock(2)\n.\n\n\nRLIMIT_MSGQUEUE\n: The maximum amount of memory in bytes that a process can allocate for POSIX message queues.\n\n\nRLIMIT_NICE\n: The limit to which a process\u2019s nice value can be raised to affect its scheduling priority.\n\n\nRLIMIT_NOFILE\n: The maximum number of open files per process. Changing this limit affects the value returned by the \nsysconf\n function for its \n_SC_OPEN_MAX\n argument.\n\n\nRLIMIT_NPROC\n: The maximum number of child processes per real user ID. Changing this limit affects the value returned for \n_SC_CHILD_MAX\n by the \nsysconf\n function.\n\n\nRLIMIT_NPTS\n: The maximum number of pseudo terminals that a user can have open at one time.\n\n\nRLIMIT_RSS\n: Maximum resident set size (RSS) in bytes. If available physical memory is low, the kernel takes memory from processes that exceed their RSS.\n\n\nRLIMIT_SBSIZE\n: The maximum size in bytes of socket buffers that a user can consume at any given time.\n\n\nRLIMIT_SIGPENDING\n: The maximum number of signals that can be queued for a process. This limit is enforced by the sigqueue function\n\n\nRLIMIT_STACK\n: The maximum size in bytes of the stack. See \nFigure 7.6\n.\n\n\nRLIMIT_SWAP\n: The maximum amount of swap space in bytes that a user can consume.\n\n\nRLIMIT_VMEM\n This is a synonym for \nRLIMIT_AS\n.\n\n\n\n\n\n\n\n\nRules of changing resource limits:\n\n\n\n\nA process can change its soft limit to a value less than or equal to its hard limit.\n\n\nA process can lower its hard limit to a value greater than or equal to its soft limit. \nThis lowering of the hard limit is irreversible for normal users.\n\n\nOnly a superuser process can raise a hard limit.\n\n\n\n\nThe resource limits affect the calling process and are inherited by any of its children. This means that the setting of resource limits needs to be built into the shells to affect all our future processes. Indeed, the Bourne shell, the GNU Bourne-again shell, and the Korn shell have the built-in \nulimit\n command, and the C shell has the built-in limit command. (The \numask\n and \nchdir\n functions also have to be handled as shell built-ins.)\n\n\nExample:\n\n\n\n\ngetrlimit.c\n\n\n\n\nSummary\n\n\nUnderstanding the environment of a C program within a UNIX system\u2019s environment is a prerequisite to understanding the process control features of the UNIX System. This chapter discusses process start and termination, and how a process is passed  an argument list and an environment. Although both the argument list and the environment are uninterpreted by the kernel, it is the kernel that passes both from the caller of \nexec\n to the new process.  This chapter also examines the typical memory layout of a C program and how a process can dynamically allocate and free memory.", 
            "title": "Chapter 7. Process Environment"
        }, 
        {
            "location": "/apue/ch8/", 
            "text": "Chapter 8. Process Control\n\n\nProcess Identifiers\n\n\nEvery process has a unique process ID, a non-negative integer. As processes terminate, their IDs can be reused. \nMost UNIX systems implement algorithms to delay reuse so that newly created processes are assigned IDs different from those used by processes that terminated recently. This prevents a new process from being mistaken for the previous process to have used the same ID.\n\n\nThere are some special processes, but the details differ from implementation to implementation:\n\n\n\n\nProcess ID 0: scheduler process (often known as the \nswapper\n), which is part of the kernel and is known as a system process\n\n\nProcess ID 1: \ninit\n process, invoked by the kernel at the end of the bootstrap procedure.\n\n\nIt is responsible for bringing up a UNIX system after the kernel has been bootstrapped. \ninit\n usually reads the system-dependent initialization files (\n/etc/rc*\n files or \n/etc/inittab\n and the files in \n/etc/init.d\n) and brings the system to a certain state.\n\n\nIt never dies.\n\n\nIt is a normal user process, not a system process within the kernel.\n\n\nIt runs with superuser privileges.\n\n\n\n\n\n\n\n\nEach UNIX System implementation has its own set of kernel processes that provide operating system services.\n For example, on some virtual memory implementations of the UNIX System, process ID 2 is the \npagedaemon\n. This process is responsible for supporting the paging of the virtual memory system.\n\n\napue_getpid.h\n\n\ninclude\n \nunistd\n.\nh\n\n\n\npid_t\n \ngetpid\n(\nvoid\n);\n\n\n/* Returns: process ID of calling process */\n\n\n\npid_t\n \ngetppid\n(\nvoid\n);\n\n\n/* Returns: parent process ID of calling process */\n\n\n\nuid_t\n \ngetuid\n(\nvoid\n);\n\n\n/* Returns: real user ID of calling process */\n\n\n\nuid_t\n \ngeteuid\n(\nvoid\n);\n\n\n/* Returns: effective user ID of calling process */\n\n\n\ngid_t\n \ngetgid\n(\nvoid\n);\n\n\n/* Returns: real group ID of calling process */\n\n\n\ngid_t\n \ngetegid\n(\nvoid\n);\n\n\n/* Returns: effective group ID of calling process */\n\n\n\n\n\n\nNone of these functions has an error return.\n\n\nfork\n Function\n\n\nAn existing process can create a new one by calling the \nfork\n function.\n\n\napue_fork.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \nfork\n(\nvoid\n);\n\n\n\n/* Returns: 0 in child, process ID of child in parent, \u22121 on error */\n\n\n\n\n\n\n\n\nThe new process created by \nfork\n is called the \nchild process\n. This function is called once but returns twice. The only difference in the returns is that the return value in the child is 0, whereas the return value in the parent is the process ID of the new child. [p299]\n\n\nfork\n returns child's process ID in parent: a process can have more than one child, and \nthere is no function that allows a process to obtain the process IDs of its children\n\n\nfork\n returns 0 in child: \na process can have only a single parent, and the child can always call \ngetppid\n to obtain the process ID of its parent\n\n\n\n\n\n\nBoth the child and the parent continue executing with the instruction that follows the call to \nfork\n. The child is a copy of the parent. For example, the child gets a copy of the parent\u2019s data space, heap, and stack. Note that this is a copy for the child the parent and the child do not share these portions of memory. The parent and the child do share the text segment.\n\n\nCopy-on-write (COW) is used on modern implementations: a complete copy of the parent\u2019s data, stack and heap is not performed. The shared regions are changed to read-only by the kernel. The kernel makes a copy of that piece of memory only if either process tries to modify these regions.\n\n\n\n\nVariations of the \nfork\n function are provided by some platforms. All four platforms discussed in this book support the \nvfork(2)\n variant discussed in the next section. Linux 3.2.0 also provides new process creation through the \nclone(2)\n system call. This is a generalized form of \nfork\n that allows the caller to control what is shared between parent and child.\n\n\nExample (\nfork1.c\n):\n\n\n#include \napue.h\n\n\n\nint\n \nglobvar\n \n=\n \n6\n;\n \n/* external variable in initialized data */\n\n\nchar\n \nbuf\n[]\n \n=\n \na write to stdout\n\\n\n;\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nvar\n;\n \n/* automatic variable on the stack */\n\n    \npid_t\n \npid\n;\n\n\n    \nvar\n \n=\n \n88\n;\n\n    \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \nbuf\n,\n \nsizeof\n(\nbuf\n)\n-\n1\n)\n \n!=\n \nsizeof\n(\nbuf\n)\n-\n1\n)\n\n        \nerr_sys\n(\nwrite error\n);\n\n    \nprintf\n(\nbefore fork\n\\n\n);\n \n/* we don\u2019t flush stdout */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n        \nglobvar\n++\n;\n \n/* modify variables */\n\n        \nvar\n++\n;\n\n    \n}\n \nelse\n \n{\n\n        \nsleep\n(\n2\n);\n \n/* parent */\n\n    \n}\n\n\n    \nprintf\n(\npid = %ld, glob = %d, var = %d\n\\n\n,\n \n(\nlong\n)\ngetpid\n(),\n \nglobvar\n,\n\n           \nvar\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\n$ ./a.out\na write to stdout\nbefore fork\npid = 430, glob = 7, var = 89 # child\u2019s variables were changed\npid = 429, glob = 6, var = 88 # parent\u2019s copy was not changed\n$ ./a.out \n temp.out\n$ cat temp.out\na write to stdout\nbefore fork\npid = 432, glob = 7, var = 89\nbefore fork\npid = 431, glob = 6, var = 88\n\n\n\n\n\nAnalysis:\n\n\n\n\nWhether the child starts executing before the parent or vice versa is not known. The order depends on the scheduling algorithm used by the kernel. If it\u2019s required that the child and parent synchronize their actions, some form of interprocess communication is required.\n\n\nsizeof(buf)-1\n (subtracting 1 from the size of \nbuf\n) avoids writing the terminating null byte. \nstrlen\n calculates the length of a string not including the terminating null byte, while \nsizeof\n calculates the size of the buffer, including the terminating null byte. However, using \nstrlen\n requires a function call, whereas \nsizeof\n calculates the buffer length at compile time.\n\n\n\"a write to stdout\" (once): \nwrite\n function is not buffered and is called before the \nfork\n, its data is written once to standard output\n\n\n\"before fork\" (once in the first case, twice in the second case): \nprintf\n from the standard I/O library is buffered\n\n\nFirst case (running the program interactively): standard I/O is \nline buffered\n and standard output buffer is flushed by the newline\n\n\nSecond case (redirect stdout to a file): standard I/O is \nfully buffered\n. The \nprintf\n (\nprintf(\"before fork\\n\");\n) before the \nfork\n is called once, but the line remains in the buffer when \nfork\n is called. \nThis buffer is then copied into the child when the parent\u2019s data space is copied to the child. Both the parent and the child now have a standard I/O buffer with this line in it.\n The second \nprintf\n (\nprintf(\"pid = %ld, glob = %d, var = %d\\n\", ...);\n), right before the exit, just appends its data to the existing buffer. When each process terminates, its copy of the buffer is finally flushed.\n\n\n\n\n\n\n\n\nFile Sharing\n\n\nOne characteristic of \nfork\n is that all file descriptors that are open in the parent are duplicated in the child, because it\u2019s as if the \ndup\n function had been called for each descriptor. The parent and the child shareafile table entry for every open descriptor.\n\n\nFor a process that has three different files opened for standard input, standard output, and standard error, on return from \nfork\n, we have the arrangement shown below:\n\n\n\n\nIt is important that the parent and the child share the same file offset. Otherwise, this type of interaction would be more difficult to accomplish and would require explicit actions by the parent.\n\n\nThere are two normal cases for handling the descriptors after a \nfork\n:\n\n\n\n\nThe parent waits for the child to complete.\n\n\nBoth the parent and the child go their own ways. After the fork, both the parent and child close the descriptors that they don't need, so neither interferes with the other\u2019s open descriptors. This scenario is often found with network servers.\n\n\n\n\nBesides the open files, other properties of the parent are inherited by the child:\n\n\n\n\nReal user ID, real group ID, effective user ID, and effective group ID\n\n\nSupplementary group IDs\n\n\nProcess group ID\n\n\nSession ID\n\n\nControlling terminal\n\n\nThe set-user-ID and set-group-ID flags\n\n\nCurrent working directory\n\n\nRoot directory\n\n\nFile mode creation mask\n\n\nSignal mask and dispositions\n\n\nThe close-on-exec flag for any open file descriptors\n\n\nEnvironment\n\n\nAttached shared memory segments\n\n\nMemory mappings\n\n\nResource limits\n\n\n\n\nThe differences between the parent and child are:\n\n\n\n\nThe return values from fork are different.\n\n\nThe process IDs are different.\n\n\nThe two processes have different parent process IDs: the parent process ID of the child is the parent; the parent process ID of the parent doesn\u2019t change.\n\n\nThe child\u2019s \ntms_utime\n, \ntms_stime\n, \ntms_cutime\n, and \ntms_cstime\n values are set to 0 (these times are discussed in Section 8.17).\n\n\nFile locks set by the parent are not inherited by the child.\n\n\nPending alarms are cleared for the child.\n\n\nThe set of pending signals for the child is set to the empty set\n\n\n\n\nThe two main reasons for \nfork\n to fail\n\n\n\n\nIf too many processes are already in the system, which usually means that something else is wrong\n\n\nIf the total number of processes for this real user ID exceeds the system\u2019s limit. (\nCHILD_MAX\n specifies the maximum number of simultaneous processes per real user ID.)\n\n\n\n\nThe two uses for \nfork\n\n\n\n\nWhen a process wants to duplicate itself so that the parent and the child can each execute different sections of code at the same time.\n\n\nThis is common for network servers\u2014the parent waits for a service request from a client. When the request arrives, the parent calls \nfork\n and lets the child handle the request. The parent goes back to waiting for the next service request to arrive.\n\n\n\n\n\n\nWhen a process wants to execute a different program.\n\n\nThis is common for shells. In this case, the child does an \nexec\n right after it returns from the \nfork\n.\n\n\n\n\n\n\n\n\nSome operating systems combine the operations from step 2, a \nfork\n followed by an \nexec\n, into a single operation called a \nspawn\n. The UNIX System separates the two, as there are numerous cases where it is useful to \nfork\n without doing an \nexec\n. Also, separating the two operations allows the child to change the per-process attributes between the \nfork\n and the \nexec\n, such as I/O redirection, user ID, signal disposition, and so on\n\n\nvfork\n Function\n\n\nThe function \nvfork\n has the same calling sequence and same return values as \nfork\n, but the semantics of the two functions differ.\n\n\nThe \nvfork\n function was intended to create a new process for the purpose of executing a new program (step 2 at the end of the previous section). \nThe \nvfork\n function creates the new process, just like \nfork\n, without copying the address space of the parent into the child\n, as the child won\u2019t reference that address space; the child simply calls \nexec\n (or \nexit\n) right after the \nvfork\n. Instead, \nthe child runs in the address space of the parent until it calls either \nexec\n or \nexit\n.\n\n\nThis optimization is more efficient on some implementations of the UNIX System, but leads to undefined results if the child:\n\n\n\n\nmodifies any data (except the variable used to hold the return value from \nvfork\n)\n\n\nmakes function calls\n\n\nreturns without calling \nexec\n or \nexit\n\n\n\n\nAnother difference between the two functions is that \nvfork\n guarantees that the child runs first, until the child calls \nexec\n or \nexit\n. When the child calls either of these functions, the parent resumes. (This can lead to deadlock if the child depends on further actions of the parent before calling either of these two functions.)\n\n\nExample (\nvfork1.c\n)\n\n\nThe program is a modified version of the program from \nfork1.c\n. We\u2019ve replaced the call to \nfork\n with \nvfork\n and removed the write to standard output. Also, we don\u2019t need to have the parent call \nsleep\n, as we\u2019re guaranteed that it is put to sleep by the kernel until the child calls either \nexec\n or \nexit\n.\n\n\n#include \napue.h\n\n\n\nint\n \nglobvar\n \n=\n \n6\n;\n \n/* external variable in initialized data */\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nvar\n;\n \n/* automatic variable on the stack */\n\n    \npid_t\n \npid\n;\n\n\n    \nvar\n \n=\n \n88\n;\n\n    \nprintf\n(\nbefore vfork\n\\n\n);\n \n/* we don\u2019t flush stdio */\n\n    \nif\n \n((\npid\n \n=\n \nvfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nvfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n        \nglobvar\n++\n;\n \n/* modify parent\u2019s variables */\n\n        \nvar\n++\n;\n\n        \n_exit\n(\n0\n);\n \n/* child terminates */\n\n    \n}\n\n\n    \n/* parent continues here */\n\n    \nprintf\n(\npid = %ld, glob = %d, var = %d\n\\n\n,\n \n(\nlong\n)\ngetpid\n(),\n \nglobvar\n,\n\n           \nvar\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nRunning this program gives us\n\n\n$ ./a.out\nbefore vfork\npid = 29039, glob = 7, var = 89\n\n\n\n\n\nAnalysis:\n\n\n\n\nThe incrementing of the variables done by the child changes the values in the parent. Because the child runs in the address space of the parent.\n\n\n_exit\n is called instead of \nexit\n, because \n_exit\n does not perform any flushing of standard I/O buffers. If we call \nexit\n instead, the results are indeterminate. Depending on the implementation of the standard I/O library, we might see no difference in the output, or we might find that the output from the \nfirst \nprintf\n (see \nDoubts and Solutions\n) in the parent has disappeared.\n\n\nIf the implementation only flushes the standard I/O streams, then we will see no difference from the output generated if the child called \n_exit\n.\n\n\nIf the implementation also closes the standard I/O streams, however, the memory representing the \nFILE\n object for the standard output will be cleared out. Because the child is borrowing the parent\u2019s address space, when the parent resumes and calls \nprintf\n, no output will appear and \nprintf\n will return \u22121.\n\n\nThe parent\u2019s \nSTDOUT_FILENO\n is still valid, as the child gets a copy of the parent\u2019s file descriptor array\n\n\n\n\n\n\n\n\nMost modern implementations of \nexit\n do not close the streams. Because the process is about to exit, the kernel will close all the file descriptors open in the process. Closing them in the library simply adds overhead without any benefit.\n\n\nexit\n Functions\n\n\nA process can terminate normally in five ways (as described in \nSection 7.3\n):\n\n\n\n\nExecuting a return from the \nmain\n function. This is equivalent to calling \nexit\n.\n\n\nCalling the \nexit\n function, which includes the calling of all exit handlers that have been registered by calling \natexit\n and closing all standard I/O streams.\n\n\nISO C does not deal with file descriptors, multiple processes (parents and children), and job control. The definition of this function is incomplete for a UNIX system.\n\n\n\n\n\n\nCalling the \n_exit\n or \n_Exit\n function.\n\n\n_Exit\n: defined by ISO C to provide a way for a process to terminate without running exit handlers or signal handlers\n\n\n_exit\n: called by \nexit\n and handles the UNIX system-specific details; \n_exit\n is specified by POSIX.1.\n\n\nWhether standard I/O streams are flushed depends on the implementation.\n\n\nOn UNIX systems, \n_Exit\n and \n_exit\n are synonymous and do not flush standard I/O streams.\n\n\n\n\n\n\nExecuting a \nreturn\n from the start routine of the last thread in the process.\n\n\nThe return value of the thread is not used as the return value of the process. When the last thread returns from its start routine, the process exits with a termination status of 0.\n\n\n\n\n\n\nCalling the \npthread_exit\n function from the last thread in the process.\n\n\n\n\nThe three forms of abnormal termination:\n\n\n\n\nCalling \nabort\n. This is a special case of the next item, as it generates the \nSIGABRT\n signal.\n\n\nWhen the process receives certain signals. The signal can be generated by:\n\n\nthe process itself, e.g. calling the \nabort\n function\n\n\nsome other processes\n\n\nthe kernel, e.g. the process references a memory location not within its address space or tries to divide by 0\n\n\n\n\n\n\nThe last thread responds to a cancellation request. By default, cancellation occurs in a deferred manner: one thread requests that another be canceled, and sometime later the target thread terminates.\n\n\n\n\nRegardless of how a process terminates, the same code in the kernel is eventually executed. This kernel code closes all the open descriptors for the process, releases the memory that it was using, and so on.\n\n\nThe terminating process is to be able to notify its parent how it terminated by by passing an exit status as the argument to one of the three exit functions. In the case of an abnormal termination, the kernel (not the process) generates a termination status to indicate the reason for the abnormal termination. In any case, the parent of the process can obtain the termination status from either the \nwait\n or the \nwaitpid\n function.\n\n\nExit status vs. termination status\n\n\n\n\nExit status\n: is the argument to one of the three exit functions or the return value from main.\n\n\nTermination status\n: the exit status is converted into a termination status by the kernel when \n_exit\n is finally called. If the child terminated normally, the parent can obtain the exit status of the child.\n\n\n\n\nOrphan process\n\n\nOrphan process\n (or \norphaned child process\n) is any process whose parent terminates.\n\n\nThe child has a parent process after the call to \nfork\n. What happens if the parent terminates before the child? The answer is the \ninit\n process becomes the parent process of any process whose parent terminates. This is called \"the process has been inherited by \ninit\n\". Whenever a process terminates, the kernel goes through all active processes to see whether the terminating process is the parent of any process that still exists. If so, the parent process ID of the surviving process is changed to be 1 (the process ID of \ninit\n). This way, it's guaranteed that every process has a parent.\n\n\nZombie process\n\n\nZombie process\n is a process that has terminated, but whose parent has not yet waited for it. The \nps(1)\n command prints the state of a zombie process\nas \nZ\n.\n\n\nWhat happens when a child terminates before its parent?\n\n\nIf the child completely disappeared, the parent wouldn\u2019t be able to fetch its termination status when and if the parent was finally ready to check if the child had terminated. The kernel keeps a small amount of information for every terminating process, so that the information is available when the parent of the terminating process calls \nwait\n or \nwaitpid\n. This information consists of the process ID, the termination status of the process, and the amount of CPU time taken by the process. The kernel can discard all the memory used by the process and close its open files.\n\n\ninit\n's children\n\n\nWhat happens when a process that has been inherited by \ninit\n terminates? It does not become a zombie. \ninit\n is written so that whenever one of its children terminates, \ninit\n calls one of the \nwait\n functions to fetch the termination status. By doing this, init prevents the system from being clogged by zombies.\n\n\nOne of init\u2019s children refers to either of the following:\n\n\n\n\nA process that \ninit\n generates directly (e.g. \ngetty\n)\n\n\nA process whose parent has terminated and has been subsequently inherited by \ninit\n.\n\n\n\n\nwait\n and \nwaitpid\n Functions\n\n\nWhen a process terminates, either normally or abnormally, the kernel notifies the parent by sending the \nSIGCHLD\n signal to the parent.\n Because the termination of a child is an asynchronous event (it can happen at any time while the parent is running). This signal is the asynchronous notification from the kernel to the parent. The parent can choose to ignore this signal, or it can provide a function that is called when the signal occurs: a signal handler. \nThe default action for this signal is to be ignored.\n\n\nA process that calls \nwait\n or \nwaitpid\n can:\n\n\n\n\nBlock, if all of its children are still running\n\n\nReturn immediately with the termination status of a child, if a child has terminated and is waiting for its termination status to be fetched\n\n\nReturn immediately with an error, if it doesn\u2019t have any child processes\n\n\n\n\nIf the process is calling \nwait\n because it received the \nSIGCHLD\n signal, we expect wait to return immediately. But if we call it at any random point in time, it can block.\n\n\napue_wait.h\n\n\n#include \nsys/wait.h\n\n\n\npid_t\n \nwait\n(\nint\n \n*\nstatloc\n);\n\n\npid_t\n \nwaitpid\n(\npid_t\n \npid\n,\n \nint\n \n*\nstatloc\n,\n \nint\n \noptions\n);\n\n\n\n/* Both return: process ID if OK, 0 (see later), or \u22121 on error */\n\n\n\n\n\n\nThe differences between these two functions are:\n\n\n\n\nThe \nwait\n function can block the caller until a child process terminates, whereas \nwaitpid\n has an option that prevents it from blocking.\n\n\nThe \nwaitpid\n function doesn\u2019t wait for the child that terminates first; it has a number of options that control which process it waits for.\n\n\n\n\nIf a child has already terminated and is a zombie, \nwait\n returns immediately with that child\u2019s status. Otherwise, it blocks the caller until a child terminates. If the caller blocks and has multiple children, \nwait\n returns when one terminates. We can always tell which child terminated, because the process ID is returned by the function.\n\n\nThe argument \nstatloc\n is is a pointer to an integer. If this argument is not a null pointer, the termination status of the terminated process is stored in the location pointed to by the argument.\n\n\nThe integer status that these two functions return has been defined by the implementation, with certain bits indicating the exit status (for a normal return), other bits indicating the signal number (for an abnormal return), one bit indicating whether a core file was generated, and so on.\n\n\nFour mutually exclusive macros are defined in \nsys/wait.h\n to tell us how the process terminated, and they all begin with \nWIF\n. Based on which of these four macros is true, other macros are used to obtain the exit status, signal number, and the like.\n\n\nMacros to examine the termination status returned by \nwait\n and \nwaitpid\n:\n\n\n\n\n\n\n\n\nMacro\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nWIFEXITED(status)\n\n\nTrue if status was returned for a child that terminated normally. In this case, we can execute \nWEXITSTATUS(status)\n to fetch the low-order 8 bits of the argument that the child passed to \nexit\n, \n_exit\n, or \n_Exit\n.\n\n\n\n\n\n\nWIFSIGNALED(status)\n\n\nTrue if status was returned for a child that terminated abnormally, by receipt of a signal that it didn\u2019t catch. In this case, we can execute \nWTERMSIG(status)\n to fetch the signal number that caused the termination. Additionally, some implementations (but not the Single UNIX Specification) define the macro \nWCOREDUMP(status)\n that returns true if a core file of the terminated process was generated.\n\n\n\n\n\n\nWIFSTOPPED(status)\n\n\nTrue if status was returned for a child that is currently stopped. In this case, we can execute \nWSTOPSIG(status)\n to fetch the signal number that caused the child to stop.\n\n\n\n\n\n\nWIFCONTINUED(status)\n\n\nTrue if status was returned for a child that has been continued after a job control stop (XSI option; \nwaitpid\n only).\n\n\n\n\n\n\n\n\nThe function \npr_exit\n uses these macros (above) to print a description of the termination status.\n\n\n\n\nlib/prexit.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nvoid\n\n\npr_exit\n(\nint\n \nstatus\n)\n\n\n{\n\n    \nif\n \n(\nWIFEXITED\n(\nstatus\n))\n\n        \nprintf\n(\nnormal termination, exit status = %d\n\\n\n,\n\n                \nWEXITSTATUS\n(\nstatus\n));\n\n    \nelse\n \nif\n \n(\nWIFSIGNALED\n(\nstatus\n))\n\n        \nprintf\n(\nabnormal termination, signal number = %d%s\n\\n\n,\n\n                \nWTERMSIG\n(\nstatus\n),\n\n\n#ifdef  WCOREDUMP\n\n                \nWCOREDUMP\n(\nstatus\n)\n \n?\n \n (core file generated)\n \n:\n \n);\n\n\n#else\n\n                \n);\n\n\n#endif\n\n    \nelse\n \nif\n \n(\nWIFSTOPPED\n(\nstatus\n))\n\n        \nprintf\n(\nchild stopped, signal number = %d\n\\n\n,\n\n                \nWSTOPSIG\n(\nstatus\n));\n\n\n}\n\n\n\n\n\n\n\n\nwait1.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstatus\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_sys\n(\nfork error\n);\n\n    \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n              \n/* child */\n\n        \nexit\n(\n7\n);\n\n\n    \nif\n \n(\nwait\n(\nstatus\n)\n \n!=\n \npid\n)\n       \n/* wait for child */\n\n        \nerr_sys\n(\nwait error\n);\n\n    \npr_exit\n(\nstatus\n);\n                \n/* and print its status */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_sys\n(\nfork error\n);\n\n    \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n              \n/* child */\n\n        \nabort\n();\n                    \n/* generates SIGABRT */\n\n\n    \nif\n \n(\nwait\n(\nstatus\n)\n \n!=\n \npid\n)\n       \n/* wait for child */\n\n        \nerr_sys\n(\nwait error\n);\n\n    \npr_exit\n(\nstatus\n);\n                \n/* and print its status */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_sys\n(\nfork error\n);\n\n    \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n              \n/* child */\n\n        \nstatus\n \n/=\n \n0\n;\n                \n/* divide by 0 generates SIGFPE */\n\n\n    \nif\n \n(\nwait\n(\nstatus\n)\n \n!=\n \npid\n)\n       \n/* wait for child */\n\n        \nerr_sys\n(\nwait error\n);\n\n    \npr_exit\n(\nstatus\n);\n                \n/* and print its status */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\nnormal termination, exit status = 7\nabnormal termination, signal number = 6 (core file generated)\nabnormal termination, signal number = 8 (core file generated)\n\n\n\n\n\nWe print the signal number from \nWTERMSIG\n. We can look at the \nsignal.h\n header to verify that \nSIGABRT\n has a value of 6 and that \nSIGFPE\n has a value of 8.\n\n\nwait\n for a specific process: \nwaitpid\n\n\nIf we have more than one child, \nwait\n returns on termination of any of the children. If we want to wait for a specific process to terminate (assuming we know which process ID we want to wait for), in older versions of the UNIX System, we would have to call \nwait\n and compare the returned process ID with the one we\u2019re interested in. The POSIX.1 \nwaitpid\n function can be used to wait for a specific process.\n\n\nThe interpretation of the pid argument for waitpid depends on its value:\n\n\n\n\npid\n == \u22121 - Waits for any child process. In this respect, \nwaitpid\n is equivalent to \nwait\n.\n\n\npid\n \n 0 - Waits for the child whose process ID equals \npid\n.\n\n\npid\n == 0 - Waits for any child whose \nprocess group ID\n equals that of the calling process.\n\n\npid\n \n \u22121 - Waits for any child whose process group ID equals the absolute value of \npid\n.\n\n\n\n\nThe \nwaitpid\n function returns the process ID of the child that terminated and stores the child\u2019s termination status in the memory location pointed to by \nstatloc\n.\n\n\nErrors of \nwait\n and \nwaitpid\n\n\n\n\nWith \nwait\n, the only real error is if the calling process has no children. (Another error return is possible, in case the function call is interrupted by a signal) [p242]\n\n\nWith \nwaitpid\n, it\u2019s possible to get an error if the specified process or process group does not exist or is not a child of the calling process\n\n\n\n\noptions\n argument of \nwaitpid\n\n\nThe \noptions\n argument either is 0 or is constructed from the bitwise OR of the constants in the table below.\n\n\nThe \noptions\n constants for \nwaitpid\n:\n\n\n\n\n\n\n\n\nConstant\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nWCONTINUED\n\n\nIf the implementation supports job control, the status of any child specified by \npid\n that has been continued after being stopped, but whose status has not yet been reported, is returned (XSI option).\n\n\n\n\n\n\nWNOHANG\n\n\nThe \nwaitpid\n function will not block if a child specified by \npid\n is not immediately available. In this case, the return value is 0.\n\n\n\n\n\n\nWUNTRACED\n\n\nIf the implementation supports job control, the status of any child specified by \npid\n that has stopped, and whose status has not been reported since it has stopped, is returned. The \nWIFSTOPPED\n macro determines whether the return value corresponds to a stopped child process.\n\n\n\n\n\n\n\n\nThe \nwaitpid\n function provides three features that aren\u2019t provided by the \nwait\n function:\n\n\n\n\nThe \nwaitpid\n function lets us wait for one particular process, whereas the \nwait\n function returns the status of any terminated child (\npopen\n function)\n\n\nThe \nwaitpid\n function provides a nonblocking version of \nwait\n. There are times when we want to fetch a child\u2019s status, but we don\u2019t want to block.\n\n\nThe \nwaitpid\n function provides support for job control with the \nWUNTRACED\n and \nWCONTINUED\n options.\n\n\n\n\nfork\n twice\n\n\nExample (\nfork2.c\n)\n\n\nIf we want to write a process so that it \nfork\ns a child but we don\u2019t want to wait for the child to complete and we don\u2019t want the child to become a zombie until we terminate, \nthe trick is to call \nfork\n twice.\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n      \n/* first child */\n\n        \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n            \nerr_sys\n(\nfork error\n);\n\n        \nelse\n \nif\n \n(\npid\n \n \n0\n)\n\n            \nexit\n(\n0\n);\n    \n/* parent from second fork == first child */\n\n\n        \n/*\n\n\n         * We\nre the second child; our parent becomes init as soon\n\n\n         * as our real parent calls exit() in the statement above.\n\n\n         * Here\ns where we\nd continue executing, knowing that when\n\n\n         * we\nre done, init will reap our status.\n\n\n         */\n\n        \nsleep\n(\n2\n);\n\n        \nprintf\n(\nsecond child, parent pid = %ld\n\\n\n,\n \n(\nlong\n)\ngetppid\n());\n\n        \nexit\n(\n0\n);\n\n    \n}\n\n\n    \nif\n \n(\nwaitpid\n(\npid\n,\n \nNULL\n,\n \n0\n)\n \n!=\n \npid\n)\n   \n/* wait for first child */\n\n        \nerr_sys\n(\nwaitpid error\n);\n\n\n    \n/*\n\n\n     * We\nre the parent (the original process); we continue executing,\n\n\n     * knowing that we\nre not the parent of the second child.\n\n\n     */\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\n$ second child, parent pid = 1\n\n\n\n\n\nAnalysis:\n\n\nWe call \nsleep\n in the second child to ensure that the first child terminates before printing the parent process ID. After a \nfork\n, either the parent or the child can continue executing; we never know which will resume execution first. If we didn\u2019t put the second child to sleep, and if it resumed execution after the \nfork\n before its parent, the parent process ID that it printed would be that of its parent, not process ID 1.\n\n\nNote that the shell prints its prompt when the original process terminates, which is before the second child prints its parent process ID.\n\n\nwaitid\n Function\n\n\nThe Single UNIX Specification includes an additional \nwaitid\n function to retrieve the exit status of a process.\n\n\napue_waitid.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n \nwaitid\n(\nidtype_t\n \nidtype\n,\n \nid_t\n \nid\n,\n \nsiginfo_t\n \n*\ninfop\n,\n \nint\n \noptions\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nLike \nwaitpid\n, \nwaitid\n allows a process to specify which children to wait for. Instead of encoding this information in a single argument combined with the process ID or process group ID, two separate arguments are used. The \nid\n parameter is interpreted based on the value of \nidtype\n.\n\n\n\n\n\n\nThe \nidtype\n constants for \nwaitid\n:\n\n\n\n\n\n\n\n\nConstant\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nP_PID\n\n\nWait for a particular process: \nid\n contains the process ID of the child to wait for.\n\n\n\n\n\n\nP_PGID\n\n\nWait for any child process in a particular process group: \nid\n contains the process group ID of the children to wait for.\n\n\n\n\n\n\nP_ALL\n\n\nWait for any child process: \nid\n is ignored.\n\n\n\n\n\n\n\n\n\n\n\n\nThe \noptions\n argument is a bitwise OR of the flags shown below:\n\n\n\n\n\n\n\n\nConstant\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nWCONTINUED\n\n\nWait for a process that has previously stopped and has been continued, and whose status has not yet been reported.\n\n\n\n\n\n\nWEXITED\n\n\nWait for processes that have exited.\n\n\n\n\n\n\nWNOHANG\n\n\nReturn immediately instead of blocking if there is no child exit status available.\n\n\n\n\n\n\nWNOWAIT\n\n\nDon\u2019t destroy the child exit status. The child\u2019s exit status can be retrieved by a subsequent call to \nwait\n, \nwaitid\n, or \nwaitpid\n.\n\n\n\n\n\n\nWSTOPPED\n\n\nWait for a process that has stopped and whose status has not yet been reported.\n\n\n\n\n\n\n\n\nAt least one of \nWCONTINUED\n, \nWEXITED\n, or \nWSTOPPED\n must be specified in the options argument.\n\n\n\n\n\n\nThe \ninfop\n argument is a pointer to a \nsiginfo\n structure. This structure contains detailed information about the signal generated that caused the state change in the child process (Section 10.14)\n\n\n\n\n\n\nwait3\n and \nwait4\n Functions\n\n\nMost UNIX system implementations provide two additional functions: \nwait3\n and \nwait4\n, with an additional argument \nrusage\n that allows the kernel to return a summary of the resources used by the terminated process and all its child processes.\n\n\napue_wait3.h\n\n\n#include \nsys/types.h\n\n\n#include \nsys/wait.h\n\n\n#include \nsys/time.h\n\n\n#include \nsys/resource.h\n\n\n\npid_t\n \nwait3\n(\nint\n \n*\nstatloc\n,\n \nint\n \noptions\n,\n \nstruct\n \nrusage\n \n*\nrusage\n);\n\n\npid_t\n \nwait4\n(\npid_t\n \npid\n,\n \nint\n \n*\nstatloc\n,\n \nint\n \noptions\n,\n \nstruct\n \nrusage\n \n*\nrusage\n);\n\n\n\n/* Both return: process ID if OK, 0, or \u22121 on error */\n\n\n\n\n\n\nThe resource information includes such statistics as the amount of user CPU time, amount of system CPU time, number of page faults, number of signals received, and the like. Refer to the \ngetrusage(2)\n manual page for additional details.\n\n\nRace Conditions\n\n\nA \nrace condition\n occurs when multiple processes are trying to do something with shared data and the final outcome depends on the order in which the processes run. The \nfork\n function is a lively breeding ground for race conditions, \nif any of the logic after the \nfork\n depends on whether the parent or child runs first. In general, we cannot predict which process runs first. Even if we knew which process would run first, what happens after that process starts running depends on the system load and the kernel\u2019s scheduling algorithm.\n\n\nWe saw a potential race condition in the program in \nFigure 8.8\n when the second child printed its parent process ID.\n\n\n\n\nIf the second child runs before the first child, then its parent process will be the first child.\n\n\nIf the first child runs first and has enough time to \nexit\n, then the parent process of the second child is init.\n\n\nIf the system was heavily loaded, the second child could resume after sleep returns, before the first child has a chance to run, calling \nsleep\n  guarantees nothing.\n\n\n\n\nProblems of this form can be difficult to debug because they tend to work \"most of the time\".\n\n\n\n\nA process that wants to wait for a child to terminate must call one of the \nwait\n functions.\n\n\nA process that wants to wait for its parent to terminate can use a loop in the following form:\n\n\n\n\nwhile\n \n(\ngetppid\n()\n \n!=\n \n1\n)\n\n    \nsleep\n(\n1\n);\n\n\n\n\n\n\nThe problem with this type of loop, called \npolling\n, is that it wastes CPU time, as the caller is awakened every second to test the condition.\n\n\nTo avoid race conditions and to avoid polling, some form of signaling is required between multiple processes:\n\n\n\n\nSignals can be used for this purpose\n\n\nInterprocess communication (IPC) can also be used\n\n\n\n\nFor a parent and child relationship, we often have the following scenario. After the \nfork\n, both the parent and the child have something to do. For example, the parent could update a record in a log file with the child\u2019s process ID, and the child might have to create a file for the parent. In this example, we require that each process tell the other when it has finished its initial set of operations, and that each wait for the other to complete, before heading off on its own. The following code illustrates this scenario:\n\n\n#include \napue.h\n\n\n\nTELL_WAIT\n();\n \n/* set things up for TELL_xxx \n WAIT_xxx */\n\n\n\nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n    \nerr_sys\n(\nfork error\n);\n\n\n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n\n    \n/* child does whatever is necessary ... */\n\n\n    \nTELL_PARENT\n(\ngetppid\n());\n \n/* tell parent we\u2019re done */\n\n    \nWAIT_PARENT\n();\n \n/* and wait for parent */\n\n\n    \n/* and the child continues on its way ... */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n/* parent does whatever is necessary ... */\n\n\n\nTELL_CHILD\n(\npid\n);\n \n/* tell child we\u2019re done */\n\n\nWAIT_CHILD\n();\n \n/* and wait for child */\n\n\n\n/* and the parent continues on its way ... */\n\n\nexit\n(\n0\n);\n\n\n\n\n\n\nWe assume that the header \napue.h\n defines whatever variables are required. The five routines \nTELL_WAIT\n, \nTELL_PARENT\n, \nTELL_CHILD\n, \nWAIT_PARENT\n, and \nWAIT_CHILD\n can be either macros or functions (\nlib/tellwait.c\n). We\u2019ll show various ways to implement these \nTELL\n and \nWAIT\n routines in later chapters: Section 10.16 shows an implementation using signals; Figure 15.7 shows an implementation using pipes.\n\n\nThe program below contains a race condition because the output depends on the order in which the processes are run by the kernel and the length of time for which each process runs.\n\n\n\n\ntellwait1.c\n\n\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \ncharatatime\n(\nchar\n \n*\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n        \ncharatatime\n(\noutput from child\n\\n\n);\n\n    \n}\n \nelse\n \n{\n\n        \ncharatatime\n(\noutput from parent\n\\n\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\ncharatatime\n(\nchar\n \n*\nstr\n)\n\n\n{\n\n    \nchar\n    \n*\nptr\n;\n\n    \nint\n     \nc\n;\n\n\n    \nsetbuf\n(\nstdout\n,\n \nNULL\n);\n           \n/* set unbuffered */\n\n    \nfor\n \n(\nptr\n \n=\n \nstr\n;\n \n(\nc\n \n=\n \n*\nptr\n++\n)\n \n!=\n \n0\n;\n \n)\n\n        \nputc\n(\nc\n,\n \nstdout\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\nooutput from child\nutput from parent\n$ ./a.out\nooutput from child\nutput from parent\n$ ./a.out\noutput from child\noutput from parent\n\n\n\n\n\nAnalysis:\nWe set the standard output unbuffered, so every character output generates a write.  The goal in this example is to allow the kernel to switch between the two processes as often as possible to demonstrate the race condition.\n\n\nWe need to change (part of) the above program in to use the \nTELL\n and \nWAIT\n functions.\n\n\n\n\nThe parent goes first:\n\n\n\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n        \nWAIT_PARENT\n();\n      \n/* parent goes first */\n\n        \ncharatatime\n(\noutput from child\n\\n\n);\n\n    \n}\n \nelse\n \n{\n\n        \ncharatatime\n(\noutput from parent\n\\n\n);\n\n        \nTELL_CHILD\n(\npid\n);\n\n    \n}\n\n\n\n\n\n\n\n\nThe child goes first:\n\n\n\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n        \ncharatatime\n(\noutput from child\n\\n\n);\n\n        \nTELL_PARENT\n(\ngetppid\n());\n\n    \n}\n \nelse\n \n{\n\n        \nWAIT_CHILD\n();\n \n/* child goes first */\n\n        \ncharatatime\n(\noutput from parent\n\\n\n);\n\n    \n}\n\n\n\n\n\n\nexec\n Functions\n\n\nOne use of the \nfork\n function is to create a new process (the child) that then causes another program to be executed by calling one of the \nexec\n functions.\n\n\n\n\nWhen a process calls one of the \nexec\n functions, that process is completely replaced by the new program which starts executing at its \nmain\n function.\n\n\nThe process ID does not change across an \nexec\n, because a new process is not created.\n\n\nexec\n merely replaces the current process (its text, data, heap, and stack segments) with a brand-new program from disk.\n\n\n\n\nUNIX System process control primitives:\n\n\n\n\nfork\n creates new processes\n\n\nexec\n functions initiates new programs\n\n\nexit\n handles termination\n\n\nwait\n functions handle waiting for termination\n\n\n\n\nWe\u2019ll use these primitives in later sections to build additional functions, such as \npopen\n and \nsystem\n.\n\n\nThere are seven different \nexec\n functions:\n\n\napue_execl.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nexecl\n(\nconst\n \nchar\n \n*\npathname\n,\n \nconst\n \nchar\n \n*\narg0\n,\n \n...\n \n/* (char *)0 */\n \n);\n\n\nint\n \nexecv\n(\nconst\n \nchar\n \n*\npathname\n,\n \nchar\n \n*\nconst\n \nargv\n[]);\n\n\nint\n \nexecle\n(\nconst\n \nchar\n \n*\npathname\n,\n \nconst\n \nchar\n \n*\narg0\n,\n \n...\n\n           \n/* (char *)0, char *const envp[] */\n \n);\n\n\nint\n \nexecve\n(\nconst\n \nchar\n \n*\npathname\n,\n \nchar\n \n*\nconst\n \nargv\n[],\n \nchar\n \n*\nconst\n \nenvp\n[]);\n\n\nint\n \nexeclp\n(\nconst\n \nchar\n \n*\nfilename\n,\n \nconst\n \nchar\n \n*\narg0\n,\n \n...\n \n/* (char *)0 */\n \n);\n\n\nint\n \nexecvp\n(\nconst\n \nchar\n \n*\nfilename\n,\n \nchar\n \n*\nconst\n \nargv\n[]);\n\n\nint\n \nfexecve\n(\nint\n \nfd\n,\n \nchar\n \n*\nconst\n \nargv\n[],\n \nchar\n \n*\nconst\n \nenvp\n[]);\n\n\n\n/* All seven return: \u22121 on error, no return on success */\n\n\n\n\n\n\nThe first four take a pathname argument, the next two take a filename argument, and the last one takes a file descriptor argument.\n\n\nWhen \nfilename\n argument is specified:\n\n\n\n\nIf filename contains a slash, it is taken as a pathname.\n\n\nOtherwise, the executable file is searched for in the directories specified by the PATH environment variable.\n\n\nThe \nPATH\n variable contains a list of directories, called path prefixes, that are separated by colons, like the \nname=value\n environment string \nPATH=/bin:/usr/bin:/usr/local/bin/:.\n. The dot (\n.\n) specifies the current directory (There are security reasons for never including the current directory in the search path). A zero-length prefix also means the current directory. It can be specified as:\n\n\na colon at the beginning of the \nvalue\n: \nPATH=:/bin:/usr/bin\n\n\ntwo colons in a row: \nPATH=/bin::/usr/bin\n\n\na colon at the end of the \nvalue\n: \nPATH=/bin:/usr/bin:\n\nIf either \nexeclp\n or \nexecvp\n finds an executable file using one of the path prefixes, but the file isn\u2019t a machine executable that was generated by the link editor, the function assumes that the file is a shell script and tries to invoke \n/bin/sh\n with the filename as input to the shell.\n\n\n\n\n\n\n\n\nWith \nfexecve\n (using a file descriptor), the caller can verify the file is in fact the intended file and execute it without a race. Otherwise, a malicious user with appropriate privileges could replace the executable file (or a portion of the path to the executable file) after it has been located and verified, but before the caller can execute it. See \nTOCTTOU\n errors in Section 3.3.\n\n\nThe passing of the argument list (\nl\n stands for list and \nv\n stands for vector):\n\n\n\n\nexecl\n, \nexeclp\n, and \nexecle\n require each of the command-line arguments to be specified as separate arguments.\n\n\nexecv\n, \nexecvp\n, \nexecve\n, and \nfexecve\n require (the address) of an array of pointers to the arguments\n\n\n\n\nThe arguments for \nexecl\n, \nexecle\n, and \nexeclp\n are shown as:\n\n\n    \nchar\n \n*\narg0\n,\n \nchar\n \n*\narg1\n,\n \n...,\n \nchar\n \n*\nargn\n,\n \n(\nchar\n \n*\n)\n0\n\n\n\n\n\n\nThe final command-line argument is followed by a null pointer. If this null pointer is specified by the constant 0, we must cast it to a pointer; if we don\u2019t, it\u2019s interpreted as an integer argument.\n\n\nThe passing of the environment list to the new program.\n\n\n\n\nexecle\n, \nexecve\n, and \nfexecve\n functions (ending in \ne\n) allow us to pass a pointer to an array of pointers to the environment strings.\n\n\nexecl\n, \nexecv\n, \nexeclp\n and \nexecvp\n use the \nenviron\n variable in the calling process to copy the existing environment for the new program. [p251]\n\n\n\n\nThe arguments to \nexecle\n were shown as:\n\n\nchar\n \n*\npathname\n,\n \nchar\n \n*\narg0\n,\n \n...,\n \nchar\n \n*\nargn\n,\n \n(\nchar\n \n*\n)\n0\n,\n \nchar\n \n*\nenvp\n[]\n\n\n\n\n\n\nDifferences among the seven \nexec\n functions\n\n\n\n\n\n\n\n\nFunction\n\n\npathname\n\n\nfilename\n\n\nfd\n\n\nArg list\n\n\nargv[]\n\n\nenviron\n\n\nenvp[]\n\n\n\n\n\n\n\n\n\n\n\n\nexecl\n\n\n*\n\n\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexeclp\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexecle\n\n\n*\n\n\n\n\n\n\n*\n\n\n\n\n\n\n*\n\n\n\n\n\n\n\n\nexecv\n\n\n*\n\n\n\n\n\n\n\n\n*\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexecvp\n\n\n\n\n*\n\n\n\n\n\n\n*\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexecve\n\n\n*\n\n\n\n\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\nfexecve\n\n\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\n(letter in name)\n\n\n\n\np\n\n\nf\n\n\nl\n\n\nv\n\n\n\n\ne\n\n\n\n\n\n\n\n\n\n\nEvery system has a limit on the total size of the argument list and the environment list. This limit is given by \nARG_MAX\n and its value must be at least 4,096 bytes on a POSIX.1 system. For example, the following command can generate a shell error:\n\n\n$\n grep getrlimit /usr/share/man/*/*\n\nArgument list too long\n\n\n\n\n\n\nTo get around the limitation in argument list size, we can use the \nxargs(1)\n:\n\n\n$\n find /usr/share/man -type f -print \n|\n xargs grep getrlimit\n\n$\n find /usr/share/man -type f -print \n|\n xargs bzgrep getrlimit\n\n\n\n\n\nThe process ID does not change after an \nexec\n, but the new program inherits additional properties from the calling process:\n\n\n\n\nProcess ID and parent process ID\n\n\nReal user ID and real group ID\n\n\nSupplementary group IDs\n\n\nProcess group ID\n\n\nSession ID\n\n\nControlling terminal\n\n\nTime left until alarm clock\n\n\nCurrent working directory\n\n\nRoot directory\n\n\nFile mode creation mask\n\n\nFile locks\n\n\nProcess signal mask\n\n\nPending signals\n\n\nResource limits\n\n\nNice value\n\n\nValues for \ntms_utime\n, \ntms_stime\n, \ntms_cutime\n, and \ntms_cstime\n\n\n\n\nThe handling of open files depends on the value of the close-on-exec (\nFD_CLOEXEC\n) flag for each descriptor:\n\n\n\n\nIf this flag is set, the descriptor is closed across an exec. The default (the flag is not set) is to leave the descriptor open across the \nexec\n.\n\n\nPOSIX.1 specifically requires that open directory streams (see \nopendir\n in \nChapter 4\n). This is normally done by the\n\nopendir\n function calling \nfcntl\n to set the close-on-exec flag.\n\n\n\n\nThe real user ID and the real group ID remain the same across the \nexec\n, but the effective IDs can change, depending on the status of the set-user-ID and the setgroup-ID bits for the program file that is executed. If the set-user-ID bit is set for the new program, the effective user ID becomes the owner ID of the program file.  Otherwise, the effective user ID is not changed (it\u2019s not set to the real user ID). The group ID is handled in the same way.\n\n\nexec\n library functions and system call\n\n\nIn many UNIX system implementations, only one of these seven functions, \nexecve\n, is a system call within the kernel. The other six are just library functions that eventually invoke this system call.\n\n\nRelationship of the seven \nexec\n functions:\n\n\n\n\nExample:\n\n\n\n\nexec1.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nchar\n    \n*\nenv_init\n[]\n \n=\n \n{\n \nUSER=unknown\n,\n \nPATH=/tmp\n,\n \nNULL\n \n};\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n  \n/* specify pathname, specify environment */\n\n        \nif\n \n(\nexecle\n(\n/home/sar/bin/echoall\n,\n \nechoall\n,\n \nmyarg1\n,\n\n                \nMY ARG2\n,\n \n(\nchar\n \n*\n)\n0\n,\n \nenv_init\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexecle error\n);\n\n    \n}\n\n\n    \nif\n \n(\nwaitpid\n(\npid\n,\n \nNULL\n,\n \n0\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nwait error\n);\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n  \n/* specify filename, inherit environment */\n\n        \nif\n \n(\nexeclp\n(\nechoall\n,\n \nechoall\n,\n \nonly 1 arg\n,\n \n(\nchar\n \n*\n)\n0\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexeclp error\n);\n\n    \n}\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\n\n\nechoall.c\n\n\n\n\n#include \napue.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nint\n         \ni\n;\n\n    \nchar\n        \n**\nptr\n;\n\n    \nextern\n \nchar\n \n**\nenviron\n;\n\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nargc\n;\n \ni\n++\n)\n      \n/* echo all command-line args */\n\n        \nprintf\n(\nargv[%d]: %s\n\\n\n,\n \ni\n,\n \nargv\n[\ni\n]);\n\n\n    \nfor\n \n(\nptr\n \n=\n \nenviron\n;\n \n*\nptr\n \n!=\n \n0\n;\n \nptr\n++\n)\n   \n/* and all env strings */\n\n        \nprintf\n(\n%s\n\\n\n,\n \n*\nptr\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\nargv[0]: echoall\nargv[1]: myarg1\nargv[2]: MY ARG2\nUSER=unknown\nPATH=/tmp\n$ argv[0]: echoall\nargv[1]: only 1 arg\nUSER=sar\nLOGNAME=sar\nSHELL=/bin/bash\n...\nHOME=/home/sar\n\n\n\n\n\nAnalysis:\n\n\n\n\nThe program \nechoall\n is executed twice in the program.\n\n\nWe set the first argument, \nargv[0]\n in the new program, to be the filename component of the pathname. Some shells set this argument to be the complete pathname. This is a convention only; we can set \nargv[0]\n to any string we like.\n\n\nThe \nlogin\n command does this when it executes the shell. Before executing the shell, login adds a dash as a prefix to \nargv[0]\n to indicate to the shell that it is being invoked as a login shell. A login shell will execute the start-up profile commands, whereas a nonlogin shell will not.\n\n\n\n\n\n\nThe shell prompt (\n$\n) appeared before the printing of \nargv[0]\n from the second exec. This occurred because the parent did not wait for this child process to finish.\n\n\n\n\nChanging User IDs and Group IDs\n\n\nIn the UNIX System, privileges and access control are on user and group IDs. When programs need additional privileges or access to unallowed resources, they need to change their user or group ID to an ID that has the appropriate privilege or access. It is similar when the programs need to lower their privileges or prevent access to certain resources. [p255]\n\n\nWhen designing applications, we try to use the \nleast-privilege\n model, which means our programs should use the least privilege necessary to accomplish any given task. This reduces the risk that security might be compromised by a malicious user trying to trick our programs into using their privileges in unintended ways.\n\n\nWe can set the real user ID and effective user ID with the \nsetuid\n function and set the real group ID and the effective group ID with the \nsetgid\n function.\n\n\napue_setuid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsetuid\n(\nuid_t\n \nuid\n);\n\n\nint\n \nsetgid\n(\ngid_t\n \ngid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe rules for who can change the IDs, considering only the user ID now (Everything we describe for the user ID also applies to the group ID.)\n\n\n\n\nIf the process has superuser privileges, the \nsetuid\n function sets the real user ID, effective user ID, and saved set-user-ID to \nuid\n.\n\n\nIf the process does not have superuser privileges, but \nuid\n equals either the real user ID or the saved set-user-ID, setuid sets only the effective user ID to \nuid\n. The real user ID and the saved set-user-ID are not changed.\n\n\nIf neither of these two conditions is true, \nerrno\n is set to \nEPERM\n and \u22121 is returned.\n\n\n\n\nWe are assuming that \n_POSIX_SAVED_IDS\n is true. The saved IDs areamandatory feature in the 2001 version of POSIX.1.\n\n\nThe statements about the three user IDs that the kernel maintains:\n\n\n\n\nOnly a superuser process can change the real user ID.\n\n\nNormally, the real user ID is set by the \nlogin(1)\n program when we log in and never changes. Because \nlogin\n is a superuser process, it sets all three user IDs when it calls \nsetuid\n.\n\n\n\n\n\n\nThe effective user ID is set by the \nexec\n functions only if the set-user-ID bit is set for the program file.\n\n\nIf the set-user-ID bit is not set, the \nexec\n functions leave the effective user ID as its current value.\n\n\nWe can call \nsetuid\n at any time to set the effective user ID to either the real user ID or the saved set-user-ID.\n\n\nNaturally, we can\u2019t set the effective user ID to any random value.\n\n\n\n\n\n\nThe saved set-user-ID is copied from the effective user ID by \nexec\n. If the file\u2019s set-user-ID bit is set, this copy is saved after \nexec\n stores the effective user ID from the file\u2019s user ID.\n\n\n\n\nThe following figure summarizes the various ways these three user IDs can be changed:\n\n\n\n\nWe can obtain only the current value of the real user ID and the effective user ID with the functions \ngetuid\n and \ngeteuid\n (\napue_getpid.h\n). There is no portable way to obtain the current value of the saved set-user-ID. FreeBSD 8.0 and LINUX 3.2.0 provide the \ngetresuid\n and \ngetresgid\n functions, which can be used to get the saved set-user-ID and saved set-group-ID, respectively.\n\n\nsetreuid\n and \nsetregid\n Functions\n\n\nHistorically, BSD supported the swapping of the real user ID and the effective user ID with the setreuid function.\n\n\napue_setreuid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsetreuid\n(\nuid_t\n \nruid\n,\n \nuid_t\n \neuid\n);\n\n\nint\n \nsetregid\n(\ngid_t\n \nrgid\n,\n \ngid_t\n \negid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nA value of \u22121 for any of the arguments indicates that the corresponding ID should remain unchanged.\n\n\nAn unprivileged user can always swap between the real user ID and the effective user ID. This allows a set-user-ID program to swap to the user\u2019s normal permissions and swap back again later for set-user-ID operations.\n\n\nWhen the saved set-user-ID feature was introduced with POSIX.1, the rule was enhanced to also allow an unprivileged user to set its effective user ID to its saved set-user-ID.\n\n\n\n\n[p257]\n\n\nseteuid\n and \nsetegid\n Functions\n\n\nPOSIX.1 includes \nseteuid\n and \nsetegid\n that only change the effective user ID or effective group ID.\n\n\napue_seteuid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nseteuid\n(\nuid_t\n \nuid\n);\n\n\nint\n \nsetegid\n(\ngid_t\n \ngid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nAn unprivileged user can set its effective user ID to either its real user ID or its saved set-user-ID.\n\n\nFor a privileged user, only the effective user ID is set to \nuid\n. This differs from \nsetuid\n function, which changes all three user IDs.\n\n\n\n\nThe figure below summarizes all the functions that we\u2019ve described here that modify the three user IDs:\n\n\n\n\nGroup IDs\n\n\nEverything covered so far for user IDs in this section also applies in a similar fashion to group IDs. The \nsupplementary group IDs\n are not affected by \nsetgid\n, \nsetregid\n, or \nsetegid\n.\n\n\nExample of set-user-ID programs: \nat\n\n\nOn Linux 3.2.0, the \nat\n program is installed set-user-ID to user \ndaemon\n and the programs are run by the \natd(8)\n daemon. This allows the at command to write privileged files owned by the daemon that will run the commands on behalf of the user running the \nat\n command.\n\n\nTo prevent privilege breach, the daemon that run the commands on users's behalf have to switch between sets of privileges: users and those of the daemon. The following steps take place [p259-260]:\n\n\n\n\nAssuming that the \nat\n program file is owned by \nroot\n with set-user-ID bit set. When we run it, we have:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = root\n\n\nsaved set-user-ID = root\n\n\n\n\n\n\nat\n command reduces its privileges by calling \nseteuid\n function to set the effective user ID to our read user ID:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = our user ID\n\n\nsaved set-user-ID = root (unchanged)\n\n\n\n\n\n\nWhen \nat\n needs to access the configuration files (these files are owned by the daemon that will run the commands for us) that control which commands are to be run and the time at which they need to run, it calls \nseteuid\n to set the effective user ID to root, which is allowed because the argument to seteuid equals the saved set-user-ID:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = root\n\n\nsaved set-user-ID = root (unchanged)\n\n\n\n\n\n\nAfter the files are modified to record the commands to be run and the time at which they are to be run, the \nat\n command lowers its privileges by calling \nseteuid\n to set its effective user ID to our user ID:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = our user ID\n\n\nsaved set-user-ID = root (unchanged)\n\n\n\n\n\n\nThe daemon starts out running with root privileges. To run commands on our behalf, the daemon calls \nfork\n and the child calls \nsetuid\n to change its user ID to our user ID. Because the child is running with root privileges, this changes all of the IDs. We have:\n\n\nreal user ID = our user ID\n\n\neffective user ID = our user ID\n\n\nsaved set-user-ID = our user ID\n\n\n\n\n\n\n\n\nThen the daemon safely executes commands on our behalf, because it can access only the files to which we normally have access.\n\n\nBy using the saved set-user-ID in this fashion, we can use the extra privileges granted to us by the set-user-ID of the program file only when we need elevated privileges. Any other time, however, the process runs with our normal permissions. [p260]\n\n\nInterpreter Files\n\n\nOn contemporary UNIX systems, \ninterpreter files\n are text files that begin with a line of the form (\nshebang\n):\n\n\n#! pathname [ optional-argument ]\n\n\n\n\n\n\nThe space between the exclamation point and the pathname is optional. The most common of these interpreter files begin with the line:\n\n\n#!/bin/sh\n\n\n\n\n\n\n\n\npathname\n is normally an absolute pathname, since no special operations are performed on it (\nPATH\n is not used)\n\n\nThe recognition of interpreter files is done within the kernel as part of processing the \nexec\n system call\n\n\nThe actual file that gets executed by the kernel is not the interpreter file, but rather the file specified by the \npathname\n on the first line of the interpreter file.\n\n\n\n\nInterpreter file vs. Interpreter\n\n\n\n\nInterpreter file: is a text file that begins with \n#!\n.\n\n\nInterpreter: is specified by the \npathname\n on the first line of the interpreter file.\n\n\n\n\nBe aware that systems place a size limit on the first line of an interpreter file. This limit includes the \n#!\n, the \npathname\n, the optional argument, the terminating newline, and any spaces. On Linux 3.2.0, the limit is 128 bytes.\n\n\nExample: A program that \nexec\ns an interpreter file\n\n\n\n\nexec2.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n        \nif\n \n(\nexecl\n(\n/home/sar/bin/testinterp\n,\n\n                  \ntestinterp\n,\n \nmyarg1\n,\n \nMY ARG2\n,\n \n(\nchar\n \n*\n)\n0\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexecl error\n);\n\n    \n}\n\n    \nif\n \n(\nwaitpid\n(\npid\n,\n \nNULL\n,\n \n0\n)\n \n \n0\n)\n \n/* parent */\n\n        \nerr_sys\n(\nwaitpid error\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ cat /home/sar/bin/testinterp\n#!/home/sar/bin/echoarg foo\n$ ./a.out\nargv[0]: /home/sar/bin/echoarg\nargv[1]: foo\nargv[2]: /home/sar/bin/testinterp\nargv[3]: myarg1\nargv[4]: MY ARG2\n\n\n\n\n\nAnalysis:\n\n\nThe program (from \nSection 7.4\n) \nechoarg\n is the interpreter that echoes each of its command-line arguments.\n\n\nWhen the kernel \nexec\ns the interpreter (\n/home/sar/bin/echoarg\n):\n\n\n\n\nargv[0]\n is \npathname\n of the interpreter\n\n\nargv[1]\n is the optional argument from the interpreter file (\nfoo\n)\n\n\nThe remaining arguments are the \npathname\n (\n/home/sar/bin/testinterp\n) and the second and third arguments from the call to \nexecl\n in the program (\nmyarg1\n and \nMY ARG2\n)\n\n\nBoth \nargv[1]\n and \nargv[2]\n from the call to \nexecl\n have been shifted right two positions.\n\n\nThe kernel takes the \npathname\n from the \nexecl\n call instead of the first argument (\ntestinterp\n), on the assumption that the \npathname\n might contain more information than the first argument.\n\n\n\n\nExample: \nawk\n\n\nA common use for the optional argument following the interpreter pathname is to specify the \n-f\n option for programs that support this option. For example, an \nawk(1)\n program can be executed as:\n\n\nawk -f myfile\n\n\n\n\n\nIt tells \nawk\n to read the \nawk\n program from the file \nmyfile\n.\n\n\nUsing the \n-f\n option with an interpreter file lets us write\n\n\n#!/bin/awk -f\n\n\n# (awk program follows in the interpreter file)\n\n\n\n\n\n\n\n\nawkexample\n\n\n\n\n#!/usr/bin/awk -f\n\nBEGIN \n{\n\n    \nfor\n \n(\ni\n \n=\n 0\n;\n i \n ARGC\n;\n i++\n)\n\n        \nprintf\n \nARGV[%d] = %s\\n\n, i, ARGV\n[\ni\n]\n\n    \nexit\n\n\n}\n\n\n\n\n\n\nAssume the above interpreter file is  \n/usr/local/bin/awkexample\n and one of the path prefixes is \n/usr/local/bin\n, we can execute the program:\n\n\n$ awkexample file1 FILENAME2 f3\nARGV[0] = awk\nARGV[1] = file1\nARGV[2] = FILENAME2\nARGV[3] = f3\n\n\n\n\n\nWhen \n/bin/awk\n is executed, its command-line arguments are:\n\n\n/bin/awk -f /usr/local/bin/awkexample file1 FILENAME2 f3\n\n\n\n\n\n[p263]\n\n\nInterpreter files provide an efficiency gain for the user at some expense in the kernel, since it\u2019s the kernel that recognizes these files. They are useful for the following reasons:\n\n\nFirst, they hide that certain programs are scripts in some other language. For example, use \nawkexample optional-arguments\n instead of \nawk -f awkexample optional-argument\n, we do not need to know that the program is really an \nawk\n script.\n\n\nSecond, interpreter scripts provide an efficiency gain. For example, if we place the previous \nawk\n program into a shell script like this:\n\n\nawk \nBEGIN {\n\n\n    for (i = 0; i \n ARGC; i++)\n\n\n        printf \nARGV[%d] = %s\\n\n, i, ARGV[i]\n\n\n    exit\n\n\n}\n \n$*\n\n\n\n\n\n\nMore work is required when executing this script:\n\n\n\n\nThe shell reads the command and tries to \nexeclp\n the filename (shell script). Since the shell script is an executable file but isn't a machine executable, an error is returned and \nexeclp\n assumes that the file is a shell script.\n\n\n/bin/sh\n is executed with the pathname of the shell script as its argument.\n\n\nThe shell correctly runs the script, but to run the \nawk\n programs, the shell does \nfork\n, \nexec\n and \nwait\n.\n\n\n\n\nThird, interpreter scripts let us write shell scripts using shells other than \n/bin/sh\n. When it finds an executable file that isn\u2019t a machine executable, \nexeclp\n has to choose a shell to invoke, and it always uses \n/bin/sh\n.\n\n\nsystem\n Function\n\n\nIt is convenient to execute a command string from within a program.\n\n\napue_system.h\n\n\n#include \nstdlib.h\n\n\n\nint\n \nsystem\n(\nconst\n \nchar\n \n*\ncmdstring\n);\n\n\n\n\n\n\nArguments:\n\n\nIf \ncmdstring\n is a null pointer, system returns nonzero only if a command processor is available, which determines whether the \nsystem\n function is supported on a given platform. Under UNIX systems, it is always available.\n\n\nReturn values:\n\n\nSince \nsystem\n is implemented by calling \nfork\n, \nexec\n, and \nwaitpid\n, there are three types of return values:\n\n\n\n\nIf either the \nfork\n fails or \nwaitpid\n returns an error other than \nEINTR\n, \nsystem\n returns \u22121 with \nerrno\n set to indicate the error.\n\n\nIf the \nexec\n fails, implying that the shell can\u2019t be executed, the return value is as if the shell had executed \nexit(127)\n.\n\n\nIf all three functions succeed, the return value is the termination status of the shell, in the format specified for \nwaitpid\n.\n\n\n\n\nThe code below is an implementation of the \nsystem\n function, which doesn't handle signals.\n\n\n#include    \nsys/wait.h\n\n\n#include    \nerrno.h\n\n\n#include    \nunistd.h\n\n\n\nint\n\n\nsystem\n(\nconst\n \nchar\n \n*\ncmdstring\n)\n   \n/* version without signal handling */\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstatus\n;\n\n\n    \nif\n \n(\ncmdstring\n \n==\n \nNULL\n)\n\n        \nreturn\n(\n1\n);\n      \n/* always a command processor with UNIX */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nstatus\n \n=\n \n-\n1\n;\n    \n/* probably out of processes */\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n              \n/* child */\n\n        \nexecl\n(\n/bin/sh\n,\n \nsh\n,\n \n-c\n,\n \ncmdstring\n,\n \n(\nchar\n \n*\n)\n0\n);\n\n        \n_exit\n(\n127\n);\n     \n/* execl error */\n\n    \n}\n \nelse\n \n{\n                            \n/* parent */\n\n        \nwhile\n \n(\nwaitpid\n(\npid\n,\n \nstatus\n,\n \n0\n)\n \n \n0\n)\n \n{\n\n            \nif\n \n(\nerrno\n \n!=\n \nEINTR\n)\n \n{\n\n                \nstatus\n \n=\n \n-\n1\n;\n \n/* error other than EINTR from waitpid() */\n\n                \nbreak\n;\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n    \nreturn\n(\nstatus\n);\n\n\n}\n\n\n\n\n\n\n\n\nThe shell\u2019s \n-c\n option tells it to take the next command-line argument, \ncmdstring\n, as its command input instead of reading from standard input or from a given file. The shell parses this null-terminated C string and breaks it up into separate command-line arguments for the command. The actual command string that is passed to the shell can contain any valid shell commands.\n\n\n_exit\n is called instead of \nexit\n. This prevents any standard I/O buffers, which would have been copied from the parent to the child across the \nfork\n, from being flushed in the child.\n\n\n\n\n[p266-267]\n\n\nSet-User-ID Programs\n\n\nCalling \nsystem\n from a set-user-ID program creates a security hole and should never be attempted.\n\n\n[p267-269]\n\n\nThe superuser permissions that we gave the set-user-ID program are retained across the \nfork\n and \nexec\n that are done by \nsystem\n.\n\n\nIf it is running with special permissions (set-user-ID or set-group-ID), and wants to spawn another process, a process should use \nfork\n and \nexec\n directly, being certain to change back to normal permissions after the \nfork\n, before calling \nexec\n. The \nsystem\n function should never be used from a set-user-ID or a set-group-ID program.\n\n\nProcess Accounting\n\n\nOn UNIX systems, process accounting can be enabled so that kernel writes an accounting record each time a process terminates, which typically contain a small amount of binary data with the name of the command, the amount of CPU time used, the user ID and group ID, the starting time.\n\n\nThe function \nacct\n enables and disables process accounting. The only use of this function is from the \naccton(8)\n command.\n\n\nA superuser executes accton with a pathname argument to enable accounting. The accounting records are written to the specified file, which is usually \n/var/account/acct\n on FreeBSD and Mac OS X, \n/var/log/account/pacct\n on Linux, and \n/var/adm/pacct\n on Solaris. Accounting is turned off by executing accton without any arguments.\n\n\nThe structure of the accounting records is defined in the header \nsys/acct.h\n, which look something like:\n\n\ntypedef\n \nu_short\n \ncomp_t\n;\n \n/* 3-bit base 8 exponent; 13-bit fraction */\n\n\n\nstruct\n \nacct\n\n\n{\n\n    \nchar\n \nac_flag\n;\n \n/* flag (see Figure 8.26) */\n\n    \nchar\n \nac_stat\n;\n \n/* termination status (signal \n core flag only) */\n\n    \n/* (Solaris only) */\n\n    \nuid_t\n \nac_uid\n;\n \n/* real user ID */\n\n    \ngid_t\n \nac_gid\n;\n \n/* real group ID */\n\n    \ndev_t\n \nac_tty\n;\n \n/* controlling terminal */\n\n    \ntime_t\n \nac_btime\n;\n \n/* starting calendar time */\n\n    \ncomp_t\n \nac_utime\n;\n \n/* user CPU time */\n\n    \ncomp_t\n \nac_stime\n;\n \n/* system CPU time */\n\n    \ncomp_t\n \nac_etime\n;\n \n/* elapsed time */\n\n    \ncomp_t\n \nac_mem\n;\n \n/* average memory usage */\n\n    \ncomp_t\n \nac_io\n;\n \n/* bytes transferred (by read and write) */\n\n    \n/* \nblocks\n on BSD systems */\n\n    \ncomp_t\n \nac_rw\n;\n \n/* blocks read or written */\n\n    \n/* (not present on BSD systems) */\n\n    \nchar\n \nac_comm\n[\n8\n];\n \n/* command name: [8] for Solaris, */\n\n    \n/* [10] for Mac OS X, [16] for FreeBSD, and */\n\n    \n/* [17] for Linux */\n\n\n};\n\n\n\n\n\n\n\n\nTimes are recorded in units of clock ticks on most platforms, but FreeBSD stores microseconds instead.\n\n\nThe \nac_flag\n member records certain events during the execution of the process. See table below.\n\n\n\n\n\n\n\n\n\n\nac_flag\n\n\nDescription\n\n\nFreeBSD 8.0\n\n\nLinux 3.2.0\n\n\nMac OS X 10.6.8\n\n\nSolaris 10\n\n\n\n\n\n\n\n\n\n\nAFORK\n\n\nprocess is the result of \nfork\n, but never called \nexec\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nASU\n\n\nprocess used superuser privileges\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nACORE\n\n\nprocess dumped core\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nAXSIG\n\n\nprocess was killed by a signal\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nAEXPND\n\n\nexpanded accounting entry\n\n\n\n\n\n\n\n\nx\n\n\n\n\n\n\nANVER\n\n\nnew record format\n\n\nx\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe data required for the accounting record (e.g. CPU times and number of characters transferred) is kept by the kernel in the process table and initialized whenever a new process is created, as in the child after a \nfork\n. Each accounting record is written when the process terminates. This has two consequences:\n\n\n\n\nWe cannot get accounting records for processes that never terminate, such as \ninit\n and kernel daemons.\n\n\nThe order of the records in the accounting file corresponds to the termination order of the processes, not the order in which they were started. [p270]. We can\u2019t reconstruct the exact starting order of various processes, given the data in the accounting file.\n\n\n\n\nThe accounting records correspond to processes, not programs. A new record is initialized by the kernel for the child after a \nfork\n, not when a new program is executed. Although exec doesn\u2019t create a new accounting record, the command name changes, and the \nAFORK\n flag is cleared. For example, if A \nexec\ns B, then B \nexec\ns C, and C \nexit\n, only a single accounting record is written.  The command name in the record corresponds to program C, but the CPU times are the sum for programs A, B, and C.\n\n\nUser Identification\n\n\nAny process can find out its real and effective user ID and group ID. \ngetpwuid(getuid())\n can be used to find out the login name of the user who\u2019s running the program. However, a single user can have multiple login names, that is, a person might have multiple entries in the password file with the same user ID to have a different login shell for each entry. The system normally keeps track of the name we log in under the \nutmp\n file (see \nSection 6.8\n), and the \ngetlogin\n function provides a way to fetch that login name.\n\n\napue_getlogin.h\n\n\n#include \nunistd.h\n\n\n\nchar\n \n*\ngetlogin\n(\nvoid\n);\n\n\n\n/* Returns: pointer to string giving login name if OK, NULL on error */\n\n\n\n\n\n\nThis function can fail if the process is not attached to a terminal that a user logged in to. We normally call these processes \ndaemons\n.\n\n\nGiven the login name, we can then use it to look up the user in the password file (e.g. to determine the login shell) using \ngetpwnam\n.\n\n\nThe environment variable \nLOGNAME\n is usually initialized with the user\u2019s login name by \nlogin(1)\n and inherited by the login shell. However, a user can modify an environment variable, so we shouldn\u2019t use \nLOGNAME\n to validate the user in any way. Instead, we should use \ngetlogin\n.\n\n\nProcess Scheduling\n\n\nHistorically, the UNIX System provided processes with only coarse control over their scheduling priority. The scheduling policy and priority were determined by the kernel.\n\n\n\n\nA process could choose to run with lower priority by adjusting its \nnice value\n\n\nA process could be \"nice\" and reduce its share of the CPU by adjusting its nice value\n\n\n\n\n\n\nOnly a privileged process was allowed to increase its scheduling priority.\n\n\n\n\nIn the Single UNIX Specification, nice values range from 0 to \n(2*NZERO)\u22121\n, although some implementations support a range from 0 to \n2*NZERO\n. Lower nice values have higher scheduling priority. Lower nice values have higher scheduling priority. \n\"The more nice you are, the lower your scheduling priority is.\"\n \nNZERO\n is the default nice value of the system. [p276]\n\n\nA process can retrieve and change its nice value with the \nnice\n function. With this function, a process can affect only its own nice value; it can\u2019t affect the nice value of any other process.\n\n\napue_nice.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nnice\n(\nint\n \nincr\n);\n\n\n\n/* Returns: new nice value \u2212 NZERO if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe \nincr\n argument is added to the nice value of the calling process.\n\n\nIf \nincr\n is too large or too small, the system silently reduces it to the maximum or minimum legal value.\n\n\n-1 is a legal successful return value. We need to clear \nerrno\n before calling nice and check its value if nice returns \u22121. If the call to nice succeeds and the return value is \u22121, then errno will still be zero. If \nerrno\n is nonzero, it means that the call to nice failed.\n\n\n\n\n\n\n\n\nThe \ngetpriority\n function can be used to get the nice value for a process and for a group of related processes.\n\n\napue_getpriority.h\n\n\n#include \nsys/resource.h\n\n\n\nint\n \ngetpriority\n(\nint\n \nwhich\n,\n \nid_t\n \nwho\n);\n\n\n\n/* Returns: nice value between \u2212NZERO and NZERO\u22121 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe \nwhich\n argument can take on one of three following values; it controls how the \nwho\n argument is interpreted:\n\n\nPRIO_PROCESS\n: a process\n\n\nPRIO_PGRP\n: a process group\n\n\nPRIO_USER\n: a user ID\n\n\n\n\n\n\nThe \nwho\n argument:\n\n\n0 (a value of zero): the calling process, process group, or user (depending on the value of the \nwhich\n argument).\n\n\n\n\n\n\n\n\nWhen the which argument applies to more than one process, the highest priority (lowest value) of all the applicable processes is returned.\n\n\nThe \nsetpriority\n function can be used to set the priority of a process, a process group, or all the processes belonging to a particular user ID.\n\n\napue_setpriority.h\n\n\n#include \nsys/resource.h\n\n\n\nint\n \nsetpriority\n(\nint\n \nwhich\n,\n \nid_t\n \nwho\n,\n \nint\n \nvalue\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nwhich\n and \nwho\n arguments are the same as in the \ngetpriority\n function. The \nvalue\n is added to \nNZERO\n and this becomes the new nice value.\n\n\nA child process inherits the nice value from its parent process in FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10.\n\n\nProcess Times\n\n\nThree times can be measured:\n\n\n\n\nWall clock time\n\n\nUser CPU time\n\n\nSystem CPU time\n\n\n\n\nAny process can call the \ntimes\n function to obtain these values for itself and any terminated children.\n\n\napue_times.h\n\n\n#include \nsys/times.h\n\n\n\nclock_t\n \ntimes\n(\nstruct\n \ntms\n \n*\nbuf\n);\n\n\n\n/* Returns: elapsed wall clock time in clock ticks if OK, \u22121 on error */\n\n\n\n\n\n\nThis function fills in the \ntms\n structure pointed to by \nbuf\n:\n\n\nstruct\n \ntms\n \n{\n\n    \nclock_t\n \ntms_utime\n;\n \n/* user CPU time */\n\n    \nclock_t\n \ntms_stime\n;\n \n/* system CPU time */\n\n    \nclock_t\n \ntms_cutime\n;\n \n/* user CPU time, terminated children */\n\n    \nclock_t\n \ntms_cstime\n;\n \n/* system CPU time, terminated children */\n\n\n};\n\n\n\n\n\n\nThe \ntms\n structure does not contain any measurement for the wall clock time. Instead, the function returns the wall clock time as the value of the function. This value is measured from some arbitrary point in the past, so we can\u2019t use its absolute value; instead, we use its relative value. We call \ntimes\n and save the return value. At some later time, we call \ntimes\n again and subtract the earlier return value from the new return value. The difference is the wall clock time.\n\n\nThe two structure fields for child processes contain values only for children that we have waited for with one of the \nwait\n functions.\n\n\nAll the \nclock_t\n values returned by this function are converted to seconds using the number of clock ticks per second, the \n_SC_CLK_TCK\n value returned by \nsysconf\n, that is, divide the \nclock_t\n value by the \n_SC_CLK_TCK\n value. For example,\n\n\n[p280-282]\n\n\n#include \napue.h\n\n\n#include \nsys/times.h\n\n\n\nclock_t\n \nstart\n,\n \nend\n;\n\n\nlong\n \nclktck\n \n=\n \n0\n;\n\n\nstruct\n \ntms\n \ntmsstart\n,\n \ntmsend\n\n\n\nif\n \n((\nclktck\n \n=\n \nsysconf\n(\n_SC_CLK_TCK\n))\n \n \n0\n)\n\n    \nerr_sys\n(\nsysconf error\n);\n\n\n\nif\n \n((\nstart\n \n=\n \ntimes\n(\ntmsstart\n))\n \n==\n \n-\n1\n)\n \n/* starting values */\n\n    \nerr_sys\n(\ntimes error\n);\n\n\n\n/* do some work */\n\n\n\nif\n \n((\nend\n \n=\n \ntimes\n(\ntmsend\n))\n \n==\n \n-\n1\n)\n \n/* ending values */\n\n    \nerr_sys\n(\ntimes error\n);\n\n\n\nprintf\n(\n real: %7.2f\n\\n\n,\n \nreal\n \n/\n \n(\ndouble\n)\n \nclktck\n);\n\n\n\n\n\n\nSummary\n\n\nA thorough understanding of process control is essential for advanced UNIX programming. There are only a few functions to master: \nfork\n, the \nexec\n family, \n_exit\n, \nwait\n, and \nwaitpid\n. These primitives are used in many applications.\n\n\nExamination of the \nsystem\n function and process accounting gave us another look at all these process control functions.\n\n\nAn understanding of the various user IDs and group IDs that are provided (real, effective, and saved) is critical to writing safe set-user-ID programs.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np235 on \nvfork\n\n\n\n\nIf we call \nexit\n instead, the results are indeterminate. Depending on the implementation of the standard I/O library, we might see no difference in the output, or we might find that the output from the first \nprintf\n in the parent has disappeared.\n\n\n\n\nI think \"first \nprintf\n\" should be \"second \nprintf\n\", because the output of the first \nprintf\n is flushed. For the second \nprintf\n, it says \"no output will appear and \nprintf\n will return \u22121\".", 
            "title": "Chapter 8. Process Control"
        }, 
        {
            "location": "/apue/ch9/", 
            "text": "Chapter 9. Process Relationships\n\n\nIntroduction\n\n\nEvery process has a parent process (the initial kernel-level process is usually its own parent). The parent is notified when the child terminates, and the parent can obtain the child\u2019s exit status.\n\n\nThis chapter details process groups and the concept of session introduced by POSIX.1, as well as relationship between the login shell that is invoked when a user logs in and all the processes that are started from the login shell.\n\n\nThe concept of UNIX system signal mechanism in \nChapter 10\n is needed.\n\n\nTerminal Logins\n\n\nIn early UNIX systems, the terminals (dumb terminals that are hard-wired connected to the host) were either local (directly connected) or remote (connected through a modem). These logins came through a terminal device driver in the kernel. [p285]\n\n\nAs bitmapped graphical terminals became available, windowing systems were developed to provide users with new ways to interact with host computers.  Applications were developed to create \"terminal windows\" to emulate character-based terminals, allowing users to interact with hosts in familiar ways (i.e., via the shell command line).\n\n\nToday, some platforms allow you to start a windowing system after logging in, whereas other platforms automatically start the windowing system for you. In the latter case, you might still have to log in, depending on how the windowing system is configured (some windowing systems can be configured to log you in automatically).\n\n\nThe procedure that we now describe is used to log in to a UNIX system using a terminal. The procedure is similar regardless of the type of terminal we use. It could be a:\n\n\n\n\ncharacter-based terminal,\n\n\na graphical terminal emulating a simple character-based terminal,\n\n\nor a graphical terminal running a windowing system.\n\n\n\n\nBSD Terminal Logins\n\n\nThe file \n/etc/ttys\n (created by the system administrator) has one line per terminal device. Each line specifies the name of the device and other parameters (e.g. baud rate) that are passed to the \ngetty\n program.\n\n\nAfter the system is bootstrapped, the kernel creates the \ninit\n process (PID 1) which brings the system up in multiuser mode. The \ninit\n process reads the file \n/etc/ttys\n and, for every terminal device that allows a login, does a \nfork\n followed by an \nexec\n of the program \ngetty\n.\n\n\n\n\nAll the processes shown in the figure above have a real user ID of 0 and an effective user ID of 0 (they all have superuser privileges). All the processes other than the original \ninit\n process have a parent process ID of 1.\n\n\n\n\nThe \ninit\n process \nexec\ns the \ngetty\n program with an empty environment.\n\n\ngetty\n calls \nopen\n to open terminal device for reading and writing. File descriptors 0, 1, and 2 are set to the device.\n\n\nThen, \ngetty\n outputs something like \nlogin:\n and waits for us to enter our user name. \ngetty\n can detect special characters to change the terminal's speed (baud rate). [p287]\n\n\n\n\nWhen we enter our user name, \ngetty\n\u2019s job is complete, and it then invokes the \nlogin\n program, similar to:\n\n\nexecle(\n/bin/login\n, \nlogin\n, \n-p\n, username, (char *)0, envp);\n\n\n\n\n\n\n\n\n\nThough \ninit\n invokes \ngetty\n with an empty environment, \ngetty\n creates an environment for \nlogin\n (the \nenvp\n argument) with the name of the terminal (something like \nTERM=foo\n, where the type of terminal \nfoo\n is taken from the \ngettytab\n file) and any environment strings that are specified in the \ngettytab\n. The \n-p\n flag to \nlogin\n tells it to preserve the environment that it is passed and to add to that environment, not replace it.\n\n\n\n\nlogin\n does the following things:\n\n\nIt calls \ngetpwnam\n to fetch our password file entry.\n\n\nIt calls \ngetpass(3)\n to display the prompt \nPassword:\n and read our password (with echoing disabled).\n\n\nIt calls \ncrypt(3)\n to encrypt the password that we entered and compares the encrypted result to the \npw_passwd\n field from our shadow password file entry.\n\n\nIf the login attempt fails because of an invalid password (after a few tries), \nlogin\n calls \nexit\n with an argument of 1. This termination will be noticed by the parent (\ninit\n), and it will do another \nfork\n followed by an \nexec\n of \ngetty\n, starting the procedure over again for this terminal.\n\n\n\n\n\n\n\n\nThis is the traditional authentication procedure used on UNIX systems. Modern UNIX systems have evolved to support multiple authentication procedures. FreeBSD, Linux, Mac OS X, and Solaris all support a more flexible scheme known as PAM (\nPluggable Authentication Modules\n). PAM allows an administrator to configure the authentication methods to be used to access services that are written to use the PAM library. [p288]\n\n\nIf we log in correctly, \nlogin\n will:\n\n\n\n\nChange to our home directory (\nchdir\n)\n\n\nChange the ownership of our terminal device (\nchown\n) so we own it\n\n\nChange the access permissions for our terminal device so we have permission to read from and write to it\n\n\nSet our group IDs by calling \nsetgid\n and \ninitgroups\n\n\nInitialize the environment with all the information that login has:\n\n\nour home directory (\nHOME\n),\n\n\nshell (\nSHELL\n),\n\n\nuser name (\nUSER\n and \nLOGNAME\n),\n\n\nand a default path (\nPATH\n).\n\n\n\n\n\n\n\n\nChange to our user ID (\nsetuid\n) and invoke our login shell, as in\n\n\nexecl(\n/bin/sh\n, \n-sh\n, (char *)0);\n\n\n\n\n\nThe minus sign as the first character of \nargv[0]\n is a flag to all the shells that indicates they are being invoked as a \nlogin shell\n. The shells can look at this character and modify their start-up accordingly.\n\n\n\n\n\n\nThe \nlogin\n can optionally print the \nmessage-of-the-day\n file, check for new mail, and performs other tasks.\n\n\nSince it is called by a superuser process, \nsetuid\n changes all three user IDs: the real user ID, effective user ID, and saved set-user-ID. The call to \nsetgid\n that was done earlier by \nlogin\n has the same effect on all three group IDs.\n\n\nAt this point, our login shell is running. Its parent process ID is the original \ninit\n process (process ID 1), so when our login shell terminates, \ninit\n is sent a \nSIGCHLD\n signal and it starts the whole procedure over again for this terminal. File descriptors 0, 1, and 2 for our login shell are set to the terminal device. See the figure below:\n\n\n\n\nOur login shell now reads its start-up files (\n.profile\n for the Bourne shell and Korn shell; \n.bash_profile\n, \n.bash_login\n, or \n.profile\n for the GNU Bourne-again shell; and \n.cshrc\n and \n.login\n for the C shell). These start-up files usually change some of the environment variables and add many other variables to the environment. For example, most users set their own \nPATH\n and often prompt for the actual terminal type (\nTERM\n). When the start-up files are done, we finally get the shell\u2019s prompt and can enter commands.\n\n\nMac OS X Terminal Logins\n\n\nOn Mac OS X, the terminal login process follows essentially the same steps as in the BSD login process (since Mac OS X is based in part on FreeBSD) with the following differences:\n\n\n\n\nThe work of \ninit\n is performed by \nlaunchd\n.\n\n\nWe are presented with a graphical-based login screen from the start.\n\n\n\n\nLinux Terminal Logins\n\n\nThe Linux login procedure is very similar to the BSD procedure. The login command is derived from 4.3BSD. The main difference is in terminal configuration.\n\n\nSome Linux distributions ship with a version of the \ninit\n program that uses administrative files patterned after System V\u2019s \ninit\n file formats. where \n/etc/inittab\n specifies the terminal devices for which \ninit\n should start a \ngetty\n process. Other Linux distributions, such as Ubuntu, ship with a version of init that is known as \"\nUpstart\n\". It uses configuration files named \n*.conf\n that are\nstored in the \n/etc/init\n directory. For example, the specifications for running \ngetty\n on \n/dev/tty1\n might be found in the file \n/etc/init/tty1.conf\n.\n\n\nDepending on the version of \ngetty\n in use, the terminal characteristics are specified either on the command line (as with \nagetty\n) or in the file \n/etc/gettydefs\n (as with \nmgetty\n).\n\n\nSolaris Terminal Logins\n\n\n[p290]\n\n\nNetwork Logins\n\n\nThe main difference between a serial terminal login and a network login is that the connection between the terminal and the computer isn\u2019t point-to-point. In this case, \nlogin\n is simply a service available, just like any other network service, such as FTP or SMTP.\n\n\nWith the terminal logins, \ninit\n knows which terminal devices are enabled for logins and spawns a \ngetty\n process for each device. In the case of network logins, however, all the logins come through the kernel\u2019s network interface drivers (e.g., the Ethernet driver), and we don\u2019t know ahead of time how many of these will occur. Instead of having a process waiting for each possible login, we now have to wait for a network connection request to arrive.\n\n\nTo allow the same software to process logins over both terminal logins and network logins, a software driver called a \npseudo terminal\n (detailed in \nChapter 19\n) is used to emulate the behavior of a serial terminal and map terminal operations to network operations, and vice versa.\n\n\nBSD Network Logins\n\n\nIn BSD, the \ninetd\n process, sometimes called the \nInternet superserver\n, waits for most network connections.\n\n\nAs part of the system start-up, \ninit\n invokes a shell that executes the shell script \n/etc/rc\n, which starts \ninetd\n along with other daemons. Once the shell script terminates, the parent process of \ninetd\n becomes \ninit\n; \ninetd\n waits for TCP/IP connection requests to arrive at the host. When a connection request arrives for it to handle, \ninetd\n does a \nfork\n and \nexec\n of the appropriate program.\n\n\nAssume a TCP connection request arrives for the TELNET server (a remote login application). The remote user initiates the login by starting the TELNET client:\n\n\ntelnet hostname\n\n\n\n\n\nThe client opens a TCP connection to \nhostname\n and the user who started the client program is now logged in to the server\u2019s host. The figure below shows the sequence of processes involved in executing the TELNET server, called \ntelnetd\n:\n\n\n\n\nThen, \nthe \ntelnetd\n process then opens a pseudo terminal device and splits into two processes using \nfork\n,\n which do the following:\n\n\n\n\nThe parent (\ntelnetd\n) handles the communication across the network connection.\n\n\nThe child \nexec\ns the \nlogin\n program.\n\n\nThe parent and the child are connected through the pseudo terminal. Before doing the \nexec\n, the child sets up file descriptors 0, 1, and 2 to the pseudo terminal.\n\n\nIf we log in correctly, login performs the same steps described in \nSection 9.2\n: it changes to our home directory and sets our group IDs, user ID, and our initial environment. Then \nlogin\n replaces itself with our login shell by calling \nexec\n.\n\n\n\n\n\n\nWhether we log in through a terminal (\nFigure 9.3\n) or a network (\nFigure 9.5\n), we have a login shell with its standard input, standard output, and standard error connected to either a terminal device or a pseudo terminal device.\n\n\nIn the coming sections, we'll see that the login shell is the start of a POSIX.1 session, and that the terminal or pseudo terminal is the controlling terminal for the session.\n\n\nMac OS X Network Logins\n\n\nThe network login on Mac OS X is identical to that on BSD, except that the \ntelnet\n daemon is run from \nlaunchd\n. By default, the \ntelnet\n daemon is disabled on Mac OS X (although it can be enabled with the \nlaunchctl(1)\n command). The preferred way to perform a network login on Mac OS X is with \nssh\n, the secure shell command.\n\n\nLinux Network Logins\n\n\nNetwork logins under Linux are the same as under BSD, except that some distributions use an alternative \ninetd\n process called the extended Internet services daemon, \nxinetd\n. The \nxinetd\n process provides a finer level of control over services it starts compared to \ninetd\n.\n\n\nSolaris Network Logins\n\n\n[p293]\n\n\nProcess Groups\n\n\nIn addition to having a process ID, each process belongs to a \nprocess group\n.\n\n\n\n\nA process group is a collection of one or more processes (usually associated with the same job) that can receive signals from the same terminal.\n\n\nEach process group has a unique process group ID. Process group IDs are similar to process IDs: they are positive integers and can be stored in a \npid_t\n data type.\n\n\n\n\nThe function \ngetpgrp\n returns the process group ID of the calling process. The \ngetpgid\n function took a \npid\n argument and returned the process group for that process.\n\n\napue_getpgrp.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \ngetpgrp\n(\nvoid\n);\n\n\n/* Returns: process group ID of calling process */\n\n\n\npid_t\n \ngetpgid\n(\npid_t\n \npid\n);\n\n\n/* Returns: process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nFor \ngetpgid\n, if \npid\n is 0, the process group ID of the calling process is returned. Thus,\n\n\ngetpgid\n(\n0\n);\n\n\n\n\n\n\nis equivalent to:\n\n\ngetpgrp\n();\n\n\n\n\n\n\nEach process group can have a \nprocess group leader\n, whose process group ID equals to its process ID.\n\n\nProcess group lifetime\n\n\nThe process group life time is the period of time that begins when the group is created and ends when the last remaining process leaves the group. It is possible for a process group leader to create a process group, create processes in the group, and then terminate. The process group still exists, as long as at least one process is in the group, regardless of whether the group leader terminates. The last remaining process in the process group can either terminate or enter some other process group.\n\n\nsetpgid\n function\n\n\nA process can join an existing process group or creates a new process group by calling \nsetpgid\n.\n\n\napue_setpgid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsetpgid\n(\npid_t\n \npid\n,\n \npid_t\n \npgid\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nsetpgid\n function sets the process group ID of the process whose process ID equals \npid\n to \npgid\n.\n\n\nArguments:\n\n\n\n\nIf \npid\n == \npgid\n, the process specified by \npid\n becomes a process group leader.\n\n\nIf \npid\n == 0, the process ID of the caller is used.\n\n\nIf \npgid\n == 0, then the specified \npid\n is used as the process group ID.\n\n\n\n\nRules:\n\n\n\n\nA process can set the process group ID of only itself or any of its children.\n\n\nA process cannot change the process group ID of one of its children after that child has called one of the \nexec\n functions.\n\n\n\n\nJob-control shells\n\n\nIn most job-control shells, this function is called after a \nfork\n to have the parent set the process group ID of the child, and to have the child set its own process group ID. \nOne of these calls is redundant, but by doing both, we are guaranteed that the child is placed into its own process group before either process assumes that this has happened.  If we didn\u2019t do this, we would have a race condition, since the child\u2019s process group membership would depend on which process executes first.\n (See \nDoubts and Solutions\n for details) [p294]\n\n\nProcess groups and signals\n\n\nWe can send a signal to either a single process (identified by its process ID) or a process group (identified by its process group ID). Similarly, the \nwaitpid\n function lets us wait for either a single process or one process from a specified process group.\n\n\nSessions\n\n\nA \nsession\n is a collection of one or more process groups.\n\n\n\n\nThe processes in a process group are usually placed there by a shell pipeline. The arrangement in the figure above is generated by the shell commands of the form:\n\n\nproc1 \n|\n proc2 \n\nproc3 \n|\n proc4 \n|\n proc5\n\n\n\n\n\nThe \nsetsid\n function\n\n\nA process establishes a new session by calling the \nsetsid\n function.\n\n\napue_setsid.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \nsetsid\n(\nvoid\n);\n\n\n\n/* Returns: process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nIf the calling process is not a process group leader, this function creates a new session. Three things happen:\n\n\n\n\nThe process becomes the \nsession leader\n of this new session. (A session leader is the process that creates a session.) The process is the only process in this new session\n\n\nThe process becomes the process group leader of a new process group. The new process group ID is the process ID of the calling process.\n\n\nThe process has no controlling terminal. If the process had a controlling terminal before calling \nsetsid\n, that association is broken.\n\n\n\n\nThis function returns an error if the caller is already a process group leader.\n\n\nEnsuring the successful call of \nsetsid\n\n\nSince the \nsetsid\n function returns an error if the caller is a process group leader, to ensure this is not the case, the usual practice is to call \nfork\n and have the parent terminate and the child continue. It is guaranteed that the child is not a process group leader, because the process group ID of the parent is inherited by the child, but the child gets a new process ID. Hence, it is impossible for the child\u2019s process ID to equal its inherited process group ID.\n\n\nSession Leader and Session ID\n\n\nThe Single UNIX Specification talks only about a \"session leader\"; there is no \"session ID\" similar to a process ID or a process group ID. A session leader is a single process that has a unique process ID, so we could talk about a session ID that is the process ID of the session leader. This concept of a session ID was introduced in SVR4.\n\n\nThe \ngetsid\n function\n\n\nThe \ngetsid\n function returns the process group ID of a process\u2019s session leader.\n\n\napue_getsid.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \ngetsid\n(\npid_t\n \npid\n);\n\n\n\n/* Returns: session leader\u2019s process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nIf \npid\n is 0, \ngetsid\n returns the process group ID of the calling process\u2019s session leader. For security reasons, some implementations may restrict the calling process from obtaining the process group ID of the session leader if \npid\n doesn\u2019t belong to the same session as the caller.\n\n\nControlling Terminal\n\n\nSessions and process groups have a few other characteristics.\n\n\n\n\nA session can have a single \ncontrolling terminal\n. This is usually the terminal device (in the case of a \nterminal login\n) or pseudo terminal device (in the case of a \nnetwork login\n) on which we log in.\n\n\nThe session leader that establishes the connection to the controlling terminal is called the \ncontrolling process\n.\n\n\nThe process groups within a session can be divided into a single \nforeground process group\n and one or more \nbackground process groups\n.\n\n\nIf a session has a controlling terminal, it has a single foreground process group and all other process groups in the session are background process groups.\n\n\nWhenever we press the terminal\u2019s interrupt key (often DELETE or Control-C), the interrupt signal is sent to all processes in the foreground process group.\n\n\nWhenever we press the terminal\u2019s quit key (often Control-backslash), the quit signal is sent to all processes in the foreground process group.\n\n\nIf a modem (or network) disconnect is detected by the terminal interface, the hang-up signal is sent to the controlling process (the session leader).\n\n\n\n\nThese characteristics are shown in the figure below:\n\n\n\n\nUsually, the controlling terminal is established automatically when we log in.\n\n\nMechanisms of allocating a controlling terminal\n\n\nSystem V\n\n\nSystems derived from UNIX System V allocate the controlling terminal for a session when the session leader opens the first terminal device that is not already associated with a session, as long as the call to \nopen\n does not specify the \nO_NOCTTY\n flag.\n\n\nBSD\n\n\nBSD-based systems allocate the controlling terminal for a session when the session leader calls \nioctl\n with a request argument of \nTIOCSCTTY\n (the third argument is a null pointer). The session cannot already have a controlling terminal for this call to succeed. Normally, this call to \nioctl\n follows a call to \nsetsid\n, which guarantees that the process is a session leader without a controlling terminal.\n\n\nNote that although Mac OS X 10.6.8 is derived from BSD, it behaves like System V when allocating a controlling terminal.\n\n\n\n\n\n\n\n\nMethod\n\n\nFreeBSD 8.0\n\n\nLinux 3.2.0\n\n\nMac OS X 10.6.8\n\n\nSolaris 10\n\n\n\n\n\n\n\n\n\n\nopen\n without \nO_NOCTTY\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nTIOCSCTTY\n \nioctl\n command\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nWhen a program wants to talk to the controlling terminal, regardless of whether the standard input or standard output is redirected, it can \nopen\n the file \n/dev/tty\n. This special file is a synonym within the kernel for the controlling terminal. If the program doesn\u2019t have a controlling terminal, the \nopen\n of this device will fail.\n\n\nThe \ncrypt\n command and \ngetpass\n function\n\n\nThe classic example is the \ngetpass(3)\n function, which reads a password (with terminal echoing turned off, of course). [p298]\n\n\nThe \ngetpass\n function is called by the \ncrypt(1)\n program and can be used in a pipeline. For example:\n\n\ncrypt \n salaries \n|\n lpr\n\n\n\n\n\nIt decrypts the file salaries and pipes the output to the print spooler. Because \ncrypt\n reads its input file on its standard input, the standard input can\u2019t be used to enter the password. Also, \ncrypt\n is designed so that we have to enter the encryption password each time we run the program, to prevent us from saving the password in a file (which could be a security hole).\n\n\ntcgetpgrp\n, \ntcsetpgrp\n, and \ntcgetsid\n Functions\n\n\nWe need a way to tell the kernel which process group is the foreground process group, so that the terminal device driver knows where to send the terminal input and the terminal-generated signals. (\nFigure 9.7\n)\n\n\napue_tcgetpgrp.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \ntcgetpgrp\n(\nint\n \nfd\n);\n\n\n/* Returns: process group ID of foreground process group if OK, \u22121 on error */\n\n\n\nint\n \ntcsetpgrp\n(\nint\n \nfd\n,\n \npid_t\n \npgrpid\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe function \ntcgetpgrp\n returns the process group ID of the foreground process group associated with the terminal open on \nfd\n.\n\n\nIf the process has a controlling terminal, the process can call \ntcsetpgrp\n to set the foreground process group ID to \npgrpid\n. The value of \npgrpid\n must be the process group ID of a process group in the same session, and \nfd\n must refer to the controlling terminal of the session.\n\n\n\n\nThese two functions are normally called by job-control shells.\n\n\nThe \ntcgetsid\n function allows an application to obtain the process group ID for the session leader given a file descriptor for the controlling TTY.\n\n\napue_tcgetsid.h\n\n\n#include \ntermios.h\n\n\n\npid_t\n \ntcgetsid\n(\nint\n \nfd\n);\n\n\n\n/* Returns: session leader\u2019s process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nApplications that need to manage controlling terminals can use \ntcgetsid\n to identify the session ID of the controlling terminal\u2019s session leader, which is equivalent to the session leader\u2019s process group ID.\n\n\nJob Control\n\n\nJob control\n allows us to start multiple jobs (groups of processes) from a single terminal and to control which jobs can access the terminal and which jobs are run in the background. Job control requires three forms of support:\n\n\n\n\nA shell that supports job control\n\n\nThe terminal driver in the kernel must support job control\n\n\nThe kernel must support certain job-control signals\n\n\n\n\nFrom our perspective, when using job control from a shell, we can start a job in either the foreground or the background. A job is simply a collection of processes, often a pipeline of processes.\n\n\nFor example, start a job consisting of one process in the foreground:\n\n\nvi main.c\n\n\n\n\n\nStart two jobs in the background (all the processes invoked by these background jobs are in the background.):\n\n\npr *.c \n|\n lpr \n\nmake all \n\n\n\n\n\n\nKorn shell example\n\n\nWhen we start a background job, the shell assigns it a job identifier and prints one or more of the process IDs.\n\n\n$ make all \n Make.out \n\n\n[1] 1475\n\n\n$ pr *.c | lpr \n\n\n[2] 1490\n\n\n$   # just press RETURN\n\n\n[2] + Done pr *.c | lpr \n\n\n[1] + Done make all \n Make.out \n\n\n\n\n\n\n\n\nThe \nmake\n is job number 1 and the starting process ID is 1475. The next pipeline is job number 2 and the process ID of the first process is 1490.\n\n\nWhen the jobs are done and we press RETURN, the shell tells us that the jobs are complete. The reason we have to press RETURN is to have the shell print its prompt. The shell doesn\u2019t print the changed status of background jobs at any random time (only after we press RETURN and right before it prints its prompt, to let us enter a new command line). If the shell didn\u2019t do this, it could produce output while we were entering an input line.\n\n\nThe interaction with the terminal driver arises because a special terminal character affects the foreground job. The terminal driver looks for three special characters, which generate signals to (all processes in ) the foreground process group:\n\n\nSIGINT\n: generated by the interrupt character (typically DELETE or Control-C).\n\n\nSIGQUIT\n: generated by the quit character (typically Control-backslash).\n\n\nSIGTSTP\n: generated by the suspend character (typically Control-Z).\n\n\n\n\n\n\n\n\nWhile we can have a foreground job and one or more background jobs, only the foreground job receives terminal input (the characters that we enter at the terminal). It is not an error for a background job to try to read from the terminal, but the terminal driver detects this and sends a special signal to the background job: \nSIGTTIN\n. This signal normally stops the background job; by using the shell, we are notified of this event and can bring the job into the foreground so that it can read from the terminal.\n\n\ncat \n temp.foo \n   # start in background, but it\u2019ll read from standard input\n\n\n[1] 1681\n\n\n$                  # we press RETURN\n\n\n[1] + Stopped (SIGTTIN) cat \n temp.foo \n\n\n$ fg %1            # bring job number 1 into the foreground\n\n\ncat \n temp.foo     # the shell tells us which job is now in the foreground\n\n\nhello, world       # enter one line\n\n\n\u02c6D                 # type the end-of-file character\n\n\n$ cat temp.foo     # check that the one line was put into the file\n\n\nhello, world\n\n\n\n\n\n\n\n\nSIGTTIN\n: When the background \ncat\n tries to read its standard input (the controlling terminal), the terminal driver, knowing that it is a background job, sends the \nSIGTTIN\n signal to the background job.\n\n\nThe shell detects the change in status of its child (see \nwait\n and \nwaitpid\n function in \nSection 8.6\n) and tells us that the job has been stopped.\n\n\nThe shell\u2019s \nfg\n command move the stopped job into the foreground, which causes the shell to place the job into the foreground process group (tcsetpgrp) and send the continue signal (\nSIGCONT\n) to the process group.\n\n\nSince it is now in the foreground process group, the job can read from the controlling terminal.\n\n\n\n\nNote that this example doesn\u2019t work on Mac OS X 10.6.8. When we try to bring the cat command into the foreground, the read fails with errno set to EINTR. Since Mac OS X is based on FreeBSD, and FreeBSD works as expected, this must be a bug in Mac OS X.\n\n\nThere is an option that we can allow or disallow a background job to send its output to the controlling terminal. Normally, we use the \nstty(1)\n command to change this option.\n\n\n$ cat temp.foo \n   # execute in background\n\n\n[1] 1719\n\n\n$ hello, world     # the output from the background job appears after the prompt\n\n\nwe press RETURN\n\n\n[1] + Done cat temp.foo \n\n\n$ stty tostop      # disable ability of background jobs to output to controlling terminal\n\n\n$ cat temp.foo \n   # try it again in the background\n\n\n[1] 1721\n\n\n$                  # we press RETURN and find the job is stopped\n\n\n[1] + Stopped(SIGTTOU) cat temp.foo \n\n\n$ fg %1            # resume stopped job in the foreground\n\n\ncat temp.foo       # the shell tells us which job is now in the foreground\n\n\nhello, world       # and here is its output\n\n\n\n\n\n\nWhen we disallow background jobs from writing to the controlling terminal, cat will block when it tries to write to its standard output, because the terminal driver identifies the write as coming from a background process and sends the job the \nSIGTTOU\n signal. When we use the shell\u2019s \nfg\n command to bring the job into the foreground, the job completes.\n\n\nThe figure below summarizes some of the features of job control that have been described so far:\n\n\n\n\n\n\nThe solid lines through the terminal driver box mean that the terminal I/O and the terminal-generated signals are always connected from the foreground process group to the actual terminal.\n\n\nThe dashed line corresponding to the \nSIGTTOU\n signal means that whether the output from a process in the background process group appears on the terminal is an option.\n\n\n\n\nJob control was originally designed and implemented before windowing terminals were widespread. It is a required feature of POSIX.1. [p302-303]\n\n\nShell Execution of Programs\n\n\nThis section examines how the shells execute programs and how this relates to the concepts of process groups, controlling terminals, and sessions\n\n\nThe shell without job control: the Bourne shell on Solaris\n\n\nFor example, with the classic Bourne shell running on Solaris, we execute:\n\n\nps -o pid,ppid,pgid,sid,comm\n\n\n\n\n\nThe output is\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1774   949   949  949 ps\n\n\n\n\n\n\n\nThe parent of the \nps\n command is the shell.\n\n\nBoth the shell and the \nps\n command are in the same session and foreground process group (949), \nbecause that is what you get when you execute a command with a shell that doesn\u2019t support job control.\n\n\n\n\nTerminal process group ID: \ntpgid\n option of the \nps(1)\n command\n\n\n[p303]\n\n\nSome platforms support an \ntpgid\n option to have the \nps(1)\n command print the process group ID associated with the session\u2019s controlling terminal. This value would be shown under the TPGID column:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm\n\n\n\n\n\nNote that it is misleading to associate a process with a terminal process group ID (the TPGID column):\n\n\n\n\nA process does not have a terminal process control group. A process belongs to a process group, and the process group belongs to a session.\n\n\nThe session may or may not have a controlling terminal.\n\n\nIf the session does have a controlling terminal, then the terminal device knows the process group ID of the foreground process. This value can be set in the terminal driver with the \ntcsetpgrp\n function (\nFigure 9.9\n).\n\n\n\n\n\n\nThe foreground process group ID is an attribute of the terminal, not the process. This value from the terminal device driver is what \nps\n prints as the TPGID. If it finds that the session doesn\u2019t have a controlling terminal, \nps\n prints either 0 or \u22121, depending on the platform.\n\n\n\n\nIf we execute the command in the background:\n\n\nps -o pid,ppid,pgid,sid,comm \n\n\n\n\n\n\nThe only value that changes is the process ID of the command:\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1812   949   949  949 ps\n\n\n\n\n\nThis shell doesn\u2019t know about job control, so the background job is not put into its own process group and the controlling terminal isn\u2019t taken away from the background job.\n\n\nTo see how this shell handles a pipeline, we execute:\n\n\nps -o pid,ppid,pgid,sid,comm \n|\n cat1\n\n\n\n\n\nThe output is:\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1823   949   949  949 cat1\n 1824  1823   949  949 ps\n\n\n\n\n\nThe program \ncat1\n is just a copy of the standard \ncat\n program, with a different name. The last process in the pipeline (\ncat\n) is the child of the shell and that the first process in the pipeline (\nps\n) is a child of the last process. It appears that \nthe shell \nfork\ns a copy of itself and that this copy then forks to make each of the previous processes in the pipeline.\n\n\nIf we execute the pipeline in the background:\n\n\nps -o pid,ppid,pgid,sid,comm \n|\n cat1 \n\n\n\n\n\n\nOnly the process IDs change. Since the shell doesn\u2019t handle job control, the process group ID of the background processes remains 949, as does the process group ID of the session\n\n\nIf a background process tries to read from its controlling terminal, like:\n\n\ncat \n temp.foo \n\n\n\n\n\n\nWithout job control, the shell automatically redirects the standard input of a background process to \n/dev/null\n, if the process doesn\u2019t redirect standard input itself. A read from \n/dev/null\n generates an end of file. This means that our background \ncat\n process immediately reads an end of file and terminates normally.\n\n\nThe previous paragraph adequately handles the case of a background process accessing the controlling terminal through its standard input, but what happens if a background process specifically opens \n/dev/tty\n and reads from the controlling terminal? The answer is \"It depends\", but the result is probably not what we want. For example:\n\n\ncrypt \n salaries \n|\n lpr \n\n\n\n\n\n\nThis pipeline is run in the background, but the \ncrypt\n program opens \n/dev/tty\n, changes the terminal characteristics (to disable echoing), reads from the device, and resets the terminal characteristics. The prompt \nPassword:\n from \ncrypt\n is printed on the terminal, but what we enter (the encryption password) is read by the shell, which tries to execute a command of that name. The next line we enter to the shell is taken as the password, and the file is not encrypted correctly, sending junk to the printer. Here we have two processes trying to read from the same device at the same time, and the result depends on the system. Job control, as described earlier, handles this multiplexing of a single terminal between multiple processes in a better fashion. [p304]\n\n\nIf we execute three processes in the pipeline, we can examine the process control used by this shell:\n\n\nps -o pid,ppid,pgid,sid,comm \n|\n cat1 \n|\n cat2\n\n\n\n\n\nThe output is: [p305]\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1988   949   949  949 cat2\n 1989  1988   949  949 ps\n 1990  1988   949  949 cat1\n\n\n\n\n\nAgain, the last process in the pipeline is the child of the shell, and all previous processes in the pipeline are children of the last process. See the figure below:\n\n\n\n\nSince the last process in the pipeline is the child of the login shell, the shell is notified when that process (\ncat2\n) terminates.\n\n\nThe shell with job control: Bourne-again shell on Linux\n\n\nStarting with this example, foreground process group are shown in \nbolder font\n.\n\n\nThe command:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm\n\n\n\n\n\ngives us:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  2837   2818   2837  2837   5796  bash\n  \n5796\n   2837   \n5796\n  2837   5796  ps\n\n\n\n\nWe can see the result, which is different from the Bourne shell example:\n\n\n\n\nThe Bourne-again shell places the foreground job (\nps\n) into its own process group (5796).\n\n\nThe \nps\n command is the process group leader and the only process in this process group. This process group is the foreground process group, since it has the controlling terminal.\n\n\nThe login shell is a background process group while the \nps\n command executes.\n\n\nBoth process groups, 2837 and 5796, are members of the same session.\n\n\n\n\nExecuting this process in the background:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm \n\n\n\n\n\n\ngives us:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  \n2837\n   2818   \n2837\n  2837   2837  bash\n  5797   2837   5797  2837   2837  ps\n\n\n\n\n\n\nps\n command is again placed into its own process group.\n\n\nThe process group (5797) is no longer the foreground process group but a background process group.\n\n\nThe foreground process group is our login shell, as indicated by TPGID of 2837.\n\n\n\n\nExecuting two processes in a pipeline, as in:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm \n|\n cat1\n\n\n\n\n\ngives us:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  2837   2818   2837  2837   5799  bash\n  \n5799\n   2837   \n5799\n  2837   5799  ps\n  \n5800\n   2837   \n5799\n  2837   5799  cat1\n\n\n\n\n\n\nBoth processes, \nps\n and \ncat1\n, are placed into a new process group (5799), which is the foreground process group.\n\n\nThe login shell is the parent of both processes. This is different from the Bourne shell, which created the last process (\ncat1\n) in the pipeline first, and this process is the parent of first process (\nps\n).\n\n\n\n\nIf we execute this pipeline in the background:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm \n|\n cat1 \n\n\n\n\n\n\nThe output:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  \n2837\n   2818   \n2837\n  2837   2837  bash\n  5801   2837   5801  2837   2837  ps\n  5802   2837   5801  2837   2837  cat1\n\n\n\n\nThe results are similar, but now \nps\n and \ncat1\n are placed in the same background process group (5801).\n\n\n[p307]\n\n\nOrphaned Process Groups\n\n\nA process whose parent terminates is called an orphan and is inherited by the \ninit\n process. The entire process groups that can be orphaned and this section discusses how POSIX.1 handles this situation.\n\n\nExample of a process whose child is stopped\n\n\nThe following figure shows a situation: the parent process has \nfork\ned a child that stops, and the parent is about to exit.\n\n\n\n\nThe program that creates an orphaned process group is shown below:\n\n\n\n\nrelation/orphan3.c\n\n\n\n\n#include \napue.h\n\n\n#include \nerrno.h\n\n\n\nstatic\n \nvoid\n\n\nsig_hup\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\nSIGHUP received, pid = %ld\n\\n\n,\n \n(\nlong\n)\ngetpid\n());\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\npr_ids\n(\nchar\n \n*\nname\n)\n\n\n{\n\n    \nprintf\n(\n%s: pid = %ld, ppid = %ld, pgrp = %ld, tpgrp = %ld\n\\n\n,\n\n        \nname\n,\n \n(\nlong\n)\ngetpid\n(),\n \n(\nlong\n)\ngetppid\n(),\n \n(\nlong\n)\ngetpgrp\n(),\n\n        \n(\nlong\n)\ntcgetpgrp\n(\nSTDIN_FILENO\n));\n\n    \nfflush\n(\nstdout\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nchar\n    \nc\n;\n\n    \npid_t\n   \npid\n;\n\n\n    \npr_ids\n(\nparent\n);\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n \n0\n)\n \n{\n   \n/* parent */\n\n        \nsleep\n(\n5\n);\n       \n/* sleep to let child stop itself */\n\n    \n}\n \nelse\n \n{\n            \n/* child */\n\n        \npr_ids\n(\nchild\n);\n\n        \nsignal\n(\nSIGHUP\n,\n \nsig_hup\n);\n    \n/* establish signal handler */\n\n        \nkill\n(\ngetpid\n(),\n \nSIGTSTP\n);\n    \n/* stop ourself */\n\n        \npr_ids\n(\nchild\n);\n    \n/* prints only if we\nre continued */\n\n        \nif\n \n(\nread\n(\nSTDIN_FILENO\n,\n \nc\n,\n \n1\n)\n \n!=\n \n1\n)\n\n            \nprintf\n(\nread error %d on controlling TTY\n\\n\n,\n \nerrno\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResult in a job-control shell:\n\n\n$ ./a.out\n\n\nparent: pid = 6099, ppid = 2837, pgrp = 6099, tpgrp = 6099\n\n\nchild: pid = 6100, ppid = 6099, pgrp = 6099, tpgrp = 6099\n\n\n$ SIGHUP received, pid = 6100\n\n\nchild: pid = 6100, ppid = 1, pgrp = 6099, tpgrp = 2837\n\n\nread error 5 on controlling TTY\n\n\n\n\n\n\nAnalysis: [p307-309]\n\n\n\n\nThe shell places the foreground process into its own process group (6099) and the shell itself stays in its own process group (2837). The child inherits the process group of its parent (6099).\n\n\nAfter \nfork\n, the parent sleeps for 5 seconds. This is our (imperfect) way of letting the child execute before the parent terminates.\n\n\nThe child establishes a signal handler for the hang-up signal (\nSIGHUP\n) so we can see whether it is sent to the child. (signal handlers are discussed in \nChapter 10\n)\n\n\nThe child sends itself the stop signal (\nSIGTSTP\n) with the \nkill\n function. This stops the child, similar to our stopping a foreground job with our terminal\u2019s suspend character (Control-Z).\n\n\nWhen the parent terminates, the child is orphaned, so the child\u2019s parent process ID becomes 1, which is the \ninit\n process ID.\n\n\nAt this point, the child is a member of an \norphaned process group\n:\n\n\nThe POSIX.1 definition of an orphaned process group: one in which the parent of every member is either itself a member of the group or is not a member of the group\u2019s session. Another way of saying this is: \nthe process group is not orphaned as long as a process in the group has a parent in a different process group but in the same session.\n\n\nIf the process group is not orphaned, there is a chance that one of those parents in a different process group but in the same session will restart a stopped process in the process group that is not orphaned. Here, the parent of every process in the group (e.g., process 1 is the parent of process 6100) belongs to another session.\n\n\n\n\n\n\nSince the process group is orphaned when the parent terminates, and the process group contains a stopped process, POSIX.1 requires that every process in the newly orphaned process group be sent the hang-up signal (\nSIGHUP\n) followed by the continue signal (\nSIGCONT\n).\n\n\nThis causes the child to be continued, after processing the hang-up signal. The default action for the hang-up signal is to terminate the process, so we have to provide a signal handler to catch the signal. We therefore expect the \nprintf\n in the \nsig_hup\n function to appear before the \nprintf\n in the \npr_ids\n function.\n\n\n\n\n\n\nNote that the shell prompt appears with the output from the child, because two processes (login shell and the child) are writing to the terminal. The parent process ID of the child has become 1.\n\n\nAfter calling \npr_ids\n in the child, the program tries to read from standard input. POSIX.1 specifies that the \nread\n is to return an error with \nerrno\n set to \nEIO\n (whose value is 5 on this system) in this situation. [p309]\n\n\nAs discussed earlier in this chapter, when a process in a background process group tries to read from its controlling terminal, \nSIGTTIN\n is generated for the background process group. But for an orphaned process group, if the kernel were to stop it with this signal, the processes in the process group would probably never be continued.\n\n\n\n\n\n\nFinally, our child was placed in a background process group when the parent terminated, since the parent was executed as a foreground job by the shell.\n\n\n\n\nFreeBSD Implementation\n\n\nThe figure below shows the FreeBSD implementation of sessions and process groups:\n\n\n\n\n\n\nsession\n structure is allocated for each session (each time \nsetsid\n is called).\n\n\ns_count\n: number of process groups in the session. When this counter is decremented to 0, the structure can be freed.\n\n\ns_leader\n: pointer to the proc structure of the session leader.\n\n\ns_ttyvp\n: pointer to the vnode structure of the controlling terminal.\n\n\ns_ttyp\n: pointer to the tty structure of the controlling terminal.\n\n\ns_sid\n: session ID. (Not part of the Single UNIX Specification)\n\n\n\n\n\n\n\n\nWhen \nsetsid\n is called, a new session structure is allocated within the kernel. \ns_count\n is set to 1, \ns_leader\n is set to point to the \nproc\n structure of the calling process, \ns_sid\n is set to the process ID, and \ns_ttyvp\n and \ns_ttyp\n are set to null pointers, since the new session doesn\u2019t have a controlling terminal.\n\n\n\n\ntty\n structure is contained in the kernel for each terminal device and each pseudo terminal device.\n\n\nt_session\n points to the \nsession\n structure that has this terminal as its controlling terminal. This pointer is used by the terminal to send a hangup signal to the session leader if the terminal loses carrier (\nFigure 9.7\n). Note that the \ntty\n and \nsession\n structure point to each other.\n\n\nt_pgrp\n points to the \npgrp\n structure of the foreground process group. This field is used by the terminal driver to send signals to the foreground process group. The three signals generated by entering special characters that are sent to the foreground process group are:\n\n\ninterrupt\n\n\nquit\n\n\nsuspend\n\n\n\n\n\n\nt_termios\n is a structure containing all the special characters and related information for this terminal, such as baud rate, whether echo is enabled, and so on.\n\n\nt_winsize\n is a \nwinsize\n structure that contains the current size of the terminal window. When the size of the terminal window changes, the \nSIGWINCH\n signal is sent to the foreground process group.\n\n\n\n\n\n\n\n\nThe kernel finds the foreground process group of a particular session by following fields of pointers, starting with the \nsession\n structure:\n\n\n\n\nFollow \ns_ttyp\n of the \nsession\n structure to get to the \ntty\n structure (controlling terminal).\n\n\n\n\nFollow \nt_pgrp\n of the \ntty\n structure to get to the \npgrp\n structure (foreground process group).\n\n\n\n\n\n\npgrp\n structure contains the information for a particular process group.\n\n\n\n\npg_id\n is the process group ID.\n\n\npg_session\n points to the \nsession\n structure for the session to which this process group belongs.\n\n\npg_members\n is a pointer to the list of \nproc\n structures that are members of this process group. The \np_pglist\n structure in that \nproc\n structure is a doubly linked list entry that points to both the next process and the previous process in the group. [p311]\n\n\n\n\n\n\nvnode\n structureis allocated when the controlling terminal device is opened. All references to \n/dev/tty\n in a process go through this \nvnode\n structure.\n\n\n\n\nSummary\n\n\nThis chapter describes relation between groups of processes, sessions, which are made up of process groups. Job control is a feature supported by most UNIX systems. The controlling terminal for a process, \n/dev/tty\n, is also involved in these process relationships.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np294 on \nfork\n's race condition concerning \nsetpgid\n\n\n\n\nIn most job-control shells, this function is called after a \nfork\n to have the parent set the process group ID of the child, and to have the child set its own process group ID. One of these calls is redundant, but by doing both, we are guaranteed that the child is placed into its own process group before either process assumes that this has happened.  If we didn\u2019t do this, we would have a race condition, since the child\u2019s process group membership would depend on which process executes first.\n\n\n\n\nSolution:\n\n\nThe shell (parent) wants and ensures the process to be in the right process group at any time before either of the child and parent continues execution.\n\n\n\n\nStack Overflow\n\n\nLaunching Jobs\n in the GNU C Library", 
            "title": "Chapter 9. Process Relationships"
        }, 
        {
            "location": "/apue/ch10/", 
            "text": "Chapter 10. Signals\n\n\nIntroduction\n\n\nSignals are software interrupts. They provide a way of handling asynchronous events. Most nontrivial application programs need to deal with signals.\n\n\nPOSIX reliable signals\n\n\nSignals have been provided since the early versions of the UNIX System, but the signal model provided with systems such as Version 7 was not reliable. Signals could get lost, and it was difficult for a process to turn off selected signals when executing critical regions of code. Both 4.3BSD and SVR3 made changes to the signal model, adding what are called \nreliable signals\n. But the changes made by Berkeley and AT\nT were incompatible. Fortunately, POSIX.1 standardized the reliable-signal routines, and that is what we describe here.\n\n\nThis chapter starts with an overview of signals and a description of what each signal is normally used for, then discusses problems with earlier implementations, since it is often important to understand what is wrong with an implementation before seeing how to do things correctly. This chapter contains numerous examples that are not entirely correct and a discussion of the defects.\n\n\nSignal Concepts\n\n\n\n\n\n\nEvery signal has a name. They all begin with the three characters \nSIG\n. For example:\n\n\n\n\nSIGABRT\n is the abort signal that is generated when a process calls the \nabort\n function.\n\n\nSIGALRM\n is the alarm signal that is generated when the timer set by the \nalarm\n function goes off.\n\n\n\n\nFreeBSD 8.0 supports 32 different signals. Mac OS X 10.6.8 and Linux 3.2.0 each support 31 different signals, whereas Solaris 10 supports 40 different signals. FreeBSD, Linux, and Solaris, support additional application-defined signals introduced to support \nreal-time applications\n.\n\n\n\n\n\n\nSignal names are all defined by positive integer constants (the signal number) in the header \nsignal.h\n.\n\n\n\n\nImplementations actually define the individual signals in a different header file, but this header file is included by \nsignal.h\n.\n\n\nIt bad for the kernel to include header files meant for user-level applications, so if the applications and the kernel both need the same definitions, the information is placed in a kernel header file that is then included by the user-level header file.\n\n\nsys/signal.h\n: FreeBSD 8.0 and Mac OS X 10.6.8\n\n\nbits/signum.h\n: Linux 3.2.0\n\n\nsys/iso/signal_iso.h\n: Solaris 10\n\n\n\n\n\n\n\n\n\n\nNo signal has a signal number of 0. The \nkill\n function uses the signal number of 0 for a special case. POSIX.1 calls this value the null signal.\n\n\nNumerous conditions can generate a signal:\n\n\nThe terminal-generated signals occur when users press certain terminal keys. Pressing the DELETE key or Control-C on the terminal normally causes the interrupt signal (\nSIGINT\n) to be generated.\n\n\nHardware exceptions generate signals. For example, divide by 0 and invalid memory reference. These conditions are usually detected by the hardware, and the kernel is notified. The kernel then generates the appropriate signal for the process that was running at the time the condition occurred. For example, \nSIGSEGV\n is generated for a process that executes an invalid memory reference.\n\n\nThe \nkill(2)\n function allows a process to send any signal to another process or process group, with limitations: we have to be the owner of the process that we\u2019re sending the signal to, or we have to be the superuser.\n\n\nThe \nkill(1)\n command allows us to send signals to other processes. This program is just an interface to the \nkill\n function. This command is often used to terminate a runaway background process.\n\n\nSoftware conditions can generate signals when a process should be notified of various events. For example:\n\n\nSIGURG\n: generated when out-of-band data arrives over a network connection),\n\n\nSIGPIPE\n: generated when a process writes to a pipe that has no reader)\n\n\nSIGALRM\n: generated when an alarm clock set by the process expires).\n\n\n\n\n\n\n\n\n\n\n\n\nSignals are classic examples of asynchronous events. They occur at random times to the process. The process can\u2019t simply test a variable (such as \nerrno\n) to see whether a signal has occurred; instead, the process has to tell the kernel \"if and when this signal occurs, do the following\".\n\n\nSignal dispositions\n\n\nWe can tell the kernel to do one of three things when a signal occurs. This is called the \ndisposition of the signal\n, or the \naction associated with a signal\n. (\nsignal(7)\n)\n\n\n\n\nIgnore the signal\n. Most signals can be ignored, but two signals can never be ignored: \nSIGKILL\n and \nSIGSTOP\n.\n\n\nThe reason these two signals can\u2019t be ignored is to provide the kernel and the superuser with a surefire way of either killing or stopping any process.\n\n\nIf we ignore some of the signals that are generated by a hardware exception (such as illegal memory reference or divide by 0), the behavior of the process is undefined.\n\n\n\n\n\n\nCatch the signal\n. To do this, we tell the kernel to call a function of ours whenever the signal occurs. In our function, we can do whatever we want to handle the condition. For example:\n\n\nIf we\u2019re writing a command interpreter, when the user generates the interrupt signal at the keyboard, we probably want to return to the main loop of the program, terminating whatever command we were executing for the user.\n\n\nIf the \nSIGCHLD\n signal is caught, it means that a child process has terminated, so the signal-catching function can call \nwaitpid\n to fetch the child\u2019s process ID and termination status.\n\n\nIf the process has created temporary files, we may want to write a signal-catching function for the SIGTERM signal (the termination signal that is the default signal sent by the kill command) to clean up the temporary files.\n\n\nNote that the two signals \nSIGKILL\n and \nSIGSTOP\n can\u2019t be caught.\n\n\n\n\n\n\nLet the default action apply\n. Every signal has a default action. The default action for most signals is to terminate the process.\n\n\n\n\nThe signals \nSIGKILL\n and \nSIGSTOP\n cannot be caught, blocked, or ignored. (\nsignal(7)\n)\n\n\nUNIX System signals\n\n\nThe following table lists the names of all the signals, an indication of which systems support the signal, and the default action for the signal. The SUS column contains \"x\" if the signal is defined as part of the base POSIX.1 specification and XSI if it is defined as part of the XSI option. The supported systems are FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8 and Solaris 10.\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nISO C\n\n\nSUS\n\n\nFreeBSD\n\n\nLinux\n\n\nMac OS X\n\n\nSolaris\n\n\nDefault action\n\n\n\n\n\n\n\n\n\n\nSIGABRT\n\n\nabnormal termination (\nabort\n)\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGALRM\n\n\ntimer expired (\nalarm\n)\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGBUS\n\n\nhardware fault\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGCANCEL\n\n\nthreads library internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGCHLD\n\n\nchange in status of child\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGCONT\n\n\ncontinue stopped process\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\ncontinue/ignore\n\n\n\n\n\n\nSIGEMT\n\n\nhardware fault\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGFPE\n\n\narithmetic exception\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGFREEZE\n\n\ncheckpoint freeze\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGHUP\n\n\nhangup\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGILL\n\n\nillegal instruction\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGINFO\n\n\nstatus request from keyboard\n\n\n\n\n\n\nx\n\n\n\n\nx\n\n\n\n\nignore\n\n\n\n\n\n\nSIGINT\n\n\nterminal interrupt character\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGIO\n\n\nasynchronous I/O\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate/ignore\n\n\n\n\n\n\nSIGIOT\n\n\nhardware fault\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGJVM1\n\n\nJava virtual machine internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGJVM2\n\n\nJava virtual machine internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGKILL\n\n\ntermination\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGLOST\n\n\nresource lost\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGLWP\n\n\nthreads library internal use\n\n\n\n\n\n\nx\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGPIPE\n\n\nwrite to pipe with no readers\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGPOLL\n\n\npollable event (\npoll\n)\n\n\n\n\n\n\n\n\nx\n\n\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGPROF\n\n\nprofiling time alarm (\nsetitimer\n)\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGPWR\n\n\npower fail/restart\n\n\n\n\n\n\n\n\nx\n\n\n\n\nx\n\n\nterminate/ignore\n\n\n\n\n\n\nSIGQUIT\n\n\nterminal quit character\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGSEGV\n\n\ninvalid memory reference\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGSTKFLT\n\n\ncoprocessor stack fault\n\n\n\n\n\n\n\n\nx\n\n\n\n\n\n\nterminate\n\n\n\n\n\n\nSIGSTOP\n\n\nstop\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGSYS\n\n\ninvalid system call\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGTERM\n\n\ntermination\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGTHAW\n\n\ncheckpoint thaw\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGTHR\n\n\nthreads library internal use\n\n\n\n\n\n\nx\n\n\n\n\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGTRAP\n\n\nhardware fault\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGTSTP\n\n\nterminal stop character\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGTTIN\n\n\nbackground read from control tty\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGTTOU\n\n\nbackground write to control tty\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGURG\n\n\nurgent condition (sockets)\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGUSR1\n\n\nuser-defined signal\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGUSR2\n\n\nuser-defined signal\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGVTALRM\n\n\nvirtual time alarm (\nsetitimer\n)\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGWAITING\n\n\nthreads library internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGWINCH\n\n\nterminal window size change\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGXCPU\n\n\nCPU limit exceeded (\nsetrlimit\n)\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core/ignore\n\n\n\n\n\n\nSIGXFSZ\n\n\nfile size limit exceeded (\nsetrlimit\n)\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core/ignore\n\n\n\n\n\n\nSIGXRES\n\n\nresource control exceeded\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\n\n\nThe core file\n\n\nWhen the default action (in the table above) is labeled \"terminate+core\", it means that a memory image of the process is left in the file named \ncore\n of the current working directory of the process. This file can be used with most UNIX System debuggers to examine the state of the process at the time it terminated.\n\n\nThe name of the \ncore\n file varies among implementations.  On Mac OS X 10.6.8, the core file is named core.\npid\n, where \npid\n is the ID of the process that received the signal. On Linux 3.2.0, the name is configured through \n/proc/sys/kernel/core_pattern\n. (\ncore(5)\n) [p315]\n\n\nMost implementations leave the core file in the current working directory of the corresponding process; Mac OS X places all core files in \n/cores\n instead.\n\n\nThe core file will not be generated if:\n\n\n\n\nthe process was set-user-ID and the current user is not the owner of the program file,\n\n\nthe process was set-group-ID and the current user is not the group owner of the file,\n\n\nthe user does not have permission to write in the current working directory,\n\n\nthe file already exists and the user does not have permission to write to it,\n\n\nthe file is too big (see \nRLIMIT_CORE\n limit in \nSection 7.11\n)\n\n\n\n\nThe permissions of the core file (assuming that the file doesn\u2019t already exist) are usually user-read and user-write, although Mac OS X sets only user-read.\n\n\nIn the table, the signals with a description of \"hardware fault\" correspond to implementation-defined hardware faults.\n\n\nDetailed description of signals\n\n\n\n\nSIGABRT\n: generated by calling the \nabort\n function.  The process terminates abnormally.\n\n\nSIGALRM\n:\n\n\nThis signal is generated when a timer set with the \nalarm\n function expires.\n\n\nThis signal is also generated when an interval timer set by the \nsetitimer(2)\n function expires.\n\n\n\n\n\n\nSIGBUS\n: indicates an implementation-defined hardware fault.  Implementations usually generate this signal on certain types of memory faults.\n\n\nSIGCANCEL\n: used internally by the Solaris threads library. It is not meant for general use.\n\n\nSIGCHLD\n: Whenever a process terminates or stops, the \nSIGCHLD\n signal is sent to the parent. By default, this signal is ignored, so the parent must catch this signal if it wants to be notified whenever a child\u2019s status changes. The normal action in the signal-catching function is to call one of the \nwait\n functions to fetch the child\u2019s process ID and termination status. [p317]\n\n\nSIGCONT\n: this job-control signal is sent to a stopped process when it is continued. The default action is to continue a stopped process, but to ignore the signal if the process wasn\u2019t stopped.\n\n\nSIGEMT\n: indicates an implementation-defined hardware fault. Not all platforms support this signal. [p318]\n\n\nSIGFPE\n: signals an arithmetic exception, such as divide by 0, floating-point overflow, and so on. The name is derived from \"floating-point exception\" (\nProgram Error Signals\n).\n\n\nSIGFREEZE\n: defined only by Solaris. \n [p318]\n\n\nSIGHUP\n: this signal is sent to the controlling process (session leader) associated with a controlling terminal if a disconnect is detected by the terminal interface.\n\n\nThis signal is generated for this condition only if the terminal\u2019s \nCLOCAL\n flag is not set. The \nCLOCAL\n flag for a terminal is set if the attached terminal is local. The flag tells the terminal driver to ignore all modem status lines.\n\n\nThe session leader that receives this signal may be in the background (\nFigure 9.7\n). This differs from the normal terminal-generated signals (interrupt, quit, and suspend), which are always delivered to the foreground process group.\n\n\nThis signal is also generated if the session leader terminates. In this case, the signal is sent to each process in the foreground process group.\n\n\nThis signal is commonly used to notify daemon processes (\nChapter 13\n) to reread their configuration files. The reason \nSIGHUP\n is chosen for this task is that a daemon should not have a controlling terminal and would normally never receive this signal.\n\n\n\n\n\n\nSIGILL\n: indicates that the process has executed an illegal hardware instruction.\n\n\n4.3BSD generated this signal from the abort function. \nSIGABRT\n is now used for this purpose.\n\n\n\n\n\n\nSIGINFO\n: This BSD signal is generated by the terminal driver when we type the status key (often Control-T). This signal is sent to all processes in the foreground process group (Figure 9.9). This signal normally causes status information on processes in the foreground process group to be displayed on the terminal. Linux doesn\u2019t provide support for \nSIGINFO\n.\n\n\nSIGINT\n: generated by the terminal driver when we press the interrupt key (often DELETE or Control-C). This signal is sent to all processes in the foreground process group (\nFigure 9.9\n). This signal is often used to terminate a runaway program, especially when it\u2019s generating a lot of unwanted output on the screen.\n\n\nSIGIO\n: indicates an asynchronous I/O event.\n\n\nSIGIOT\n: indicates an implementation-defined hardware fault. \nSIGABRT\n is now used for this purpose. On FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10, \nSIGIOT\n is defined to be the same value as \nSIGABRT\n.\n\n\nSIGJVM1\n and \nSIGJVM2\n: reserved for use by the Java virtual machine on Solaris.\n\n\nSIGKILL\n: one of the two that can\u2019t be caught or ignored. It provides the system administrator with a sure way to kill any process.\n\n\nSIGLOST\n: used to notify a process running on a Solaris NFSv4 client system that a lock could not be reacquired during recovery.\n\n\nSIGPIPE\n: If we write to a pipeline but the reader has terminated, \nSIGPIPE\n is generated. This signal is also generated when a process writes to a socket of type \nSOCK_STREAM\n that is no longer connected.\n\n\nSIGPOLL\n: This signal is marked obsolescent in SUSv4, so it might be removed in a future version of the standard. It can be generated when a specific event occurs on a pollable device.\n\n\nSIGPROF\n: This signal is marked obsolescent in SUSv4, so it might be removed in a future version of the standard. This signal is generated when a profiling interval timer set by the \nsetitimer(2)\n function expires.\n\n\nSIGPWR\n: system dependent, mainly used on a system that has an uninterruptible power supply (UPS).\n\n\nIf power fails, the UPS takes over and the software can usually be notified. Nothing needs to be done at this point, as the system continues running on battery power. But if the battery gets low, the software is usually notified again; at this point, it behooves the system to shut everything down. The process that is notified of the low-battery condition sends the \nSIGPWR\n signal to the \ninit\n process, and \ninit\n handles the system shutdown.\n\n\nSolaris 10 and some Linux distributions have entries in the \ninittab\n file for this purpose: \npowerfail\n and \npowerwait\n (or \npowerokwait\n).\n\n\nThe default action for \nSIGPWR\n as either \"terminate\" or \"ignore\", which depends on the system. The default on Linux is to terminate the process. On Solaris, the signal is ignored by default.\n\n\n\n\n\n\nSIGQUIT\n: generated by the terminal driver when we press the terminal quit key (often Control-backslash). This signal is sent to all processes in the foreground process group (\nFigure 9.9\n). This signal not only terminates the foreground process group (as does \nSIGINT\n), but also generates a \ncore\n file.\n\n\nSIGSEGV\n: indicates that the process has made an invalid memory reference (which is usually a sign that the program has a bug, such as dereferencing an uninitialized pointer). The name SEGV stands for \"segmentation violation\".\n\n\nSIGSTKFLT\n: This signal is defined only by Linux. It showed up in the earliest versions of Linux, where it was intended to be used for stack faults taken by the math coprocessor. This signal is not generated by the kernel, but remains for backward compatibility.\n\n\nSIGSTOP\n: This job-control signal stops a process. It is similar to the interactive stop signal (\nSIGTSTP\n), but \nSIGSTOP\n cannot be caught or ignored.\n\n\nSIGSYS\n: indicates an invalid system call. The process executed a machine instruction that the kernel thought was a system call, but the parameter with the instruction that indicates the type of system call was invalid. For example, if you build a program that uses a new system call and you then try to run the same binary on an older version of the operating system where the system call doesn\u2019t exist. [p320]\n\n\nSIGTERM\n: the termination signal sent by the \nkill(1)\n command by default. Because it can be caught by applications, using \nSIGTERM\n gives programs a chance to terminate gracefully by cleaning up before exiting (in contrast to \nSIGKILL\n, which can\u2019t be caught or ignored).\n\n\nSIGTHAW\n: defined only by Solaris and used to notify processes that need to take special action when the system resumes operation after being suspended.\n\n\nSIGTHR\n: reserved for use by the thread library on FreeBSD. It is defined to have the same value as \nSIGLWP\n.\n\n\nSIGTRAP\n: indicates an implementation-defined hardware fault. The signal name comes from the PDP-11 TRAP instruction. Implementations often use this signal to transfer control to a debugger when a breakpoint instruction is executed.\n\n\nSIGTSTP\n: This interactive stop signal is generated by the terminal driver when we press the terminal suspend key (often Control-Z). This signal is sent to all processes in the foreground process group (\nFigure 9.9\n). [p321]\n\n\nSIGTTIN\n: generated by the terminal driver when a process in a background process group tries to read from its controlling terminal. If either of the following case occurs, the signal is not generated; instead, the read operation fails with errno set to \nEIO\n:\n\n\nThe reading process is ignoring or blocking this signal.\n\n\nThe process group of the reading process is orphaned.\n\n\n\n\n\n\n\n\nSIGTTOU\n: generated by the terminal driver when a process in a background process group tries to write to its controlling terminal. Unlike the case with background reads, a process can choose to allow background writes to the controlling terminal. If background writes are not allowed, then like the \nSIGTTIN\n signal, the signal is not generated if either of the following cases occurs; instead, the read operation fails with errno set to \nEIO\n:\n\n\n\n\nThe writing process is ignoring or blocking this signal\n\n\nThe process group of the writing process is orphaned\n\n\n\n\nRegardless of whether background writes are allowed, certain terminal operations (other than writing), including \ntcsetattr\n, \ntcsendbreak\n, \ntcdrain\n, \ntcflush\n, \ntcflow\n, and \ntcsetpgrp\n can also generate the \nSIGTTOU\n signal.\n\n\n\n\n\n\nSIGURG\n: notifies the process that an urgent condition has occurred. It is optionally generated when \nout-of-band data\n is received on a network connection.\n\n\n\n\nSIGUSR1\n and \nSIGUSR2\n: user-defined signals, for use in application programs.\n\n\nSIGVTALRM\n: generated when a virtual interval timer set by the \nsetitimer(2)\n function expires.\n\n\nSIGWAITING\n: used internally by the Solaris threads library, and is not available for general use.\n\n\nSIGWINCH\n: The kernel maintains the size of the window associated with each terminal and pseudo terminal. A process can get and set the window size with the \nioctl\n function. If a process changes the window size from its previous value using the \nioctl\n set-window-size command, the kernel generates the \nSIGWINCH\n signal for the foreground process group.\n\n\nSIGXCPU\n: generated if the process exceeds its soft CPU time limit. The default action depends on the operating system. The Single UNIX Specification requires that the default action be to terminate the process abnormally.\n\n\nLinux 3.2.0 and Solaris 10 support a default action of terminate with a core file\n\n\nFreeBSD 8.0 and Mac OS X 10.6.8 support a default action of terminate without generating a core file.\n\n\n\n\n\n\nSIGXFSZ\n:  generated if the process exceeds its soft file size limit. The default action depends on the operating system, similar to \nSIGXCPU\n.\n\n\nSIGXRES\n: defined only by Solaris.\n\n\n\n\nsignal\n Function\n\n\nThe simplest interface to the signal features of the UNIX System is the signal function\n\n\napue_signal.h\n\n\n#include \nsignal.h\n\n\n\nvoid\n \n(\n*\nsignal\n(\nint\n \nsigno\n,\n \nvoid\n \n(\n*\nfunc\n)(\nint\n)))(\nint\n);\n\n\n\n/* Returns: previous disposition of signal (see following) if OK, SIG_ERR on error */\n\n\n\n\n\n\nImplementations derived from UNIX System V support the \nsignal\n function, which provides the old unreliable-signal semantics. New applications should not use these unreliable signals. 4.4BSD also provides the \nsignal\n function, but it is defined in terms of the \nsigaction\n function, so using it under 4.4BSD provides the newer reliable-signal semantics. Most current systems follow this strategy except Solaris. [p323]\n\n\nBecause the semantics of signal differ among implementations, we must use the \nsigaction\n function instead. We provide an implementation of \nsignal\n that uses \nsigaction\n (later this chapter).\n\n\nArguments:\n\n\n\n\nThe \nsigno\n argument is the name of the signal from \nprevious table\n.\n\n\nThe value of \nfunc\n one of the following:\n\n\nthe constant \nSIG_IGN\n, which tells the system ignore the signal;\n\n\nthe constant \nSIG_DFL\n, which sets the action associated with the signal to its default value;\n\n\nthe address of a function to be called when the signal occurs, which arranges to \"catch\" the signal. This function is called either the \nsignal handler\n or the \nsignal-catching function\n.\n\n\n\n\n\n\n\n\nThe prototype for the \nsignal\n function states that the function requires two arguments and returns a pointer to a function that returns nothing (\nvoid\n):\n\n\n\n\nThe first argument, \nsigno\n, is an integer.\n\n\nThe second argument, \nfunc\n, is a pointer to a function that takes a single integer argument and returns nothing.\n\n\nThe returned function (function whose address is returned as the value of \nsignal\n) takes a single integer argument (the final (\nint\n)).\n\n\n\n\nIn plain English, this declaration says that the signal handler is passed a single integer argument (the signal number) and that it returns nothing. When we call signal to establish the signal handler, the second argument is a pointer to the function.  The return value from \nsignal\n is the pointer to the previous signal handler.\n\n\nThe \nsignal\n function prototype can be made much simpler through the use of the following \ntypedef\n:\n\n\ntypedef\n \nvoid\n \nSigfunc\n(\nint\n);\n\n\n\n\n\n\nThen the prototype becomes:\n\n\nSigfunc\n \n*\nsignal\n(\nint\n,\n \nSigfunc\n \n*\n);\n\n\n\n\n\n\nThis \ntypedef\n is included in \napue.h\n and is used with the functions in this chapter.\n\n\nIf we examine the system\u2019s header \nsignal.h\n, we will probably find declarations of the form:\n\n\n#define SIG_ERR (void (*)())-1\n\n\n#define SIG_DFL (void (*)())0\n\n\n#define SIG_IGN (void (*)())1\n\n\n\n\n\n\nThese constants can be used in place of the \"pointer to a function that takes an integer argument and returns nothing\", the second argument to \nsignal\n, and the return value from \nsignal\n. The three values used for these constants need not be \u22121, 0, and 1. They must be three values that can never be the address of any declarable function. Most UNIX systems use the values shown. (See \nDoubts and Solutions\n for details)\n\n\nExample:\n\n\nThe following code shows a simple signal handler that catches either of the two user-defined signals and prints the signal number.\n\n\n\n\nsigusr.c\n\n\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_usr\n(\nint\n);\n   \n/* one handler for both signals */\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGUSR1\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt catch SIGUSR1\n);\n\n    \nif\n \n(\nsignal\n(\nSIGUSR2\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt catch SIGUSR2\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n\n        \npause\n();\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_usr\n(\nint\n \nsigno\n)\n      \n/* argument is signal number */\n\n\n{\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGUSR1\n)\n\n        \nprintf\n(\nreceived SIGUSR1\n\\n\n);\n\n    \nelse\n \nif\n \n(\nsigno\n \n==\n \nSIGUSR2\n)\n\n        \nprintf\n(\nreceived SIGUSR2\n\\n\n);\n\n    \nelse\n\n        \nerr_dump\n(\nreceived signal %d\n\\n\n,\n \nsigno\n);\n\n\n}\n\n\n\n\n\n\nWe invoke the program in the background and use the \nkill(1)\n command to send it signals. The term \nkill\n in the UNIX System is a misnomer. The \nkill(1)\n command and the \nkill(2)\n function just send a signal to a process or process group. Whether that signal terminates the process depends on which signal is sent and whether the process has arranged to catch the signal.\n\n\nResult:\n\n\n$ ./a.out \n                # start process in background\n\n\n[1] 7216                   # job-control shell prints job number and process ID\n\n\n$ kill -USR1 7216          # send it SIGUSR1\n\n\nreceived SIGUSR1\n\n\n$ kill -USR2 7216          # send it SIGUSR2\n\n\nreceived SIGUSR2\n\n\n$ kill 7216                # now send it SIGTERM\n\n\n[1]+ Terminated ./a.out\n\n\n\n\n\n\nWhen we send the \nSIGTERM\n signal, the process is terminated, since it doesn\u2019t catch the signal, and the default action for the signal is termination.\n\n\nProgram Start-Up\n\n\nWhen a program is executed, the status of all signals is either default or ignore. All signals are set to their default action, unless the process that calls \nexec\n is ignoring the signal. The \nexec\n functions change the disposition of any signals being caught to their default action and leave the status of all other signals alone. The reason is that a signal that is being caught by a process that calls \nexec\n cannot be caught by the same function in the new program, since the address of the signal-catching function in the caller probably has no meaning in the new program file that is executed. [p325]\n\n\nWith a shell that doesn\u2019t support job control, when we execute a process in the background:\n\n\ncc main.c \n\n\n\n\n\n\nThe shell automatically sets the disposition of the interrupt and quit signals in the background process to be ignored. This is done so that if we type the interrupt character, it doesn\u2019t affect the background process. If this weren\u2019t done and we typed the interrupt character, it would terminate not only the foreground process, but also all the background processes.\n\n\nMany interactive programs that catch these two signals have code that looks like:\n\n\nvoid\n \nsig_int\n(\nint\n),\n \nsig_quit\n(\nint\n);\n\n\n\nif\n \n(\nsignal\n(\nSIGINT\n,\n \nSIG_IGN\n)\n \n!=\n \nSIG_IGN\n)\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n\n\nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nSIG_IGN\n)\n \n!=\n \nSIG_IGN\n)\n\n    \nsignal\n(\nSIGQUIT\n,\n \nsig_quit\n);\n\n\n\n\n\n\nFollowing this approach, the process catches the signal only if the signal is not currently being ignored.\n\n\nThe \nsignal\n function has a limitation: we are not able to determine the current disposition of a signal without changing the disposition. The \nsigaction\n function (discussed later in this chapter) allows us to determine a signal\u2019s disposition without changing it.\n\n\nProcess Creation\n\n\nWhen a process calls \nfork\n, the child inherits the parent\u2019s signal dispositions. Here, since the child starts off with a copy of the parent\u2019s memory image, the address of a signal-catching function has meaning in the child.\n\n\nUnreliable Signals\n\n\nIn earlier versions of the UNIX System, signals were unreliable, which means that signals could get lost: a signal could occur and the process would never know about it. [p326]\n\n\nOne problem with these early versions was that the action for a signal was reset to its default each time the signal occurred. The code that was described usually looked like:\n\n\n    \nint\n \nsig_int\n();\n \n/* my signal handling function */\n\n    \n...\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* establish handler */\n\n    \n...\n\n\n\nsig_int\n()\n\n\n{\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* reestablish handler for next time */\n\n    \n...\n \n/* process the signal ... */\n \n.\n\n\n}\n\n\n\n\n\n\nThe problem with this code fragment is that there is a window of time (after the signal has occurred, but before the call to \nsignal\n in the signal handler) when the interrupt signal could occur another time. This second signal would cause the default action to occur, which terminates the process. This is one of those conditions that works correctly most of the time, causing us to think that it is correct, when it isn\u2019t.\n\n\nAnother problem with these earlier systems was that the process was unable to turn a signal off when it didn\u2019t want the signal to occur. All the process could do was ignore the signal. There are times when we would like to tell the system \"prevent the following signals from interrupting me, but remember if they do occur\". The following code catches a signal and sets a flag for the process that indicates that the signal occurred:\n\n\nint\n \nsig_int\n();\n \n/* my signal handling function */\n\n\nint\n \nsig_int_flag\n;\n \n/* set nonzero when signal occurs */\n\n\n\nmain\n()\n\n\n{\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* establish handler */\n\n    \n...\n\n    \nwhile\n \n(\nsig_int_flag\n \n==\n \n0\n)\n\n        \npause\n();\n \n/* go to sleep, waiting for signal */\n\n    \n...\n\n\n}\n\n\n\nsig_int\n()\n\n\n{\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* reestablish handler for next time */\n\n    \nsig_int_flag\n \n=\n \n1\n;\n \n/* set flag for main loop to examine */\n\n\n}\n\n\n\n\n\n\nThe process is calling the \npause\n function to put it to sleep until a signal is caught. When the signal is caught, the signal handler just sets the flag \nsig_int_flag\n to a nonzero value. The process is automatically awakened by the kernel after the signal handler returns, notices that the flag is nonzero, and does whatever it needs to do. But there is a window of time when things can go wrong. If the signal occurs after the test of \nsig_int_flag\n but before the call to pause, the process could go to sleep forever (assuming that the signal is never generated again). This occurrence of the signal is lost.\n\n\nInterrupted System Calls\n\n\nIn earlier UNIX systems, if a process caught a signal while the process was blocked in a \"slow\" system call, the system call was interrupted. The system call returned an error and \nerrno\n was set to \nEINTR\n. This was done under the assumption that since a signal occurred and the process caught it, there is a good chance that something has happened that should wake up the blocked system call.\n\n\nSlow system calls\n\n\nThe system calls are divided into two categories: the \"slow\" system calls and all the others. The slow system calls are those that can block forever:\n\n\n\n\nReads that can block the caller forever if data isn\u2019t present with certain file types (pipes, terminal devices, and network devices)\n\n\nWrites that can block the caller forever if the data can\u2019t be accepted immediately by these same file types\n\n\nOpens on certain file types that block the caller until some condition occurs (such as a terminal device open waiting until an attached modem answers the phone)\n\n\nThe \npause\n function (which by definition puts the calling process to sleep until a signal is caught) and the \nwait\n function\n\n\nCertain \nioctl\n operations\n\n\nSome of the interprocess communication functions\n\n\n\n\nThe notable exception to these slow system calls is anything related to disk I/O. Although a read or a write of a disk file can block the caller temporarily (while the disk driver queues the request and then the request is executed), unless a hardware error occurs, the I/O operation always returns and unblocks the caller quickly.\n\n\nHistorically, POSIX.1 semantics gave implementations a choice of how to deal with \nread\ns and \nwrite\ns that have processed partial amounts of data, implementations derived from System V fail the system call, whereas BSD-derived implementations return partial success. With the 2001 version of the POSIX.1 standard, the BSD-style semantics are required. [p328]\n\n\nThe problem with interrupted system calls is that we now have to handle the error return explicitly. Assuming a read operation and assuming that we want to restart the read even if it\u2019s interrupted, the typical code sequence would be:\n\n\nagain\n:\n\n    \nif\n \n((\nn\n \n=\n \nread\n(\nfd\n,\n \nbuf\n,\n \nBUFFSIZE\n))\n \n \n0\n)\n \n{\n\n        \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n            \ngoto\n \nagain\n;\n \n/* just an interrupted system call */\n\n        \n/* handle other errors */\n\n    \n}\n\n\n\n\n\n\nAutomatic restarts of interrupted system calls\n\n\nAutomatic restarting of certain interrupted system calls were introducted since 4.2BSD to prevent applications from having to handle interrupted system calls. The system calls that were automatically restarted are:\n\n\n\n\nFunctions that are interrupted by a signal only if they are operating on a slow device:\n\n\nioctl\n\n\nread\n\n\nreadv\n\n\nwrite\n\n\nwritev\n\n\n\n\n\n\nFunctions that are always interrupted when a signal is caught.\n\n\nwait\n\n\nwaitpid\n\n\n\n\n\n\n\n\nSome applications didn\u2019t want the operation restarted if it was interrupted; 4.3BSD allowed the process to disable this feature on a per-signal basis.\n\n\nDifference between the \nsignal\n and \nsigaction\n functions on restarts\n\n\nPOSIX.1 requires an implementation to restart system calls only when the \nSA_RESTART\n flag is in effect for the interrupting signal. This flag is used with the \nsigaction\n function to allow applications to request that interrupted system calls be restarted.\n\n\nHistorically, when using the \nsignal\n function to establish a signal handler, implementations varied with respect to how interrupted system calls were handled. System V never restarted system calls by default. BSD, in contrast, restarted them if the calls were interrupted by signals. On FreeBSD 8.0, Linux 3.2.0, and Mac OS X 10.6.8, when signal handlers are installed with the \nsignal\n function, interrupted system calls will be restarted. By using our own implementation of the \nsignal\n function, we avoid having to deal with these differences. [p329]\n\n\nOne reason 4.2BSD introduced the automatic restart feature is that sometimes we don\u2019t know that the input or output device is a slow device. [p329]\n\n\nThe figure below summarizes the signal functions and their semantics provided by the various implementations.\n\n\n\n\nLater this chapter, we provide our own version of the \nsignal\n function that automatically tries to restart interrupted system calls (other than for the \nSIGALRM\n signal), and \nsignal_intr\n, that tries to never do the restart.\n\n\nReentrant Functions\n\n\nWhen a signal that is being caught is handled by a process, the normal sequence of instructions being executed by the process is temporarily interrupted by the signal handler. The process then continues executing, but the instructions in the signal handler are now executed. If the signal handler returns (instead of calling \nexit\n or \nlongjmp\n), then the normal sequence of instructions that the process was executing when the signal was caught continues executing. This is similar to what happens when a hardware interrupt occurs.\n\n\nHowever, in the signal handler, we can\u2019t tell where the process was executing when the signal was caught:\n\n\n\n\nWhat if the process was in the middle of allocating additional memory on its heap using \nmalloc\n, and we call \nmalloc\n from the signal handler?\n\n\nHavoc can result for the process, since \nmalloc\n usually maintains a linked list of all its allocated areas, and it may have been in the middle of changing this list.\n\n\n\n\n\n\nWhat if the process was in the middle of a call to a function, such as \ngetpwnam\n (\nSection 6.2\n), that stores its result in a static location, and we call the same function from the signal handler?\n\n\nThe information returned to the normal caller can get overwritten with the information returned to the signal handler.\n\n\n\n\n\n\n\n\nThe Single UNIX Specification specifies the functions that are guaranteed to be safe to call from within a signal handler. These functions are reentrant and are called \nasync-signal safe\n by the SUS. Besides being reentrant, they block any signals during operation if delivery of a signal might cause inconsistencies.\n\n\nThe following table lists these async-signal safe functions, which are reentrant functions that may be called from a signal handler.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nabort\n\n\nfaccessat\n\n\nlinkat\n\n\nselect\n\n\nsocketpair\n\n\n\n\n\n\naccept\n\n\nfchmod\n\n\nlisten\n\n\nsem_post\n\n\nstat\n\n\n\n\n\n\naccess\n\n\nfchmodat\n\n\nlseek\n\n\nsend\n\n\nsymlink\n\n\n\n\n\n\naio_error\n\n\nfchown\n\n\nlstat\n\n\nsendmsg\n\n\nsymlinkat\n\n\n\n\n\n\naio_return\n\n\nfchownat\n\n\nmkdir\n\n\nsendto\n\n\ntcdrain\n\n\n\n\n\n\naio_suspend\n\n\nfcntl\n\n\nmkdirat\n\n\nsetgid\n\n\ntcflow\n\n\n\n\n\n\nalarm\n\n\nfdatasync\n\n\nmkfifo\n\n\nsetpgid\n\n\ntcflush\n\n\n\n\n\n\nbind\n\n\nfexecve\n\n\nmkfifoat\n\n\nsetsid\n\n\ntcgetattr\n\n\n\n\n\n\ncfgetispeed\n\n\nfork\n\n\nmknod\n\n\nsetsockopt\n\n\ntcgetpgrp\n\n\n\n\n\n\ncfgetospeed\n\n\nfstat\n\n\nmknodat\n\n\nsetuid\n\n\ntcsendbreak\n\n\n\n\n\n\ncfsetispeed\n\n\nfstatat\n\n\nopen\n\n\nshutdown\n\n\ntcsetattr\n\n\n\n\n\n\ncfsetospeed\n\n\nfsync\n\n\nopenat\n\n\nsigaction\n\n\ntcsetpgrp\n\n\n\n\n\n\nchdir\n\n\nftruncate\n\n\npause\n\n\nsigaddset\n\n\ntime\n\n\n\n\n\n\nchmod\n\n\nfutimens\n\n\npipe\n\n\nsigdelset\n\n\ntimer_getoverrun\n\n\n\n\n\n\nchown\n\n\ngetegid\n\n\npoll\n\n\nsigemptyset\n\n\ntimer_gettime\n\n\n\n\n\n\nclock_gettime\n\n\ngeteuid\n\n\nposix_trace_event\n\n\nsigfillset\n\n\ntimer_settime\n\n\n\n\n\n\nclose\n\n\ngetgid\n\n\npselect\n\n\nsigismember\n\n\ntimes\n\n\n\n\n\n\nconnect\n\n\ngetgroups\n\n\nraise\n\n\nsignal\n\n\numask\n\n\n\n\n\n\ncreat\n\n\ngetpeername\n\n\nread\n\n\nsigpause\n\n\nuname\n\n\n\n\n\n\ndup\n\n\ngetpgrp\n\n\nreadlink\n\n\nsigpending\n\n\nunlink\n\n\n\n\n\n\ndup2\n\n\ngetpid\n\n\nreadlinkat\n\n\nsigprocmask\n\n\nunlinkat\n\n\n\n\n\n\nexecl\n\n\ngetppid\n\n\nrecv\n\n\nsigqueue\n\n\nutime\n\n\n\n\n\n\nexecle\n\n\ngetsockname\n\n\nrecvfrom\n\n\nsigset\n\n\nutimensat\n\n\n\n\n\n\nexecv\n\n\ngetsockopt\n\n\nrecvmsg\n\n\nsigsuspend\n\n\nutimes\n\n\n\n\n\n\nexecve\n\n\ngetuid\n\n\nrename\n\n\nsleep\n\n\nwait\n\n\n\n\n\n\n_Exit\n\n\nkill\n\n\nrenameat\n\n\nsockatmark\n\n\nwaitpid\n\n\n\n\n\n\n_exit\n\n\nlink\n\n\nrmdir\n\n\nsocket\n\n\nwrite\n\n\n\n\n\n\n\n\nMost of the functions that are not included in table above are missing because:\n\n\n\n\nThey are known to use static data structures;\n\n\nThey call \nmalloc\n or \nfree\n;\n\n\nThey are part of the standard I/O library.\n\n\n\n\nNote when using the functions in the table above:\n\n\n\n\nMost implementations of the standard I/O library use global data structures in a nonreentrant way.\n\n\n\n\nBe aware that even if we call a function listed in the table above from a signal handler, there is only one \nerrno\n variable per thread (recall the discussion of errno and threads in \nSection 1.7\n), and we might potentially modify its value.\n\n\n\n\nConsider a signal handler that is invoked right after main has set \nerrno\n. If the signal handler calls \nread\n, for example, this call can change the value of \nerrno\n, wiping out the value that was just stored in \nmain\n.\n\n\n\n\nTherefore, as a general rule, when calling the functions listed in the table above from a signal handler, we should save and restore \nerrno\n. Be aware that a commonly caught signal is \nSIGCHLD\n, and its signal handler usually calls one of the wait functions. All the \nwait\n functions can change \nerrno\n.\n\n\n\n\n\n\nlongjmp\n (\nSection 7.10\n) and \nsiglongjmp\n (\nSection 10.15\n) are missing\nfrom the table because the signal may have occurred while the \nmain\n routine was updating a data structure in a nonreentrant way. This data structure could be left half updated if we call \nsiglongjmp\n instead of returning from the signal handler. If it is going to do such things as update global data structures, while catching signals that cause \nsigsetjmp\n to be executed, an application needs to block the signals while updating the data structures.\n\n\n\n\n\n\nExample of calling \ngetpwnam\n from a signal handler *\n\n\nThe code below shows a program that calls the nonreentrant function \ngetpwnam\n from a signal handler that is called every second. We use the \nalarm\n function (\nSection 10.10\n) here to generate a \nSIGALRM\n signal every second.\n\n\nsignals/reenter.c\n\n\n#include \napue.h\n\n\n#include \npwd.h\n\n\n\nstatic\n \nvoid\n\n\nmy_alarm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nstruct\n \npasswd\n   \n*\nrootptr\n;\n\n\n    \nprintf\n(\nin signal handler\n\\n\n);\n\n    \nif\n \n((\nrootptr\n \n=\n \ngetpwnam\n(\nroot\n))\n \n==\n \nNULL\n)\n\n            \nerr_sys\n(\ngetpwnam(root) error\n);\n\n    \nalarm\n(\n1\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nstruct\n \npasswd\n   \n*\nptr\n;\n\n\n    \nsignal\n(\nSIGALRM\n,\n \nmy_alarm\n);\n\n    \nalarm\n(\n1\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n((\nptr\n \n=\n \ngetpwnam\n(\nsar\n))\n \n==\n \nNULL\n)\n\n            \nerr_sys\n(\ngetpwnam error\n);\n\n        \nif\n \n(\nstrcmp\n(\nptr\n-\npw_name\n,\n \nsar\n)\n \n!=\n \n0\n)\n\n            \nprintf\n(\nreturn value corrupted!, pw_name = %s\n\\n\n,\n\n                    \nptr\n-\npw_name\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWhen this program was run, the results were random. Usually, the program would be terminated by a \nSIGSEGV\n signal when the signal handler returned after several iterations. An examination of the \ncore\n file showed that the main function had called \ngetpwnam\n, but that when \ngetpwnam\n called \nfree\n, the signal handler interrupted it and called \ngetpwnam\n, which in turn called \nfree\n. The data structures maintained by \nmalloc\n and \nfree\n had been corrupted when the signal handler (indirectly) called \nfree\n while the main function was also calling \nfree\n. Occasionally, the program would run for several seconds before crashing with a \nSIGSEGV\n error. When the main function did run correctly after the signal had been caught, the return value was sometimes corrupted and sometimes fine.\n\n\nSIGCLD\n Semantics\n\n\nTwo signals that continually generate confusion are \nSIGCLD\n and \nSIGCHLD\n. The name \nSIGCLD\n (without the \nH\n) is from System V, and this signal has different semantics from the BSD signal, named \nSIGCHLD\n. The POSIX.1 signal is also named \nSIGCHLD\n.\n\n\nThe semantics of the BSD \nSIGCHLD\n signal are normal and its semantics are similar to all other signals. When the signal occurs, the status of a child has changed, and we need to call one of the \nwait\n functions to determine what has happened.\n\n\nSystem V, however, has traditionally handled the \nSIGCLD\n signal differently from other signals:\n\n\n\n\nIf the process specifically sets its disposition to \nSIG_IGN\n, children of the calling process will not generate zombie processes. [p333]\n\n\n4.4BSD always generates zombies if \nSIGCHLD\n is ignored. If we want to avoid zombies, we have to \nwait\n for our children.\n\n\n\n\n\n\nIf we set the disposition of \nSIGCLD\n to be caught, the kernel immediately checks whether any child processes are ready to be \nwait\ned for and, if so, calls the \nSIGCLD\n handler. [p333-335]\n\n\nFreeBSD 8.0 and Mac OS X 10.6.8 don\u2019t exhibit this problem, because BSD-based systems generally don\u2019t support historical System V semantics for SIGCLD.\n\n\nLinux 3.2.0 also doesn\u2019t exhibit this problem, because it doesn\u2019t call the \nSIGCHLD\n signal handler when a process arranges to catch \nSIGCHLD\n and child processes are ready to be waited for, even though \nSIGCLD\n and \nSIGCHLD\n are defined to be the same value.\n\n\nSolaris avoids this problem by including extra code in the kernel.\n\n\n\n\n\n\n\n\nOf the four platforms described in this text, only Linux 3.2.0 and Solaris 10 define \nSIGCLD\n. On these platforms, \nSIGCLD\n is equivalent to \nSIGCHLD\n.\n\n\nReliable-Signal Terminology and Semantics\n\n\nThis section defines some terms used through the discussion of signals.\n\n\n\n\nA signal is \ngenerated\n for a process (or sent to a process) when the event that causes the signal occurs. When the signal is generated, the kernel usually sets a flag of some form in the process table. The event could be:\n\n\nHardware exception (e.g., divide by 0),\n\n\nSoftware condition (e.g., an alarm timer expiring),\n\n\nTerminal-generated signal,\n\n\nA call to the \nkill\n function.\n\n\n\n\n\n\nA signal is \ndelivered\n to a process when the action for a signal is taken.\n\n\nA signal is \npending\n during the time between its generation and delivery.\n\n\n\n\nA process has the option of \nblocking\n the delivery of a signal. If a signal that is blocked is generated for a process, and if the action for that signal is either the default action or to catch the signal, then the signal remains pending for the process until the process either:\n\n\n\n\nunblocks the signal, or\n\n\nchanges the action to ignore the signal.\n\n\n\n\nThe system determines what to do with a blocked signal when the signal is delivered, not when it\u2019s generated. This allows the process to change the action for the signal before it\u2019s delivered. The \nsigpending\n function (\nSection 10.13\n) can be called by a process to determine which signals are blocked and pending.\n\n\n\n\n\n\nPOSIX.1 allows the system to deliver the signal either once or more than once in case a blocked signal is generated more than once before the process unblocks the signal. If the system delivers the signal more than once, we say that the signals are \nqueued\n. Most UNIX systems, however, do not queue signals unless they support the real-time extensions to POSIX.1. Instead, the UNIX kernel simply delivers the signal once. [p336]\n\n\nSection 10.20\n discusses queueing signals further.\n\n\nPOSIX.1 does not specify the order in which the signals are delivered to the process. The Rationale for POSIX.1 does suggest, however, that signals related to the current state of the process be delivered before other signals. (\nSIGSEGV\n is one such signal.)\n\n\nEach process has a \nsignal mask\n that defines the set of signals currently blocked from delivery to that process. This mask has one bit for each possible signal. If the bit is on for a given signal, that signal is currently blocked. A process can examine and change its current signal mask by calling \nsigprocmask\n (\nSection 10.12\n). Since it is possible for the number of signals to exceed the number of bits in an integer, POSIX.1 defines a data type, called \nsigset_t\n, that holds a \nsignal set\n. The signal mask is stored in one of these signal sets. The five functions that operate on signal sets are described in \nSection 10.11\n.\n\n\nkill\n and \nraise\n Functions\n\n\n\n\nThe \nkill\n function sends a signal to a process or a group of processes.\n\n\nThe \nraise\n function allows a process to send a signal to itself.\n\n\nThe \nraise\n function was originally defined by ISO C. POSIX.1 includes it to align itself with the ISO C standard, but POSIX.1 extends the specification of raise to deal with threads. Since ISO C does not deal with multiple processes, it could not define a function, such as \nkill\n, that requires a process ID argument.\n\n\n\n\n\n\n\n\n#include \nsignal.h\n\n\n\nint\n \nkill\n(\npid_t\n \npid\n,\n \nint\n \nsigno\n);\n\n\nint\n \nraise\n(\nint\n \nsigno\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe call:\n\n\nraise\n(\nsigno\n);\n\n\n\n\n\n\nis equivalent to the call:\n\n\nkill\n(\ngetpid\n(),\n \nsigno\n);\n\n\n\n\n\n\nThere are four different conditions for the \npid\n argument to kill:\n\n\n\n\npid\n \n 0. The signal is sent to the process whose process ID is \npid\n.\n\n\npid\n == 0 The signal is sent to all processes whose process group ID equals the process group ID of the sender and for which the sender has permission to send the signal.\n\n\npid\n \n 0. The signal is sent to all processes whose process group ID equals the absolute value of \npid\n and for which the sender has permission to send the signal.\n\n\npid\n == \u22121. The signal is sent to all processes on the system for which the sender has permission to send the signal.\n\n\n\n\nNote that the term \nall processes\n in the four conditions above excludes an implementation-defined set of system processes, including kernel processes and \ninit\n (pid 1).\n\n\nA process needs permission to send a signal to another process:\n\n\n\n\nThe superuser can send a signal to any process.\n\n\nFor other users, the real or effective user ID of the sender has to equal the real or effective user ID of the receiver. If the implementation supports \n_POSIX_SAVED_IDS\n, the saved set-user-ID of the receiver is checked instead of its effective user ID.\n\n\nOne special case for the permission testing also exists: if the signal being sent is \nSIGCONT\n,aprocess can send it to any other process in the same session.\n\n\n\n\nSome other notes on the \nkill\n function:\n\n\n\n\nPOSIX.1 defines signal number 0 as the null signal. If the \nsigno\n argument is 0, then the normal error checking is performed by \nkill\n, but no signal is sent. This technique is often used to determine if a specific process still exists. If we send the process the null signal and it doesn\u2019t exist, \nkill\n returns \u22121 and \nerrno\n is set to \nESRCH\n. Be aware, however, that UNIX systems recycle process IDs after some amount of time, so the existence of a process with a given process ID does not necessarily mean that it\u2019s the process that you think it is.\n\n\nThe test for process existence is not atomic. By the time that \nkill\n returns the answer to the caller, the process in question might have exited, so the answer is of limited value.\n\n\nIf the call to \nkill\n causes the signal to be generated for the calling process and if the signal is not blocked, either \nsigno\n or some other pending, unblocked signal is delivered to the process before \nkill\n returns. For additional conditions that occur with threads, see \nSection 12.8\n.\n\n\n\n\nalarm\n and \npause\n Functions\n\n\nThe \nalarm\n function sets a timer that will expire at a specified time in the future. When the timer expires, the \nSIGALRM\n signal is generated. If we ignore or don\u2019t catch this signal, its default action is to terminate the process.\n\n\n#include \nunistd.h\n\n\n\nunsigned\n \nint\n \nalarm\n(\nunsigned\n \nint\n \nseconds\n);\n\n\n\n/* Returns: 0 or number of seconds until previously set alarm */\n\n\n\n\n\n\n\n\nThe \nseconds\n value is the number of clock seconds in the future when the signal should be generated. When that time occurs, the signal is generated by the kernel, although additional time could elapse before the process gets control to handle the signal, because of processor scheduling delays.\n\n\nThere is only one of these alarm clocks per process. If \nalarm\n is called with a previously registered alarm clock not yet expired, then:\n\n\nThe number of seconds left for previous alarm clock is returned as the value of this function.\n\n\nThe previous alarm clock is replaced by the new value.\n\n\n\n\n\n\nIf a previously registered alarm clock for the process has not yet expired and if the seconds value is 0, the previous alarm clock is canceled. The number of seconds left for that previous alarm clock is still returned as the value of the function.\n\n\n\n\nAlthough the default action for \nSIGALRM\n is to terminate the process, most processes that use an alarm clock catch this signal, which can perform whatever cleanup is required before terminating if the process wants to terminate. \nIf we intend to catch \nSIGALRM\n, we need to be careful to install its signal handler before calling \nalarm\n. If we call \nalarm\n first and are sent \nSIGALRM\n before we can install the signal handler, our process will terminate.\n\n\nThe \npause\n function suspends the calling process until a signal is caught.\n\n\n#include \nunistd.h\n\n\n\nint\n \npause\n(\nvoid\n);\n\n\n\n/* Returns: \u22121 with errno set to EINTR */\n\n\n\n\n\n\nThe only time \npause\n returns is if a signal handler is executed and that handler returns. In that case, \npause\n returns \u22121 with \nerrno\n set to \nEINTR\n.\n\n\nsleep1\n example\n\n\nUsing \nalarm\n and \npause\n, we can put a process to sleep for a specified amount of time. The following implementation of \nsleep1\n is incomplete and has problems:\n\n\nsignals/sleep1.c\n\n\n#include    \nsignal.h\n\n\n#include    \nunistd.h\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \n/* nothing to do, just return to wake up the pause */\n\n\n}\n\n\n\nunsigned\n \nint\n\n\nsleep1\n(\nunsigned\n \nint\n \nseconds\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nreturn\n(\nseconds\n);\n\n    \nalarm\n(\nseconds\n);\n     \n/* start the timer */\n\n    \npause\n();\n            \n/* next caught signal wakes us up */\n\n    \nreturn\n(\nalarm\n(\n0\n));\n   \n/* turn off timer, return unslept time */\n\n\n}\n\n\n\n\n\n\nThis simple implementation has three problems:\n\n\n\n\nIf the caller already has an alarm set, that alarm is erased by the first call to \nalarm\n.\n We can correct this by looking at \nalarm\n\u2019s return value:\n\n\nIf the number of seconds until some previously set alarm is less than the argument, then we should wait only until the existing alarm expires.\n\n\nIf the previously set alarm will go off after ours, then before returning we should reset this alarm to occur at its designated time in the future.\n\n\n\n\n\n\nWe have modified the disposition for \nSIGALRM\n.\n If we\u2019re writing a function for others to call, we should save the disposition when our function is called and restore it when we\u2019re done. We can correct this by saving the return value from \nsignal\n and resetting the disposition before our function returns.\n\n\nThere is a race condition between the first call to \nalarm\n and the call to \npause\n.  On a busy system, it\u2019s possible for the alarm to go off and the signal handler to be called before we call pause. If that happens, the caller is suspended forever in the call to \npause\n (assuming that some other signal isn\u2019t caught).\n\n\n\n\nsleep2\n example: using \nsetjmp\n and \nlongjmp\n\n\nThe following example corrects problem 3 as described above using \nsetjmp\n. The problem 3 can also be corrected using \nsigprocmask\n and \nsigsuspend\n, as described in \nSection 10.19\n.\n\n\nsignals/sleep2.c\n\n\n#include    \nsetjmp.h\n\n\n#include    \nsignal.h\n\n\n#include    \nunistd.h\n\n\n\nstatic\n \njmp_buf\n  \nenv_alrm\n;\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nlongjmp\n(\nenv_alrm\n,\n \n1\n);\n\n\n}\n\n\n\nunsigned\n \nint\n\n\nsleep2\n(\nunsigned\n \nint\n \nseconds\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nreturn\n(\nseconds\n);\n\n    \nif\n \n(\nsetjmp\n(\nenv_alrm\n)\n \n==\n \n0\n)\n \n{\n\n        \nalarm\n(\nseconds\n);\n     \n/* start the timer */\n\n        \npause\n();\n            \n/* next caught signal wakes us up */\n\n    \n}\n\n    \nreturn\n(\nalarm\n(\n0\n));\n       \n/* turn off timer, return unslept time */\n\n\n}\n\n\n\n\n\n\nThe \nsleep2\n function avoids the race condition. Even if the \npause\n is never executed, the \nsleep2\n function returns when the \nSIGALRM\n occurs.\n\n\nsleep2\n's interaction with other signals\n\n\nThere is another subtle problem with the \nsleep2\n function involving its interaction with other signals. If the \nSIGALRM\n interrupts some other signal handler, then when we call \nlongjmp\n, we abort the other signal handler, as shown in the following code:\n\n\nsignals/tsleep2.c\n\n\n#include \napue.h\n\n\n\nunsigned\n \nint\n    \nsleep2\n(\nunsigned\n \nint\n);\n\n\nstatic\n \nvoid\n     \nsig_int\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nunsigned\n \nint\n    \nunslept\n;\n\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nunslept\n \n=\n \nsleep2\n(\n5\n);\n\n    \nprintf\n(\nsleep2 returned: %u\n\\n\n,\n \nunslept\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nint\n             \ni\n,\n \nj\n;\n\n    \nvolatile\n \nint\n    \nk\n;\n\n\n/*\n\n\n     * Tune these loops to run for more than 5 seconds\n\n\n     * on whatever system this test program is run.\n\n\n     */\n\n    \nprintf\n(\n\\n\nsig_int starting\n\\n\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \n300000\n;\n \ni\n++\n)\n\n        \nfor\n \n(\nj\n \n=\n \n0\n;\n \nj\n \n \n4000\n;\n \nj\n++\n)\n\n            \nk\n \n+=\n \ni\n \n*\n \nj\n;\n\n    \nprintf\n(\nsig_int finished\n\\n\n);\n\n\n}\n\n\n\n\n\n\nThe loop in the \nSIGINT\n handler was written so that it executes for longer than 5 seconds on one of the systems used by the author. We simply want it to execute longer than the argument to \nsleep2\n. The integer \nk\n is declared as \nvolatile\n to prevent an optimizing compiler from discarding the loop.\n\n\nRun this program and interrupt the sleep by typing the interrupt character:\n\n\n$ ./a.out\n\n\n\u02c6C                 # we type the interrupt character\n\n\nsig_int starting\n\n\nsleep2 returned: 0\n\n\n\n\n\n\nThe \nlongjmp\n from the \nsleep2\n function aborted the other signal handler, \nsig_int\n, even though it wasn\u2019t finished.\n\n\nThe above examples of \nsleep1\n and \nsleep2\n show the pitfalls in dealing naively with signals. The following sections will show ways around all these problems, so we can handle signals reliably, without interfering with other pieces of code.\n\n\nImplementing a timeout using \nalarm\n\n\nA common use for \nalarm\n, in addition to implementing the \nsleep\n function, is to put an upper time limit on operations that can block. For example, if we have a \nread\n operation on a device that can block (slow device, as described in \nSection 10.5\n), we might want the \nread\n to time out after some amount of time. The following example reads one line from standard input (with a timeout) and writes it to standard.\n\n\nsignals/read1.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_alrm\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGALRM) error\n);\n\n\n    \nalarm\n(\n10\n);\n\n    \nif\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nline\n,\n \nMAXLINE\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n    \nalarm\n(\n0\n);\n\n\n    \nwrite\n(\nSTDOUT_FILENO\n,\n \nline\n,\n \nn\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \n/* nothing to do, just return to interrupt the read */\n\n\n}\n\n\n\n\n\n\nThough this code is common in UNIX applications, it has two problems:\n\n\n\n\nThere is a a race condition between the first call to \nalarm\n and the call to \nread\n, similar to the first \nalarm\n and \npause\n example in \nearly this section\n. If the kernel blocks the process between these two function calls for longer than the alarm period, the \nread\n could block forever, though most operations of this type use a long alarm period (a minute or more) making this unlikely.\n\n\nIf system calls are automatically restarted, the \nread\n is not interrupted when the \nSIGALRM\n signal handler returns. In this case, the timeout does nothing.\n\n\n\n\nImplementing a timeout with \nalarm\n and \nlongjmp\n\n\nsignals/read2.c\n\n\n#include \napue.h\n\n\n#include \nsetjmp.h\n\n\n\nstatic\n \nvoid\n     \nsig_alrm\n(\nint\n);\n\n\nstatic\n \njmp_buf\n  \nenv_alrm\n;\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGALRM) error\n);\n\n    \nif\n \n(\nsetjmp\n(\nenv_alrm\n)\n \n!=\n \n0\n)\n\n        \nerr_quit\n(\nread timeout\n);\n\n\n    \nalarm\n(\n10\n);\n\n    \nif\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nline\n,\n \nMAXLINE\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n    \nalarm\n(\n0\n);\n\n\n    \nwrite\n(\nSTDOUT_FILENO\n,\n \nline\n,\n \nn\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nlongjmp\n(\nenv_alrm\n,\n \n1\n);\n\n\n}\n\n\n\n\n\n\nThis version works as expected, regardless of whether the system restarts interrupted system calls. However, we still have the problem of interactions with other signal handlers, \nas described previously\n.\n\n\nIf we want to set a time limit on an I/O operation, we need to use \nlongjmp\n, as shown previously, while recognizing its possible interaction with other signal handlers. Another option is to use the \nselect\n or \npoll\n functions described in \nSection 14.4\n.\n\n\nSignal Sets\n\n\nA \nsignal set\n is a data type to represent multiple signals. This data type is used with functions like \nsigprocmask\n to tell the kernel not to allow any of the signals in the set to occur. As mentioned earlier, the number of different signals can exceed the number of bits in an integer, so in general we can\u2019t use an integer to represent the set with one bit per signal.\n\n\nPOSIX.1 defines the data type \nsigset_t\n to contain a signal set and the following five functions to manipulate signal sets.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigemptyset\n(\nsigset_t\n \n*\nset\n);\n\n\nint\n \nsigfillset\n(\nsigset_t\n \n*\nset\n);\n\n\nint\n \nsigaddset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n);\n\n\nint\n \nsigdelset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n);\n\n\n\n/* All four return: 0 if OK, \u22121 on error */\n\n\n\nint\n \nsigismember\n(\nconst\n \nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n);\n\n\n/* Returns: 1 if true, 0 if false, \u22121 on error */\n\n\n\n\n\n\n\n\nsigemptyset\n initializes the signal set pointed to by \nset\n so that all signals are excluded.\n\n\nsigfillset\n initializes the signal set so that all signals are included.\n\n\nsigaddset\n adds a single signal to an existing set.\n\n\nsigdelset\n removes a single signal from a set.\n\n\n\n\nAll applications have to call either \nsigemptyset\n or \nsigfillset\n once for each signal set, before using the signal set, because we cannot assume that the C initialization for external and static variables (0) corresponds to the implementation of signal sets on a given system.\n\n\nIn all the functions that take a signal set as an argument, we always pass the address of the signal set as the argument.\n\n\nImplementation of signal sets\n\n\nIf the implementation has fewer signals than bits in an integer,asignal set can be implemented using one bit per signal. This section assumes that an implementation has 31 signals and 32-bit integers. The \nsigemptyset\n function zeros the integer, and the \nsigfillset\n function turns on all the bits in the integer. These two functions can be implemented as macros in the \nsignal.h\n header:\n\n\n#define sigemptyset(ptr) (*(ptr) = 0)\n\n\n#define sigfillset(ptr) (*(ptr) = ~(sigset_t)0, 0)\n\n\n\n\n\n\nNote that \nsigfillset\n must return 0, in addition to setting all the bits on in the signal set, so we use C\u2019s comma operator, which returns the value after the comma as the value of the expression.\n\n\nUsing this implementation, \nsigaddset\n turns on a single bit and \nsigdelset\n turns off a single bit; \nsigismember\n tests a certain bit. Since no signal is ever numbered 0, we subtract 1 from the signal number to obtain the bit to manipulate.\n\n\nsignals/setops.c\n\n\n#include    \nsignal.h\n\n\n#include    \nerrno.h\n\n\n\n/*\n\n\n * \nsignal.h\n usually defines NSIG to include signal number 0.\n\n\n */\n\n\n#define SIGBAD(signo)   ((signo) \n= 0 || (signo) \n= NSIG)\n\n\n\nint\n\n\nsigaddset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n)\n\n\n{\n\n    \nif\n \n(\nSIGBAD\n(\nsigno\n))\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n\n    \n}\n\n    \n*\nset\n \n|=\n \n1\n \n \n(\nsigno\n \n-\n \n1\n);\n       \n/* turn bit on */\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\nint\n\n\nsigdelset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n)\n\n\n{\n\n    \nif\n \n(\nSIGBAD\n(\nsigno\n))\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n\n    \n}\n\n    \n*\nset\n \n=\n \n~\n(\n1\n \n \n(\nsigno\n \n-\n \n1\n));\n    \n/* turn bit off */\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\nint\n\n\nsigismember\n(\nconst\n \nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n)\n\n\n{\n\n    \nif\n \n(\nSIGBAD\n(\nsigno\n))\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n\n    \n}\n\n    \nreturn\n((\n*\nset\n \n \n(\n1\n \n \n(\nsigno\n \n-\n \n1\n)))\n \n!=\n \n0\n);\n\n\n}\n\n\n\n\n\n\nsigprocmask\n Function\n\n\nAs discussed in \nSection 10.8\n, the signal mask of a process is the set of signals currently blocked from delivery to that process. A process can examine its signal mask, change its signal mask, or perform both operations in one step by calling the following function.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigprocmask\n(\nint\n \nhow\n,\n \nconst\n \nsigset_t\n \n*\nrestrict\n \nset\n,\n\n                \nsigset_t\n \n*\nrestrict\n \noset\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nIf \noset\n is a non-null pointer, the current signal mask for the process is returned through \noset\n.\n\n\nIf \nset\n is a non-null pointer, the \nhow\n argument indicates how the current signal mask is modified; if \nset\n is a null pointer, the signal mask of the process is not changed, and \nhow\n is ignored.\n\n\n\n\nThe \nhow\n argument is one in the following table:\n\n\n\n\n\n\n\n\nhow\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSIG_BLOCK\n\n\nThe new signal mask for the process is the union of its current signal mask and the signal set pointed to by \nset\n. That is, \nset\n contains the additional signals that we want to block.\n\n\n\n\n\n\nSIG_UNBLOCK\n\n\nThe new signal mask for the process is the intersection of its current signal mask and the complement of the signal set pointed to by \nset\n. That is, \nset\n contains the signals that we want to unblock.\n\n\n\n\n\n\nSIG_SETMASK\n\n\nThe new signal mask for the process is replaced by the value of the signal set pointed to by \nset\n.\n\n\n\n\n\n\n\n\n\n\n\n\nAfter calling \nsigprocmask\n, if any unblocked signals are pending, at least one of these signals is delivered to the process before \nsigprocmask\n returns.\n\n\nNote that the \nsigprocmask\n function is defined only for single-threaded processes. A separate function, discussed in \nSection 12.8\n is provided to manipulate a thread\u2019s signal mask in a multithreaded process.\n\n\nThe following example shows a function that prints the names of the signals in the signal mask of the calling process.\n\n\nlib/prmask.c\n\n\n#include \napue.h\n\n\n#include \nerrno.h\n\n\n\nvoid\n\n\npr_mask\n(\nconst\n \nchar\n \n*\nstr\n)\n\n\n{\n\n    \nsigset_t\n    \nsigset\n;\n\n    \nint\n         \nerrno_save\n;\n\n\n    \nerrno_save\n \n=\n \nerrno\n;\n     \n/* we can be called by signal handlers */\n\n    \nif\n \n(\nsigprocmask\n(\n0\n,\n \nNULL\n,\n \nsigset\n)\n \n \n0\n)\n \n{\n\n        \nerr_ret\n(\nsigprocmask error\n);\n\n    \n}\n \nelse\n \n{\n\n        \nprintf\n(\n%s\n,\n \nstr\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGINT\n))\n\n            \nprintf\n(\n SIGINT\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGQUIT\n))\n\n            \nprintf\n(\n SIGQUIT\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGUSR1\n))\n\n            \nprintf\n(\n SIGUSR1\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGALRM\n))\n\n            \nprintf\n(\n SIGALRM\n);\n\n\n        \n/* remaining signals can go here  */\n\n\n        \nprintf\n(\n\\n\n);\n\n    \n}\n\n\n    \nerrno\n \n=\n \nerrno_save\n;\n     \n/* restore errno */\n\n\n}\n\n\n\n\n\n\nsigpending\n Function\n\n\nThe \nsigpending\n function returns the set of signals that are blocked from delivery and currently pending for the calling process. The set of signals is returned through the \nset\n argument.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigpending\n(\nsigset_t\n \n*\nset\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nExample of \nsigpending\n and other signal features\n\n\nThe example below shows many of the signal features that have been described.\n\n\nsignals/critical.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_quit\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nsigset_t\n    \nnewmask\n,\n \noldmask\n,\n \npendmask\n;\n\n\n    \nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nsig_quit\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt catch SIGQUIT\n);\n\n\n    \n/*\n\n\n     * Block SIGQUIT and save current signal mask.\n\n\n     */\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGQUIT\n);\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n    \nsleep\n(\n5\n);\n   \n/* SIGQUIT here will remain pending */\n\n\n    \nif\n \n(\nsigpending\n(\npendmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nsigpending error\n);\n\n    \nif\n \n(\nsigismember\n(\npendmask\n,\n \nSIGQUIT\n))\n\n        \nprintf\n(\n\\n\nSIGQUIT pending\n\\n\n);\n\n\n    \n/*\n\n\n     * Restore signal mask which unblocks SIGQUIT.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n    \nprintf\n(\nSIGQUIT unblocked\n\\n\n);\n\n\n    \nsleep\n(\n5\n);\n   \n/* SIGQUIT here will terminate with core file */\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_quit\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\ncaught SIGQUIT\n\\n\n);\n\n    \nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nSIG_DFL\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt reset SIGQUIT\n);\n\n\n}\n\n\n\n\n\n\nRun this program:\n\n\n$ ./a.out\n\n\n\u02c6\\                    # generate signal once (before 5 seconds are up)\n\n\nSIGQUIT               # pending after return from sleep\n\n\ncaught SIGQUIT        # in signal handler\n\n\nSIGQUIT unblocked     # after return from sigprocmask\n\n\n\u02c6\\Quit(coredump)      # generate signal again\n\n\n$ ./a.out\n\n\n\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\  # generate signal 10 times (before 5 seconds are up)\n\n\nSIGQUIT pending\n\n\ncaught SIGQUIT        # signal is generated only once\n\n\nSIGQUIT unblocked\n\n\n\u02c6\\Quit(coredump)      # generate signal again\n\n\n\n\n\n\n[p349]\n\n\nSome notes from this example:\n\n\n\n\nWe saved the old mask when we blocked the signal. To unblock the signal, we did a \nSIG_SETMASK\n of the old mask. Alternatively, we could \nSIG_UNBLOCK\n only the signal that we had blocked. Be aware, however, if we write a function that can be called by others and if we need to block a signal in our function, we can\u2019t use \nSIG_UNBLOCK\n to unblock the signal. In this case, we have to use \nSIG_SETMASK\n and restore the signal mask to its prior value, because it\u2019s possible that the caller had specifically blocked this signal before calling our function. We\u2019ll see an example of this in the \nsystem\n function in \nSection 10.18\n.\n\n\nWhen we run the program the second time, we generate the quit signal ten times while the process is asleep, yet the signal is delivered only once to the process when it\u2019s unblocked. This demonstrates that signals are not queued on this system\n\n\n\n\nsigaction\n Function\n\n\nThe \nsigaction\n function allows us to examine or modify (or both) the action associated with a particular signal. This function supersedes the \nsignal\n function from earlier releases of the UNIX System. Indeed, at the end of this section, we show an implementation of \nsignal\n using \nsigaction\n.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigaction\n(\nint\n \nsigno\n,\n \nconst\n \nstruct\n \nsigaction\n \n*\nrestrict\n \nact\n,\n\n              \nstruct\n \nsigaction\n \n*\nrestrict\n \noact\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe argument \nsigno\n is the signal number whose action we are examining or modifying.\n\n\nIf the \nact\n pointer is non-null, we are modifying the action.\n\n\nIf the \noact\n pointer is non-null, the system returns the previous action for the signal through the \noact\n pointer\n\n\n\n\nThis function uses the following structure:\n\n\nstruct\n \nsigaction\n \n{\n\n    \nvoid\n \n(\n*\nsa_handler\n)(\nint\n);\n  \n/* addr of signal handler, */\n\n                              \n/* or SIG_IGN, or SIG_DFL */\n\n    \nsigset_t\n \nsa_mask\n;\n         \n/* additional signals to block */\n\n    \nint\n \nsa_flags\n;\n             \n/* signal options, Figure 10.16 */\n\n\n    \n/* alternate handler */\n\n    \nvoid\n \n(\n*\nsa_sigaction\n)(\nint\n,\n \nsiginfo_t\n \n*\n,\n \nvoid\n \n*\n);\n\n\n};\n\n\n\n\n\n\nIf the \nsa_handler\n field contains the address of a signal-catching function (rather than \nSIG_IGN\n or \nSIG_DFL\n), then the \nsa_mask\n field specifies a set of signals that are added to the signal mask of the process before the signal-catching function is called. If and when the signal-catching function returns, the signal mask of the process is reset to its previous value. This enables us to block certain signals whenever a signal handler is invoked. \nThe operating system includes the signal being delivered in the signal mask when the handler is invoked. Hence, we are guaranteed that whenever we are processing a given signal, another occurrence of that same signal is blocked until we\u2019re finished processing the first occurrence.\n Additional occurrences of the same signal are usually not queued (\nSection 10.8\n). If the signal occurs five times while it is blocked, when we unblock the signal, the signal-handling function for that signal will usually be invoked only one time.\n\n\nOnce we install an action for a given signal, that action remains installed until we explicitly change it by calling \nsigaction\n. [p350]\n\n\nThe \nsa_flags\n field of the act structure specifies various options for the handling of this signal. The table below details the meaning of these options when set.\n\n\nThe \nsa_sigaction\n field is an alternative signal handler used when the \nSA_SIGINFO\n flag is used with \nsigaction\n. Implementations might use the same storage for both the \nsa_sigaction\n field and the \nsa_handler\n field, so applications can use only one of these fields at a time.\n\n\nOption flags (\nsa_flags\n) for the handling of each signal:\n\n\n\n\n\n\n\n\nOption\n\n\nSUS\n\n\nFreeBSD\n\n\nLinux\n\n\nMac OS X\n\n\nSolaris\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSA_INTERRUPT\n\n\n\n\n\n\nx\n\n\n\n\n\n\nSystem calls interrupted by this signal are not automatically restarted (the XSI default for \nsigaction\n). See \nSection 10.5\n.\n\n\n\n\n\n\nSA_NOCLDSTOP\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nIf \nsigno\n is \nSIGCHLD\n, do not generate this signal when a child process stops (job control). This signal is still generated, of course, when a child terminates (but see the \nSA_NOCLDWAIT\n option below). When the XSI option is supported, \nSIGCHLD\n won\u2019t be sent when a stopped child continues if this flag is set.\n\n\n\n\n\n\nSA_NOCLDWAIT\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nIf \nsigno\n is \nSIGCHLD\n, this option prevents the system from creating zombie processes when children of the calling process terminate. If it subsequently calls \nwait\n, the calling process blocks until all its child processes have terminated and then returns \u22121 with \nerrno\n set to \nECHILD\n. (\nSection 10.7\n)\n\n\n\n\n\n\nSA_NODEFER\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nWhen this signal is caught, the signal is not automatically blocked by the system while the signal-catching function executes (unless the signal is also included in \nsa_mask\n). Note that this type of operation corresponds to the earlier unreliable signals.\n\n\n\n\n\n\nSA_ONSTACK\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nIf an alternative stack has been declared with \nsigaltstack(2)\n, this signal is delivered to the process on the alternative stack.\n\n\n\n\n\n\nSA_RESETHAND\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nThe disposition for this signal is reset to \nSIG_DFL\n, and the \nSA_SIGINFO\n flag is cleared on entry to the signal-catching function. Note that this type of operation corresponds to the earlier unreliable signals. The disposition for the two signals \nSIGILL\n and \nSIGTRAP\n can\u2019t be reset automatically, however. Setting this flag can optionally cause sigaction to behave as if \nSA_NODEFER\n is also set.\n\n\n\n\n\n\nSA_RESTART\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nSystem calls interrupted by this signal are automatically restarted. (\nSection 10.5\n)\n\n\n\n\n\n\nSA_SIGINFO\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nThis option provides additional information to a signal handler: a pointer to a \nsiginfo\n structure and a pointer to an identifier for the process context.\n\n\n\n\n\n\n\n\nNormally, the signal handler is called as:\n\n\nvoid\n \nhandler\n(\nint\n \nsigno\n);\n\n\n\n\n\n\nIf the \nSA_SIGINFO\n flag is set, the signal handler is called as:\n\n\nvoid\n \nhandler\n(\nint\n \nsigno\n,\n \nsiginfo_t\n \n*\ninfo\n,\n \nvoid\n \n*\ncontext\n);\n\n\n\n\n\n\nThe \nsiginfo\n structure contains information about why the signal was generated. All POSIX.1-compliant implementations must include at least the \nsi_signo\n and \nsi_code\n members. Additionally, implementations that are XSI compliant contain at least the following fields:\n\n\nstruct\n \nsiginfo\n \n{\n\n    \nint\n \nsi_signo\n;\n \n/* signal number */\n\n    \nint\n \nsi_errno\n;\n \n/* if nonzero, errno value from errno.h */\n\n    \nint\n \nsi_code\n;\n \n/* additional info (depends on signal) */\n\n    \npid_t\n \nsi_pid\n;\n \n/* sending process ID */\n\n    \nuid_t\n \nsi_uid\n;\n \n/* sending process real user ID */\n\n    \nvoid\n \n*\nsi_addr\n;\n \n/* address that caused the fault */\n\n    \nint\n \nsi_status\n;\n \n/* exit value or signal number */\n\n    \nunion\n \nsigval\n \nsi_value\n;\n \n/* application-specific value */\n\n    \n/* possibly other fields also */\n\n\n};\n\n\n\n\n\n\nThe \nsigval\n union contains the following fields:\n\n\nint\n \nsival_int\n;\n\n\nvoid\n \n*\nsival_ptr\n;\n\n\n\n\n\n\nApplications pass an integer value in \nsi_value.sival_int\n or pass a pointer value in \nsi_value.sival_ptr\n when delivering signals.\n\n\nIf the signal is \nSIGCHLD\n, then the \nsi_pid\n, \nsi_status\n, and \nsi_uid\n fields will be set.\nIf the signal is \nSIGBUS\n, \nSIGILL\n, \nSIGFPE\n, or \nSIGSEGV\n, then the \nsi_addr\n contains the address responsible for the fault.\nThe \nsi_errno\n field contains the error number corresponding to the condition that caused the signal to be generated.\n\n\nThe table shows values of \nsi_code\n for various signals, as defined by the Single UNIX Specification:\n\n\n\n\nThe \ncontext\n argument to the signal handler is a typeless pointer that can be cast to a \nucontext_t\n structure identifying the process context at the time of signal delivery. This structure contains at least the following fields:\n\n\nucontext_t\n \n*\nuc_link\n;\n    \n/* pointer to context resumed when */\n\n                        \n/* this context returns */\n\n\nsigset_t\n \nuc_sigmask\n;\n    \n/* signals blocked when this context */\n\n                        \n/* is active */\n\n\nstack_t\n \nuc_stack\n;\n       \n/* stack used by this context */\n\n\nmcontext_t\n \nuc_mcontext\n;\n \n/* machine-specific representation of */\n\n                        \n/* saved context */\n\n\n\n\n\n\nThe \nuc_stack\n field describes the stack used by the current context. It contains at least the following members:\n\n\nvoid\n \n*\nss_sp\n;\n \n/* stack base or pointer */\n\n\nsize_t\n \nss_size\n;\n \n/* stack size */\n\n\nint\n \nss_flags\n;\n \n/* flags */\n\n\n\n\n\n\nWhen an implementation supports the real-time signal extensions, signal handlers established with the \nSA_SIGINFO\n flag will result in signals being queued reliably. A separate range of reserved signal numbers is available for real-time application use. Applications can pass information along with the signal by using the sigqueue function (\nSection 10.20\n).\n\n\nExample: \nsignal\n Function\n\n\nThe following is the implementation of the \nsignal\n function using \nsigaction\n. [p354]\n\n\nlib/signal.c\n\n\n#include \napue.h\n\n\n\n/* Reliable version of signal(), using POSIX sigaction().  */\n\n\nSigfunc\n \n*\n\n\nsignal\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nact\n,\n \noact\n;\n\n\n    \nact\n.\nsa_handler\n \n=\n \nfunc\n;\n\n    \nsigemptyset\n(\nact\n.\nsa_mask\n);\n\n    \nact\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGALRM\n)\n \n{\n\n\n#ifdef  SA_INTERRUPT\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_INTERRUPT\n;\n\n\n#endif\n\n    \n}\n \nelse\n \n{\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_RESTART\n;\n\n    \n}\n\n    \nif\n \n(\nsigaction\n(\nsigno\n,\n \nact\n,\n \noact\n)\n \n \n0\n)\n\n        \nreturn\n(\nSIG_ERR\n);\n\n    \nreturn\n(\noact\n.\nsa_handler\n);\n\n\n}\n\n\n\n\n\n\n\n\nWe must use \nsigemptyset\n to initialize the \nsa_mask\n member of the structure since we\u2019re not guaranteed that \nact.sa_mask = 0\n does the same thing.\n\n\nWe intentionally set the \nSA_RESTART\n flag for all signals other than \nSIGALRM\n, so that any system call interrupted by these other signals will be automatically restarted. The reason we don\u2019t want \nSIGALRM\n restarted is to allow us to set a timeout for I/O operations. (\nFigure 10.10\n)\n\n\nSome older systems, such as SunOS, define the \nSA_INTERRUPT\n flag. These systems restart interrupted system calls by default, so specifying this flag causes system calls to be interrupted. Linux defines the \nSA_INTERRUPT\n flag for compatibility with applications that use it, but by default does not restart system calls when the signal handler is installed with \nsigaction\n. The Single UNIX Specification specifies that the \nsigaction\n function not restart interrupted system calls unless the \nSA_RESTART\n flag is specified.\n\n\n\n\nExample: \nsignal_intr\n Function\n\n\nThe following code shows a version of the \nsignal\n function that tries to prevent any interrupted system calls from being restarted.\n\n\nlib/signalintr.c\n\n\n#include \napue.h\n\n\n\nSigfunc\n \n*\n\n\nsignal_intr\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nact\n,\n \noact\n;\n\n\n    \nact\n.\nsa_handler\n \n=\n \nfunc\n;\n\n    \nsigemptyset\n(\nact\n.\nsa_mask\n);\n\n    \nact\n.\nsa_flags\n \n=\n \n0\n;\n\n\n#ifdef  SA_INTERRUPT\n\n    \nact\n.\nsa_flags\n \n|=\n \nSA_INTERRUPT\n;\n\n\n#endif\n\n    \nif\n \n(\nsigaction\n(\nsigno\n,\n \nact\n,\n \noact\n)\n \n \n0\n)\n\n        \nreturn\n(\nSIG_ERR\n);\n\n    \nreturn\n(\noact\n.\nsa_handler\n);\n\n\n}\n\n\n\n\n\n\nFor improved portability, we specify the \nSA_INTERRUPT\n flag, if defined by the system, to prevent interrupted system calls from being restarted.\n\n\nsigsetjmp\n and \nsiglongjmp\n Functions\n\n\nsetjmp\n and \nlongjmp\n functions (\nSection 7.10\n) can be used for nonlocal branching. The \nlongjmp\n function is often called from a signal handler to return to the main loop of a program, instead of returning from the handler. (\nFigure 10.8\n and \nFigure 10.11\n).\n\n\nHowever, there is a problem in calling \nlongjmp\n. When a signal is caught, the signal-catching function is entered, with the current signal automatically being added to the signal mask of the process. This prevents subsequent occurrences of that signal from interrupting the signal handler. If we \nlongjmp\n out of the signal handler, what happens to the signal mask for the process depends on the platform:\n\n\n\n\nUnder FreeBSD 8.0 and Mac OS X 10.6.8, \nsetjmp\n and \nlongjmp\n save and restore the signal mask.\n\n\nLinux 3.2.0 and Solaris 10, however, do not save and restore the signal mask, although Linux supports an option to provide BSD behavior.\n\n\nFreeBSD and Mac OS X provide the functions \n_setjmp\n and \n_longjmp\n, which do not save and restore the signal mask.\n\n\n\n\nTo allow either form of behavior, POSIX.1 does not specify the effect of \nsetjmp\n and \nlongjmp\n on signal masks. Instead, two new functions, \nsigsetjmp\n and \nsiglongjmp\n, are defined by POSIX.1. These two functions should always be used when branching from a signal handler.\n\n\n#include \nsetjmp.h\n\n\n\nint\n \nsigsetjmp\n(\nsigjmp_buf\n \nenv\n,\n \nint\n \nsavemask\n);\n\n\n/* Returns: 0 if called directly, nonzero if returning from a call to siglongjmp */\n\n\n\nvoid\n \nsiglongjmp\n(\nsigjmp_buf\n \nenv\n,\n \nint\n \nval\n);\n\n\n\n\n\n\nThe only difference between these functions and the \nsetjmp\n and \nlongjmp\n functions is that \nsigsetjmp\n has an additional argument. If \nsavemask\n is nonzero, then \nsigsetjmp\n also saves the current signal mask of the process in \nenv\n. When \nsiglongjmp\n is called, if the \nenv\n argument was saved by a call to \nsigsetjmp\n with a nonzero \nsavemask\n, then \nsiglongjmp\n restores the saved signal mask.\n\n\nsignals/mask.c\n\n\n#include \napue.h\n\n\n#include \nsetjmp.h\n\n\n#include \ntime.h\n\n\n\nstatic\n \nvoid\n                     \nsig_usr1\n(\nint\n);\n\n\nstatic\n \nvoid\n                     \nsig_alrm\n(\nint\n);\n\n\nstatic\n \nsigjmp_buf\n               \njmpbuf\n;\n\n\nstatic\n \nvolatile\n \nsig_atomic_t\n    \ncanjump\n;\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGUSR1\n,\n \nsig_usr1\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGUSR1) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGALRM) error\n);\n\n\n    \npr_mask\n(\nstarting main: \n);\n     \n/* {Prog prmask} */\n\n\n    \nif\n \n(\nsigsetjmp\n(\njmpbuf\n,\n \n1\n))\n \n{\n\n\n        \npr_mask\n(\nending main: \n);\n\n\n        \nexit\n(\n0\n);\n\n    \n}\n\n    \ncanjump\n \n=\n \n1\n;\n    \n/* now sigsetjmp() is OK */\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n\n        \npause\n();\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_usr1\n(\nint\n \nsigno\n)\n\n\n{\n\n    \ntime_t\n  \nstarttime\n;\n\n\n    \nif\n \n(\ncanjump\n \n==\n \n0\n)\n\n        \nreturn\n;\n     \n/* unexpected signal, ignore */\n\n\n    \npr_mask\n(\nstarting sig_usr1: \n);\n\n\n    \nalarm\n(\n3\n);\n               \n/* SIGALRM in 3 seconds */\n\n    \nstarttime\n \n=\n \ntime\n(\nNULL\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n             \n/* busy wait for 5 seconds */\n\n        \nif\n \n(\ntime\n(\nNULL\n)\n \n \nstarttime\n \n+\n \n5\n)\n\n            \nbreak\n;\n\n\n    \npr_mask\n(\nfinishing sig_usr1: \n);\n\n\n    \ncanjump\n \n=\n \n0\n;\n\n    \nsiglongjmp\n(\njmpbuf\n,\n \n1\n);\n  \n/* jump back to main, don\nt return */\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npr_mask\n(\nin sig_alrm: \n);\n\n\n}\n\n\n\n\n\n\n\n\nWe set the variable \ncanjump\n to a nonzero value only after we\u2019ve called \nsigsetjmp\n. This variable is examined in the signal handler, and \nsiglongjmp\n is called only if the flag \ncanjump\n is nonzero. This technique provides protection against the signal handler being called at some earlier or later time, when the jump buffer hasn\u2019t been initialized by \nsigsetjmp\n. This technique should be used whenever \nsiglongjmp\n is called from a signal handler, but is not required with longjmp in normal C code. Since a signal can occur at any time, therefore we need the added protection in a signal handler.\n\n\nWe use the data type \nsig_atomic_t\n, which is defined by the ISO C standard to be the type of variable that can be written without being interrupted.\n\n\nThis means that a variable of type \nsig_atomic_t\n should not extend across page boundaries on a system with virtual memory and can be accessed with a single machine instruction, for example.\n\n\nWe always include the ISO type qualifier \nvolatile\n for these data types as well, since the variable is being accessed by two different threads of control: the \nmain\n function and the asynchronously executing signal handler.\n\n\n\n\n\n\n\n\nWe can divide the following figure into three parts:\n\n\n\n\nLeft part (corresponding to \nmain\n)\n\n\nCenter part (\nsig_usr1\n)\n\n\nRight part (\nsig_alrm\n).\n\n\n\n\nWhile the process is executing in the left part, its signal mask is 0 (no signals are blocked). While executing in the center part, its signal mask is \nSIGUSR1\n. While executing in the right part, its signal mask is \nSIGUSR1\n|\nSIGALRM\n.\n\n\n\n\nThe output of the program:\n\n\n$ ./a.out \n             # start process in background\n\n\nstarting main:\n\n\n[1] 531                 # the job-control shell prints its process ID\n\n\n$ kill -USR1 531        # send the process SIGUSR1\n\n\nstarting sig_usr1: SIGUSR1\n\n\n$ in sig_alrm: SIGUSR1 SIGALRM\n\n\nfinishing sig_usr1: SIGUSR1\n\n\nending main:\n\n\n                        # just press RETURN\n\n\n[1] + Done ./a.out \n\n\n\n\n\n\nThe output is what we expect: when a signal handler is invoked, the signal being caught is added to the current signal mask of the process. The original mask is restored when the signal handler returns. Also, \nsiglongjmp\n restores the signal mask that was saved by \nsigsetjmp\n.\n\n\nsigsuspend\n Function\n\n\nWe have seen how we can change the signal mask for a process to block and unblock selected signals. We can use this technique to protect critical regions of code that we don\u2019t want interrupted by a signal. But what if we want to unblock a signal and then \npause\n, waiting for the previously blocked signal to occur? Assuming that the signal is \nSIGINT\n, the incorrect way to do this is:\n\n\n  \nsigset_t\n \nnewmask\n,\n \noldmask\n;\n\n\n  \nsigemptyset\n(\nnewmask\n);\n\n  \nsigaddset\n(\nnewmask\n,\n \nSIGINT\n);\n\n\n  \n/* block SIGINT and save current signal mask */\n\n  \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n      \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n  \n/* critical region of code */\n\n\n  \n/* restore signal mask, which unblocks SIGINT */\n\n  \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n      \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n  \n/* window is open */\n\n  \npause\n();\n \n/* wait for signal to occur */\n\n\n  \n/* continue processing */\n\n\n\n\n\n\nIf the signal is sent to the process while it is blocked, the signal delivery will be deferred until the signal is unblocked. To the application, this can look as if the signal occurs between the unblocking and the \npause\n (depending on how the kernel implements signals). If this happens, or if the signal does occur between the unblocking and the \npause\n, we have a problem. Any occurrence of the signal in this window of time is lost, in the sense that we might not see the signal again, in which case the \npause\n will block indefinitely. This is another problem with the earlier unreliable signals.\n\n\nTo correct this problem, we need a way to both restore the signal mask and put the process to sleep in a single atomic operation. This feature is provided by the \nsigsuspend\n function.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigsuspend\n(\nconst\n \nsigset_t\n \n*\nsigmask\n);\n\n\n\n/* Returns: \u22121 with errno set to EINTR */\n\n\n\n\n\n\nThe signal mask of the process is set to the value pointed to by \nsigmask\n. Then the process is suspended until a signal is caught or until a signal occurs that terminates the process. If a signal is caught and if the signal handler returns, then \nsigsuspend\n returns, and the signal mask of the process is set to its value before the call to \nsigsuspend\n.\n\n\nExample of \nsigsuspend\n to protect a critial region\n\n\nThe following code shows the correct way to protect a critical region of code from a specific signal.\n\n\nsignals/suspend1.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_int\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nsigset_t\n    \nnewmask\n,\n \noldmask\n,\n \nwaitmask\n;\n\n\n    \npr_mask\n(\nprogram start: \n);\n\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nsigemptyset\n(\nwaitmask\n);\n\n    \nsigaddset\n(\nwaitmask\n,\n \nSIGUSR1\n);\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGINT\n);\n\n\n    \n/*\n\n\n     * Block SIGINT and save current signal mask.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n    \n/*\n\n\n     * Critical region of code.\n\n\n     */\n\n    \npr_mask\n(\nin critical region: \n);\n\n\n    \n/*\n\n\n     * Pause, allowing all signals except SIGUSR1.\n\n\n     */\n\n    \nif\n \n(\nsigsuspend\n(\nwaitmask\n)\n \n!=\n \n-\n1\n)\n\n        \nerr_sys\n(\nsigsuspend error\n);\n\n\n    \npr_mask\n(\nafter return from sigsuspend: \n);\n\n\n    \n/*\n\n\n     * Reset signal mask which unblocks SIGINT.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n    \n/*\n\n\n     * And continue processing ...\n\n\n     */\n\n    \npr_mask\n(\nprogram exit: \n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npr_mask\n(\n\\n\nin sig_int: \n);\n\n\n}\n\n\n\n\n\n\nWhen \nsigsuspend\n returns, it sets the signal mask to its value before the cal SIGINT signal will be blocked, so we restore the signal mask to the value\nthat we saved earlier (oldmask).\n\n\nRunning the program produces the following output:\n\n\n$ ./a.out\n\n\nprogram start:\n\n\nin critical region: SIGINT\n\n\n\u02c6C                          # type the interrupt character\n\n\nin sig_int: SIGINT SIGUSR1\n\n\nafter return from sigsuspend: SIGINT\n\n\nprogram exit:\n\n\n\n\n\n\nExample of \nsigsuspend\n to wait for a signal handler to set a global variable\n\n\nIn the following program, we catch both the interrupt signal and the quit signal, but want to wake up the main routine only when the quit signal is caught.\n\n\nsignals/suspend2.c\n\n\n#include \napue.h\n\n\n\nvolatile\n \nsig_atomic_t\n   \nquitflag\n;\n   \n/* set nonzero by signal handler */\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n  \n/* one signal handler for SIGINT and SIGQUIT */\n\n\n{\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGINT\n)\n\n        \nprintf\n(\n\\n\ninterrupt\n\\n\n);\n\n    \nelse\n \nif\n \n(\nsigno\n \n==\n \nSIGQUIT\n)\n\n        \nquitflag\n \n=\n \n1\n;\n   \n/* set flag for main loop */\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nsigset_t\n    \nnewmask\n,\n \noldmask\n,\n \nzeromask\n;\n\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGQUIT) error\n);\n\n\n    \nsigemptyset\n(\nzeromask\n);\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGQUIT\n);\n\n\n    \n/*\n\n\n     * Block SIGQUIT and save current signal mask.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n    \nwhile\n \n(\nquitflag\n \n==\n \n0\n)\n\n        \nsigsuspend\n(\nzeromask\n);\n\n\n    \n/*\n\n\n     * SIGQUIT has been caught and is now blocked; do whatever.\n\n\n     */\n\n    \nquitflag\n \n=\n \n0\n;\n\n\n    \n/*\n\n\n     * Reset signal mask which unblocks SIGQUIT.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nSample output from this program is:\n\n\n$ ./a.out\n\n\n\u02c6C           # type the interrupt character\n\n\ninterrupt\n\n\n\u02c6C           # type the interrupt character again\n\n\ninterrupt\n\n\n\u02c6C           # and again\n\n\ninterrupt\n\n\n\u02c6\\ $         # now terminate with the quit character\n\n\n\n\n\n\nExample of signals that synchronize a parent and child\n\n\nThis example shows how signals can be used to synchronize a parent and child. The following example shows implementations of the five routines \nTELL_WAIT\n, \nTELL_PARENT\n, \nTELL_CHILD\n, \nWAIT_PARENT\n, and \nWAIT_CHILD\n from \nSection 8.9\n.\n\n\nlib/tellwait.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvolatile\n \nsig_atomic_t\n \nsigflag\n;\n \n/* set nonzero by sig handler */\n\n\nstatic\n \nsigset_t\n \nnewmask\n,\n \noldmask\n,\n \nzeromask\n;\n\n\n\nstatic\n \nvoid\n\n\nsig_usr\n(\nint\n \nsigno\n)\n  \n/* one signal handler for SIGUSR1 and SIGUSR2 */\n\n\n{\n\n    \nsigflag\n \n=\n \n1\n;\n\n\n}\n\n\n\nvoid\n\n\nTELL_WAIT\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGUSR1\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGUSR1) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGUSR2\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGUSR2) error\n);\n\n    \nsigemptyset\n(\nzeromask\n);\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGUSR1\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGUSR2\n);\n\n\n    \n/* Block SIGUSR1 and SIGUSR2, and save current signal mask */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n}\n\n\n\nvoid\n\n\nTELL_PARENT\n(\npid_t\n \npid\n)\n\n\n{\n\n    \nkill\n(\npid\n,\n \nSIGUSR2\n);\n     \n/* tell parent we\nre done */\n\n\n}\n\n\n\nvoid\n\n\nWAIT_PARENT\n(\nvoid\n)\n\n\n{\n\n    \nwhile\n \n(\nsigflag\n \n==\n \n0\n)\n\n        \nsigsuspend\n(\nzeromask\n);\n  \n/* and wait for parent */\n\n    \nsigflag\n \n=\n \n0\n;\n\n\n    \n/* Reset signal mask to original value */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n}\n\n\n\nvoid\n\n\nTELL_CHILD\n(\npid_t\n \npid\n)\n\n\n{\n\n    \nkill\n(\npid\n,\n \nSIGUSR1\n);\n         \n/* tell child we\nre done */\n\n\n}\n\n\n\nvoid\n\n\nWAIT_CHILD\n(\nvoid\n)\n\n\n{\n\n    \nwhile\n \n(\nsigflag\n \n==\n \n0\n)\n\n        \nsigsuspend\n(\nzeromask\n);\n  \n/* and wait for child */\n\n    \nsigflag\n \n=\n \n0\n;\n\n\n    \n/* Reset signal mask to original value */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n}\n\n\n\n\n\n\nIn the example, two user-defined signals are used: \nSIGUSR1\n is sent by the parent to the child, and \nSIGUSR2\n is sent by the child to the parent.\n\n\nThe \nsigsuspend\n function is fine if we want to go to sleep while we\u2019re waiting for a signal to occur. If we want to call other system functions while we\u2019re waiting, the only solution is to use multiple threads and dedicate a separate thread to handling signals (\nSection 12.8\n).\n\n\nWithout using threads, the best we can do is to set a global variable in the signal handler when the signal occurs. For example, if we catch both \nSIGINT\n and \nSIGALRM\n and install the signal handlers using the \nsignal_intr\n function\n, the signals will interrupt any slow system call that is blocked. The signals are most likely to occur when we\u2019re blocked in a call to the \nread\n function waiting for input from a slow device.  (This is especially true for \nSIGALRM\n, since we set the alarm clock to prevent us from waiting forever for input.) The code to handle this looks similar to the following:\n\n\n    \nif\n \n(\nintr_flag\n)\n      \n/* flag set by our SIGINT handler */\n\n        \nhandle_intr\n();\n\n    \nif\n \n(\nalrm_flag\n)\n      \n/* flag set by our SIGALRM handler */\n\n        \nhandle_alrm\n();\n\n\n    \n/* signals occurring in here are lost */\n\n\n    \nwhile\n \n(\nread\n(\n \n...\n \n)\n \n \n0\n)\n \n{\n\n        \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n \n{\n\n            \nif\n \n(\nalrm_flag\n)\n\n                \nhandle_alrm\n();\n\n            \nelse\n \nif\n \n(\nintr_flag\n)\n\n                \nhandle_intr\n();\n\n        \n}\n \nelse\n \n{\n\n            \n/* some other error */\n\n            \n}\n\n        \n}\n \nelse\n \nif\n \n(\nn\n \n==\n \n0\n)\n \n{\n\n            \n/* end of file */\n\n        \n}\n \nelse\n \n{\n\n            \n/* process input */\n\n    \n}\n\n\n\n\n\n\nWe test each of the global flags before calling \nread\n and again if \nread\n returns an interrupted system call error. The problem occurs if either signal is caught between the first two if statements and the subsequent call to read. Signals occurring in here are lost, as indicated by the code comment. The signal handlers are called, and they set the appropriate global variable, but the \nread\n never returns (unless some data is ready to be read).\n\n\nWhat we would like to be able to do is the following sequence of steps, in order.\n\n\n\n\nBlock \nSIGINT\n and \nSIGALRM\n.\n\n\nTest the two global variables to see whether either signal has occurred and, if so, handle the condition.\n\n\nCall \nread\n (or any other system function) and unblock the two signals, as an atomic operation.\n\n\n\n\nThe \nsigsuspend\n function helps us only if step 3 is a \npause\n operation.\n\n\nabort\n Function\n\n\nThe \nabort\n function causes abnormal program termination.\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \nabort\n(\nvoid\n);\n\n\n\n/* This function never returns */\n\n\n\n\n\n\nThe \nabort\n function sends the \nSIGABRT\n signal to the caller. Processes should not ignore this signal. ISO C states that calling abort will deliver an unsuccessful termination notification to the host environment by calling \nraise(SIGABRT)\n.\n\n\n[p365]\n\n\nISO C:\n\n\n\n\nIf the signal is caught and the signal handler returns, \nabort\n still doesn\u2019t return to its caller. If this signal is caught, the only way the signal handler can\u2019t return is if it calls \nexit\n, \n_exit\n, \n_Exit\n, \nlongjmp\n, or \nsiglongjmp\n.\n\n\nIt is up to the implementation as to whether output streams are flushed and whether temporary files (\nSection 5.13\n) are deleted.\n\n\n\n\nPOSIX.1:\n\n\n\n\nabort\n overrides the blocking or ignoring of the signal by the process.\n\n\nThe intent of letting the process catch the \nSIGABRT\n is to allow it to perform any cleanup that it wants to do before the process terminates.\n\n\nIf the process doesn\u2019t terminate itself from this signal handler, when the signal handler returns, \nabort\n terminates the process.\n\n\nAn implementation is allowed to call \nfclose\n on open standard I/O streams before terminating if the call to abort terminates the process.\n\n\n\n\nSince most UNIX System implementations of \ntmpfile\n call \nunlink\n immediately after creating the file, the ISO C warning about temporary files does not usually concern us. [p366]\n\n\nThe following is an implementation of the \nabort\n function as specified by POSIX.1:\n\n\n#include \nsignal.h\n\n\n#include \nstdio.h\n\n\n#include \nstdlib.h\n\n\n#include \nunistd.h\n\n\n\nvoid\n\n\nabort\n(\nvoid\n)\n         \n/* POSIX-style abort() function */\n\n\n{\n\n    \nsigset_t\n            \nmask\n;\n\n    \nstruct\n \nsigaction\n    \naction\n;\n\n\n    \n/* Caller can\nt ignore SIGABRT, if so reset to default */\n\n    \nsigaction\n(\nSIGABRT\n,\n \nNULL\n,\n \naction\n);\n\n    \nif\n \n(\naction\n.\nsa_handler\n \n==\n \nSIG_IGN\n)\n \n{\n\n        \naction\n.\nsa_handler\n \n=\n \nSIG_DFL\n;\n\n        \nsigaction\n(\nSIGABRT\n,\n \naction\n,\n \nNULL\n);\n\n    \n}\n\n    \nif\n \n(\naction\n.\nsa_handler\n \n==\n \nSIG_DFL\n)\n\n        \nfflush\n(\nNULL\n);\n           \n/* flush all open stdio streams */\n\n\n    \n/* Caller can\nt block SIGABRT; make sure it\ns unblocked */\n\n    \nsigfillset\n(\nmask\n);\n\n    \nsigdelset\n(\nmask\n,\n \nSIGABRT\n);\n  \n/* mask has only SIGABRT turned off */\n\n    \nsigprocmask\n(\nSIG_SETMASK\n,\n \nmask\n,\n \nNULL\n);\n\n    \nkill\n(\ngetpid\n(),\n \nSIGABRT\n);\n    \n/* send the signal */\n\n\n    \n/* If we\nre here, process caught SIGABRT and returned */\n\n    \nfflush\n(\nNULL\n);\n               \n/* flush all open stdio streams */\n\n    \naction\n.\nsa_handler\n \n=\n \nSIG_DFL\n;\n\n    \nsigaction\n(\nSIGABRT\n,\n \naction\n,\n \nNULL\n);\n  \n/* reset to default */\n\n    \nsigprocmask\n(\nSIG_SETMASK\n,\n \nmask\n,\n \nNULL\n);\n  \n/* just in case ... */\n\n    \nkill\n(\ngetpid\n(),\n \nSIGABRT\n);\n                \n/* and one more time */\n\n    \nexit\n(\n1\n);\n    \n/* this should never be executed ... */\n\n\n}\n\n\n\n\n\n\n\n\nThis implementation of \nabort\n first check whether the default action will occur; if so, it flush all the standard I/O streams. This is not equivalent to calling \nfclose\n on all the open streams (since it just flushes them and doesn\u2019t close them), but when the process terminates, the system closes all open files.\n\n\nIf the process catches the signal and returns, we flush all the streams again, since the process could have generated more output.\n\n\nThe only condition we don\u2019t handle is the case where the process catches the signal and calls \n_exit\n or \n_Exit\n. In this case, any unflushed standard I/O buffers in memory are discarded. (We assume that a caller that does this doesn\u2019t want the buffers flushed.)\n\n\nAs mentioned in \nSection 10.9\n, if calling \nkill\n causes the signal to be generated for the caller, and if the signal is not blocked, then the signal (or some other pending, unlocked signal) is delivered to the process before \nkill\n returns. We block all signals except \nSIGABRT\n, so we know that if the call to \nkill\n returns, the process caught the signal and the signal handler returned.\n\n\n\n\nsystem\n Function\n\n\nSection 8.13\n showed an implementation of the \nsystem\n function, which did not do any signal handling. POSIX.1 requires that system ignore \nSIGINT\n and \nSIGQUIT\n and block \nSIGCHLD\n. Before showing a version that handles these signals correctly, let\u2019s see why we need to worry about signal handling.\n\n\nExample of \nsystem\n invoking \ned\n editor\n\n\nThe program (Figure 10.26) shown below uses the \nsystem\n function from \nSection 8.13\n to invoke the \ned(1)\n editor. It is an interactive program that catches the interrupt and quit signals. If \ned\n is invoked from a shell and type the interrupt character, it catches the interrupt signal and prints a question mark. The \ned\n program also sets the disposition of the quit signal so that it is ignored.\n\n\nsignals/systest2.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\ncaught SIGINT\n\\n\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_chld\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\ncaught SIGCHLD\n\\n\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGCHLD\n,\n \nsig_chld\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGCHLD) error\n);\n\n    \nif\n \n(\nsystem\n(\n/bin/ed\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nsystem() error\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThis program catches both \nSIGINT\n and \nSIGCHLD\n. If we invoke the program, we get:\n\n\n$ ./a.out\n\n\na                         # append text to the editor\u2019s buffer\n\n\nHere is one line of text\n\n\n.                         # period on a line by itself stops append mode\n\n\n1,$p                      # print first through last lines of buffer to see what\u2019s there\n\n\nHere is one line of text\n\n\nw temp.foo                # write the buffer to a file\n\n\n25                        # editor says it wrote 25 bytes\n\n\nq                         # and leave the editor\n\n\ncaught SIGCHLD\n\n\n\n\n\n\n\n\nWhen the editor terminates, the kernel sends the \nSIGCHLD\n signal to the parent (the \na.out\n process) and it is caught and returned from the signal handler. The parent should be catching the \nSIGCHLD\n signal because it has created its own children, so that it knows when its children have terminated.\n\n\nThe delivery of the \nSIGCHLD\n signal in the parent should be blocked while the \nsystem\n function is executing\n, as specified by POSIX.1. Otherwise, when the child created by \nsystem\n terminates, it would fool the caller of \nsystem\n into thinking that one of its own children terminated. The caller would then use one of the \nwait\n functions to get the termination status of the child, thereby preventing the \nsystem\n function from being able to obtain the child\u2019s termination status for its return value.\n\n\n\n\nIf we run the program again, this time sending the editor an interrupt signal, we get\n\n\n$ ./a.out\n\n\na                # append text to the editor\u2019s buffer\n\n\nhello, world\n\n\n.                # period on a line by itself stops append mode\n\n\n1,$p             # print first through last lines to see what\u2019s there\n\n\nhello, world\n\n\nw temp.foo       # write the buffer to a file\n\n\n13               # editor says it wrote 13 bytes\n\n\n\u02c6C               # type the interrupt character\n\n\n?                # editor catches signal, prints question mark\n\n\ncaught SIGINT    # and so does the parent process\n\n\nq                # leave editor\n\n\ncaught SIGCHLD\n\n\n\n\n\n\nAs mentioned in \nSection 9.6\n, typing the interrupt character causes the interrupt signal to be sent to all the processes in the foreground process group. The following figure shows the arrangement of the processes when the editor is running.\n\n\n\n\nIn this example:\n\n\nSIGINT\n is sent to all three foreground processes (the shell ignores it) and both the \na.out\n process and the editor catch the signal. When running another program with the \nsystem\n function, we shouldn\u2019t have both the parent and the child catching the two terminal-generated signals: interrupt and quit. Instead, these two signals should be sent to the program that is running: the child. Since the command that is executed by system can be an interactive command (the \ned\n program in this example) and since the caller of \nsystem\n gives up control while the program executes, waiting for it to finish, \nthe caller of \nsystem\n should not be receiving these two terminal-generated signals.\n For this reason, POSIX.1 specifies that \nthe \nsystem\n function should ignore the \nSIGINT\n and \nSIGQUIT\n signals while waiting for the command to complete.\n\n\nImplementation of \nsystem\n with signal handling\n\n\nThe program below shows an implementation of the system function with the required signal handling.\n\n\nsignals/system.c\n\n\n#include    \nsys/wait.h\n\n\n#include    \nerrno.h\n\n\n#include    \nsignal.h\n\n\n#include    \nunistd.h\n\n\n\nint\n\n\nsystem\n(\nconst\n \nchar\n \n*\ncmdstring\n)\n   \n/* with appropriate signal handling */\n\n\n{\n\n    \npid_t\n               \npid\n;\n\n    \nint\n                 \nstatus\n;\n\n    \nstruct\n \nsigaction\n    \nignore\n,\n \nsaveintr\n,\n \nsavequit\n;\n\n    \nsigset_t\n            \nchldmask\n,\n \nsavemask\n;\n\n\n    \nif\n \n(\ncmdstring\n \n==\n \nNULL\n)\n\n        \nreturn\n(\n1\n);\n      \n/* always a command processor with UNIX */\n\n\n    \nignore\n.\nsa_handler\n \n=\n \nSIG_IGN\n;\n    \n/* ignore SIGINT and SIGQUIT */\n\n    \nsigemptyset\n(\nignore\n.\nsa_mask\n);\n\n    \nignore\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigaction\n(\nSIGINT\n,\n \nignore\n,\n \nsaveintr\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nif\n \n(\nsigaction\n(\nSIGQUIT\n,\n \nignore\n,\n \nsavequit\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nsigemptyset\n(\nchldmask\n);\n         \n/* now block SIGCHLD */\n\n    \nsigaddset\n(\nchldmask\n,\n \nSIGCHLD\n);\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nchldmask\n,\n \nsavemask\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nstatus\n \n=\n \n-\n1\n;\n    \n/* probably out of processes */\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n          \n/* child */\n\n        \n/* restore previous signal actions \n reset signal mask */\n\n        \nsigaction\n(\nSIGINT\n,\n \nsaveintr\n,\n \nNULL\n);\n\n        \nsigaction\n(\nSIGQUIT\n,\n \nsavequit\n,\n \nNULL\n);\n\n        \nsigprocmask\n(\nSIG_SETMASK\n,\n \nsavemask\n,\n \nNULL\n);\n\n\n        \nexecl\n(\n/bin/sh\n,\n \nsh\n,\n \n-c\n,\n \ncmdstring\n,\n \n(\nchar\n \n*\n)\n0\n);\n\n        \n_exit\n(\n127\n);\n     \n/* exec error */\n\n    \n}\n \nelse\n \n{\n                        \n/* parent */\n\n        \nwhile\n \n(\nwaitpid\n(\npid\n,\n \nstatus\n,\n \n0\n)\n \n \n0\n)\n\n            \nif\n \n(\nerrno\n \n!=\n \nEINTR\n)\n \n{\n\n                \nstatus\n \n=\n \n-\n1\n;\n \n/* error other than EINTR from waitpid() */\n\n                \nbreak\n;\n\n            \n}\n\n    \n}\n\n\n    \n/* restore previous signal actions \n reset signal mask */\n\n    \nif\n \n(\nsigaction\n(\nSIGINT\n,\n \nsaveintr\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nif\n \n(\nsigaction\n(\nSIGQUIT\n,\n \nsavequit\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \nsavemask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n\n    \nreturn\n(\nstatus\n);\n\n\n}\n\n\n\n\n\n\nThis implementation of \nsystem\n differs from the previous flawed one in the following ways:\n\n\n\n\nNo signal is sent to the calling process when we type the interrupt or quit character.\n\n\nWhen the \ned\n command exits, \nSIGCHLD\n is not sent to the calling process. Instead, it is blocked until we unblock it in the last call to \nsigprocmask\n, after the \nsystem\n function retrieves the child\u2019s termination status by calling \nwaitpid\n.\n\n\n\n\nPOSIX.1 states that if \nwait\n or \nwaitpid\n returns the status of a child process while \nSIGCHLD\n is pending, then \nSIGCHLD\n should not be delivered to the process unless the status of another child process is also available. FreeBSD 8.0, Mac OS X 10.6.8, and Solaris 10 all implement this semantic, while Linux 3.2.0 doesn\u2019t. In Linux, \nSIGCHLD\n remains pending after the \nsystem\n function calls \nwaitpid\n; when the signal is unblocked, it is delivered to the caller. If we called \nwait\n in the \nsig_chld\n function in \nFigure 10.26\n, a Linux system would return \u22121 with \nerrno\n set to \nECHILD\n, since the \nsystem\n function already retrieved the termination status of the child.\n\n\nMany older texts show the ignoring of the interrupt and quit signals as follows:\n\n\n  \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n      \nerr_sys\n(\nfork error\n);\n\n  \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n    \n/* child */\n\n    \nexecl\n(...);\n\n    \n_exit\n(\n127\n);\n\n  \n}\n\n\n  \n/* parent */\n\n  \nold_intr\n \n=\n \nsignal\n(\nSIGINT\n,\n \nSIG_IGN\n);\n\n  \nold_quit\n \n=\n \nsignal\n(\nSIGQUIT\n,\n \nSIG_IGN\n);\n\n  \nwaitpid\n(\npid\n,\n \nstatus\n,\n \n0\n)\n\n  \nsignal\n(\nSIGINT\n,\n \nold_intr\n);\n\n  \nsignal\n(\nSIGQUIT\n,\n \nold_quit\n);\n\n\n\n\n\n\nThe problem with this sequence of code is that we have no guarantee after the \nfork\n regarding whether the parent or child runs first. If the child runs first and the parent doesn\u2019t run for some time after, an interrupt signal might be generated before the parent is able to change its disposition to be ignored. For this reason, in the implementation of \nsystem\n, we change the disposition of the signals before the \nfork\n.\n\n\nNote that we have to reset the dispositions of these two signals in the child before the call to \nexecl\n. This allows execl to change their dispositions to the default, based on the caller\u2019s dispositions, as described in \nSection 8.10\n.\n\n\nReturn Value from \nsystem\n\n\nThe return value from \nsystem\n is the termination status of the shell, which isn\u2019t always the termination status of the command string. [p371]\n\n\nRun the program in \nFigure 8.24\n and send some signals to the command that\u2019s executing:\n\n\n$ tsys \nsleep 30\n\n\n\u02c6Cnormal termination, exit status = 130  # we press the interrupt key\n\n\n$ tsys \nsleep 30\n\n\n\u02c6\\sh: 946                                # Quit we press the quit key\n\n\nnormal termination, exit status = 131\n\n\n\n\n\n\nWhen we terminate the \nsleep\n call with the interrupt signal, the \npr_exit\n function (Figure 8.5) thinks that it terminated normally. The same thing happens when we kill the \nsleep\n call with the quit key. This is because the Bourne shell has a poorly documented feature in which its termination status is 128 plus the signal number, when the command it was executing is terminated by a signal. [p372]\n\n\nTry a similar example, but this time we\u2019ll send a signal directly to the shell and see what is returned by system:\n\n\n$ tsys \nsleep 30\n \n      # start it in background this time\n\n\n9257\n\n\n$ ps -f                  # look at the process IDs\n\n\nUID PID PPID TTY TIME CMD\n\n\nsar 9260 949 pts/5 0:00 ps -f\n\n\nsar 9258 9257 pts/5 0:00 sh -c sleep 30\n\n\nsar 949 947 pts/5 0:01 /bin/sh\n\n\nsar 9257 949 pts/5 0:00 tsys sleep 30\n\n\nsar 9259 9258 pts/5 0:00 sleep 30\n\n\n$ kill -KILL 9258        # kill the shell itself\n\n\nabnormal termination, signal number = 9\n\n\n\n\n\n\nWe can see that the return value from system reports an abnormal termination only when the shell itself terminates abnormally.\n\n\nOther shells behave differently when handling terminal-generated signals, such as \nSIGINT\n and \nSIGQUIT\n. With \nbash\n and \ndash\n, for example, pressing the interrupt or quit key will result in an exit status indicating abnormal termination with the corresponding signal number. However, if we find our process executing \nsleep\n and send it a signal directly, so that the signal goes only to the individual process instead of the entire foreground process group, we will find that these shells behave like the Bourne shell and exit with a normal termination status of 128 plus the signal number.\n\n\nWhen writing programs that use the \nsystem\n function, be sure to interpret the return value correctly. If you call \nfork\n, \nexec\n, and \nwait\n yourself, the termination status is not the same as if you call system.\n\n\nsleep\n, \nnanosleep\n, and \nclock_nanosleep\n Functions\n\n\n#include \nunistd.h\n\n\n\nunsigned\n \nint\n \nsleep\n(\nunsigned\n \nint\n \nseconds\n);\n\n\n\n/* Returns: 0 or number of unslept seconds */\n\n\n\n\n\n\nThe \nsleep\n function causes the calling process to be suspended until either:\n\n\n\n\nThe amount of wall clock time specified by seconds has elapsed. In this case, the return value is 0.\n\n\nA signal is caught by the process and the signal handler returns. In this case the return value is the number of unslept seconds (the requested time minus the actual time slept).\n\n\n\n\nAs with an \nalarm\n signal, the actual return may occur at a time later than requested because of other system activity.\n\n\nAlthough sleep can be implemented with the \nalarm\n function (\nSection 10.10\n), this isn\u2019t required. If \nalarm\n is used, there can be interactions between the two functions. The POSIX.1 standard leaves all these interactions unspecified.\n\n\nFreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10 implement \nsleep\n using the \nnanosleep\n function, which allows the implementation to be independent of signals and the alarm timer.\n\n\nThe follow example shows an implementation of the POSIX.1 \nsleep\n function. This function is a modification of \nFigure 10.7\n, which handles signals reliably, avoiding the race condition in the earlier implementation, but does not handle any interactions with previously set alarms.\n\n\nlib/sleep.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \n/* nothing to do, just returning wakes up sigsuspend() */\n\n\n}\n\n\n\nunsigned\n \nint\n\n\nsleep\n(\nunsigned\n \nint\n \nseconds\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nnewact\n,\n \noldact\n;\n\n    \nsigset_t\n            \nnewmask\n,\n \noldmask\n,\n \nsuspmask\n;\n\n    \nunsigned\n \nint\n        \nunslept\n;\n\n\n    \n/* set our handler, save previous information */\n\n    \nnewact\n.\nsa_handler\n \n=\n \nsig_alrm\n;\n\n    \nsigemptyset\n(\nnewact\n.\nsa_mask\n);\n\n    \nnewact\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nsigaction\n(\nSIGALRM\n,\n \nnewact\n,\n \noldact\n);\n\n\n    \n/* block SIGALRM and save current signal mask */\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGALRM\n);\n\n    \nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n);\n\n\n    \nalarm\n(\nseconds\n);\n\n    \nsuspmask\n \n=\n \noldmask\n;\n\n\n    \n/* make sure SIGALRM isn\nt blocked */\n\n    \nsigdelset\n(\nsuspmask\n,\n \nSIGALRM\n);\n\n\n    \n/* wait for any signal to be caught */\n\n    \nsigsuspend\n(\nsuspmask\n);\n\n\n    \n/* some signal has been caught, SIGALRM is now blocked */\n\n\n    \nunslept\n \n=\n \nalarm\n(\n0\n);\n\n\n    \n/* reset previous action */\n\n    \nsigaction\n(\nSIGALRM\n,\n \noldact\n,\n \nNULL\n);\n\n\n    \n/* reset signal mask, which unblocks SIGALRM */\n\n    \nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n);\n\n    \nreturn\n(\nunslept\n);\n\n\n}\n\n\n\n\n\n\nThis code doesn't use any form of nonlocal branching (as in \nFigure 10.8\n to avoid the race condition between alarm and pause), so there is no effect on other signal handlers that may be executing when the \nSIGALRM\n is handled.\n\n\nThe \nnanosleep\n function is similar to the \nsleep\n function, but provides nanosecond-level granularity.\n\n\n#include \ntime.h\n\n\n\nint\n \nnanosleep\n(\nconst\n \nstruct\n \ntimespec\n \n*\nreqtp\n,\n \nstruct\n \ntimespec\n \n*\nremtp\n);\n\n\n\n/* Returns: 0 if slept for requested time or \u22121 on error */\n\n\n\n\n\n\nThis function suspends the calling process until either the requested time has elapsed or the function is interrupted by a signal.\n\n\nArguments:\n\n\n\n\nThe \nreqtp\n parameter specifies the amount of time to sleep in seconds and nanoseconds.\n\n\nThe \nremtp\n parameter. If the sleep interval is interrupted by a signal and the process doesn\u2019t terminate, the \ntimespec\n structure pointed to by the \nremtp\n parameter will be set to the amount of time left in the sleep interval. We can set this parameter to NULL if we are uninterested in the time unslept.\n\n\n\n\nNotes on \nnanosleep\n:\n\n\n\n\nIf the system doesn\u2019t support nanosecond granularity, the requested time is rounded up.\n\n\nBecause the nanosleep function doesn\u2019t involve the generation of any signals, we can use it without worrying about interactions with other functions.\n\n\n\n\nThe \nclock_nanosleep\n function provides the capability to suspend the calling thread using a delay time relative to a particular clock, using multiple system clocks (\nSection 6.10\n)\n\n\n#include \ntime.h\n\n\n\nint\n \nclock_nanosleep\n(\nclockid_t\n \nclock_id\n,\n \nint\n \nflags\n,\n\n                    \nconst\n \nstruct\n \ntimespec\n \n*\nreqtp\n,\n \nstruct\n \ntimespec\n \n*\nremtp\n);\n\n\n\n/* Returns: 0 if slept for requested time or error number on failure */\n\n\n\n\n\n\nArguments:\n\n\n\n\nThe \nclock_id\n argument specifies the clock against which the time delay is evaluated. Identifiers for clocks are listed in \nFigure 6.8\n.\n\n\nThe \nflags\n argument is used to control whether the delay is absolute or relative.\n\n\nWhen flags is set to 0, the sleep time is relative (how long we want to sleep).\n\n\nWhen it is set to \nTIMER_ABSTIME\n, the sleep time is absolute (we want to sleep until the clock reaches the specified time).\n\n\n\n\n\n\nThe \nreqtp\n and \nremtp\n arguments are the same as in the \nnanosleep\n function. However:\n\n\nWhen we use an absolute time, the \nremtp\n argument is unused, because it isn\u2019t needed.\n\n\nWe can reuse the same value for the \nreqtp\n argument for additional calls to \nclock_nanosleep\n until the clock reaches the specified absolute time value.\n\n\n\n\n\n\n\n\nExcept for error returns, the call:\n\n\nclock_nanosleep\n(\nCLOCK_REALTIME\n,\n \n0\n,\n \nreqtp\n,\n \nremtp\n);\n\n\n\n\n\n\nhas the same effect as the call:\n\n\nnanosleep\n(\nreqtp\n,\n \nremtp\n);\n\n\n\n\n\n\nSome applications require precision with how long they sleep, and a relative sleep time can lead to sleeping longer than desired. Using an absolute time improves the precision, even though a time-sharing process scheduler makes no guarantee that our task will execute immediately after our sleep time has ended. [p375]\n\n\nsigqueue\n Function\n\n\nAs discussed in \nSection 10.8\n, most UNIX systems don\u2019t queue signals. With the real-time extensions to POSIX.1, some systems began adding support for queueing signals. With SUSv4, the queued signal functionality has moved from the real-time extensions to the base specification.\n\n\nThese extensions allow applications to pass more information along with the delivery (\nSection 10.14\n). This information is embedded in a \nsiginfo\n structure.\n\n\nTo use queued signals we have to do the following:\n\n\n\n\nSpecify the \nSA_SIGINFO\n flag when we install a signal handler using the \nsigaction\n function. Without this flag, it is left up to the implementation whether the signal is queued.\n\n\nProvide a signal handler in the \nsa_sigaction\n member of the \nsigaction\n structure instead of using the usual \nsa_handler\n field. Implementations might allow us to use the \nsa_handler\n field, but we won\u2019t be able to obtain the extra information sent with the \nsigqueue\n function.\n\n\nUse the \nsigqueue\n function to send signals.\n\n\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigqueue\n(\npid_t\n \npid\n,\n \nint\n \nsigno\n,\n \nconst\n \nunion\n \nsigval\n \nvalue\n)\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nsigqueue\n function is similar to the \nkill\n function, except that:\n\n\n\n\nWe can only direct signals to a single process\n\n\nWe can use the \nvalue\n argument to transmit either an integer or a pointer value to the signal handler.\n\n\n\n\nSignals can\u2019t be queued infinitely. When the SIGQUEUE_MAX limit (\nPOSIX Limits\n) is reached, \nsigqueue\n can fail with \nerrno\n set to\n\nEAGAIN\n.\n\n\nWith the real-time signal enhancements, other signal numbers between \nSIGRTMIN\n and \nSIGRTMAX\n inclusive can be queued, and the  default action for these signals is to terminate the process. [p376]\n\n\nThe table below summarizes behavior of queued signals on various platforms:\n\n\n\n\n\n\n\n\nBehavior\n\n\nSUS\n\n\nFreeBSD\n\n\nLinux\n\n\nMac OS X\n\n\nSolaris\n\n\n\n\n\n\n\n\n\n\nsupports \nsigqueue\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nqueues other signals besides SIGRTMIN to SIGRTMAX\n\n\noptional\n\n\nx\n\n\n\n\n\n\nx\n\n\n\n\n\n\nqueues signals even if the caller doesn\u2019t use the \nSA_SIGINFO\n\n\noptional\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\n\n\n\n\nJob-Control Signals\n\n\nPOSIX.1 considers six to be job-control signals:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSIGCHLD\n\n\nChild process has stopped or terminated.\n\n\n\n\n\n\nSIGCONT\n\n\nContinue process, if stopped.\n\n\n\n\n\n\nSIGSTOP\n\n\nStop signal (can\u2019t be caught or ignored).\n\n\n\n\n\n\nSIGTSTP\n\n\nInteractive stop signal.\n\n\n\n\n\n\nSIGTTIN\n\n\nRead from controlling terminal by background process group member.\n\n\n\n\n\n\nSIGTTOU\n\n\nWrite to controlling terminal by a background process group member.\n\n\n\n\n\n\n\n\nThe following program demonstrates the normal sequence of code used when a program handles job control.\n\n\nsignals/sigtstp.c\n\n\n#include \napue.h\n\n\n\n#define BUFFSIZE    1024\n\n\n\nstatic\n \nvoid\n\n\nsig_tstp\n(\nint\n \nsigno\n)\n \n/* signal handler for SIGTSTP */\n\n\n{\n\n    \nsigset_t\n    \nmask\n;\n\n\n    \n/* ... move cursor to lower left corner, reset tty mode ... */\n\n\n    \n/*\n\n\n     * Unblock SIGTSTP, since it\ns blocked while we\nre handling it.\n\n\n     */\n\n    \nsigemptyset\n(\nmask\n);\n\n    \nsigaddset\n(\nmask\n,\n \nSIGTSTP\n);\n\n    \nsigprocmask\n(\nSIG_UNBLOCK\n,\n \nmask\n,\n \nNULL\n);\n\n\n    \nsignal\n(\nSIGTSTP\n,\n \nSIG_DFL\n);\n   \n/* reset disposition to default */\n\n\n    \nkill\n(\ngetpid\n(),\n \nSIGTSTP\n);\n    \n/* and send the signal to ourself */\n\n\n    \n/* we won\nt return from the kill until we\nre continued */\n\n\n    \nsignal\n(\nSIGTSTP\n,\n \nsig_tstp\n);\n  \n/* reestablish signal handler */\n\n\n    \n/* ... reset tty mode, redraw screen ... */\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nchar\n    \nbuf\n[\nBUFFSIZE\n];\n\n\n    \n/*\n\n\n     * Only catch SIGTSTP if we\nre running with a job-control shell.\n\n\n     */\n\n    \nif\n \n(\nsignal\n(\nSIGTSTP\n,\n \nSIG_IGN\n)\n \n==\n \nSIG_DFL\n)\n\n        \nsignal\n(\nSIGTSTP\n,\n \nsig_tstp\n);\n\n\n    \nwhile\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nbuf\n,\n \nBUFFSIZE\n))\n \n \n0\n)\n\n        \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \nbuf\n,\n \nn\n)\n \n!=\n \nn\n)\n\n            \nerr_sys\n(\nwrite error\n);\n\n\n    \nif\n \n(\nn\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThis program does the following:\n\n\n\n\nWhen the program starts, it arranges to catch the \nSIGTSTP\n signal only if the signal\u2019s disposition is \nSIG_DFL\n. The reason is that \nwhen the program is started by a shell that doesn\u2019t support job control (\n/bin/sh\n, for example), the signal\u2019s disposition should be set to \nSIG_IGN\n. In fact, the shell doesn\u2019t explicitly ignore this signal; \ninit\n sets the disposition of the three job-control signals (\nSIGTSTP\n, \nSIGTTIN\n, and \nSIGTTOU\n) to \nSIG_IGN\n. This disposition is then inherited by all login shells. Only a job-control shell should reset the disposition of these three signals to \nSIG_DFL\n.\n\n\nWhen we type the suspend character, the process receives the \nSIGTSTP\n signal and the signal handler is invoked. At this point, we would do any terminal-related processing: move the cursor to the lower-left corner, restore the terminal mode, etc.\n\n\nAfter resetting the disposition of \nSIGSTOP\n to its default (stop the process) and unblocking it, we send ourself the \nSIGSTOP\n signal (\nkill(getpid(), SIGTSTP);\n). We have to unblock it since we\u2019re currently handling that same signal, and the system blocks it automatically while it\u2019s being caught.\n\n\nAt this point, the system stops the process. It is continued only when it receives (usually from the job-control shell, in response to an interactive \nfg\n command) a \nSIGCONT\n signal.\n\n\nWe don\u2019t catch \nSIGCONT\n since its default disposition is to continue the stopped process; when this happens, the program continues as though it returned from the \nkill\n function. When the program is continued, we reset the disposition for the \nSIGTSTP\n signal and do any terminal processing (as indicated in the comments).\n\n\n\n\nSignal Names and Numbers\n\n\nThis section discusses how to map between signal numbers and names. Some systems provide the array:\n\n\nextern\n \nchar\n \n*\nsys_siglist\n[];\n\n\n\n\n\n\nThe array index is the signal number, giving a pointer to the character string name of the signal. [p379]\n\n\nTo print the signal's character string in a portable manner, use the \npsignal\n function:\n\n\n#include \nsignal.h\n\n\n\nvoid\n \npsignal\n(\nint\n \nsigno\n,\n \nconst\n \nchar\n \n*\nmsg\n);\n\n\n\n\n\n\nThe string \nmsg\n (which normally includes the name of the program) is output to the standard error, followed by a colon and a space, followed by a description of the signal, followed by a newline. If \nmsg\n is \nNULL\n, then only the description is written to the standard error. This function is similar to \nperror\n (\nSection 1.7\n).\n\n\nIf you have a \nsiginfo\n structure from an alternative \nsigaction\n signal handler, you can print the signal information with the \npsiginfo\n function.\n\n\n#include \nsignal.h\n\n\n\nvoid\n \npsiginfo\n(\nconst\n \nsiginfo_t\n \n*\ninfo\n,\n \nconst\n \nchar\n \n*\nmsg\n);\n\n\n\n\n\n\nYou can use the \nstrsignal\n function if you only need the string description of the signal. This function is similar to \nstrerror\n (\nSection 1.7\n).\n\n\n#include \nstring.h\n\n\n\nchar\n \n*\nstrsignal\n(\nint\n \nsigno\n);\n\n\n\n/* Returns: a pointer to a string describing the signal */\n\n\n\n\n\n\nSummary\n\n\nAn understanding of signal handling is essential to advanced UNIX System programming. This chapter has taken a long and thorough look at UNIX System signals, from previous implementations to the POSIX.1 reliable-signal concept and all the related functions, followed by POSIX.1 \nabort\n, \nsystem\n, and \nsleep\n functions.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\n[p324] on some macro constants in \nsignal.h\n:\n\n\n\n\nThese constants can be used in place of the \"pointer to a function that takes an integer argument and returns nothing\", the second argument to \nsignal\n, and the return value from \nsignal\n. The three values used for these constants need not be \u22121, 0, and 1. They must be three values that can never be the address of any declarable function. Most UNIX systems use the values shown.\n\n\n\n\nWhy is the macro in the form \nSIG_ERR (void (*)())-1\n and the like?\n\n\nSolution:\n\n\nThey are integer that cast into an address which means the \"pointer to a function that takes an integer argument and returns nothing\". \nvoid (*)()\n tells the compiler to ignore type-checking for the parameters. See:\n\n\n\n\nStack Overflow\n\n\n\n\n[p359] on unblocking signals:\n\n\n\n\nIf the signal is sent to the process while it is blocked, the signal delivery will be deferred until the signal is unblocked. To the application, this can look as if the signal occurs between the unblocking and the \npause\n (depending on how the kernel implements signals). If this happens, or if the signal does occur between the unblocking and the \npause\n, we have a problem. Any occurrence of the signal in this window of time is lost, in the sense that we might not see the signal again, in which case the \npause\n will block indefinitely. This is another problem with the earlier unreliable signals.\n\n\n\n\nWhat is exactly the window? Shouldn't be the unblocked signals delivered to the process? Not fully understood.", 
            "title": "Chapter 10. Signals"
        }, 
        {
            "location": "/apue/ch11/", 
            "text": "Chapter 11. Threads\n\n\nIntroduction\n\n\nProcesses are discussed in earlier chapters. A limited amount of sharing can occur between related processes.\n\n\nThis chapter looks inside a process further to see how to use multiple threads of control (or simply threads) to perform multiple tasks within the environment of a single process. All threads within a single process have access to the same process components, such as file descriptors and memory.\n\n\nThis chapter is concluded with synchronization mechanisms available to prevent multiple threads from viewing inconsistencies in their shared resources.\n\n\nThread Concepts\n\n\nWith multiple threads of control, the programs can more than one thing at a time within a single process, with each thread handling a separate task. This approach can have several benefits:\n\n\n\n\nWe can simplify code that deals with asynchronous events by assigning a separate thread to handle each event type, while each thread can then handle its event using a synchronous programming model. A synchronous programming model is much simpler than an asynchronous one.\n\n\nMultiple processes have to use complex mechanisms provided by the operating system to share memory and file descriptors. Threads, in contrast, automatically have access to the same memory address space and file descriptors\n\n\nThe processing of independent tasks can be interleaved by assigning a separate thread per task (only if they don\u2019t depend on the processing performed by each other), so that overall program throughput can be improved. (A single-threaded process has to implicitly serializes those tasks.)\n\n\nInteractive programs can be improved in response time by using multiple threads to separate the portions of the program that deal with user input and output from the other parts of the program.\n\n\n\n\nThe benefits of a multithreaded programming model can be realized on multiprocessor or multicore systems, and even on uniprocessor systems. A program can be simplified using threads regardless of the number of processors, since that doesn\u2019t affect the program structure. As long as your program has to block when serializing tasks, there are improvements in response time and throughput when running on a uniprocessor, because some threads might be able to run while others are blocked.\n\n\nA thread consists of the information necessary to represent an execution context within a process:\n\n\n\n\nThread ID\n: identifies the thread within a process\n\n\nSet of register values\n\n\nStack\n\n\nScheduling priority and policy,\n\n\nSignal mask\n\n\nAn errno variable (\nSection 1.7\n)\n\n\nThread-specific data (\nSection 12.6\n).\n\n\n\n\nEverything within a process is sharable among the threads in a process:\n\n\n\n\nText of the executable program\n\n\nThe program\u2019s global and heap memory\n\n\nStacks\n\n\nFile descriptors.\n\n\n\n\nThe threads interfaces of this chapter are from POSIX.1-2001, known as \npthreads\n for \"POSIX threads\". The feature test macro for POSIX threads is \n_POSIX_THREADS\n. Applications can either use this in an \n#ifdef\n test to determine at compile time whether threads are supported or call \nsysconf\n with the \n_SC_THREADS\n constant to determine this at runtime. [p384]\n\n\nThread Identification\n\n\nUnlike the process ID, which is unique in the system, the thread ID has significance only within the context of the process to which it belongs.\n\n\nA thread ID is represented by the \npthread_t\n data type. Implementations are allowed to use a structure to represent the \npthread_t\n data type, so portable implementations can\u2019t treat them as integers (process ID's \npid_t\n data type is a non-negative integer). The \npthread_equal\n function (below) must be used to compare two thread IDs. A consequence of allowing the \npthread_t\n data type to be a structure is that there is no portable way to print its value. Linux 3.2.0 uses an unsigned long integer for the \npthread_t\n data type. FreeBSD 8.0 and Mac OS X 10.6.8 use a pointer to the \npthread\n structure for the \npthread_t\n data type.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_equal\n(\npthread_t\n \ntid1\n,\n \npthread_t\n \ntid2\n);\n\n\n\n/* Returns: nonzero if equal, 0 otherwise */\n\n\n\n\n\n\nA thread can obtain its own thread ID by calling the pthread_self function.\n\n\n#include \npthread.h\n\n\n\npthread_t\n \npthread_self\n(\nvoid\n);\n\n\n\nReturns\n:\n \nthe\n \nthread\n \nID\n \nof\n \nthe\n \ncalling\n \nthread\n\n\n\n\n\n\nThis function can be used with \npthread_equal\n when a thread needs to identify data structures that are tagged with its thread ID. For example, a single master thread places new jobs on a work queue. A pool of three worker threads removes jobs from the queue. Instead of allowing each thread to process whichever job is at the head of the queue, the master thread controls job assignment by placing the ID of the thread that should process the job in each job structure. Each worker thread then removes only jobs that are tagged with its own thread ID. This situation is illustrated below:\n\n\n\n\nThread Creation\n\n\nThe traditional UNIX process model (one thread of control per process) is conceptually the same as a threads-based model whereby each process is made up of only one thread. As the program runs, its behavior should be indistinguishable from the traditional process, until it creates more threads of control. [p385] Additional threads can be created by calling the \npthread_create\n function:\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_create\n(\npthread_t\n \n*\nrestrict\n \ntidp\n,\n\n                   \nconst\n \npthread_attr_t\n \n*\nrestrict\n \nattr\n,\n\n                   \nvoid\n \n*\n(\n*\nstart_rtn\n)(\nvoid\n \n*\n),\n \nvoid\n \n*\nrestrict\n \narg\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nThe memory location pointed to by \ntidp\n is set to the thread ID of the newly created thread when \npthread_create\n returns successfully.\n\n\nThe \nattr\n argument is used to customize various thread attributes (detailed in \nSection 12.3\n). This chapter sets this to \nNULL\n to create a thread with the default attributes.\n\n\nThe newly created thread starts running at the address of the \nstart_rtn\n function.\n\n\nThe \narg\n is a pointer to the single argument passed to the \nstart_rtn\n. If you need to pass more than one argument to the \nstart_rtn\n function, then you need to store them in a structure and pass the address of the structure in \narg\n.\n\n\n\n\nWhen a thread is created, there is no guarantee whether the newly created thread or the calling thread. \nThe newly created thread has access to the process address space and inherits the calling thread\u2019s floating-point environment (\nfenv.h\n) and signal mask; however, the set of pending signals for the thread is cleared.\n\n\nThe following example creates one thread and prints the process and thread IDs of the new thread and the initial thread:\n\n\nthreads/threadid.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\npthread_t\n \nntid\n;\n\n\n\nvoid\n\n\nprintids\n(\nconst\n \nchar\n \n*\ns\n)\n\n\n{\n\n    \npid_t\n       \npid\n;\n\n    \npthread_t\n   \ntid\n;\n\n\n    \npid\n \n=\n \ngetpid\n();\n\n    \ntid\n \n=\n \npthread_self\n();\n\n    \nprintf\n(\n%s pid %lu tid %lu (0x%lx)\n\\n\n,\n \ns\n,\n \n(\nunsigned\n \nlong\n)\npid\n,\n\n      \n(\nunsigned\n \nlong\n)\ntid\n,\n \n(\nunsigned\n \nlong\n)\ntid\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintids\n(\nnew thread: \n);\n\n    \nreturn\n((\nvoid\n \n*\n)\n0\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nerr\n;\n\n\n    \nerr\n \n=\n \npthread_create\n(\nntid\n,\n \nNULL\n,\n \nthr_fn\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread\n);\n\n    \nprintids\n(\nmain thread:\n);\n\n    \nsleep\n(\n1\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThis example handles the races between the main thread and the new thread as follows:\n\n\n\n\nFirst is the need to sleep in the main thread. Without sleep, the main thread might exit, thereby terminating the entire process before the new thread\ngets a chance to run. This behavior is dependent on the operating system\u2019s threads implementation and scheduling algorithms\n\n\nSecond, the new thread obtains its thread ID by calling \npthread_self\n instead of reading it out of shared memory or receiving it as an argument to its thread-start routine. If the new thread runs before the main thread returns from calling \npthread_create\n, then the new thread will see the uninitialized contents of \nntid\n instead of the thread ID. [p387-388]\n\n\n\n\nThread Termination\n\n\nIf any thread within a process calls \nexit\n, \n_Exit\n, or \n_exit\n, then the entire process terminates. Similarly, when the default action is to terminate the process, a signal sent to a thread will terminate the entire process.\n\n\nA single thread can exit in three ways, without terminating the entire process:\n\n\n\n\nThe thread can simply return from the start routine. The return value is the thread\u2019s exit code.\n\n\nThe thread can be canceled by another thread in the same process.\n\n\nThe thread can call \npthread_exit\n.\n\n\n\n\nThe \npthread_exit\n and \npthread_join\n functions\n\n\n#include \npthread.h\n\n\n\nvoid\n \npthread_exit\n(\nvoid\n \n*\nrval_ptr\n);\n\n\n\n\n\n\nThe \nrval_ptr\n argument is a typeless pointer is available to other threads in the process by calling the \npthread_join\n function.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_join\n(\npthread_t\n \nthread\n,\n \nvoid\n \n**\nrval_ptr\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe thread that calls \npthread_join\n will block until the specified thread calls \npthread_exit\n, returns from its start routine, or is canceled. If the thread simply returned from its start routine, \nrval_ptr\n will contain the return code. If the thread was canceled, the memory location specified by \nrval_ptr\n is set to \nPTHREAD_CANCELED\n.\n\n\nBy calling \npthread_join\n, we automatically place the thread with which we\u2019re joining in the detached state so that its resources can be recovered.  If the thread was already in the detached state, \npthread_join\n can fail, returning \nEINVAL\n.\n\n\nIf we\u2019re not interested in a thread\u2019s return value, we can set \nrval_ptr\n to \nNULL\n.\n\n\nThe following example shows how to fetch the exit code from a thread that has terminated:\n\n\nthreads/exitstatus.c\n\n\n[p389-390]\n\n\nThe typeless pointer passed to \npthread_create\n and \npthread_exit\n can be used to pass the address of a structure containing more complex information.\n\n\nIf the structure was allocated on the caller\u2019s stack, the memory contents might have changed by the time the structure is used. If a thread allocates a structure on its stack and passes a pointer to this structure to \npthread_exit\n, then the stack might be destroyed and its memory reused for something else by the time the caller of \npthread_join\n tries to use it.\n\n\nThe following example shows the problem with using an automatic variable (allocated on the stack) as the argument to \npthread_exit\n:\n\n\nthreads/badexit2.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n \na\n,\n \nb\n,\n \nc\n,\n \nd\n;\n\n\n};\n\n\n\nvoid\n\n\nprintfoo\n(\nconst\n \nchar\n \n*\ns\n,\n \nconst\n \nstruct\n \nfoo\n \n*\nfp\n)\n\n\n{\n\n    \nprintf\n(\n%s\n,\n \ns\n);\n\n    \nprintf\n(\n  structure at 0x%lx\n\\n\n,\n \n(\nunsigned\n \nlong\n)\nfp\n);\n\n    \nprintf\n(\n  foo.a = %d\n\\n\n,\n \nfp\n-\na\n);\n\n    \nprintf\n(\n  foo.b = %d\n\\n\n,\n \nfp\n-\nb\n);\n\n    \nprintf\n(\n  foo.c = %d\n\\n\n,\n \nfp\n-\nc\n);\n\n    \nprintf\n(\n  foo.d = %d\n\\n\n,\n \nfp\n-\nd\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn1\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nstruct\n \nfoo\n  \nfoo\n \n=\n \n{\n1\n,\n \n2\n,\n \n3\n,\n \n4\n};\n\n\n    \nprintfoo\n(\nthread 1:\n\\n\n,\n \nfoo\n);\n\n    \npthread_exit\n((\nvoid\n \n*\n)\nfoo\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn2\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\nthread 2: ID is %lu\n\\n\n,\n \n(\nunsigned\n \nlong\n)\npthread_self\n());\n\n    \npthread_exit\n((\nvoid\n \n*\n)\n0\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n         \nerr\n;\n\n    \npthread_t\n   \ntid1\n,\n \ntid2\n;\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n\n    \nerr\n \n=\n \npthread_create\n(\ntid1\n,\n \nNULL\n,\n \nthr_fn1\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 1\n);\n\n    \nerr\n \n=\n \npthread_join\n(\ntid1\n,\n \n(\nvoid\n \n*\n)\nfp\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt join with thread 1\n);\n\n    \nsleep\n(\n1\n);\n\n    \nprintf\n(\nparent starting second thread\n\\n\n);\n\n    \nerr\n \n=\n \npthread_create\n(\ntid2\n,\n \nNULL\n,\n \nthr_fn2\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 2\n);\n\n    \nsleep\n(\n1\n);\n\n    \nprintfoo\n(\nparent:\n\\n\n,\n \nfp\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWhen we run this program on Linux, we get:\n\n\n$ ./a.out\n\n\nthread 1:\n\n\nstructure at 0x7f2c83682ed0\n\n\nfoo.a = 1\n\n\nfoo.b = 2\n\n\nfoo.c = 3\n\n\nfoo.d = 4\n\n\nparent starting second thread\n\n\nthread 2: ID is 139829159933696\n\n\nparent:\n\n\nstructure at 0x7f2c83682ed0\n\n\nfoo.a = -2090321472\n\n\nfoo.b = 32556\n\n\nfoo.c = 1\n\n\nfoo.d = 0\n\n\n\n\n\n\nThe contents of the structure (allocated on the stack of thread \ntid1\n) have changed by the time the main thread can access the structure. Note how the stack of the second thread (\ntid2\n) has overwritten the first thread\u2019s stack. To solve this problem, we can either use a global structure or allocate the structure using \nmalloc\n.\n\n\nThe \npthread_cancel\n function\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cancel\n(\npthread_t\n \ntid\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nBy default, \npthread_cancel\n will cause the thread specified by \ntid\n to behave as if it had called \npthread_exit\n with an argument of \nPTHREAD_CANCELED\n, though a thread can ignore or otherwise control how it is canceled.\n\n\npthread_cancel\n doesn\u2019t wait for the thread to terminate; it merely makes the request.\n\n\n\n\nThe \npthread_cleanup_push\n and \npthread_cleanup_pop\n functions\n\n\nA thread can arrange for functions to be called when it exits, similar to the way that the \natexit\n function (\nSection 7.3\n). The functions are known as \nthread cleanup handlers\n. More than one cleanup handler can be established for a thread. The handlers are recorded in a stack, which means that they are executed in the reverse order from that with which they were registered.\n\n\n#include \npthread.h\n\n\n\nvoid\n \npthread_cleanup_push\n(\nvoid\n \n(\n*\nrtn\n)(\nvoid\n \n*\n),\n \nvoid\n \n*\narg\n);\n\n\nvoid\n \npthread_cleanup_pop\n(\nint\n \nexecute\n);\n\n\n\n\n\n\nThe \npthread_cleanup_push\n function schedules the cleanup function, \nrtn\n, to be called with the single argument, \narg\n, when the thread performs one of the following actions:\n\n\n\n\nMakes a call to \npthread_exit\n\n\nResponds to a cancellation request\n\n\nMakes a call to \npthread_cleanup_pop\n with a nonzero execute argument\n\n\n\n\nIf the \nexecute\n argument is set to zero, the cleanup function is not called.\n\n\npthread_cleanup_pop\n removes the cleanup handler established by the last call to \npthread_cleanup_push\n.\n\n\nBecause they can be implemented as macros, they must be used in matched pairs within the same scope in a thread. The macro definition of \npthread_cleanup_push\n can include a \n{\n character, in which case the matching \n}\n character is in the \npthread_cleanup_pop\n definition.\n\n\nThe following example shows how to use thread cleanup handlers. We need to match calls to \npthread_cleanup_pop\n with the calls to \npthread_cleanup_push\n; otherwise, the program might not compile. [p394]\n\n\nthreads/cleanup.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\nvoid\n\n\ncleanup\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\ncleanup: %s\n\\n\n,\n \n(\nchar\n \n*\n)\narg\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn1\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\nthread 1 start\n\\n\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 1 first handler\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 1 second handler\n);\n\n    \nprintf\n(\nthread 1 push complete\n\\n\n);\n\n    \nif\n \n(\narg\n)\n\n        \nreturn\n((\nvoid\n \n*\n)\n1\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \nreturn\n((\nvoid\n \n*\n)\n1\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn2\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\nthread 2 start\n\\n\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 2 first handler\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 2 second handler\n);\n\n    \nprintf\n(\nthread 2 push complete\n\\n\n);\n\n    \nif\n \n(\narg\n)\n\n        \npthread_exit\n((\nvoid\n \n*\n)\n2\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \npthread_exit\n((\nvoid\n \n*\n)\n2\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n         \nerr\n;\n\n    \npthread_t\n   \ntid1\n,\n \ntid2\n;\n\n    \nvoid\n        \n*\ntret\n;\n\n\n    \nerr\n \n=\n \npthread_create\n(\ntid1\n,\n \nNULL\n,\n \nthr_fn1\n,\n \n(\nvoid\n \n*\n)\n1\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 1\n);\n\n    \nerr\n \n=\n \npthread_create\n(\ntid2\n,\n \nNULL\n,\n \nthr_fn2\n,\n \n(\nvoid\n \n*\n)\n1\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 2\n);\n\n    \nerr\n \n=\n \npthread_join\n(\ntid1\n,\n \ntret\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt join with thread 1\n);\n\n    \nprintf\n(\nthread 1 exit code %ld\n\\n\n,\n \n(\nlong\n)\ntret\n);\n\n    \nerr\n \n=\n \npthread_join\n(\ntid2\n,\n \ntret\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt join with thread 2\n);\n\n    \nprintf\n(\nthread 2 exit code %ld\n\\n\n,\n \n(\nlong\n)\ntret\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nRunning the program  on Linux gives us:\n\n\n$ ./a.out\n\n\nthread 1 start\n\n\nthread 1 push complete\n\n\nthread 2 start\n\n\nthread 2 push complete\n\n\ncleanup: thread 2 second handler\n\n\ncleanup: thread 2 first handler\n\n\nthread 1 exit code 1\n\n\nthread 2 exit code 2\n\n\n\n\n\n\nNote that if the thread terminates by returning from its start routine, its cleanup handlers are not called. [p396]\n\n\nThe table below summarize similarities between the thread functions and the process functions.\n\n\n\n\n\n\n\n\nProcess primitive\n\n\nThread primitive\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfork\n\n\npthread_create\n\n\ncreate a new flow of control\n\n\n\n\n\n\nexit\n\n\npthread_exit\n\n\nexit from an existing flow of control\n\n\n\n\n\n\nwaitpid\n\n\npthread_join\n\n\nget exit status from flow of control\n\n\n\n\n\n\natexit\n\n\npthread_cleanup_push\n\n\nregister function to be called at exit from flow of control\n\n\n\n\n\n\ngetpid\n\n\npthread_self\n\n\nget ID for flow of control\n\n\n\n\n\n\nabort\n\n\npthread_cancel\n\n\nrequest abnormal termination of flow of control\n\n\n\n\n\n\n\n\nThe \npthread_detach\n function\n\n\nBy default, a thread\u2019s termination status is retained until we call \npthread_join\n for that thread. A thread\u2019s underlying storage can be reclaimed immediately on termination if the thread has been detached. After a thread is detached, we can\u2019t use the \npthread_join\n function to wait for its termination status, because calling \npthread_join\n for a detached thread results in undefined behavior. We can detach a thread by calling \npthread_detach\n.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_detach\n(\npthread_t\n \ntid\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\nWe can create a thread that is already in the detached state by modifying the thread attributes we pass to \npthread_create\n. This is detailed in the next chapter.\n\n\nThread Synchronization\n\n\nWhen multiple threads of control share the same memory, one thread can modify a variable that other threads can read or modify, thus we need to synchronize the threads to ensure that they don\u2019t use an invalid value when accessing the variable\u2019s memory contents.\n\n\nWhen one thread modifies a variable, other threads can potentially see inconsistencies when reading the value of that variable. On processor architectures in which the modification takes more than one memory cycle, this can happen when the memory read is interleaved between the memory write cycles.\n\n\nIn the following figure, thread A reads the variable and then writes a new value to it, but the write operation takes two memory cycles.  If thread B reads the same variable between the two write cycles, it will see an inconsistent value:\n\n\n\n\nTo solve this problem, the threads have to use a lock that will allow only one thread to access the variable at a time, as show in the following figure:\n\n\n\n\n\n\nIf thread B wants to read the variable, it acquires a lock.\n\n\nWhen thread A updates the variable, it acquires the same lock. Thus thread B will be unable to read the variable until thread A releases the lock.\n\n\n\n\nWe also need to synchronize two or more threads that might try to modify the same variable at the same time.\n\n\nFor example (as in the following figure), the increment operation is usually broken down into three steps.\n\n\n\n\nRead the memory location into a register.\n\n\nIncrement the value in the register.\n\n\nWrite the new value back to the memory location.\n\n\n\n\n\n\nIf two threads try to increment the same variable at almost the same time without synchronizing with each other, the results can be inconsistent. [p398]\n\n\nThere is no race if one of the following (assumed) condition occurs:\n\n\n\n\nThe modification is atomic.\n\n\n(In the previous example) The increment takes only one memory cycle.\n\n\nData always appears to be \nsequentially consistent\n.\n\n\n\n\nOur operations are sequentially consistent when multiple threads can\u2019t observe inconsistencies in our data. In modern computer systems, memory accesses take multiple bus cycles, and multiprocessors generally interleave bus cycles among multiple processors, so we aren\u2019t guaranteed that our data is sequentially consistent.\n\n\n[p399]\n\n\nBesides the computer architecture, races can arise from the ways in which our programs use variables, creating places where it is possible to view inconsistencies. For example, we might increment a variable and then make a decision based on its value. The combination of the increment step and the decision-making step isn\u2019t atomic, which opens a window where inconsistencies can arise.\n\n\nMutexes\n\n\nWe can protect our data and ensure access by only one thread at a time by using the pthreads mutual-exclusion interfaces. A \nmutex\n is basically a lock that we set (lock) before accessing a shared resource and release (unlock) when we\u2019re done.\n\n\n\n\nWhile it is set, any other thread that tries to set it will block until we release it.\n\n\nIf more than one thread is blocked when we unlock the mutex, then all threads blocked on the lock will be made runnable, and the first one to run will be able to set the lock. The others will see that the mutex is still locked and go back to waiting for it to become available again.\n\n\n\n\nIn this way, only one thread will proceed at a time.\n\n\n[p400]\n\n\nA mutex variable is represented by the \npthread_mutex_t\n data type. Before we can use a mutex variable, we must first initialize it by either setting it to the constant \nPTHREAD_MUTEX_INITIALIZER\n (for statically allocated mutexes only) or calling \npthread_mutex_init\n. If we allocate the mutex dynamically (by calling \nmalloc\n, for example), then we need to call \npthread_mutex_destroy\n before freeing the memory.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_mutex_init\n(\npthread_mutex_t\n \n*\nrestrict\n \nmutex\n,\n\n                       \nconst\n \npthread_mutexattr_t\n \n*\nrestrict\n \nattr\n);\n\n\n\nint\n \npthread_mutex_destroy\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nTo initialize a mutex with the default attributes, we set \nattr\n to \nNULL\n (mutex attributes is discussed \nSection 12.4\n).\n\n\nTo lock a mutex, we call \npthread_mutex_lock\n. If the mutex is already locked, the calling thread will block until the mutex is unlocked. To unlock a mutex, we call \npthread_mutex_unlock\n.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_mutex_lock\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\nint\n \npthread_mutex_trylock\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\nint\n \npthread_mutex_unlock\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\n\n/* All return: 0 if OK, error number on failure */\n\n\n\n\n\n\nIf a thread can\u2019t afford to block, it can use \npthread_mutex_trylock\n to lock the mutex conditionally. If the mutex is unlocked at the time \npthread_mutex_trylock\n is called, then \npthread_mutex_trylock\n will lock the mutex without blocking and return 0. Otherwise, \npthread_mutex_trylock\n will fail, returning \nEBUSY\n without locking the mutex.\n\n\nThe following example illustrates a mutex used to protect a data structure. When more than one thread needs to access a dynamically allocated object, we can embed a reference count in the object to ensure that we don\u2019t free its memory before all threads are done using it.\n\n\nthreads/mutex1.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n             \nf_count\n;\n\n    \npthread_mutex_t\n \nf_lock\n;\n\n    \nint\n             \nf_id\n;\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_alloc\n(\nint\n \nid\n)\n \n/* allocate the object */\n\n\n{\n\n    \nstruct\n \nfoo\n \n*\nfp\n;\n\n\n    \nif\n \n((\nfp\n \n=\n \nmalloc\n(\nsizeof\n(\nstruct\n \nfoo\n)))\n \n!=\n \nNULL\n)\n \n{\n\n        \nfp\n-\nf_count\n \n=\n \n1\n;\n\n        \nfp\n-\nf_id\n \n=\n \nid\n;\n\n        \nif\n \n(\npthread_mutex_init\n(\nfp\n-\nf_lock\n,\n \nNULL\n)\n \n!=\n \n0\n)\n \n{\n\n            \nfree\n(\nfp\n);\n\n            \nreturn\n(\nNULL\n);\n\n        \n}\n\n        \n/* ... continue initialization ... */\n\n    \n}\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_hold\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* add a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nfp\n-\nf_count\n++\n;\n\n    \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_rele\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* release a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nif\n \n(\n--\nfp\n-\nf_count\n \n==\n \n0\n)\n \n{\n \n/* last reference */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_destroy\n(\nfp\n-\nf_lock\n);\n\n        \nfree\n(\nfp\n);\n\n    \n}\n \nelse\n \n{\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nWe lock the mutex before incrementing the reference count, decrementing the reference count, and checking whether the reference count reaches zero.\n\n\nNo locking is necessary when we initialize the reference count to 1 in the \nfoo_alloc\n function, because the allocating thread is the only reference to it so far.\n If we were to place the structure on a list at this point, it could be found by other threads, so we would need to lock it first.\n\n\n\n\nBefore using the object, threads are expected to add a reference to it by calling \nfoo_hold\n. When they are done, they must call \nfoo_rele\n to release the reference. When the last reference is released, the object\u2019s memory is freed.\n\n\nIn this example, we have ignored how threads find an object before calling \nfoo_hold\n. Even though the reference count is zero, it would be a mistake for \nfoo_rele\n to free the object\u2019s memory if another thread is blocked on the mutex in a call to \nfoo_hold\n. We can avoid this problem by ensuring that the object can\u2019t be found before freeing its memory. We\u2019ll see how to do this in the examples that follow.\n\n\nDeadlock Avoidance\n\n\nA thread will deadlock itself if it tries to lock the same mutex twice. There are less obvious ways to create deadlocks with mutexes. For example, when we use more than one mutex in our programs, a deadlock can occur if we allow one thread to hold a mutex and block while trying to lock a second mutex at the same time that another thread holding the second mutex tries to lock the first mutex. Neither thread can proceed, because each needs a resource that is held by the other.\n\n\nDeadlocks can be avoided by carefully controlling the order in which mutexes are locked. For example, assume that you have two mutexes, A and B, that you need to lock at the same time. If all threads always lock mutex A before mutex B (vice versa), no deadlock can occur from the use of the two mutexes (but you can still deadlock on other resources). You\u2019ll have the potential for a deadlock only when one thread attempts to lock the mutexes in the opposite order from another thread.\n\n\nAnother approach when many locks and data structures are involved (it is difficult to apply the previous approach) is that you might be able to release your locks and try again at a later time. You can use the \npthread_mutex_trylock\n interface to avoid deadlocking in this case. If you are already holding locks and \npthread_mutex_trylock\n is successful, then you can proceed. If it can\u2019t acquire the lock, however, you can release the locks you already hold, clean up, and try again later.\n\n\nExample of two mutexes\n\n\nIn the following example which shows the use of two mutexes, we avoid deadlocks by ensuring that when we need to acquire two mutexes at the same time, we always lock them in the same order. The second mutex protects a hash list that we use to keep track of the foo data structures. Thus the hashlock mutex protects both the fh hash table and the \nf_next\n hash link field in the foo structure. The \nf_lock\n mutex in the foo structure protects access to the remainder of the foo structure\u2019s fields.\n\n\nthreads/mutex2.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\n#define NHASH 29\n\n\n#define HASH(id) (((unsigned long)id)%NHASH)\n\n\n\nstruct\n \nfoo\n \n*\nfh\n[\nNHASH\n];\n\n\n\npthread_mutex_t\n \nhashlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n             \nf_count\n;\n\n    \npthread_mutex_t\n \nf_lock\n;\n\n    \nint\n             \nf_id\n;\n\n    \nstruct\n \nfoo\n     \n*\nf_next\n;\n \n/* protected by hashlock */\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_alloc\n(\nint\n \nid\n)\n \n/* allocate the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \nif\n \n((\nfp\n \n=\n \nmalloc\n(\nsizeof\n(\nstruct\n \nfoo\n)))\n \n!=\n \nNULL\n)\n \n{\n\n        \nfp\n-\nf_count\n \n=\n \n1\n;\n\n        \nfp\n-\nf_id\n \n=\n \nid\n;\n\n        \nif\n \n(\npthread_mutex_init\n(\nfp\n-\nf_lock\n,\n \nNULL\n)\n \n!=\n \n0\n)\n \n{\n\n            \nfree\n(\nfp\n);\n\n            \nreturn\n(\nNULL\n);\n\n        \n}\n\n        \nidx\n \n=\n \nHASH\n(\nid\n);\n\n        \npthread_mutex_lock\n(\nhashlock\n);\n\n        \nfp\n-\nf_next\n \n=\n \nfh\n[\nidx\n];\n\n        \nfh\n[\nidx\n]\n \n=\n \nfp\n;\n\n        \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \n/* ... continue initialization ... */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_hold\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* add a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nfp\n-\nf_count\n++\n;\n\n    \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n\n}\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_find\n(\nint\n \nid\n)\n \n/* find an existing object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nfor\n \n(\nfp\n \n=\n \nfh\n[\nHASH\n(\nid\n)];\n \nfp\n \n!=\n \nNULL\n;\n \nfp\n \n=\n \nfp\n-\nf_next\n)\n \n{\n\n        \nif\n \n(\nfp\n-\nf_id\n \n==\n \nid\n)\n \n{\n\n            \nfoo_hold\n(\nfp\n);\n\n            \nbreak\n;\n\n        \n}\n\n    \n}\n\n    \npthread_mutex_unlock\n(\nhashlock\n);\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_rele\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* release a reference to the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\ntfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nif\n \n(\nfp\n-\nf_count\n \n==\n \n1\n)\n \n{\n \n/* last reference */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_lock\n(\nhashlock\n);\n\n        \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n        \n/* need to recheck the condition */\n\n        \nif\n \n(\nfp\n-\nf_count\n \n!=\n \n1\n)\n \n{\n\n            \nfp\n-\nf_count\n--\n;\n\n            \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n            \npthread_mutex_unlock\n(\nhashlock\n);\n\n            \nreturn\n;\n\n        \n}\n\n        \n/* remove from list */\n\n        \nidx\n \n=\n \nHASH\n(\nfp\n-\nf_id\n);\n\n        \ntfp\n \n=\n \nfh\n[\nidx\n];\n\n        \nif\n \n(\ntfp\n \n==\n \nfp\n)\n \n{\n\n            \nfh\n[\nidx\n]\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n \nelse\n \n{\n\n            \nwhile\n \n(\ntfp\n-\nf_next\n \n!=\n \nfp\n)\n\n                \ntfp\n \n=\n \ntfp\n-\nf_next\n;\n\n            \ntfp\n-\nf_next\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_destroy\n(\nfp\n-\nf_lock\n);\n\n        \nfree\n(\nfp\n);\n\n    \n}\n \nelse\n \n{\n\n        \nfp\n-\nf_count\n--\n;\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nComparing \nthreads/mutex2.c\n with \nthreads/mutex1.c\n, we can see;\n\n\n\n\nThe allocation function \nfoo_alloc\n now locks the hash list lock, adds the new structure to a hash bucket, and \nbefore unlocking the hash list lock, locks the mutex in the new structure.\n Since the new structure is placed on a global list, other threads can find it, so we need to block them if they try to access the new structure, until we are done initializing it.\n\n\nThe \nfoo_find\n function locks the hash list lock and searches for the requested structure. If it is found, we increase the reference count and return a pointer to the structure. This follows the lock ordering by locking the hash list lock in \nfoo_find\n before \nfoo_hold\n locks the foo structure\u2019s f_lock mutex.\n\n\nWith two locks, the \nfoo_rele\n function is more complicated. If this is the last reference, we need to unlock the structure mutex so that we can acquire the hash list lock, since we\u2019ll need to remove the structure from the hash list. Then we reacquire the structure mutex. Because we could have blocked since the last time we held the structure mutex, we need to recheck the condition to see whether we still need to free the structure. If another thread found the structure and added a reference to it while we blocked to honor the lock ordering, we simply need to decrement the reference count, unlock everything, and return.\n\n\n\n\nExample of two mutexes (simplified)\n\n\nWe can simplify the previous example considerably by using the hash list lock to protect the structure reference count. The structure mutex can be used to protect everything else in the \nfoo\n structure.\n\n\nthreads/mutex3.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\n#define NHASH 29\n\n\n#define HASH(id) (((unsigned long)id)%NHASH)\n\n\n\nstruct\n \nfoo\n \n*\nfh\n[\nNHASH\n];\n\n\npthread_mutex_t\n \nhashlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n             \nf_count\n;\n \n/* protected by hashlock */\n\n    \npthread_mutex_t\n \nf_lock\n;\n\n    \nint\n             \nf_id\n;\n\n    \nstruct\n \nfoo\n     \n*\nf_next\n;\n \n/* protected by hashlock */\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_alloc\n(\nint\n \nid\n)\n \n/* allocate the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \nif\n \n((\nfp\n \n=\n \nmalloc\n(\nsizeof\n(\nstruct\n \nfoo\n)))\n \n!=\n \nNULL\n)\n \n{\n\n        \nfp\n-\nf_count\n \n=\n \n1\n;\n\n        \nfp\n-\nf_id\n \n=\n \nid\n;\n\n        \nif\n \n(\npthread_mutex_init\n(\nfp\n-\nf_lock\n,\n \nNULL\n)\n \n!=\n \n0\n)\n \n{\n\n            \nfree\n(\nfp\n);\n\n            \nreturn\n(\nNULL\n);\n\n        \n}\n\n        \nidx\n \n=\n \nHASH\n(\nid\n);\n\n        \npthread_mutex_lock\n(\nhashlock\n);\n\n        \nfp\n-\nf_next\n \n=\n \nfh\n[\nidx\n];\n\n        \nfh\n[\nidx\n]\n \n=\n \nfp\n;\n\n        \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \n/* ... continue initialization ... */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_hold\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* add a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nfp\n-\nf_count\n++\n;\n\n    \npthread_mutex_unlock\n(\nhashlock\n);\n\n\n}\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_find\n(\nint\n \nid\n)\n \n/* find an existing object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nfor\n \n(\nfp\n \n=\n \nfh\n[\nHASH\n(\nid\n)];\n \nfp\n \n!=\n \nNULL\n;\n \nfp\n \n=\n \nfp\n-\nf_next\n)\n \n{\n\n        \nif\n \n(\nfp\n-\nf_id\n \n==\n \nid\n)\n \n{\n\n            \nfp\n-\nf_count\n++\n;\n\n            \nbreak\n;\n\n        \n}\n\n    \n}\n\n    \npthread_mutex_unlock\n(\nhashlock\n);\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_rele\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* release a reference to the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\ntfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nif\n \n(\n--\nfp\n-\nf_count\n \n==\n \n0\n)\n \n{\n \n/* last reference, remove from list */\n\n        \nidx\n \n=\n \nHASH\n(\nfp\n-\nf_id\n);\n\n        \ntfp\n \n=\n \nfh\n[\nidx\n];\n\n        \nif\n \n(\ntfp\n \n==\n \nfp\n)\n \n{\n\n            \nfh\n[\nidx\n]\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n \nelse\n \n{\n\n            \nwhile\n \n(\ntfp\n-\nf_next\n \n!=\n \nfp\n)\n\n                \ntfp\n \n=\n \ntfp\n-\nf_next\n;\n\n            \ntfp\n-\nf_next\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \npthread_mutex_destroy\n(\nfp\n-\nf_lock\n);\n\n        \nfree\n(\nfp\n);\n\n    \n}\n \nelse\n \n{\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nIn this example, we solved the lock-ordering issues surrounding the hash list and the reference count when we use the same lock for both purposes. Multithreaded software design involves these types of trade-offs:\n\n\n\n\nIf the locking granularity is too coarse, you end up with too many threads blocking behind the same locks, with little improvement possible from concurrency.\n\n\nIf the locking granularity is too fine, then you suffer bad performance from excess locking overhead, and you end up with complex code.\n\n\n\n\nAs a programmer, you need to find the correct balance between code complexity and performance, while still satisfying your locking requirements.\n\n\npthread_mutex_timedlock\n Function\n\n\nThe \npthread_mutex_timedlock\n function allows us to bound the time that a thread blocks when a mutex it is trying to acquire is already locked is equivalent to \npthread_mutex_lock\n, but if the timeout value is reached, \npthread_mutex_timedlock\n will return the error code \nETIMEDOUT\n without locking the mutex:\n\n\n#include \npthread.h\n\n\n#include \ntime.h\n\n\n\nint\n \npthread_mutex_timedlock\n(\npthread_mutex_t\n \n*\nrestrict\n \nmutex\n,\n\n                            \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe timeout is represented by the \ntimespec\n structure (seconds and nanoseconds) and is \nabsolute time\n.\n\n\nThe following example uses \npthread_mutex_timedlock\n to avoid blocking indefinitely:\n\n\nthreads/timedlock.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nerr\n;\n\n    \nstruct\n \ntimespec\n \ntout\n;\n\n    \nstruct\n \ntm\n \n*\ntmp\n;\n\n    \nchar\n \nbuf\n[\n64\n];\n\n    \npthread_mutex_t\n \nlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n    \npthread_mutex_lock\n(\nlock\n);\n\n    \nprintf\n(\nmutex is locked\n\\n\n);\n\n    \nclock_gettime\n(\nCLOCK_REALTIME\n,\n \ntout\n);\n\n    \ntmp\n \n=\n \nlocaltime\n(\ntout\n.\ntv_sec\n);\n\n    \nstrftime\n(\nbuf\n,\n \nsizeof\n(\nbuf\n),\n \n%r\n,\n \ntmp\n);\n\n    \nprintf\n(\ncurrent time is %s\n\\n\n,\n \nbuf\n);\n\n    \ntout\n.\ntv_sec\n \n+=\n \n10\n;\n  \n/* 10 seconds from now */\n\n    \n/* caution: this could lead to deadlock */\n\n    \nerr\n \n=\n \npthread_mutex_timedlock\n(\nlock\n,\n \ntout\n);\n\n    \nclock_gettime\n(\nCLOCK_REALTIME\n,\n \ntout\n);\n\n    \ntmp\n \n=\n \nlocaltime\n(\ntout\n.\ntv_sec\n);\n\n    \nstrftime\n(\nbuf\n,\n \nsizeof\n(\nbuf\n),\n \n%r\n,\n \ntmp\n);\n\n    \nprintf\n(\nthe time is now %s\n\\n\n,\n \nbuf\n);\n\n    \nif\n \n(\nerr\n \n==\n \n0\n)\n\n        \nprintf\n(\nmutex locked again!\n\\n\n);\n\n    \nelse\n\n        \nprintf\n(\ncan\nt lock mutex again: %s\n\\n\n,\n \nstrerror\n(\nerr\n));\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThe following is the output:\n\n\n$ ./a.out\n\n\nmutex is locked\n\n\ncurrent time is 11:41:58 AM\n\n\nthe time is now 11:42:08 AM\n\n\ncan\u2019t lock mutex again: Connection timed out\n\n\n\n\n\n\nThis strategy is not recommended in practice, because it can lead to deadlock.\n\n\nMac OS X 10.6.8 doesn\u2019t support \npthread_mutex_timedlock\n yet, but FreeBSD 8.0, Linux 3.2.0, and Solaris 10 do support it.\n\n\nReader\u2013Writer Locks\n\n\nThe state of a mutex is either locked or unlocked, and only one thread can lock it at a time. A reader\u2013writer lock (also called shared\u2013exclusive lock) has three possible states:\n\n\n\n\nLocked in read mode (also called locked in shared mode)\n\n\nLocked in write mode (also called locked in exclusive mode)\n\n\nUnlocked\nOnly one thread at a time can hold a reader\u2013writer lock in write mode, but multiple threads can hold a reader\u2013writer lock in read mode at the same time.\n\n\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_rwlock_init\n(\npthread_rwlock_t\n \n*\nrestrict\n \nrwlock\n,\n\n                        \nconst\n \npthread_rwlockattr_t\n \n*\nrestrict\n \nattr\n);\n\n\n\nint\n \npthread_rwlock_destroy\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nA reader\u2013writer lock is initialized by \npthread_rwlock_init\n. A \nNULL\n value of \nattr\n indicates default attributes.\n\n\nBefore freeing the memory backing a reader\u2013writer lock, we need to call \npthread_rwlock_destroy\n to clean it up. If \npthread_rwlock_init\n allocated any resources for the reader\u2013writer lock, \npthread_rwlock_destroy\n frees those resources. If we free the memory backing a reader\u2013writer lock without first calling \npthread_rwlock_destroy\n, any resources assigned to the lock will be lost (see \nDoubts and Solutions\n).\n\n\nA reader\u2013writer lock can be read locked, write locked and unlocked with the following functions:\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_rwlock_rdlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\nint\n \npthread_rwlock_wrlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\nint\n \npthread_rwlock_unlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\n\n/* All return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nImplementations might limit the number of times a reader\u2013writer lock can be locked in shared mode, so we need to check the return value of \npthread_rwlock_rdlock\n.\n\n\npthread_rwlock_wrlock\n and \npthread_rwlock_unlock\n have error returns and technically we should always check for errors when we call functions that can potentially fail. However, if we design our locking properly, we don\u2019t need to check for errors. [p410]\n\n\n\n\nThe SUS also defines conditional versions of the reader\u2013writer locking primitives.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_rwlock_tryrdlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\nint\n \npthread_rwlock_trywrlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nWhen the lock can be acquired, these functions return 0. Otherwise, they return the error \nEBUSY\n. These functions can be used to avoid deadlocks in situations where conforming to a lock hierarchy is difficult.\n\n\nThe program below illustrates the use of reader\u2013writer locks. A queue of job requests is protected by a single reader\u2013writer lock. This example shows a possible implementation of \nFigure 11.1\n, whereby multiple worker threads obtain jobs assigned to them by a single master thread.\n\n\nthreads/rwlock.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\nstruct\n \njob\n \n{\n\n    \nstruct\n \njob\n \n*\nj_next\n;\n\n    \nstruct\n \njob\n \n*\nj_prev\n;\n\n    \npthread_t\n   \nj_id\n;\n   \n/* tells which thread handles this job */\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nqueue\n \n{\n\n    \nstruct\n \njob\n      \n*\nq_head\n;\n\n    \nstruct\n \njob\n      \n*\nq_tail\n;\n\n    \npthread_rwlock_t\n \nq_lock\n;\n\n\n};\n\n\n\n/*\n\n\n * Initialize a queue.\n\n\n */\n\n\nint\n\n\nqueue_init\n(\nstruct\n \nqueue\n \n*\nqp\n)\n\n\n{\n\n    \nint\n \nerr\n;\n\n\n    \nqp\n-\nq_head\n \n=\n \nNULL\n;\n\n    \nqp\n-\nq_tail\n \n=\n \nNULL\n;\n\n    \nerr\n \n=\n \npthread_rwlock_init\n(\nqp\n-\nq_lock\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nreturn\n(\nerr\n);\n\n    \n/* ... continue initialization ... */\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\n/*\n\n\n * Insert a job at the head of the queue.\n\n\n */\n\n\nvoid\n\n\njob_insert\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \nstruct\n \njob\n \n*\njp\n)\n\n\n{\n\n    \npthread_rwlock_wrlock\n(\nqp\n-\nq_lock\n);\n\n    \njp\n-\nj_next\n \n=\n \nqp\n-\nq_head\n;\n\n    \njp\n-\nj_prev\n \n=\n \nNULL\n;\n\n    \nif\n \n(\nqp\n-\nq_head\n \n!=\n \nNULL\n)\n\n        \nqp\n-\nq_head\n-\nj_prev\n \n=\n \njp\n;\n\n    \nelse\n\n        \nqp\n-\nq_tail\n \n=\n \njp\n;\n    \n/* list was empty */\n\n    \nqp\n-\nq_head\n \n=\n \njp\n;\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n\n}\n\n\n\n/*\n\n\n * Append a job on the tail of the queue.\n\n\n */\n\n\nvoid\n\n\njob_append\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \nstruct\n \njob\n \n*\njp\n)\n\n\n{\n\n    \npthread_rwlock_wrlock\n(\nqp\n-\nq_lock\n);\n\n    \njp\n-\nj_next\n \n=\n \nNULL\n;\n\n    \njp\n-\nj_prev\n \n=\n \nqp\n-\nq_tail\n;\n\n    \nif\n \n(\nqp\n-\nq_tail\n \n!=\n \nNULL\n)\n\n        \nqp\n-\nq_tail\n-\nj_next\n \n=\n \njp\n;\n\n    \nelse\n\n        \nqp\n-\nq_head\n \n=\n \njp\n;\n    \n/* list was empty */\n\n    \nqp\n-\nq_tail\n \n=\n \njp\n;\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n\n}\n\n\n\n/*\n\n\n * Remove the given job from a queue.\n\n\n */\n\n\nvoid\n\n\njob_remove\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \nstruct\n \njob\n \n*\njp\n)\n\n\n{\n\n    \npthread_rwlock_wrlock\n(\nqp\n-\nq_lock\n);\n\n    \nif\n \n(\njp\n \n==\n \nqp\n-\nq_head\n)\n \n{\n\n        \nqp\n-\nq_head\n \n=\n \njp\n-\nj_next\n;\n\n        \nif\n \n(\nqp\n-\nq_tail\n \n==\n \njp\n)\n\n            \nqp\n-\nq_tail\n \n=\n \nNULL\n;\n\n        \nelse\n\n            \njp\n-\nj_next\n-\nj_prev\n \n=\n \njp\n-\nj_prev\n;\n\n    \n}\n \nelse\n \nif\n \n(\njp\n \n==\n \nqp\n-\nq_tail\n)\n \n{\n\n        \nqp\n-\nq_tail\n \n=\n \njp\n-\nj_prev\n;\n\n        \njp\n-\nj_prev\n-\nj_next\n \n=\n \njp\n-\nj_next\n;\n\n    \n}\n \nelse\n \n{\n\n        \njp\n-\nj_prev\n-\nj_next\n \n=\n \njp\n-\nj_next\n;\n\n        \njp\n-\nj_next\n-\nj_prev\n \n=\n \njp\n-\nj_prev\n;\n\n    \n}\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n\n}\n\n\n\n/*\n\n\n * Find a job for the given thread ID.\n\n\n */\n\n\nstruct\n \njob\n \n*\n\n\njob_find\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \npthread_t\n \nid\n)\n\n\n{\n\n    \nstruct\n \njob\n \n*\njp\n;\n\n\n    \nif\n \n(\npthread_rwlock_rdlock\n(\nqp\n-\nq_lock\n)\n \n!=\n \n0\n)\n\n        \nreturn\n(\nNULL\n);\n\n\n    \nfor\n \n(\njp\n \n=\n \nqp\n-\nq_head\n;\n \njp\n \n!=\n \nNULL\n;\n \njp\n \n=\n \njp\n-\nj_next\n)\n\n        \nif\n \n(\npthread_equal\n(\njp\n-\nj_id\n,\n \nid\n))\n\n            \nbreak\n;\n\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n    \nreturn\n(\njp\n);\n\n\n}\n\n\n\n\n\n\nIn this example, we lock the queue\u2019s reader\u2013writer lock in write mode whenever we need to add a job to the queue or remove a job from the queue. Whenever we search the queue, we grab the lock in read mode, allowing all the worker threads to search the queue concurrently. Using a reader\u2013writer lock will improve performance in this case only if threads search the queue much more frequently than they add or remove jobs. The worker threads take only those jobs that match their thread ID off the queue. Since the job structures are used only by one thread at a time, they don\u2019t need any extra locking.\n\n\nReader\u2013Writer Locking with Timeouts\n\n\nAs with mutexes, the SUS provides functions to lock reader\u2013writer locks with a timeout to give applications a way to avoid blocking\nindefinitely while trying to acquire a reader\u2013writer lock.\n\n\n#include \npthread.h\n\n\n#include \ntime.h\n\n\n\nint\n \npthread_rwlock_timedrdlock\n(\npthread_rwlock_t\n \n*\nrestrict\n \nrwlock\n,\n\n                               \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\nint\n \npthread_rwlock_timedwrlock\n(\npthread_rwlock_t\n \n*\nrestrict\n \nrwlock\n,\n\n                               \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe \ntsptr\n argument points to a \ntimespec\n structure specifying the time at which the thread should stop blocking. If they can\u2019t acquire the lock, these functions return the \nETIMEDOUT\n error when the timeout expires. Like the \npthread_mutex_timedlock\n function, the timeout specifies an absolute time, not a relative one.\n\n\nCondition Variables\n\n\nCondition variables are another synchronization mechanism available to threads. These synchronization objects provide a place for threads to rendezvous. When used with mutexes, condition variables allow threads to wait in a race-free way for arbitrary conditions to occur.\n\n\nThe condition itself is protected by a mutex. A thread must first lock the mutex to change the condition state. Other threads will not notice the change until they acquire the mutex, because the mutex must be locked to be able to evaluate the condition.\n\n\nA condition variable, represented by the pthread_cond_t data type, must be initialized and can be initialized in two ways:\n\n\n\n\nAssign the constant \nPTHREAD_COND_INITIALIZER\n to a statically allocated condition\n\n\nUse the \npthread_cond_init\n function to initialize a dynamically allocated condition\n\n\n\n\npthread_cond_destroy\n deinitializes a condition variable before freeing its underlying memory.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cond_init\n(\npthread_cond_t\n \n*\nrestrict\n \ncond\n,\n\n                      \nconst\n \npthread_condattr_t\n \n*\nrestrict\n \nattr\n);\n\n\nint\n \npthread_cond_destroy\n(\npthread_cond_t\n \n*\ncond\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nUnless using nondefault attributes, the \nattr\n argument to \npthread_cond_init\n can be set to \nNULL\n.\n\n\nWe use \npthread_cond_wait\n to wait for a condition to be true. A variant \npthread_cond_timedwait\n is provided to return an error code if the condition hasn\u2019t been satisfied in the specified amount of time.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cond_wait\n(\npthread_cond_t\n \n*\nrestrict\n \ncond\n,\n\n                      \npthread_mutex_t\n \n*\nrestrict\n \nmutex\n);\n\n\n\nint\n \npthread_cond_timedwait\n(\npthread_cond_t\n \n*\nrestrict\n \ncond\n,\n\n                           \npthread_mutex_t\n \n*\nrestrict\n \nmutex\n,\n\n                           \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe mutex passed to \npthread_cond_wait\n protects the condition. \nThe caller passes the locked mutex to the function, which then atomically places the calling thread on the list of threads waiting for the condition and unlocks the mutex. This closes the window between the time that the condition is checked and the time that the thread goes to sleep waiting for the condition to change, so that the thread doesn\u2019t miss a change in the condition. When \npthread_cond_wait\n returns, the mutex is again locked.\n\n\nThe \npthread_cond_timedwait\n function provides the same functionality as the \npthread_cond_wait\n function with the addition of the timeout (\ntsptr\n). The timeout value specifies how long we are willing to wait expressed as a \ntimespec\n structure, as an absolute time instead of a relative time, as in the \nexample\n of \npthread_mutex_timedlock\n.\n\n\nAlternatively to the \nclock_gettime\n function, we can use the \ngettimeofday\n function to get the current time expressed as a timeval structure and translate it into a \ntimespec\n structure. The following function can be used to obtain the absolute time for the timeout value\n\n\nthreads/maketimeout.c\n\n\n#include \nsys/time.h\n\n\n#include \nstdlib.h\n\n\n\nvoid\n\n\nmaketimeout\n(\nstruct\n \ntimespec\n \n*\ntsp\n,\n \nlong\n \nminutes\n)\n\n\n{\n\n    \nstruct\n \ntimeval\n \nnow\n;\n\n\n    \n/* get the current time */\n\n    \ngettimeofday\n(\nnow\n,\n \nNULL\n);\n\n    \ntsp\n-\ntv_sec\n \n=\n \nnow\n.\ntv_sec\n;\n\n    \ntsp\n-\ntv_nsec\n \n=\n \nnow\n.\ntv_usec\n \n*\n \n1000\n;\n \n/* usec to nsec */\n\n    \n/* add the offset to get timeout value */\n\n    \ntsp\n-\ntv_sec\n \n+=\n \nminutes\n \n*\n \n60\n;\n\n\n}\n\n\n\n\n\n\nIf the timeout expires without the condition occurring, \npthread_cond_timedwait\n will reacquire the mutex and return the error \nETIMEDOUT\n. When it returns from a successful call to \npthread_cond_wait\n or \npthread_cond_timedwait\n, a thread needs to reevaluate the condition, since another thread might have run and already changed the condition.\n\n\nThere are two functions to notify threads that a condition has been satisfied. The \npthread_cond_signal\n function will wake up at least one thread waiting on a condition (The POSIX specification allows for implementations of \npthread_cond_signal\n to wake up more than one thread, to make the implementation simpler.), whereas the \npthread_cond_broadcast\n function will wake up all threads waiting on a condition.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cond_signal\n(\npthread_cond_t\n \n*\ncond\n);\n\n\nint\n \npthread_cond_broadcast\n(\npthread_cond_t\n \n*\ncond\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nWhen we call \npthread_cond_signal\n or \npthread_cond_broadcast\n, we are said to be signaling the thread or condition. We have to be careful to signal the threads only after changing the state of the condition.\n\n\nThe following example shows how to use a condition variable and a mutex together to synchronize threads.\n\n\nthreads/condvar.c\n\n\n#include \npthread.h\n\n\n\nstruct\n \nmsg\n \n{\n\n    \nstruct\n \nmsg\n \n*\nm_next\n;\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nmsg\n \n*\nworkq\n;\n\n\n\npthread_cond_t\n \nqready\n \n=\n \nPTHREAD_COND_INITIALIZER\n;\n\n\n\npthread_mutex_t\n \nqlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n\nvoid\n\n\nprocess_msg\n(\nvoid\n)\n\n\n{\n\n    \nstruct\n \nmsg\n \n*\nmp\n;\n\n\n    \nfor\n \n(;;)\n \n{\n\n        \npthread_mutex_lock\n(\nqlock\n);\n\n        \nwhile\n \n(\nworkq\n \n==\n \nNULL\n)\n\n            \npthread_cond_wait\n(\nqready\n,\n \nqlock\n);\n\n        \nmp\n \n=\n \nworkq\n;\n\n        \nworkq\n \n=\n \nmp\n-\nm_next\n;\n\n        \npthread_mutex_unlock\n(\nqlock\n);\n\n        \n/* now process the message mp */\n\n    \n}\n\n\n}\n\n\n\nvoid\n\n\nenqueue_msg\n(\nstruct\n \nmsg\n \n*\nmp\n)\n\n\n{\n\n    \npthread_mutex_lock\n(\nqlock\n);\n\n    \nmp\n-\nm_next\n \n=\n \nworkq\n;\n\n    \nworkq\n \n=\n \nmp\n;\n\n    \npthread_mutex_unlock\n(\nqlock\n);\n\n    \npthread_cond_signal\n(\nqready\n);\n\n\n}\n\n\n\n\n\n\n\n\nThe condition is the state of the work queue.\n\n\nWe protect the condition with a mutex and evaluate the condition in a \nwhile\n loop.\n\n\nWhen we put a message on the work queue, we need to hold the mutex, but we don\u2019t need to hold the mutex when we signal the waiting threads.\n\n\nAs long as it is okay for a thread to pull the message off the queue before we call \npthread_cond_signal\n, we can do this after releasing the mutex. Since we check the condition in a \nwhile\n loop, this doesn\u2019t present a problem; a thread will wake up, find that the queue is still empty, and go back to waiting again. If the code couldn\u2019t tolerate this race, we would need to hold the mutex when we signal the threads.\n\n\n\n\nSpin Locks\n\n\nA \nspin lock\n is like a mutex, except that instead of blocking a process by sleeping, the process is blocked by busy-waiting (spinning) until the lock can be acquired. \nA spin lock could be used in situations where locks are held for short periods of times and threads don\u2019t want to incur the cost of being descheduled.\n\n\nSpin locks are often used as low-level primitives to implement other types of locks. They can be implemented efficiently using \ntest-and-set\n instructions. Although efficient, they can lead to wasting CPU resources: while a thread is spinning and waiting for a lock to become available, the CPU can\u2019t do anything else. \nThis is why spin locks should be held only for short periods of time.\n\n\n\n\nKernel-space\n. Spin locks are useful when used in a nonpreemptive kernel. Besides providing a mutual exclusion mechanism, they block interrupts so an interrupt handler can\u2019t deadlock the system by trying to acquire a spin lock that is already locked (think of interrupts as another type of preemption). In these types of kernels, interrupt handlers can\u2019t sleep, so the only synchronization primitives they can use are spin locks.\n\n\nUser-space\n. Spin locks are not as useful unless you are running in a realtime scheduling class that doesn\u2019t allow preemption. User-level threads running in a time-sharing scheduling class can be descheduled when their time quantum expires or when a thread with a higher scheduling priority becomes runnable. In these cases, if a thread is holding a spin lock, it will be put to sleep and other threads blocked on the lock will continue spinning longer than intended.\n\n\n\n\nMany mutex implementations are efficient: using mutex locks is equivalent to using spin locks in terms of an application's performance. Some mutex implementations will spin for a limited amount of time trying to acquire the mutex, and only sleep when the spin count threshold is reached. These factors, combined with faster context switch in modern processors, make spin locks useful only in limited circumstances. [p417]\n\n\nSimilar to mutex (we can replace one with the other), we can initialize a spin lock with the \npthread_spin_init\n function. To deinitialize a spin lock, we can call the \npthread_spin_destroy\n function.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_spin_init\n(\npthread_spinlock_t\n \n*\nlock\n,\n \nint\n \npshared\n);\n\n\nint\n \npthread_spin_destroy\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nOnly one attribute is specified for spin locks, which matters only if the platform supports the Thread Process-Shared Synchronization option.\n\n\nThe \npshared\n argument represents the process-shared attribute, which indicates how the spin lock will be acquired.\n\n\nIf it is set to \nPTHREAD_PROCESS_SHARED\n, then the spin lock can be acquired by threads that have access to the lock\u2019s underlying memory, even if those threads are from different processes.\n\n\nOtherwise, the \npshared\n argument is set to \nPTHREAD_PROCESS_PRIVATE\n and the spin lock can be accessed only from threads within the process that initialized it.\n\n\n\n\n\n\n\n\nTo lock the spin lock, we can call either of the following:\n\n \npthread_spin_lock\n, which will spin until the lock is acquired\n\n pthread_spin_trylock, which will return the \nEBUSY\n error if the lock can\u2019t be acquired immediately. \nNote that \npthread_spin_trylock\n doesn\u2019t spin.\n\n\nRegardless of how it was locked, a spin lock can be unlocked by calling \npthread_spin_unlock\n.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_spin_lock\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\nint\n \npthread_spin_trylock\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\nint\n \npthread_spin_unlock\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\n\n/* All return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nIf a spin lock is currently unlocked, then the \npthread_spin_lock\n function can lock it without spinning.\n\n\nIf the thread already has it locked, the results are undefined. The call to \npthread_spin_lock\n could fail with the \nEDEADLK\n error (or some other error), or the call could spin indefinitely. The behavior depends on the implementation.\n\n\nIf we try to unlock a spin lock that is not locked, the results are also undefined.\n\n\n\n\nIf either \npthread_spin_lock\n or \npthread_spin_trylock\n returns 0, then the spin lock is locked. We need to be careful not to call any functions that might sleep while holding the spin lock. Otherwise, other threads trying to acquire it will spin, wasting CPU resources.\n\n\nBarriers\n\n\nBarriers are a synchronization mechanism to coordinate multiple threads working in parallel. A barrier allows each thread to wait until all cooperating\nthreads have reached the same point, and then continue executing from there. The \npthread_join\n function acts as a barrier to allow one thread to wait until another thread exits.\n\n\nBarrier objects are more general. They allow an arbitrary number of threads to wait until all of the threads have completed processing, but \nthe threads don\u2019t have to exit. They can continue working after all threads have reached the barrier.\n\n\nThe \npthread_barrier_init\n function initializes a barrier, and \npthread_barrier_destroy\n function deinitializes a barrier.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_barrier_init\n(\npthread_barrier_t\n \n*\nrestrict\n \nbarrier\n,\n\n                         \nconst\n \npthread_barrierattr_t\n \n*\nrestrict\n \nattr\n,\n\n                         \nunsigned\n \nint\n \ncount\n);\n\n\nint\n \npthread_barrier_destroy\n(\npthread_barrier_t\n \n*\nbarrier\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\n\n\nThe \ncount\n argument for \npthread_barrier_init\n specifies the number of threads that must reach the barrier before all of the threads will be allowed to continue.\n\n\n\n\n\n\nThe \nattr\n argument specifies the attributes of the barrier object (\nNULL\n for default attributes).\n\n\n\n\n\n\nIf the \npthread_barrier_init\n function allocated any resources for the barrier, the resources will be freed when we deinitialize the barrier by calling the \npthread_barrier_destroy\n function.\n\n\nThe \npthread_barrier_wait\n function indicates that a thread is done with its work and is ready to wait for all the other threads to catch up.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_barrier_wait\n(\npthread_barrier_t\n \n*\nbarrier\n);\n\n\n\n/* Returns: 0 or PTHREAD_BARRIER_SERIAL_THREAD if OK, error number on failure */\n\n\n\n\n\n\nThe thread calling \npthread_barrier_wait\n is put to sleep if the barrier count (set in the call to \npthread_barrier_init\n) is not yet satisfied. If the thread is the last one to call \npthread_barrier_wait\n, thereby satisfying the barrier count, all of the threads are awakened.\n\n\nTo one arbitrary thread, it will appear as if the \npthread_barrier_wait\n function returned a value of \nPTHREAD_BARRIER_SERIAL_THREAD\n. The remaining threads see a return value of 0. This allows one thread to continue as the master to act on the results of the work done by all of the other threads.\n\n\n\n\nOnce the barrier count is reached and the threads are unblocked, the barrier can be used again.\n\n\nThe barrier count can\u2019t be changed unless we call the \npthread_barrier_destroy\n function followed by the \npthread_barrier_init\n function with a different count.\n\n\n\n\nThe following example shows how a barrier can be used to synchronize threads cooperating on a single task.\n\n\nthreads/barrier.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n#include \nlimits.h\n\n\n#include \nsys/time.h\n\n\n\n#define NTHR   8                \n/* number of threads */\n\n\n#define NUMNUM 8000000L         \n/* number of numbers to sort */\n\n\n#define TNUM   (NUMNUM/NTHR)    \n/* number to sort per thread */\n\n\n\nlong\n \nnums\n[\nNUMNUM\n];\n\n\nlong\n \nsnums\n[\nNUMNUM\n];\n\n\n\npthread_barrier_t\n \nb\n;\n\n\n\n#ifdef SOLARIS\n\n\n#define heapsort qsort\n\n\n#else\n\n\nextern\n \nint\n \nheapsort\n(\nvoid\n \n*\n,\n \nsize_t\n,\n \nsize_t\n,\n\n                    \nint\n \n(\n*\n)(\nconst\n \nvoid\n \n*\n,\n \nconst\n \nvoid\n \n*\n));\n\n\n#endif\n\n\n\n/*\n\n\n * Compare two long integers (helper function for heapsort)\n\n\n */\n\n\nint\n\n\ncomplong\n(\nconst\n \nvoid\n \n*\narg1\n,\n \nconst\n \nvoid\n \n*\narg2\n)\n\n\n{\n\n    \nlong\n \nl1\n \n=\n \n*\n(\nlong\n \n*\n)\narg1\n;\n\n    \nlong\n \nl2\n \n=\n \n*\n(\nlong\n \n*\n)\narg2\n;\n\n\n    \nif\n \n(\nl1\n \n==\n \nl2\n)\n\n        \nreturn\n \n0\n;\n\n    \nelse\n \nif\n \n(\nl1\n \n \nl2\n)\n\n        \nreturn\n \n-\n1\n;\n\n    \nelse\n\n        \nreturn\n \n1\n;\n\n\n}\n\n\n\n/*\n\n\n * Worker thread to sort a portion of the set of numbers.\n\n\n */\n\n\nvoid\n \n*\n\n\nthr_fn\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nlong\n    \nidx\n \n=\n \n(\nlong\n)\narg\n;\n\n\n    \nheapsort\n(\nnums\n[\nidx\n],\n \nTNUM\n,\n \nsizeof\n(\nlong\n),\n \ncomplong\n);\n\n    \npthread_barrier_wait\n(\nb\n);\n\n\n    \n/*\n\n\n     * Go off and perform more work ...\n\n\n     */\n\n    \nreturn\n((\nvoid\n \n*\n)\n0\n);\n\n\n}\n\n\n\n/*\n\n\n * Merge the results of the individual sorted ranges.\n\n\n */\n\n\nvoid\n\n\nmerge\n()\n\n\n{\n\n    \nlong\n    \nidx\n[\nNTHR\n];\n\n    \nlong\n    \ni\n,\n \nminidx\n,\n \nsidx\n,\n \nnum\n;\n\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNTHR\n;\n \ni\n++\n)\n\n        \nidx\n[\ni\n]\n \n=\n \ni\n \n*\n \nTNUM\n;\n\n    \nfor\n \n(\nsidx\n \n=\n \n0\n;\n \nsidx\n \n \nNUMNUM\n;\n \nsidx\n++\n)\n \n{\n\n        \nnum\n \n=\n \nLONG_MAX\n;\n\n        \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNTHR\n;\n \ni\n++\n)\n \n{\n\n            \nif\n \n((\nidx\n[\ni\n]\n \n \n(\ni\n+\n1\n)\n*\nTNUM\n)\n \n \n(\nnums\n[\nidx\n[\ni\n]]\n \n \nnum\n))\n \n{\n\n                \nnum\n \n=\n \nnums\n[\nidx\n[\ni\n]];\n\n                \nminidx\n \n=\n \ni\n;\n\n            \n}\n\n        \n}\n\n        \nsnums\n[\nsidx\n]\n \n=\n \nnums\n[\nidx\n[\nminidx\n]];\n\n        \nidx\n[\nminidx\n]\n++\n;\n\n    \n}\n\n\n}\n\n\n\nint\n\n\nmain\n()\n\n\n{\n\n    \nunsigned\n \nlong\n   \ni\n;\n\n    \nstruct\n \ntimeval\n  \nstart\n,\n \nend\n;\n\n    \nlong\n \nlong\n       \nstartusec\n,\n \nendusec\n;\n\n    \ndouble\n          \nelapsed\n;\n\n    \nint\n             \nerr\n;\n\n    \npthread_t\n       \ntid\n;\n\n\n    \n/*\n\n\n     * Create the initial set of numbers to sort.\n\n\n     */\n\n    \nsrandom\n(\n1\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNUMNUM\n;\n \ni\n++\n)\n\n        \nnums\n[\ni\n]\n \n=\n \nrandom\n();\n\n\n    \n/*\n\n\n     * Create 8 threads to sort the numbers.\n\n\n     */\n\n    \ngettimeofday\n(\nstart\n,\n \nNULL\n);\n\n    \npthread_barrier_init\n(\nb\n,\n \nNULL\n,\n \nNTHR\n+\n1\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNTHR\n;\n \ni\n++\n)\n \n{\n\n        \nerr\n \n=\n \npthread_create\n(\ntid\n,\n \nNULL\n,\n \nthr_fn\n,\n \n(\nvoid\n \n*\n)(\ni\n \n*\n \nTNUM\n));\n\n        \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n            \nerr_exit\n(\nerr\n,\n \ncan\nt create thread\n);\n\n    \n}\n\n    \npthread_barrier_wait\n(\nb\n);\n\n    \nmerge\n();\n\n    \ngettimeofday\n(\nend\n,\n \nNULL\n);\n\n\n    \n/*\n\n\n     * Print the sorted list.\n\n\n     */\n\n    \nstartusec\n \n=\n \nstart\n.\ntv_sec\n \n*\n \n1000000\n \n+\n \nstart\n.\ntv_usec\n;\n\n    \nendusec\n \n=\n \nend\n.\ntv_sec\n \n*\n \n1000000\n \n+\n \nend\n.\ntv_usec\n;\n\n    \nelapsed\n \n=\n \n(\ndouble\n)(\nendusec\n \n-\n \nstartusec\n)\n \n/\n \n1000000.0\n;\n\n    \nprintf\n(\nsort took %.4f seconds\n\\n\n,\n \nelapsed\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNUMNUM\n;\n \ni\n++\n)\n\n        \nprintf\n(\n%ld\n\\n\n,\n \nsnums\n[\ni\n]);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nIn this example:\n\n We use eight threads to divide the job of sorting 8 million numbers.  Each thread sorts 1 million numbers using the heapsort algorithm. Then the main thread calls a function to merge the results.\n\n We don\u2019t need to use the \nPTHREAD_BARRIER_SERIAL_THREAD\n return value from \npthread_barrier_wait\n to decide which thread merges the results, because we use the main thread for this task. That is why \nwe specify the barrier count as one more than the number of worker threads; the main thread counts as one waiter.\n\n\nThis example shows the use of a barrier in a simplified situation where the threads perform only one task. In more realistic situations, the worker threads will continue with other activities after the call to \npthread_barrier_wait\n returns.\n\n\n[p422]\n\n\nSummary\n\n\nThis chapter introduces the concept of threads and discussed the POSIX.1 primitives available to create and destroy them. We also introduced the problem of thread synchronization. We discussed five fundamental synchronization mechanisms: mutexes, reader\u2013writer locks, condition variables, spin locks, and barriers; and we saw how to use them to protect shared resources.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np409-410 on Reader\u2013Writer Locks\n\n\n\n\nIf we free the memory backing a reader\u2013writer lock without first calling \npthread_rwlock_destroy\n, any resources assigned to the lock will be lost.\n\n\n\n\n\"any resources assigned to the lock will be lost\" probably means a form of \nresource leak\n.\n\n\np409 on \nPTHREAD_BARRIER_SERIAL_THREAD.\n\n\n\n\nTo one arbitrary thread, it will appear as if the \npthread_barrier_wait\n function returned a value of \nPTHREAD_BARRIER_SERIAL_THREAD\n. The remaining threads see a return value of 0.\n\n\n\n\n\"one arbitrary thread\" means \"one unspecified thread\". As in \npthread_barrier_wait\n:\n\n\nUpon successful completion, the \npthread_barrier_wait()\n function shall return \nPTHREAD_BARRIER_SERIAL_THREAD\n for a single (arbitrary) thread synchronized at the barrier and zero for each of the other threads.", 
            "title": "Chapter 11. Threads"
        }, 
        {
            "location": "/apue/ch12/", 
            "text": "Chapter 12. Thread Control\n\n\nIntroduction\n\n\nThis chapter discusses the details of controlling thread behavior by looking at thread attributes and synchronization primitive attributes, followed by how threads can keep data private from other threads in the same process.", 
            "title": "Chapter 12. Thread Control"
        }, 
        {
            "location": "/apue/ch13/", 
            "text": "Chapter 13. Daemon Processes\n\n\nIntroduction\n\n\nDaemons are processes that are often started when the system is bootstrapped and terminate only when the system is shut down. Because they don\u2019t\nhave a controlling terminal, they run in the background. UNIX systems have numerous daemons that perform day-to-day activities.\n\n\nThis chapter details the process structure of daemons and explores how to write a daemon. Since a daemon does not have a controlling terminal, we need to see how a daemon can report error conditions when something goes wrong.\n\n\nDaemon Characteristics\n\n\nThis section describes some common system daemons with the concepts of process groups, controlling terminals, and sessions as described in \nChapter 9\n.\n\n\nps -axj\n\n\n\n\n\n\n\nThe \n-a\n option shows the status of processes owned by others.\n\n\nThe \n-x\n option shows processes that don\u2019t have a controlling terminal.\n\n\nThe \n-j\n option displays the job-related information:\n\n\nSession ID\n\n\nProcess group ID\n\n\nControlling terminal\n\n\nTerminal process group ID\n\n\n\n\n\n\n\n\nThe output from \nps\n on Linux 3.2.0 looks like:\n\n\nUID PID PPID    PGID    SID TTY CMD\nroot    1   0   1   1   ?   /sbin/init\nroot    2   0   0   0   ?   [kthreadd]\nroot    3   2   0   0   ?   [ksoftirqd/0]\nroot    6   2   0   0   ?   [migration/0]\nroot    7   2   0   0   ?   [watchdog/0]\nroot    21  2   0   0   ?   [cpuset]\nroot    22  2   0   0   ?   [khelper]\nroot    26  2   0   0   ?   [sync_supers]\nroot    27  2   0   0   ?   [bdi-default]\nroot    29  2   0   0   ?   [kblockd]\nroot    35  2   0   0   ?   [kswapd0]\nroot    49  2   0   0   ?   [scsi_eh_0]\nroot    256 2   0   0   ?   [jbd2/sda5-8]\nroot    257 2   0   0   ?   [ext4-dio-unwrit]\nsyslog  847 1   843 843 ?   rsyslogd -c5\nroot    906 1   906 906 ?   /usr/sbin/cupsd -F\nroot    1037    1   1037    1037    ?   /usr/sbin/inetd\nroot    1067    1   1067    1067    ?   cron\ndaemon  1068    1   1068    1068    ?   atd\nroot    8196    1   8196    8196    ?   /usr/sbin/sshd -D\nroot    13047   2   0   0   ?   [kworker/1:0]\nroot    14596   2   0   0   ?   [flush-8:0]\nroot    26464   1   26464   26464   ?   rpcbind -w\nstatd   28490   1   28490   28490   ?   rpc.statd -L\nroot    28553   2   0   0   ?   [rpciod]\nroot    28554   2   0   0   ?   [nfsiod]\nroot    28561   1   28561   28561   ?   rpc.idmapd\nroot    28761   2   0   0   ?   [lockd]\nroot    28764   2   0   0   ?   [nfsd]\nroot    28775   1   28775   28775   ?   /usr/sbin/rpc.mountd --manage-gids\n\n\n\n\n\nThe column headings, in order, are:\n\n\n\n\nUser ID\n\n\nProcess ID\n\n\nParent process ID\n\n\nProcess group ID\n\n\nSession ID\n\n\nTerminal name\n\n\nCommand string\n\n\n\n\nThe system processes in this output depend on the operating system implementation. Anything with a parent process ID of 0 is usually a kernel process (started as part of the system bootstrap procedure), except \ninit\n, which is a user-level command started by the kernel at boot time. Kernel processes are special and generally exist for the entire lifetime of the system. They run with superuser privileges and have no controlling terminal and no command line.\n\n\nIn the (above) sample \nps\n output, kernel daemons has their names in square brackets.\n\n\n\n\nkthreadd\n is a special kernel process on Linux that creates other kernel process, and thus appears as the parent of other kernel daemons. A kernel component, which need to run in a process context but isn't invoked from the context of a user-level process, will usually have its own kernel daemon. For example:\n\n\nkswapd\n: pageout daemon. It supports the virtual memory subsystem by writing dirty pages to disk slowly over time, so the pages can be reclaimed.\n\n\nflush\n.\n\n\nThis daemon flushes dirty pages to disk when available memory reaches a configured minimum threshold.\n\n\nIt also flushes dirty pages back to disk at regular intervals to decrease data loss in the event of a system failure.\n\n\nSeveral flush daemons can exist with one for each backing device. The sample output \nflush-8:0\n means the backing device is identified by its major device number (8) and its minor device number (0).\n\n\n\n\n\n\nThe \nsync_supers\n daemon periodically flushes file system metadata to disk.\n\n\nThe \njbd\n daemon helps implement the journal in the \next4\n file system\n\n\n\n\n\n\ninit\n (\nlaunchd\n on Mac OS X), usually Process 1, is a system daemon responsible for, among other things, starting system services specific to various run levels.\n\n\nrpcbind\n provides the service of \nmapping RPC\n (Remote Procedure Call) program numbers to network port numbers.\n\n\nThe \nnfsd\n, \nnfsiod\n, \nlockd\n, \nrpciod\n, \nrpc.idmapd\n, \nrpc.statd\n, and \nrpc.mountd\n daemons provide support for the \nNetwork File System\n (NFS). Note that the first four are kernel daemons, while the last three are user-level daemons.\n\n\nrsyslogd\n can log system messages of any program. The messages may be printed on a console device and/or written to a file.\n\n\ncron\n executes commands at regularly scheduled dates and times. Numerous system administration tasks are handled by cron running programs at regularly intervals.\n\n\natd\n, similar to \ncron\n, allows users to execute jobs at specified times, only once.\n\n\ncupsd\n is a print spooler that handles print requests on the system.\n\n\nsshd\n provides secure remote login and execution facilities.\n\n\n\n\nSome notes:\n\n\n\n\nMost of the daemons run with superuser (root) privileges.\n\n\nNone of the daemons has a controlling terminal: the terminal name is set to a question mark. The kernel daemons are started without a controlling terminal. The lack of a controlling terminal in the user-level daemons is probably the result of the daemons having called \nsetsid\n. Most of the user-level daemons are process group leaders and session leaders, and are the only processes in their process group and session. (The one exception is \nrsyslogd\n.)\n\n\nThe parent of the user-level daemons is the \ninit\n process.\n\n\n\n\nCoding Rules\n\n\nThis section states basic rules to coding a daemon prevent unwanted interactions from happening, followed by a function \ndaemonize\n, that implements these rules.\n\n\n\n\nCall \numask\n to set the file mode creation mask\n to a known value, usually 0.\n\n\nIf the daemon process creates files, it may want to set specific permissions.\n\n\nOn the other hand, if the daemon calls library functions that result in files being created, then it might make sense to set the file mode create mask to a more restrictive value (such as 007), since the library functions might not allow the caller to specify the permissions through an explicit argument.\n\n\n\n\n\n\nCall \nfork\n and have the parent \nexit\n. This does several things:\n\n\nIf the daemon was started as a simple shell command, having the parent terminate makes the shell think that the command is done\n\n\nThe child inherits the process group ID of the parent but gets a new process ID, so we\u2019re guaranteed that the child is not a process group leader. This is a prerequisite for the call to \nsetsid\n that is done next. (See \nEnsuring the successful call of setsid\n in Chapter 9)\n\n\n\n\n\n\n\n\nCall \nsetsid\n to create a new session\n. The three steps listed in \nSection 9.5\n occur. The process:\n\n\n\n\nbecomes the leader of a new session,\n\n\nbecomes the leader of a new process group,\n\n\nand is disassociated from its controlling terminal.\n\n\n\n\nUnder System V\u2013based systems, some people recommend calling \nfork\n again at this point, terminating the parent, and continuing the daemon in the child. This guarantees that the daemon is not a session leader, which prevents it from acquiring a controlling terminal under the System V rules (\nSection 9.6\n). Alternatively, to avoid acquiring a controlling terminal, be sure to specify \nO_NOCTTY\n whenever opening a terminal device.\n\n\n\n\n\n\nChange the current working directory to the root directory.\n The current working directory inherited from the parent could be on a mounted file system.  Since daemons normally exist until the system is rebooted, if the daemon stays on a mounted file system, that file system cannot be unmounted.\n\n\nAlternatively, some daemons might change the current working directory to a specific location where they will do all their work. For example, a line printer spooling daemon might change its working directory to its spool directory.\n\n\n\n\n\n\nUnneeded file descriptors should be closed.\n This prevents the daemon from holding open any descriptors that it may have inherited from its parent (which could be a shell or some other process). We can use our \nopen_max\n function or the \ngetrlimit\n function (\nSection 7.11\n) to determine the highest descriptor and close all descriptors up to that value.\n\n\n\n\nSome daemons open file descriptors 0, 1, and 2 to \n/dev/null\n so that any library routines that try to read from standard input or write to standard output or standard error will have no effect. [p466-467]\n\n\n\n\nThe code below shows the \ndaemonize\n function that can be called from a program that wants to initialize itself as a daemon.\n\n\ndaemons/init.c\n\n\n#include \napue.h\n\n\n#include \nsyslog.h\n\n\n#include \nfcntl.h\n\n\n#include \nsys/resource.h\n\n\n\nvoid\n\n\ndaemonize\n(\nconst\n \nchar\n \n*\ncmd\n)\n\n\n{\n\n    \nint\n \ni\n,\n \nfd0\n,\n \nfd1\n,\n \nfd2\n;\n\n    \npid_t\n \npid\n;\n\n    \nstruct\n \nrlimit\n \nrl\n;\n\n    \nstruct\n \nsigaction\n \nsa\n;\n\n\n    \n/*\n\n\n     * Clear file creation mask.\n\n\n     */\n\n    \numask\n(\n0\n);\n\n\n    \n/*\n\n\n     * Get maximum number of file descriptors.\n\n\n     */\n\n    \nif\n \n(\ngetrlimit\n(\nRLIMIT_NOFILE\n,\n \nrl\n)\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt get file limit\n,\n \ncmd\n);\n\n\n    \n/*\n\n\n     * Become a session leader to lose controlling TTY.\n\n\n     */\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt fork\n,\n \ncmd\n);\n\n    \nelse\n \nif\n \n(\npid\n \n!=\n \n0\n)\n \n/* parent */\n\n        \nexit\n(\n0\n);\n\n    \nsetsid\n();\n\n\n    \n/*\n\n\n     * Ensure future opens won\nt allocate controlling TTYs.\n\n\n     */\n\n    \nsa\n.\nsa_handler\n \n=\n \nSIG_IGN\n;\n\n    \nsigemptyset\n(\nsa\n.\nsa_mask\n);\n\n    \nsa\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigaction\n(\nSIGHUP\n,\n \nsa\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt ignore SIGHUP\n,\n \ncmd\n);\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt fork\n,\n \ncmd\n);\n\n    \nelse\n \nif\n \n(\npid\n \n!=\n \n0\n)\n \n/* parent */\n\n        \nexit\n(\n0\n);\n\n\n    \n/*\n\n\n     * Change the current working directory to the root so\n\n\n     * we won\nt prevent file systems from being unmounted.\n\n\n     */\n\n    \nif\n \n(\nchdir\n(\n/\n)\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt change directory to /\n,\n \ncmd\n);\n\n\n    \n/*\n\n\n     * Close all open file descriptors.\n\n\n     */\n\n    \nif\n \n(\nrl\n.\nrlim_max\n \n==\n \nRLIM_INFINITY\n)\n\n        \nrl\n.\nrlim_max\n \n=\n \n1024\n;\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nrl\n.\nrlim_max\n;\n \ni\n++\n)\n\n        \nclose\n(\ni\n);\n\n\n    \n/*\n\n\n     * Attach file descriptors 0, 1, and 2 to /dev/null.\n\n\n     */\n\n    \nfd0\n \n=\n \nopen\n(\n/dev/null\n,\n \nO_RDWR\n);\n\n    \nfd1\n \n=\n \ndup\n(\n0\n);\n\n    \nfd2\n \n=\n \ndup\n(\n0\n);\n\n\n    \n/*\n\n\n     * Initialize the log file.\n\n\n     */\n\n    \nopenlog\n(\ncmd\n,\n \nLOG_CONS\n,\n \nLOG_DAEMON\n);\n\n    \nif\n \n(\nfd0\n \n!=\n \n0\n \n||\n \nfd1\n \n!=\n \n1\n \n||\n \nfd2\n \n!=\n \n2\n)\n \n{\n\n        \nsyslog\n(\nLOG_ERR\n,\n \nunexpected file descriptors %d %d %d\n,\n\n          \nfd0\n,\n \nfd1\n,\n \nfd2\n);\n\n        \nexit\n(\n1\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nIf the \ndaemonize\n function is called from a \nmain\n program that then goes to sleep, we can check the status of the daemon with the \nps\n command:\n\n\n$ ./a.out\n\n\n$ ps -efj\n\n\nUID PID PPID PGID SID TTY CMD\n\n\nsar 13800 1 13799 13799 ? ./a.out\n\n\n$ ps -efj | grep 13799\n\n\nsar 13800 1 13799 13799 ? ./a.out\n\n\n\n\n\n\nWe can also use ps to verify that no active process exists with ID 13799. This means that our daemon is in an orphaned process group and is not a session leader and, therefore, has no chance of allocating a controlling terminal. This is a result of performing the second \nfork\n in the \ndaemonize\n function. We can see that our daemon has been initialized correctly.\n\n\nError Logging\n\n\nOne problem a daemon has is how to handle error messages. It cannot (simply) write to:\n\n\n\n\nStandard error: it shouldn't have a controlling terminal.\n\n\nConsole device: on many workstations the console device runs a windowing system.\n\n\nSeparate files: it's a headache to keep up which daemon writes to which log file and to check these files on a regular basis.\n\n\n\n\nA central daemon error-logging facility is required. The BSD \nsyslog\n facility has been widely used since 4.2BSD. Most daemons use this facility. The following figure illustrates its structure:\n\n\n\n\nThere are three ways to generate log messages:\n\n\n\n\nKernel routines can call the \nlog\n function. These messages can be read by any user process that \nopen\ns and \nread\ns the \n/dev/klog\n device.\n\n\nMost user processes (daemons) call the \nsyslog(3)\n function to generate log messages. This causes the message to be sent to the UNIX domain datagram socket \n/dev/log\n.\n\n\nA user process on this host or some other host that is connected to this host by a TCP/IP network, can send log messages to UDP port 514. Note that the \nsyslog\n function never generates these UDP datagrams: they require explicit network programming by the process generating the log message.\n\n\n\n\nThe \nsyslogd\n daemon reads all three forms of log messages. On start-up, this daemon reads a configuration file, usually \n/etc/syslog.conf\n, which determines where different classes of messages are to be sent. For example, urgent messages can be sent to the system administrator (if logged in) and printed on the console, whereas warnings may be logged to a file.\n\n\n#include \nsyslog.h\n\n\n\nvoid\n \nopenlog\n(\nconst\n \nchar\n \n*\nident\n,\n \nint\n \noption\n,\n \nint\n \nfacility\n);\n\n\nvoid\n \nsyslog\n(\nint\n \npriority\n,\n \nconst\n \nchar\n \n*\nformat\n,\n \n...);\n\n\nvoid\n \ncloselog\n(\nvoid\n);\n\n\nint\n \nsetlogmask\n(\nint\n \nmaskpri\n);\n\n\n\n/* Returns: previous log priority mask value */\n\n\n\n\n\n\n\n\nCalling \nopenlog\n is optional. If it\u2019s not called, the first time syslog is called, openlog is called automatically.\n\n\n\n\nCalling \ncloselog\n is also optional. It closes the descriptor being used to communicate with the syslogd daemon.\n\n\n\n\n\n\nThe \nopenlog\n function:\n\n\n\n\nindent\n argument is the name of the program.\n\n\noption\n argument is a bitmask specifying various options. (see the table below)\n\n\nfacility\n argument lets the configuration file specify that messages from different facilities are to be handled differently. If we don\u2019t call \nopenlog\n, or if we call it with a facility of 0, we can still specify the facility as part of the priority argument to syslog.  (see the table below)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noption\n\n\nXSI\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nLOG_CONS\n\n\nx\n\n\nIf the log message can\u2019t be sent to \nsyslogd\n via the UNIX domain datagram, the message is written to the console instead.\n\n\n\n\n\n\nLOG_NDELAY\n\n\nx\n\n\nOpen the UNIX domain datagram socket to the \nsyslogd\n daemon immediately; don\u2019t wait until the first message is logged. Normally, the socket is not opened until the first message is logged.\n\n\n\n\n\n\nLOG_NOWAIT\n\n\nx\n\n\nDo not wait for child processes that might have been created in the process of logging the message. This prevents conflicts with applications that catch \nSIGCHLD\n, since the application might have retrieved the child\u2019s status by the time that syslog calls wait.\n\n\n\n\n\n\nLOG_ODELAY\n\n\nx\n\n\nDelay the opening of the connection to the \nsyslogd\n daemon until the first message is logged.\n\n\n\n\n\n\nLOG_PERROR\n\n\n\n\nWrite the log message to standard error in addition to sending it to \nsyslogd\n.  (Unavailable on Solaris.)\n\n\n\n\n\n\nLOG_PID\n\n\nx\n\n\nLog the process ID with each message. This is intended for daemons that fork a child process to handle different requests (as compared to daemons, such as \nsyslogd\n, that never call \nfork\n).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfacility\n\n\nXSI\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nLOG_AUDIT\n\n\n\n\nthe audit facility\n\n\n\n\n\n\nLOG_AUTH\n\n\n\n\nauthorization programs: \nlogin\n, \nsu\n, \ngetty\n, ...\n\n\n\n\n\n\nLOG_AUTHPRIV\n\n\n\n\nsame as \nLOG_AUTH\n, but logged to file with restricted permissions\n\n\n\n\n\n\nLOG_CONSOLE\n\n\n\n\nmessages written to \n/dev/console\n\n\n\n\n\n\nLOG_CRON\n\n\n\n\ncron and at\n\n\n\n\n\n\nLOG_DAEMON\n\n\n\n\nsystem daemons: \ninetd\n, \nrouted\n, ...\n\n\n\n\n\n\nLOG_FTP\n\n\n\n\nthe FTP daemon (\nftpd\n)\n\n\n\n\n\n\nLOG_KERN\n\n\n\n\nmessages generated by the kernel\n\n\n\n\n\n\nLOG_LOCAL0\n ~ \nLOG_LOCAL7\n\n\nx\n\n\nreserved for local use\n\n\n\n\n\n\nLOG_LPR\n\n\n\n\nline printer system: \nlpd\n, \nlpc\n, ...\n\n\n\n\n\n\nLOG_MAIL\n\n\n\n\nthe mail system\n\n\n\n\n\n\nLOG_NEWS\n\n\n\n\nthe Usenet network news system\n\n\n\n\n\n\nLOG_NTP\n\n\n\n\nthe network time protocol system\n\n\n\n\n\n\nLOG_SECURITY\n\n\n\n\nthe security subsystem\n\n\n\n\n\n\nLOG_SYSLOG\n\n\n\n\nthe syslogd daemon itself\n\n\n\n\n\n\nLOG_USER\n\n\n\n\n\n\n\n\n\n\nLOG_UUCP\n\n\n\n\nthe UUCP system\n\n\n\n\n\n\n\n\n\n\nThe \nsyslog\n function:\n\n\nThe \npriority\n argument is a combination of the \nfacility\n and a \nlevel\n (shown in the table below). These \nlevel\ns are ordered by priority, from highest to lowest.\n\n\nThe \nformat\n argument and any remaining arguments are passed to the \nvsprintf\n function for formatting. Any occurrences of the characters \n%m\n are first replaced with the error message string (\nstrerror\n) corresponding to the value of \nerrno\n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlevel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nLOG_EMERG\n\n\nemergency (system is unusable) (highest priority)\n\n\n\n\n\n\nLOG_ALERT\n\n\ncondition that must be fixed immediately\n\n\n\n\n\n\nLOG_CRIT\n\n\ncritical condition (e.g., hard device error)\n\n\n\n\n\n\nLOG_ERR\n\n\nerror condition\n\n\n\n\n\n\nLOG_WARNING\n\n\nwarning condition\n\n\n\n\n\n\nLOG_NOTICE\n\n\nnormal, but significant condition\n\n\n\n\n\n\nLOG_INFO\n\n\ninformational message\n\n\n\n\n\n\nLOG_DEBUG\n\n\ndebug message (lowest priority)\n\n\n\n\n\n\n\n\n\n\nThe \nsetlogmask\n function sets the log priority mask (\"logmask\") for the process and returns the previous mask. When the log priority mask is set, messages are not logged unless their priority is set in the log priority mask.\n\n\n\n\nThe \nlogger(1)\n program is also provided by many systems as a way to send log messages to the \nsyslog\n facility. The \nlogger\n command is intended for a shell script running noninteractively that needs to generate log messages.\n\n\nIn addition to \nsyslog\n, many platforms provide a variant that handles variable argument lists.\n\n\n#include \nsyslog.h\n\n\n#include \nstdarg.h\n\n\n\nvoid\n \nvsyslog\n(\nint\n \npriority\n,\n \nconst\n \nchar\n \n*\nformat\n,\n \nva_list\n \narg\n);\n\n\n\n\n\n\nMost \nsyslogd\n implementations will queue messages for a short time. If a duplicate message arrives during this period, the syslog daemon will not write it to the log. Instead, the daemon prints a message similar to \"last message repeated N times\".\n\n\nExample of \nsyslog\n\n\nIn a line printer spooler daemon, you might encounter the sequence:\n\n\nopenlog\n(\nlpd\n,\n \nLOG_PID\n,\n \nLOG_LPR\n);\n\n\nsyslog\n(\nLOG_ERR\n,\n \nopen error for %s: %m\n,\n \nfilename\n);\n\n\n\n\n\n\nThe first call to \nopenlog\n sets the \nident\n string to the program name, specifies that the process ID should always be printed, and sets the default facility to the line printer system. The call to \nsyslog\n specifies an error condition and a message string. If we had not called \nopenlog\n, the second call could have been:\n\n\nsyslog\n(\nLOG_ERR\n \n|\n \nLOG_LPR\n,\n \nopen error for %s: %m\n,\n \nfilename\n);\n\n\n\n\n\n\nHere, we specify the \npriority\n argument as a combination of a \nlevel\n and a \nfacility\n.\n\n\nSingle-Instance Daemons\n\n\nSome daemons are implemented so that only a single copy of the daemon should be running at a time for proper operation. This kind of daemon might need exclusive access to a device. For example of the \ncron\n daemon, if multiple instances were running, each copy might try to start a single scheduled operation, resulting in duplicate operations and probably an error.\n\n\nThe file- and record-locking mechanism (\nSection 14.3\n) is a way to ensure that only one copy of a daemon is running. If each daemon creates a file with a fixed name and places a write lock on the entire file, only one such write lock will be allowed to be created. Successive attempts to create write locks will fail, serving as an indication to successive copies of the daemon that another instance is already running.\n\n\n[p473]\n\n\nExample of using file locking to ensure single copy of daemon\n\n\ndaemons/single.c\n\n\n#include \nunistd.h\n\n\n#include \nstdlib.h\n\n\n#include \nfcntl.h\n\n\n#include \nsyslog.h\n\n\n#include \nstring.h\n\n\n#include \nerrno.h\n\n\n#include \nstdio.h\n\n\n#include \nsys/stat.h\n\n\n\n#define LOCKFILE \n/var/run/daemon.pid\n\n\n#define LOCKMODE (S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH)\n\n\n\nextern\n \nint\n \nlockfile\n(\nint\n);\n\n\n\nint\n\n\nalready_running\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nfd\n;\n\n    \nchar\n    \nbuf\n[\n16\n];\n\n\n    \nfd\n \n=\n \nopen\n(\nLOCKFILE\n,\n \nO_RDWR\n|\nO_CREAT\n,\n \nLOCKMODE\n);\n\n    \nif\n \n(\nfd\n \n \n0\n)\n \n{\n\n        \nsyslog\n(\nLOG_ERR\n,\n \ncan\nt open %s: %s\n,\n \nLOCKFILE\n,\n \nstrerror\n(\nerrno\n));\n\n        \nexit\n(\n1\n);\n\n    \n}\n\n    \nif\n \n(\nlockfile\n(\nfd\n)\n \n \n0\n)\n \n{\n\n        \nif\n \n(\nerrno\n \n==\n \nEACCES\n \n||\n \nerrno\n \n==\n \nEAGAIN\n)\n \n{\n\n            \nclose\n(\nfd\n);\n\n            \nreturn\n(\n1\n);\n\n        \n}\n\n        \nsyslog\n(\nLOG_ERR\n,\n \ncan\nt lock %s: %s\n,\n \nLOCKFILE\n,\n \nstrerror\n(\nerrno\n));\n\n        \nexit\n(\n1\n);\n\n    \n}\n\n    \nftruncate\n(\nfd\n,\n \n0\n);\n\n    \nsprintf\n(\nbuf\n,\n \n%ld\n,\n \n(\nlong\n)\ngetpid\n());\n\n    \nwrite\n(\nfd\n,\n \nbuf\n,\n \nstrlen\n(\nbuf\n)\n+\n1\n);\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nEach copy of the daemon will try to create a file and write its process ID in the file.  This will allow administrators to identify the process easily. If the file is already locked, the lockfile function will fail with \nerrno\n set to \nEACCES\n or \nEAGAIN\n, so we return 1, indicating that the daemon is already running. Otherwise, we truncate the file, write our process ID to it, and return 0.\n\n\n[p474]\n\n\nDaemon Conventions\n\n\nCommon conventions are followed by daemons in the UNIX System.\n\n\n\n\nThe lock file is usually stored in \n/var/run\n.\n\n\nCreating a file in this directory requires superuser permissions;\n\n\nThe name of the file is usually \nname\n.pid\n, where name is the name of the daemon or the service. For example, the name of the Linux \ncron\n daemon\u2019s lock file is \n/var/run/crond.pid\n.\n\n\n\n\n\n\nThe configuration options are usually stored in \n/etc\n.\n\n\nThe configuration file is named \nname\n.conf\n, where name is the name of the daemon or the service. For example, the configuration for the \nsyslogd\n daemon is usually \n/etc/syslog.conf\n.\n\n\n\n\n\n\nDaemons can be started from the command line, but they are usually started from one of the system initialization scripts (\n/etc/rc*\n or \n/etc/init.d/*\n).\n\n\nIf the daemon should be restarted automatically when it exits, we can arrange for init to restart it if we include a respawn entry for it in\n/etc/inittab\n (assuming the system uses a System V style \ninit\n command).\n\n\n\n\n\n\nIf a daemon has a configuration file, the daemon reads the file when it starts and won\u2019t look at it again. If an administrator changes the configuration, the daemon would need to be stopped and restarted to account for the configuration changes. \nTo avoid this, some daemons will catch \nSIGHUP\n and reread their configuration files when they receive the signal.\n Since they aren\u2019t associated with terminals and are either session leaders without controlling terminals or members of orphaned process groups, daemons have no reason to expect to receive \nSIGHUP\n. Thus they can safely reuse it.\n\n\n\n\nExamples:\n\n\n\n\ndaemons/reread.c\n\n\ndaemons/reread2.c\n\n\n\n\nClient\u2013Server Model\n\n\nA common use for a daemon process is as a server process. syslogd process (\nFigure 13.2\n) is a server that has messages sent to it by user processes (clients) using a UNIX domain datagram socket.\n\n\nA \nserver\n is a process that waits for a \nclient\n to contact it, requesting some type of service. The service provided by the \nsyslogd\n server is the logging of an error message.\n\n\nServers usually \nfork\n and \nexec\n another program to provide service to a client. These servers often manage multiple file descriptors (e.g. communication endpoints, configuration files, log files). It would be careless to leave these file descriptors open in the child process, because they probably won\u2019t be used in the program executed by the child, especially if the program is unrelated to the server. At worst, leaving them open could pose a security problem: the program executed could do something malicious, such as change the server\u2019s configuration file or trick the client into thinking it is communicating with the server, thereby gaining access to unauthorized information.\n\n\nAn easy solution to this problem is to set the close-on-exec flag for all file descriptors that the executed program won\u2019t need. The following function does that:\n\n\nlib/setfd.c\n\n\n#include \napue.h\n\n\n#include \nfcntl.h\n\n\n\nint\n\n\nset_cloexec\n(\nint\n \nfd\n)\n\n\n{\n\n    \nint\n     \nval\n;\n\n\n    \nif\n \n((\nval\n \n=\n \nfcntl\n(\nfd\n,\n \nF_GETFD\n,\n \n0\n))\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n\n    \nval\n \n|=\n \nFD_CLOEXEC\n;\n      \n/* enable close-on-exec */\n\n\n    \nreturn\n(\nfcntl\n(\nfd\n,\n \nF_SETFD\n,\n \nval\n));\n\n\n}", 
            "title": "Chapter 13. Daemon Processes"
        }, 
        {
            "location": "/apue/ch14/", 
            "text": "Chapter 14. Advanced I/O\n\n\nIntroduction\n\n\nThis chapter covers:\n\n\n\n\nNonblocking I/O\n\n\nRecord locking\n\n\nI/O multiplexing (the \nselect\n and \npoll\n functions)\n\n\nAsynchronous I/O\n\n\nThe \nreadv\n and \nwritev\n functions\n\n\nMemory-mapped I/O (\nmmap\n)\n\n\n\n\nNonblocking I/O\n\n\nSystem calls are divided into two categories: the \"slow\" ones and all the others (\nSection 10.5\n). The slow system calls are those that can block forever. They include:\n\n\n\n\nReads that can block the caller forever if data isn\u2019t present with certain file types (pipes, terminal devices, and network devices)\n\n\nWrites that can block the caller forever if the data can\u2019t be accepted immediately by these same file types (e.g., no room in the pipe, network flow control)\n\n\nOpens that block until some condition occurs on certain file types (such as an open of a terminal device that waits until an attached modem answers the phone, or an open of a FIFO for writing only, when no other process has the FIFO open for reading)\n\n\nReads and writes of files that have mandatory record locking enabled\n\n\nCertain ioctl operations\n\n\nSome of the interprocess communication functions (Chapter 15)\n\n\n\n\nSystem calls related to disk I/O are not considered slow, even though the read or write of a disk file can block the caller temporarily.\n\n\nNonblocking I/O lets us issue an I/O operation, such as an \nopen\n, \nread\n, or \nwrite\n, and not have it block forever. If the operation cannot be completed, the call returns immediately with an error noting that the operation would have blocked.\n\n\nThere are two ways to specify nonblocking I/O for a given descriptor:\n\n\n\n\nIf we call \nopen\n to get the descriptor, we can specify the \nO_NONBLOCK\n flag (\nSection 3.3\n).\n\n\nFor a descriptor that is already \nopen\n, we call \nfcntl\n to turn on the \nO_NONBLOCK\n file status flag (\nSection 3.14\n).\n\n\n\n\nExample:\n\n\n[p482-484]\n\n\nRecord Locking\n\n\nRecord locking\n is the term normally used to describe the ability of a process to prevent other processes from modifying a region of a file while the first process is reading or modifying that portion of the file. Under the UNIX System, \"record\" is a misnomer; the UNIX kernel does not have a notion of records in a file. A better term is \nbyte-range locking\n, given that it is a range of a file (possibly the entire file) that is locked.\n\n\n[p485]\n\n\nRecord locking was added to System V Release 3 through the \nfcntl\n function. The \nlockf\n function was built on top of this, providing a simplified interface. These functions allowed callers to lock arbitrary byte ranges in a file, ranging from the entire file down to a single byte within the file.\n\n\nThe table below shows the forms of record locking provided by various systems:\n\n\n\n\n\n\n\n\nSystem\n\n\nAdvisory\n\n\nMandatory\n\n\nfcntl\n\n\nlockf\n\n\nflock\n\n\n\n\n\n\n\n\n\n\nSUS\n\n\nx\n\n\n\n\nx\n\n\nXSI\n\n\n\n\n\n\n\n\nFreeBSD 8.0\n\n\nx\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nLinux 3.2.0\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nMac OS X 10.6.8\n\n\nx\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nSolaris 10\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nfcntl\n Record Locking\n\n\n#include \nfcntl.h\n\n\n\nint\n \nfcntl\n(\nint\n \nfd\n,\n \nint\n \ncmd\n,\n \n...\n \n/* struct flock *flockptr */\n \n);\n\n\n\n/* Returns: depends on cmd if OK (see following), \u22121 on error */\n\n\n\n\n\n\nFor record locking, \ncmd\n is \nF_GETLK\n, \nF_SETLK\n, or \nF_SETLKW\n. The third argument (which we\u2019ll call \nflockptr\n) is a pointer to an \nflock\n structure.\n\n\nstruct\n \nflock\n \n{\n\n    \nshort\n \nl_type\n;\n \n/* F_RDLCK, F_WRLCK, or F_UNLCK */\n\n    \nshort\n \nl_whence\n;\n \n/* SEEK_SET, SEEK_CUR, or SEEK_END */\n\n    \noff_t\n \nl_start\n;\n \n/* offset in bytes, relative to l_whence */\n\n    \noff_t\n \nl_len\n;\n \n/* length, in bytes; 0 means lock to EOF */\n\n    \npid_t\n \nl_pid\n;\n \n/* returned with F_GETLK */\n\n\n};\n\n\n\n\n\n\nThis structure describes:\n\n\n\n\nThe type of lock desired: \nF_RDLCK\n (a shared read lock), \nF_WRLCK\n (an exclusive write lock), or \nF_UNLCK\n (unlocking a region)\n\n\nThe starting byte offset of the region being locked or unlocked (\nl_start\n and \nl_whence\n)\n\n\nThe size of the region in bytes (\nl_len\n)\n\n\nThe ID (\nl_pid\n) of the process holding the lock that can block the current process (returned by \nF_GETLK\n only)\n\n\n\n\nNumerous rules apply to the specification of the region to be locked or unlocked.\n\n\n\n\nThe two elements that specify the starting offset of the region are similar to the last two arguments of the \nlseek\n function (\nSection 3.6\n). Indeed, the \nl_whence\n member is specified as \nSEEK_SET\n, \nSEEK_CUR\n, or \nSEEK_END\n.\n\n\nLocks can start and extend beyond the current end of file, but cannot start or extend before the beginning of the file.\n\n\nIf \nl_len\n is 0, it means that the lock extends to the largest possible offset of the file. This allows us to lock a region starting anywhere in the file, up through and including any data that is appended to the file. (We don\u2019t have to try to guess how many bytes might be appended to the file.)\n\n\nTo lock the entire file, we set \nl_start\n and \nl_whence\n to point to the beginning of the file and specify a length (\nl_len\n) of 0. (There are several ways to specify the beginning of the file, but most applications specify \nl_start\n as 0 and \nl_whence\n as \nSEEK_SET\n.)\n\n\n\n\nWe previously mentioned two types of locks: a shared read lock (\nl_type\n of \nF_RDLCK\n) and an exclusive write lock (\nF_WRLCK\n). The basic rule is that any number of processes can have a shared read lock on a given byte, but only one process can have an exclusive write lock on a given byte. Furthermore, if there are one or more read locks on a byte, there can\u2019t be any write locks on that byte; if there is an exclusive write lock on a byte, there can\u2019t be any read locks on that byte. This compatibility rule in Figure 14.3.\n\n\n\n\nThe compatibility rule applies to lock requests made from different processes, not to multiple lock requests made by a single process. If a process has an existing lock on a range of a file, a subsequent attempt to place a lock on the same range by the same process will replace the existing lock with the new one. Thus, if a process has a write lock on bytes 16\u201332 of a file and then tries to place a read lock on bytes 16\u201332, the request will succeed, and the write lock will be replaced by a read lock.\n\n\nTo obtain a read lock, the descriptor must be open for reading; to obtain a write lock, the descriptor must be open for writing.\n\n\nWe can now describe the three commands for the \nfcntl\n function.\n\n\n\n\nF_GETLK\n. Determine whether the lock described by \nflockptr\n is blocked by some other lock.\n\n\nIf a lock exists that would prevent ours from being created, the information on that existing lock overwrites the information pointed to by \nflockptr\n.\n\n\nIf no lock exists that would prevent ours from being created, the structure pointed to by flockptr is left unchanged except for the \nl_type\n member, which is set to \nF_UNLCK\n.\n\n\n\n\n\n\nF_SETLK\n. Set the lock described by \nflockptr\n. If we are trying to obtain a read lock (\nl_type\n of \nF_RDLCK\n) or a write lock (\nl_type\n of \nF_WRLCK\n) and the compatibility rule prevents the system from giving us the lock, \nfcntl\n returns immediately with \nerrno\n set to either \nEACCES\n or \nEAGAIN\n. This command is also used to clear the lock described by \nflockptr\n (\nl_type\n of \nF_UNLCK\n).\n\n\nF_SETLKW\n. This command is a blocking version of \nF_SETLK\n. (The \nW\n in the command name means wait.) If the requested read lock or write lock cannot be granted because another process currently has some part of the requested region locked, the calling process is put to sleep. The process wakes up either when the lock becomes available or when interrupted by a signal.\n\n\n\n\nBe aware that testing for a lock with \nF_GETLK\n and then trying to obtain that lock with \nF_SETLK\n or \nF_SETLKW\n is not an atomic operation.\n We have no guarantee that, between the two \nfcntl\n calls, some other process won\u2019t come in and obtain the same lock. If we don\u2019t want to block while waiting for a lock to become available to us, we must handle the possible error returns from \nF_SETLK\n.\n\n\nPOSIX.1 doesn\u2019t specify what happens when one process read locks a range of a file, a second process blocks while trying to get a write lock on the same range, and a third processes then attempts to get another read lock on the range. If the third process is allowed to place a read lock on the range just because the range is already read locked, then the implementation might starve processes with pending write locks. Thus, as additional requests to read lock the same range arrive, the time that the process with the pending write-lock request has to wait is extended. If the read-lock requests arrive quickly enough without a lull in the arrival rate, then the writer could wait for a long time\n\n\nWhen setting or releasing a lock on a file, the system combines or splits adjacent areas as required. For example, if we lock bytes 100 through 199 and then unlock byte 150, the kernel still maintains the locks on bytes 100 through 149 and bytes 151 through 199. The following figure illustrates the byte-range locks in this situation:\n\n\n\n\nIf we were to lock byte 150, the system would coalesce the adjacent locked regions into a single region from byte 100 through 199. The resulting picture would be the first diagram in the above figure, the same as when we started.\n\n\nExample\n\n\n[p489-491]\n\n\nImplied Inheritance and Release of Locks\n\n\nFreeBSD Implementation\n\n\nLocks at End of File\n\n\nAdvisory versus Mandatory Locking\n\n\nConsider a library of database access routines. If all the functions in the library handle record locking in a consistent way, then we say that any set of processes using these functions to access a database are cooperating processes. It is feasible for these database access functions to use advisory locking if they are the only ones being used to access the database:\n\n\n\n\nAdvisory locking\n doesn\u2019t prevent some other process that has write permission for the database file from writing whatever it wants to the database file.  This rogue process would be an uncooperating process, since it\u2019s not using the accepted method (the library of database functions) to access the database.\n\n\nMandatory locking\n causes the kernel to check every \nopen\n, \nread\n, and \nwrite\n to verify that the calling process isn\u2019t violating a lock on the file being accessed. Mandatory locking is sometimes called \nenforcement-mode locking\n.\n\n\n\n\nMandatory locking is enabled for a particular file by turning on the set-group-ID bit and turning off the group-execute bit.\n Since the set-group-ID bit makes no sense when the group-execute bit is off, the designers of SVR3 chose this way to specify that the locking for a file is to be mandatory locking and not advisory locking.\n\n\nWhat happens to a process that tries to read or write a file that has mandatory locking enabled and that part of the file is currently locked by another process? The answer depends on the type of operation (\nread\n or \nwrite\n), the type of lock held by the other process (read lock or write lock), and whether the descriptor for the \nread\n or \nwrite\n is nonblocking. The figure below shows eight possibilities:\n\n\n\n\nIn addition to the \nread\n and \nwrite\n functions in the figure above, the \nopen\n function can be affected by mandatory record locks held by another process. Normally, \nopen\n succeeds, even if the file being opened has outstanding mandatory record locks. The next read or write follows the rules listed above. But if the file being opened has outstanding mandatory record locks (either read locks or write locks), and if the flags in the call to open specify either \nO_TRUNC\n or \nO_CREAT\n, then open returns an error of \nEAGAIN\n immediately, regardless of whether \nO_NONBLOCK\n is specified.\n\n\nThis handling of locking conflicts with \nopen\n can lead to surprising results. While developing the exercises in this section, a test program was run that opened a file (whose mode specified mandatory locking), established a read lock on an entire file, and then went to sleep for a while. (a read lock should prevent writing to the file by other processes.) During this sleep period, the following behavior was seen in other typical UNIX System programs:\n\n\n\n\nThe same file could be edited with the \ned\n editor, and the results written back to disk! The mandatory record locking had no effect at all. Using the system call trace feature provided by some versions of the UNIX System, it was seen that \ned\n wrote the new contents to a temporary file, removed the original file, and then renamed the temporary file to be the original file.\n The mandatory record locking has no effect on the \nunlink\n function, which allowed this to happen.\n\n\nUnder FreeBSD 8.0 and Solaris 10, we can obtain the system call trace of a process with the \ntruss(1)\n command. Linux 3.2.0 provides the \nstrace(1)\n command for the same purpose. Mac OS X 10.6.8 provides the \ndtruss(1m)\n command to trace system calls, but its use requires superuser privileges.\n\n\n\n\n\n\nThe \nvi\n editor was never able to edit the file. It could read the file\u2019s contents, but whenever we tried to write new data to the file, \nEAGAIN\n was returned. If we tried to append new data to the file, the \nwrite\n blocked. This behavior from \nvi\n is what we expect.\n\n\nUsing the Korn shell\u2019s \n and \n operators to overwrite or append to the file resulted in the error \"cannot create\".\n\n\nUsing the same two operators with the Bourne shell resulted in an error for \n, but the \n operator just blocked until the mandatory lock was removed, and then proceeded.\n\n\nThe difference in the handling of the append operator occurs because the Korn shell \nopen\ns the file with \nO_CREAT\n and \nO_APPEND\n, and we mentioned earlier that specifying \nO_CREAT\n generates an error. The Bourne shell, however, doesn\u2019t specify \nO_CREAT\n if the file already exists, so the \nopen\n succeeds but the next \nwrite\n blocks.\n\n\n\n\n\n\n\n\nMandatory record locking can also be used by a malicious user to hold a read lock on a file that is publicly readable. This can prevent anyone from writing to the file. Consider a database file that is world readable and has mandatory record locking enabled. If a malicious user were to hold a read lock on the entire file, the file could not be written to by other processes.\n\n\nI/O Multiplexing\n\n\nselect\n and \npselect\n Functions\n\n\npoll\n Function\n\n\nAsynchronous I/O\n\n\nreadv\n and \nwritev\n Functions\n\n\nreadn\n and \nwriten\n Functions\n\n\nMemory-Mapped I/O", 
            "title": "Chapter 14. Advanced I/O"
        }, 
        {
            "location": "/apue/ch15/", 
            "text": "Chapter 15. Interprocess Communication\n\n\nThis chapter discusses other techniques for processes to communicate with one another: interprocess communication (IPC).\n\n\nThe figure below summarizes the various forms of IPC that are supported by the four implementations discussed in this text.\n\n\n\n\n\n\nThe \"SUS\" column allows an implementation to support full-duplex pipes, but requires only half-duplex pipes.\n\n\n\"(full)\" shows implementations that support half-duplex pipes by using full-duplex pipes.\n\n\nThe bullet means that basic functionality is supported.\n\n\n\"UDS\" means that the feature of full-duplex pipes can be provided through UNIX domain sockets\n\n\n\n\n[p533-534]\n\n\nThe first ten forms of IPC in the figure above are usually restricted to IPC between processes on the same host. The final two rows: sockets and STREAMS, are the only two forms that are generally supported for IPC between processes on different hosts.\n\n\nThis chapter dicusses classical IPC: pipes, FIFOs, message queues, semaphores, and shared memory.\n\n\nPipes\n\n\nPipes are the oldest form of UNIX System IPC and are provided by all UNIX systems. Pipes have two limitations:\n\n\n\n\nHistorically, they have been half duplex (data flows in only one direction).  Some systems now provide full-duplex pipes, but for maximum portability, we should never assume that this is the case.\n\n\nPipes can be used only between processes that have a common ancestor. Normally, a pipe is created by a process, that process calls \nfork\n, and the pipe is used between the parent and the child.\n\n\n\n\nFIFOs (Section 15.5) get around the second limitation, and that UNIX domain sockets (Section 17.2) get around both limitations.\n\n\nDespite these limitations, half-duplex pipes are still the most commonly used form of IPC. Every time you type a sequence of commands in a pipeline for the shell to execute, the shell creates a separate process for each command and links the standard output of one process to the standard input of the next using a pipe.\n\n\nA pipe is created by calling the \npipe\n function.\n\n\n#include \nunistd.h\n\n\n\nint\n \npipe\n(\nint\n \nfd\n[\n2\n]);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nTwo file descriptors are returned through the \nfd\n argument: \nfd[0]\n is open for reading, and \nfd[1]\n is open for writing. The output of \nfd[1]\n is the input for \nfd[0]\n.\n\n\nPOSIX.1 allows for implementations to support full-duplex pipes. For these implementations, \nfd[0]\n and \nfd[1]\n are open for both reading and writing.\n\n\nTwo ways to picture a half-duplex pipe are shown in the figure below. The left half of the figure shows the two ends of the pipe connected in a single process. The right half of the figure emphasizes that the data in the pipe flows through the kernel.\n\n\n\n\nThe \nfstat\n function returns a file type of FIFO for the file descriptor of either end of a pipe. We can test for a pipe with the \nS_ISFIFO\n macro.\n\n\nPOSIX.1 states that the \nst_size\n member of the stat structure is undefined for pipes. But when the \nfstat\n function is applied to the file descriptor for the read end of the pipe, many systems store in \nst_size\n the number of bytes available for reading in the pipe, which is nonportable.\n\n\nA pipe in a single process is next to useless. Normally, the process that calls \npipe\n then calls \nfork\n, creating an IPC channel from the parent to the child, or vice versa. The following figure shows this scenario:\n\n\n\n\nWhat happens after the \nfork\n depends on which direction of data flow we want. For a pipe from the parent to the child, the parent closes the read end of the pipe (\nfd[0]\n), and the child closes the write end (\nfd[1]\n). The following figure shows the resulting arrangement of descriptors.\n\n\n\n\nFor a pipe from the child to the parent, the parent closes fd[1], and the child closes fd[0].\n\n\nWhen one end of a pipe is closed, two rules apply:\n\n\n\n\nIf we \nread\n from a pipe whose write end has been closed, \nread\n returns 0 to\nindicate an end of file after all the data has been read.\n\n\nTechnically, we should say that this end of file is not generated until there are no more writers for the pipe.\n\n\nIt\u2019s possible to duplicate a pipe descriptor so that multiple processes have the pipe open for writing.\n\n\nNormally, there is a single reader and a single writer for a pipe. (The FIFOs in the next section dicusses that there are multiple writers for a single FIFO.)\n\n\n\n\n\n\nIf we \nwrite\n to a pipe whose read end has been closed, the signal \nSIGPIPE\n is generated. If we either ignore the signal or catch it and return from the signal handler, \nwrite\n returns \u22121 with \nerrno\n set to \nEPIPE\n.\n\n\n\n\nWhen we\u2019re writing to a pipe (or FIFO), the constant \nPIPE_BUF\n specifies the kernel\u2019s pipe buffer size. A write of \nPIPE_BUF\n bytes or less will not be interleaved with the writes from other processes to the same pipe (or FIFO). But if multiple processes are writing to a pipe (or FIFO), and if we write more than \nPIPE_BUF\n bytes, the data might be interleaved with the data from the other writers. We can determine the value of \nPIPE_BUF\n by using \npathconf\n or \nfpathconf\n.\n\n\nExample: creating a pipe between a parent and its child\n\n\nipc1/pipe1.c\n\n\n#include \napue.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nint\n     \nfd\n[\n2\n];\n\n    \npid_t\n   \npid\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nif\n \n(\npipe\n(\nfd\n)\n \n \n0\n)\n\n        \nerr_sys\n(\npipe error\n);\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n \n0\n)\n \n{\n       \n/* parent */\n\n        \nclose\n(\nfd\n[\n0\n]);\n\n        \nwrite\n(\nfd\n[\n1\n],\n \nhello world\n\\n\n,\n \n12\n);\n\n    \n}\n \nelse\n \n{\n                    \n/* child */\n\n        \nclose\n(\nfd\n[\n1\n]);\n\n        \nn\n \n=\n \nread\n(\nfd\n[\n0\n],\n \nline\n,\n \nMAXLINE\n);\n\n        \nwrite\n(\nSTDOUT_FILENO\n,\n \nline\n,\n \nn\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThe pipe direction in the code above matches the orientation shown in \nFigure 15.4\n\n\nExample: pager\n\n\nTo avoid writing all the data to a temporary file and calling system to display that file, we want to pipe the output directly to the pager. To do this, we create a pipe, \nfork\n a child process, \nset up the child\u2019s standard input to be the read end of the pipe\n, and \nexec\n the user\u2019s pager program, as shown in the program below. [p538]\n\n\nipc1/pipe2.c\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\n#define DEF_PAGER   \n/bin/more\n     \n/* default pager program */\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nint\n     \nfd\n[\n2\n];\n\n    \npid_t\n   \npid\n;\n\n    \nchar\n    \n*\npager\n,\n \n*\nargv0\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n    \nFILE\n    \n*\nfp\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: a.out \npathname\n);\n\n\n    \nif\n \n((\nfp\n \n=\n \nfopen\n(\nargv\n[\n1\n],\n \nr\n))\n \n==\n \nNULL\n)\n\n        \nerr_sys\n(\ncan\nt open %s\n,\n \nargv\n[\n1\n]);\n\n    \nif\n \n(\npipe\n(\nfd\n)\n \n \n0\n)\n\n        \nerr_sys\n(\npipe error\n);\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n \n0\n)\n \n{\n                               \n/* parent */\n\n        \nclose\n(\nfd\n[\n0\n]);\n       \n/* close read end */\n\n\n        \n/* parent copies argv[1] to pipe */\n\n        \nwhile\n \n(\nfgets\n(\nline\n,\n \nMAXLINE\n,\n \nfp\n)\n \n!=\n \nNULL\n)\n \n{\n\n            \nn\n \n=\n \nstrlen\n(\nline\n);\n\n            \nif\n \n(\nwrite\n(\nfd\n[\n1\n],\n \nline\n,\n \nn\n)\n \n!=\n \nn\n)\n\n                \nerr_sys\n(\nwrite error to pipe\n);\n\n        \n}\n\n        \nif\n \n(\nferror\n(\nfp\n))\n\n            \nerr_sys\n(\nfgets error\n);\n\n\n        \nclose\n(\nfd\n[\n1\n]);\n   \n/* close write end of pipe for reader */\n\n\n        \nif\n \n(\nwaitpid\n(\npid\n,\n \nNULL\n,\n \n0\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nwaitpid error\n);\n\n        \nexit\n(\n0\n);\n\n    \n}\n \nelse\n \n{\n                                        \n/* child */\n\n        \nclose\n(\nfd\n[\n1\n]);\n   \n/* close write end */\n\n        \nif\n \n(\nfd\n[\n0\n]\n \n!=\n \nSTDIN_FILENO\n)\n \n{\n\n            \nif\n \n(\ndup2\n(\nfd\n[\n0\n],\n \nSTDIN_FILENO\n)\n \n!=\n \nSTDIN_FILENO\n)\n\n                \nerr_sys\n(\ndup2 error to stdin\n);\n\n            \nclose\n(\nfd\n[\n0\n]);\n   \n/* don\nt need this after dup2 */\n\n        \n}\n\n\n        \n/* get arguments for execl() */\n\n        \nif\n \n((\npager\n \n=\n \ngetenv\n(\nPAGER\n))\n \n==\n \nNULL\n)\n\n            \npager\n \n=\n \nDEF_PAGER\n;\n\n        \nif\n \n((\nargv0\n \n=\n \nstrrchr\n(\npager\n,\n \n/\n))\n \n!=\n \nNULL\n)\n\n            \nargv0\n++\n;\n        \n/* step past rightmost slash */\n\n        \nelse\n\n            \nargv0\n \n=\n \npager\n;\n  \n/* no slash in pager */\n\n\n        \nif\n \n(\nexecl\n(\npager\n,\n \nargv0\n,\n \n(\nchar\n \n*\n)\n0\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexecl error for %s\n,\n \npager\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThis program does the following:\n\n\n\n\nBefore calling \nfork\n, we create a pipe.\n\n\nAfter the \nfork\n, the parent closes its read end, and the child closes its write end.\n\n\nThe child then calls \ndup2\n to have its standard input be the read end of the pipe.\n\n\nWhen the pager program is executed, its standard input will be the read end of the pipe.\n\n\n\n\nWhen we duplicate one descriptor onto another (\nfd[0]\n onto standard input in the child), we have to be careful that the descriptor doesn\u2019t already have the desired value. If the descriptor already had the desired value and we called \ndup2\n and \nclose\n, the single copy of the descriptor would be closed. In this program, if standard input had not been opened by the shell, the \nfopen\n at the beginning of the program should have used descriptor 0, the lowest unused descriptor, so \nfd[0]\n should never equal standard input. Nevertheless, \nwhenever we call \ndup2\n and close to duplicate one descriptor onto another, we\u2019ll always compare the descriptors first, as a defensive programming measure.\n\n\nImplementation of the \nTELL\n and \nWAIT\n functions using pipes\n\n\nRecall the five functions \nTELL_WAIT\n, \nTELL_PARENT\n, \nTELL_CHILD\n, \nWAIT_PARENT\n, and \nWAIT_CHILD\n from \nSection 8.9\n. Here is an implementation using pipes:\n\n\nipc1/tellwait.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nint\n  \npfd1\n[\n2\n],\n \npfd2\n[\n2\n];\n\n\n\nvoid\n\n\nTELL_WAIT\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\npipe\n(\npfd1\n)\n \n \n0\n \n||\n \npipe\n(\npfd2\n)\n \n \n0\n)\n\n        \nerr_sys\n(\npipe error\n);\n\n\n}\n\n\n\nvoid\n\n\nTELL_PARENT\n(\npid_t\n \npid\n)\n\n\n{\n\n    \nif\n \n(\nwrite\n(\npfd2\n[\n1\n],\n \nc\n,\n \n1\n)\n \n!=\n \n1\n)\n\n        \nerr_sys\n(\nwrite error\n);\n\n\n}\n\n\n\nvoid\n\n\nWAIT_PARENT\n(\nvoid\n)\n\n\n{\n\n    \nchar\n    \nc\n;\n\n\n    \nif\n \n(\nread\n(\npfd1\n[\n0\n],\n \nc\n,\n \n1\n)\n \n!=\n \n1\n)\n\n        \nerr_sys\n(\nread error\n);\n\n\n    \nif\n \n(\nc\n \n!=\n \np\n)\n\n        \nerr_quit\n(\nWAIT_PARENT: incorrect data\n);\n\n\n}\n\n\n\nvoid\n\n\nTELL_CHILD\n(\npid_t\n \npid\n)\n\n\n{\n\n    \nif\n \n(\nwrite\n(\npfd1\n[\n1\n],\n \np\n,\n \n1\n)\n \n!=\n \n1\n)\n\n        \nerr_sys\n(\nwrite error\n);\n\n\n}\n\n\n\nvoid\n\n\nWAIT_CHILD\n(\nvoid\n)\n\n\n{\n\n    \nchar\n    \nc\n;\n\n\n    \nif\n \n(\nread\n(\npfd2\n[\n0\n],\n \nc\n,\n \n1\n)\n \n!=\n \n1\n)\n\n        \nerr_sys\n(\nread error\n);\n\n\n    \nif\n \n(\nc\n \n!=\n \nc\n)\n\n        \nerr_quit\n(\nWAIT_CHILD: incorrect data\n);\n\n\n}\n\n\n\n\n\n\nThis program creates two pipes before the \nfork\n, as shown in the figure below. The parent writes the character \"p\" across the top pipe when \nTELL_CHILD\n is called, and the child writes the character \"c\" across the bottom pipe when \nTELL_PARENT\n is called. The corresponding \nWAIT_xxx\n functions do a blocking \nread\n for the single character.\n\n\n\n\nEach pipe has an extra reader, which doesn\u2019t matter. That is, in addition to the child reading from \npfd1[0]\n, the parent has this end of the top pipe open for reading. This doesn\u2019t affect us, since the parent doesn\u2019t try to read from this pipe.\n\n\npopen\n and \npclose\n Functions\n\n\nThe standard I/O library has historically provided the \npopen\n and \npclose\n functions. These two functions handle all the dirty work that we\u2019ve been doing ourselves: creating a pipe, \nfork\ning a child, closing the unused ends of the pipe, executing a shell to run the command, and waiting for the command to terminate.\n\n\n#include \nstdio.h\n\n\n\nFILE\n \n*\npopen\n(\nconst\n \nchar\n \n*\ncmdstring\n,\n \nconst\n \nchar\n \n*\ntype\n);\n\n\n\n/* Returns: file pointer if OK, NULL on error */\n\n\n\nint\n \npclose\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: termination status of cmdstring, or \u22121 on error */\n\n\n\n\n\n\nThe function \npopen\n does a \nfork\n and \nexec\n to execute the \ncmdstring\n and returns a standard I/O file pointer. If \ntype\n is \"r\", the file pointer is connected to the standard output of \ncmdstring\n, as shown in the figure below:\n\n\n\n\nIf type is \"w\", the file pointer is connected to the standard input of \ncmdstring\n, as shown in the figure below:\n\n\n\n\nThe \npclose\n function closes the standard I/O stream, waits for the command to terminate, and returns the termination status of the shell. (The termination status is described in \nSection 8.6\n. The \nsystem\n function, described in \nSection 8.13\n, also returns the termination status.) If the shell cannot be executed, the termination status returned by \npclose\n is as if the shell had executed \nexit(127)\n.\n\n\nThe cmdstring is executed by the Bourne shell, as in:\n\n\nsh -c cmdstring\n\n\n\n\n\nThis means that the shell expands any of its special characters in \ncmdstring\n. This allows us to say, for example,\n\n\nfp\n \n=\n \npopen\n(\nls *.c\n,\n \nr\n);\n\n\n\n\n\n\nor\n\n\nfp\n \n=\n \npopen\n(\ncmd 2\n1\n,\n \nr\n);\n\n\n\n\n\n\nExample: pager using \npopen\n\n\nThe following program is an reimplementation of \npager in the previous example\n using \npopen\n:\n\n\nipc1/popen2.c\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\n#define PAGER   \n${PAGER:-more}\n \n/* environment variable, or default */\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n    \nFILE\n    \n*\nfpin\n,\n \n*\nfpout\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: a.out \npathname\n);\n\n    \nif\n \n((\nfpin\n \n=\n \nfopen\n(\nargv\n[\n1\n],\n \nr\n))\n \n==\n \nNULL\n)\n\n        \nerr_sys\n(\ncan\nt open %s\n,\n \nargv\n[\n1\n]);\n\n\n    \nif\n \n((\nfpout\n \n=\n \npopen\n(\nPAGER\n,\n \nw\n))\n \n==\n \nNULL\n)\n\n        \nerr_sys\n(\npopen error\n);\n\n\n    \n/* copy argv[1] to pager */\n\n    \nwhile\n \n(\nfgets\n(\nline\n,\n \nMAXLINE\n,\n \nfpin\n)\n \n!=\n \nNULL\n)\n \n{\n\n        \nif\n \n(\nfputs\n(\nline\n,\n \nfpout\n)\n \n==\n \nEOF\n)\n\n            \nerr_sys\n(\nfputs error to pipe\n);\n\n    \n}\n\n    \nif\n \n(\nferror\n(\nfpin\n))\n\n        \nerr_sys\n(\nfgets error\n);\n\n    \nif\n \n(\npclose\n(\nfpout\n)\n \n==\n \n-\n1\n)\n\n        \nerr_sys\n(\npclose error\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nUsing \npopen\n reduces the amount of code we have to write. The shell command \n${PAGER:-more}\n means to use the value of the shell variable \nPAGER\n if it is defined and non-null; otherwise, use the string \nmore\n.\n\n\nExample: \npopen\n and \npclose\n Functions\n\n\nThe following code shows our version of \npopen\n and \npclose\n:\n\n\nipc1/popen.c\n\n\n#include \napue.h\n\n\n#include \nerrno.h\n\n\n#include \nfcntl.h\n\n\n#include \nsys/wait.h\n\n\n\n/*\n\n\n * Pointer to array allocated at run-time.\n\n\n */\n\n\nstatic\n \npid_t\n    \n*\nchildpid\n \n=\n \nNULL\n;\n\n\n\n/*\n\n\n * From our open_max(), {Prog openmax}.\n\n\n */\n\n\nstatic\n \nint\n      \nmaxfd\n;\n\n\n\nFILE\n \n*\n\n\npopen\n(\nconst\n \nchar\n \n*\ncmdstring\n,\n \nconst\n \nchar\n \n*\ntype\n)\n\n\n{\n\n    \nint\n     \ni\n;\n\n    \nint\n     \npfd\n[\n2\n];\n\n    \npid_t\n   \npid\n;\n\n    \nFILE\n    \n*\nfp\n;\n\n\n    \n/* only allow \nr\n or \nw\n */\n\n    \nif\n \n((\ntype\n[\n0\n]\n \n!=\n \nr\n \n \ntype\n[\n0\n]\n \n!=\n \nw\n)\n \n||\n \ntype\n[\n1\n]\n \n!=\n \n0\n)\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\nNULL\n);\n\n    \n}\n\n\n    \nif\n \n(\nchildpid\n \n==\n \nNULL\n)\n \n{\n     \n/* first time through */\n\n        \n/* allocate zeroed out array for child pids */\n\n        \nmaxfd\n \n=\n \nopen_max\n();\n\n        \nif\n \n((\nchildpid\n \n=\n \ncalloc\n(\nmaxfd\n,\n \nsizeof\n(\npid_t\n)))\n \n==\n \nNULL\n)\n\n            \nreturn\n(\nNULL\n);\n\n    \n}\n\n\n    \nif\n \n(\npipe\n(\npfd\n)\n \n \n0\n)\n\n        \nreturn\n(\nNULL\n);\n   \n/* errno set by pipe() */\n\n    \nif\n \n(\npfd\n[\n0\n]\n \n=\n \nmaxfd\n \n||\n \npfd\n[\n1\n]\n \n=\n \nmaxfd\n)\n \n{\n\n        \nclose\n(\npfd\n[\n0\n]);\n\n        \nclose\n(\npfd\n[\n1\n]);\n\n        \nerrno\n \n=\n \nEMFILE\n;\n\n        \nreturn\n(\nNULL\n);\n\n    \n}\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nreturn\n(\nNULL\n);\n   \n/* errno set by fork() */\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n                          \n/* child */\n\n        \nif\n \n(\n*\ntype\n \n==\n \nr\n)\n \n{\n\n            \nclose\n(\npfd\n[\n0\n]);\n\n            \nif\n \n(\npfd\n[\n1\n]\n \n!=\n \nSTDOUT_FILENO\n)\n \n{\n\n                \ndup2\n(\npfd\n[\n1\n],\n \nSTDOUT_FILENO\n);\n\n                \nclose\n(\npfd\n[\n1\n]);\n\n            \n}\n\n        \n}\n \nelse\n \n{\n\n            \nclose\n(\npfd\n[\n1\n]);\n\n            \nif\n \n(\npfd\n[\n0\n]\n \n!=\n \nSTDIN_FILENO\n)\n \n{\n\n                \ndup2\n(\npfd\n[\n0\n],\n \nSTDIN_FILENO\n);\n\n                \nclose\n(\npfd\n[\n0\n]);\n\n            \n}\n\n        \n}\n\n\n        \n/* close all descriptors in childpid[] */\n\n        \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nmaxfd\n;\n \ni\n++\n)\n\n            \nif\n \n(\nchildpid\n[\ni\n]\n \n \n0\n)\n\n                \nclose\n(\ni\n);\n\n\n        \nexecl\n(\n/bin/sh\n,\n \nsh\n,\n \n-c\n,\n \ncmdstring\n,\n \n(\nchar\n \n*\n)\n0\n);\n\n        \n_exit\n(\n127\n);\n\n    \n}\n\n\n    \n/* parent continues... */\n\n    \nif\n \n(\n*\ntype\n \n==\n \nr\n)\n \n{\n\n        \nclose\n(\npfd\n[\n1\n]);\n\n        \nif\n \n((\nfp\n \n=\n \nfdopen\n(\npfd\n[\n0\n],\n \ntype\n))\n \n==\n \nNULL\n)\n\n            \nreturn\n(\nNULL\n);\n\n    \n}\n \nelse\n \n{\n\n        \nclose\n(\npfd\n[\n0\n]);\n\n        \nif\n \n((\nfp\n \n=\n \nfdopen\n(\npfd\n[\n1\n],\n \ntype\n))\n \n==\n \nNULL\n)\n\n            \nreturn\n(\nNULL\n);\n\n    \n}\n\n\n    \nchildpid\n[\nfileno\n(\nfp\n)]\n \n=\n \npid\n;\n \n/* remember child pid for this fd */\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nint\n\n\npclose\n(\nFILE\n \n*\nfp\n)\n\n\n{\n\n    \nint\n     \nfd\n,\n \nstat\n;\n\n    \npid_t\n   \npid\n;\n\n\n    \nif\n \n(\nchildpid\n \n==\n \nNULL\n)\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n     \n/* popen() has never been called */\n\n    \n}\n\n\n    \nfd\n \n=\n \nfileno\n(\nfp\n);\n\n    \nif\n \n(\nfd\n \n=\n \nmaxfd\n)\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n     \n/* invalid file descriptor */\n\n    \n}\n\n    \nif\n \n((\npid\n \n=\n \nchildpid\n[\nfd\n])\n \n==\n \n0\n)\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n     \n/* fp wasn\nt opened by popen() */\n\n    \n}\n\n\n    \nchildpid\n[\nfd\n]\n \n=\n \n0\n;\n\n    \nif\n \n(\nfclose\n(\nfp\n)\n \n==\n \nEOF\n)\n\n        \nreturn\n(\n-\n1\n);\n\n\n    \nwhile\n \n(\nwaitpid\n(\npid\n,\n \nstat\n,\n \n0\n)\n \n \n0\n)\n\n        \nif\n \n(\nerrno\n \n!=\n \nEINTR\n)\n\n            \nreturn\n(\n-\n1\n);\n \n/* error other than EINTR from waitpid() */\n\n\n    \nreturn\n(\nstat\n);\n   \n/* return child\ns termination status */\n\n\n}\n\n\n\n\n\n\nFrom this code, we can see:\n\n\n\n\nEach time \npopen\n is called, we save the child\u2019s process ID in the array \nchildpid\n, which we index by the file descriptor. This way, when \npclose\n is called with the \nFILE\n pointer as its argument, we call the standard I/O function \nfileno\n to get the file descriptor and then have the child process ID for the call to \nwaitpid\n. Since it\u2019s possible for a given process to call popen more than once, we dynamically allocate the \nchildpid\n array (the first time popen is called), with room for as many children as there are file descriptors. [p545]\n\n\nPOSIX.1 requires that popen close any streams that are still open in the child from previous calls to popen. To do this, we go through the \nchildpid\n array in the child, closing any descriptors that are still open.\n\n\nWhat happens if the caller of \npclose\n has established a signal handler for \nSIGCHLD\n? The call to \nwaitpid\n from \npclose\n would return an error of \nEINTR\n. Since the caller is allowed to catch this signal (or any other signal that might interrupt the call to \nwaitpid\n), we simply call \nwaitpid\n again if it is interrupted by a caught signal.\n\n\nIf the application calls \nwaitpid\n and obtains the exit status of the child created by \npopen\n, we will call \nwaitpid\n when the application calls \npclose\n, find that the child no longer exists, and return \u22121 with \nerrno\n set to \nECHILD\n. This is the behavior required by POSIX.1 in this situation.\n\n\n\n\n[p546]\n\n\nSecurity concerns of \npopen\n\n\npopen\n should never be called by a set-user-ID or set-group-ID program.  When it executes the command, \npopen\n does the equivalent of:\n\n\nexecl\n(\n/bin/sh\n,\n \nsh\n,\n \n-c\n,\n \ncommand\n,\n \nNULL\n);\n\n\n\n\n\n\nwhich executes the shell and command with the environment inherited by the caller. A malicious user can manipulate the environment so that the shell executes commands other than those intended, with the elevated permissions granted by the set-ID file mode.\n\n\nExample: transforming input using \npopen\n\n\nOne thing that \npopen\n is especially well suited for is executing simple filters to transform the input or output of the running command.\n Such is the case when a command wants to build its own pipeline.\n\n\nConsider an application that writes a prompt to standard output and reads a line from standard input. With the popen function, we can interpose a program between the application and its input to transform the input. The following figure shows the arrangement of processes in this situation.\n\n\n\n\nThe following program is a simple filter to demonstrate this operation:\n\n\nipc1/myuclc.c\n\n\n#include \napue.h\n\n\n#include \nctype.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nc\n;\n\n\n    \nwhile\n \n((\nc\n \n=\n \ngetchar\n())\n \n!=\n \nEOF\n)\n \n{\n\n        \nif\n \n(\nisupper\n(\nc\n))\n\n            \nc\n \n=\n \ntolower\n(\nc\n);\n\n        \nif\n \n(\nputchar\n(\nc\n)\n \n==\n \nEOF\n)\n\n            \nerr_sys\n(\noutput error\n);\n\n        \nif\n \n(\nc\n \n==\n \n\\n\n)\n\n            \nfflush\n(\nstdout\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThe filter copies standard input to standard output, converting any uppercase character to lowercase. The reason we\u2019re careful to \nfflush\n standard output after writing a newline is discussed in the next section when we talk about coprocesses.\n\n\nWe compile this filter into the executable file \nmyuclc\n, which we then invoke from the program in the following code using \npopen\n:\n\n\nipc1/popen1.c\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n    \nFILE\n    \n*\nfpin\n;\n\n\n    \nif\n \n((\nfpin\n \n=\n \npopen\n(\nmyuclc\n,\n \nr\n))\n \n==\n \nNULL\n)\n\n        \nerr_sys\n(\npopen error\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nfputs\n(\nprompt\n \n,\n \nstdout\n);\n\n        \nfflush\n(\nstdout\n);\n\n        \nif\n \n(\nfgets\n(\nline\n,\n \nMAXLINE\n,\n \nfpin\n)\n \n==\n \nNULL\n)\n \n/* read from pipe */\n\n            \nbreak\n;\n\n        \nif\n \n(\nfputs\n(\nline\n,\n \nstdout\n)\n \n==\n \nEOF\n)\n\n            \nerr_sys\n(\nfputs error to pipe\n);\n\n    \n}\n\n    \nif\n \n(\npclose\n(\nfpin\n)\n \n==\n \n-\n1\n)\n\n        \nerr_sys\n(\npclose error\n);\n\n    \nputchar\n(\n\\n\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWe need to call \nfflush\n after writing the prompt, because the standard output is normally line buffered, and the prompt does not contain a newline.\n\n\nCoprocesses\n\n\nA UNIX system filter is a program that reads from standard input and writes to standard output. Filters are normally connected linearly in shell pipelines. A filter becomes a \ncoprocess\n when the same program generates the filter\u2019s input and reads the filter\u2019s output.\n\n\nThe Korn shell provides coprocesses. The Bourne shell, the Bourne-again shell, and the C shell don\u2019t provide a way to connect processes together as coprocesses. A coprocess normally runs in the background from a shell, and its standard input and standard output are connected to another program using a pipe.  Although the shell syntax required to initiate a coprocess and connect its input and output to other processes is quite contorted, coprocesses are also useful from a C program.\n\n\nWhereas \npopen\n gives us a one-way pipe to the standard input or from the standard output of another process, with a coprocess we have two one-way pipes to the other process: one to its standard input and one from its standard output. We want to write to its standard input, let it operate on the data, and then read from its standard output.\n\n\nExample: invoking \nadd2\n as a coprocess\n\n\nFor example, the process creates two pipes: one is the standard input of the coprocess and the other is the standard output of the coprocess. The figure below shows this arrangement:\n\n\n\n\nThe following program is a simple coprocess that reads two numbers from its standard input, computes their sum, and writes the sum to its standard output.\n\n\nipc1/add2.c\n\n\n#include \napue.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n,\n \nint1\n,\n \nint2\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nwhile\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nline\n,\n \nMAXLINE\n))\n \n \n0\n)\n \n{\n\n        \nline\n[\nn\n]\n \n=\n \n0\n;\n        \n/* null terminate */\n\n        \nif\n \n(\nsscanf\n(\nline\n,\n \n%d%d\n,\n \nint1\n,\n \nint2\n)\n \n==\n \n2\n)\n \n{\n\n            \nsprintf\n(\nline\n,\n \n%d\n\\n\n,\n \nint1\n \n+\n \nint2\n);\n\n            \nn\n \n=\n \nstrlen\n(\nline\n);\n\n            \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \nline\n,\n \nn\n)\n \n!=\n \nn\n)\n\n                \nerr_sys\n(\nwrite error\n);\n\n        \n}\n \nelse\n \n{\n\n            \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \ninvalid args\n\\n\n,\n \n13\n)\n \n!=\n \n13\n)\n\n                \nerr_sys\n(\nwrite error\n);\n\n        \n}\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWe compile this program and leave the executable in the file \nadd2\n.\n\n\nThe following program invokes the \nadd2\n coprocess after reading two numbers from its standard input. The value from the coprocess is written to its standard output.\n\n\nipc1/pipe4.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_pipe\n(\nint\n);\n      \n/* our signal handler */\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n,\n \nfd1\n[\n2\n],\n \nfd2\n[\n2\n];\n\n    \npid_t\n   \npid\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nif\n \n(\nsignal\n(\nSIGPIPE\n,\n \nsig_pipe\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal error\n);\n\n\n    \nif\n \n(\npipe\n(\nfd1\n)\n \n \n0\n \n||\n \npipe\n(\nfd2\n)\n \n \n0\n)\n\n        \nerr_sys\n(\npipe error\n);\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n \n0\n)\n \n{\n                           \n/* parent */\n\n        \nclose\n(\nfd1\n[\n0\n]);\n\n        \nclose\n(\nfd2\n[\n1\n]);\n\n\n        \nwhile\n \n(\nfgets\n(\nline\n,\n \nMAXLINE\n,\n \nstdin\n)\n \n!=\n \nNULL\n)\n \n{\n\n            \nn\n \n=\n \nstrlen\n(\nline\n);\n\n            \nif\n \n(\nwrite\n(\nfd1\n[\n1\n],\n \nline\n,\n \nn\n)\n \n!=\n \nn\n)\n\n                \nerr_sys\n(\nwrite error to pipe\n);\n\n            \nif\n \n((\nn\n \n=\n \nread\n(\nfd2\n[\n0\n],\n \nline\n,\n \nMAXLINE\n))\n \n \n0\n)\n\n                \nerr_sys\n(\nread error from pipe\n);\n\n            \nif\n \n(\nn\n \n==\n \n0\n)\n \n{\n\n                \nerr_msg\n(\nchild closed pipe\n);\n\n                \nbreak\n;\n\n            \n}\n\n            \nline\n[\nn\n]\n \n=\n \n0\n;\n    \n/* null terminate */\n\n            \nif\n \n(\nfputs\n(\nline\n,\n \nstdout\n)\n \n==\n \nEOF\n)\n\n                \nerr_sys\n(\nfputs error\n);\n\n        \n}\n\n\n        \nif\n \n(\nferror\n(\nstdin\n))\n\n            \nerr_sys\n(\nfgets error on stdin\n);\n\n        \nexit\n(\n0\n);\n\n    \n}\n \nelse\n \n{\n                                    \n/* child */\n\n        \nclose\n(\nfd1\n[\n1\n]);\n\n        \nclose\n(\nfd2\n[\n0\n]);\n\n        \nif\n \n(\nfd1\n[\n0\n]\n \n!=\n \nSTDIN_FILENO\n)\n \n{\n\n            \nif\n \n(\ndup2\n(\nfd1\n[\n0\n],\n \nSTDIN_FILENO\n)\n \n!=\n \nSTDIN_FILENO\n)\n\n                \nerr_sys\n(\ndup2 error to stdin\n);\n\n            \nclose\n(\nfd1\n[\n0\n]);\n\n        \n}\n\n\n        \nif\n \n(\nfd2\n[\n1\n]\n \n!=\n \nSTDOUT_FILENO\n)\n \n{\n\n            \nif\n \n(\ndup2\n(\nfd2\n[\n1\n],\n \nSTDOUT_FILENO\n)\n \n!=\n \nSTDOUT_FILENO\n)\n\n                \nerr_sys\n(\ndup2 error to stdout\n);\n\n            \nclose\n(\nfd2\n[\n1\n]);\n\n        \n}\n\n        \nif\n \n(\nexecl\n(\n./add2\n,\n \nadd2\n,\n \n(\nchar\n \n*\n)\n0\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexecl error\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_pipe\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\nSIGPIPE caught\n\\n\n);\n\n    \nexit\n(\n1\n);\n\n\n}\n\n\n\n\n\n\nThis program creates two pipes, with the parent and the child closing the ends they don\u2019t need. We have to use two pipes: one for the standard input of the coprocess and one for its standard output. \nThe child then calls \ndup2\n to move the pipe descriptors onto its standard input and standard output, before calling \nexecl\n.\n If we \nkill\n the add2 coprocess while the above program is waiting for our input and then enter two numbers, the signal handler is invoked when the program writes to the pipe that has no reader.\n\n\nExample: invoking \nadd2\n as a coprocess using standard I/O\n\n\nThe previous example of coprocess \nadd2\n purposely used low-level I/O (UNIX system calls): \nread\n and \nwrite\n. What happens if we rewrite this coprocess to use standard I/O? The following program is the new version:\n\n\nipc1/add2stdio.c\n\n\n#include \napue.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nint1\n,\n \nint2\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nwhile\n \n(\nfgets\n(\nline\n,\n \nMAXLINE\n,\n \nstdin\n)\n \n!=\n \nNULL\n)\n \n{\n\n        \nif\n \n(\nsscanf\n(\nline\n,\n \n%d%d\n,\n \nint1\n,\n \nint2\n)\n \n==\n \n2\n)\n \n{\n\n            \nif\n \n(\nprintf\n(\n%d\n\\n\n,\n \nint1\n \n+\n \nint2\n)\n \n==\n \nEOF\n)\n\n                \nerr_sys\n(\nprintf error\n);\n\n        \n}\n \nelse\n \n{\n\n            \nif\n \n(\nprintf\n(\ninvalid args\n\\n\n)\n \n==\n \nEOF\n)\n\n                \nerr_sys\n(\nprintf error\n);\n\n        \n}\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nIf we invoke this new coprocess from the \nparent program\n from the previous example, it no longer works. The problem is the default standard I/O buffering. When the above program is invoked, the first \nfgets\n on the standard input causes the standard I/O library to allocate a buffer and choose the type of buffering. Since the standard input is a pipe, the standard I/O library defaults to fully buffered. The same thing happens with the standard output. While \nadd2\n is blocked reading from its standard input, the parent program blocked reading from the pipe. We have a deadlock.\n\n\nWe can change the \nabove program\n by adding the following four lines before the while loop:\n\n\nif\n \n(\nsetvbuf\n(\nstdin\n,\n \nNULL\n,\n \n_IOLBF\n,\n \n0\n)\n \n!=\n \n0\n)\n\n    \nerr_sys\n(\nsetvbuf error\n);\n\n\nif\n \n(\nsetvbuf\n(\nstdout\n,\n \nNULL\n,\n \n_IOLBF\n,\n \n0\n)\n \n!=\n \n0\n)\n\n    \nerr_sys\n(\nsetvbuf error\n);\n\n\n\n\n\n\nThese lines cause \nfgets\n to return when a line is available and cause \nprintf\n to do an \nfflush\n when a newline is output (refer to \nSection 5.4\n for the details on standard I/O buffering). Making these explicit calls to \nsetvbuf\n fixes the program.\n\n\nIf we aren\u2019t able to modify the program that we\u2019re piping the output into, other techniques are required. For example, if we use \nawk(1)\n as a coprocess from our program (instead of the \nadd2\n program), the following won\u2019t work:\n\n\n#! /bin/awk -f\n\n\n{\n \nprint\n \n$\n1\n \n+\n \n$\n2\n \n}\n\n\n\n\n\n\nThe reason this won\u2019t work is again the standard I/O buffering. But in this case, we cannot change the way \nawk\n works (unless we have the source code for it). We are unable to modify the executable of \nawk\n in any way to change the way the standard I/O buffering is handled.\n\n\nThe solution for this general problem is to make the coprocess being invoked (\nawk\n in this case) think that its standard input and standard output are connected to a terminal. That causes the standard I/O routines in the coprocess to line buffer these two I/O streams, similar to what we did with the explicit calls to \nsetvbuf\n previously. We use pseudo terminals to do this in Chapter 19.\n\n\nFIFOs\n\n\nFIFOs are sometimes called named pipes. Unnamed pipes can be used only between related processes when a common ancestor has created the pipe. With FIFOs, however, unrelated processes can exchange data.\n\n\nA FIFO is a type of file (\nChapter 4\n). One of the encodings of the \nst_mode\n member of the stat structure indicates that a file is a FIFO. We can test for this with the \nS_ISFIFO\n macro. Creating a FIFO is similar to creating a file; the \npathname\n for a FIFO exists in the file system.\n\n\n#include \nsys/stat.h\n\n\n\nint\n \nmkfifo\n(\nconst\n \nchar\n \n*\npath\n,\n \nmode_t\n \nmode\n);\n\n\nint\n \nmkfifoat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npath\n,\n \nmode_t\n \nmode\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe specification of the \nmode\n argument is the same as for the \nopen\n function. The rules for the user and group ownership of the new FIFO are the same as we described in \nSection 4.6\n.  The \nmkfifoat\n function is similar to the mkfifo function, except that it can be used to create a FIFO in a location relative to the directory represented by by the \nfd\n file descriptor argument. Like the other *at functions, there are three cases:\n\n\n\n\nIf the \npath\n parameter specifies an absolute pathname, then the \nfd\n parameter is ignored and the \nmkfifoat\n function behaves like the \nmkfifo\n function.\n\n\nIf the \npath\n parameter specifies a relative pathname and the \nfd\n parameter is a valid file descriptor for an open directory, the pathname is evaluated relative to this directory.\n\n\nIf the \npath\n parameter specifies a relative pathname and the \nfd\n parameter has the special value \nAT_FDCWD\n, the pathname is evaluated starting in the current working directory, and \nmkfifoat\n behaves like \nmkfifo\n.\n\n\n\n\nOnce we have used \nmkfifo\n or \nmkfifoat\n to create a FIFO, we open it using \nopen\n. The normal file I/O functions (e.g., \nclose\n, \nread\n, \nwrite\n, \nunlink\n) all work with FIFOs.\n\n\nApplications can create FIFOs with the \nmknod\n and \nmknodat\n functions. Because POSIX.1 originally didn\u2019t include \nmknod\n, the \nmkfifo\n function was invented specifically for POSIX.1.  The \nmknod\n and \nmknodat\n functions are included in the XSI option in POSIX.1.  POSIX.1 also includes support for the \nmkfifo(1)\n command. All four platforms discussed in this text provide this command. As a result, we can create a FIFO using a shell command and then access it with the normal shell I/O redirection.\n\n\nWhen we open a FIFO, the nonblocking flag (\nO_NONBLOCK\n) affects what happens:\n\n\n\n\nIn the normal case (without \nO_NONBLOCK\n), an open for read-only blocks until some other process opens the FIFO for writing. Similarly, an open for writeonly blocks until some other process opens the FIFO for reading.\n\n\nIf \nO_NONBLOCK\n is specified, an \nopen\n for read-only returns immediately. But an open for write-only returns \u22121 with \nerrno\n set to \nENXIO\n if no process has the FIFO open for reading.\n\n\n\n\nAs with a pipe, if we \nwrite\n to a FIFO that no process has open for reading, the signal \nSIGPIPE\n is generated. When the last writer for a FIFO closes the FIFO, an end of file is generated for the reader of the FIFO.\n\n\nIt is common to have multiple writers for a given FIFO. This means that we have to worry about atomic writes if we don\u2019t want the writes from multiple processes to be interleaved. As with pipes, the constant \nPIPE_BUF\n specifies the maximum amount of data that can be written atomically to a FIFO.\n\n\nThere are two uses for FIFOs.\n\n\n\n\nFIFOs are used by shell commands to pass data from one shell pipeline to another without creating intermediate temporary files.\n\n\nFIFOs are used as rendezvous points in client\u2013server applications to pass data between the clients and the servers.\n\n\n\n\nUsing FIFOs to Duplicate Output Streams\n\n\nFIFOs can be used to duplicate an output stream in a series of shell commands. This prevents writing the data to an intermediate disk file (similar to using pipes to avoid intermediate disk files). But whereas pipes can be used only for linear connections between processes, a FIFO has a name, so it can be used for nonlinear connections.\n\n\nConsider a procedure that needs to process a filtered input stream twice. The figure below shows this arrangement.\n\n\n\n\nWith a FIFO and the UNIX program \ntee(1)\n, we can accomplish this procedure without using a temporary file. (The \ntee\n program copies its standard input to both its standard output and the file named on its command line.)\n\n\nmkfifo fifo1\nprog3 \n fifo1 \n\nprog1 \n infile \n|\n tee fifo1 \n|\n prog2\n\n\n\n\n\nWe create the FIFO and then start \nprog3\n in the background, reading from the FIFO. We then start \nprog1\n and use \ntee\n to send its input to both the FIFO and \nprog2\n. The following figure shows the process arrangement.\n\n\n\n\nClient\u2013Server Communication Using a FIFO\n\n\nAnother use for FIFOs is to send data between a client and a server. If we have a server that is contacted by numerous clients, each client can write its request to a well-known FIFO that the server creates. \"well-known\" means that the pathname of the FIFO is known to all the clients that need to contact the server.\n\n\n\n\nSince there are multiple writers for the FIFO, the requests sent by the clients to the server need to be less than \nPIPE_BUF\n bytes in size. This prevents any interleaving of the client writes.\n\n\nThe problem in using FIFOs for this type of client\u2013server communication is how to send replies back from the server to each client. A single FIFO can\u2019t be used, as the clients would never know when to read their response versus responses for other clients. One solution is for each client to send its process ID with the request. The server then creates a unique FIFO for each client, using a pathname based on the client\u2019s process ID. For example, the server can create a FIFO with the name \n/tmp/serv1.XXXXX\n, where \nXXXXX\n is replaced with the client\u2019s process ID. This arrangement is shown the figure below.\n\n\nThis arrangement works, although it is impossible for the server to tell whether a client crashes. A client crash leaves the client-specific FIFO in the file system. The server also must catch \nSIGPIPE\n, since it\u2019s possible for a client to send a request and terminate before reading the response, leaving the client-specific FIFO with one writer (the server) and no reader.\n\n\n\n\nWith the arrangement shown in the figure above, if the server opens its well-known FIFO read-only (since it only reads from it) each time the number of clients goes from 1 to 0, the server will read an end of file on the FIFO. To prevent the server from having to handle this case, a common trick is just to have the server open its well-known FIFO for read\u2013write.\n\n\nXSI IPC\n\n\nThe three types of IPC that we call XSI IPC: message queues, semaphores, and shared memory, have many similarities. This section covers these similar features; in the following sections, we look at the specific functions for each of the three IPC types.\n\n\nIdentifiers and Keys\n\n\nEach IPC structure (message queue, semaphore, or shared memory segment) in the kernel is referred to by a non-negative integer identifier. To send a message to or fetch a message from a message queue, for example, all we need know is the identifier for the queue. Unlike file descriptors, IPC identifiers are not small integers. Indeed, when a given IPC structure is created and then removed, the identifier associated with that structure continually increases until it reaches the maximum positive value for an integer, and then wraps around to 0.\n\n\nThe identifier is an internal name for an IPC object. Cooperating processes need an external naming scheme to be able to rendezvous using the same IPC object. For this purpose, an IPC object is associated with a \nkey\n that acts as an external name.\n\n\nWhenever an IPC structure is being created (by calling \nmsgget\n, \nsemget\n, or \nshmget\n), a key must be specified. The data type of this key is the primitive system data type \nkey_t\n, which is often defined as a long integer in the header \nsys/types.h\n.  This key is converted into an identifier by the kernel.\n\n\n[p557-560]\n\n\nPermission Structure\n\n\nConfiguration Limits\n\n\nAdvantages and Disadvantages\n\n\nMessage Queues\n\n\nA message queue is a linked list of messages stored within the kernel and identified by a message queue identifier. The message queue is called a \nqueue\n and its identifier is called a \nqueue ID\n.\n\n\n[p561-565]\n\n\nSemaphores\n\n\nA semaphore isn\u2019t a form of IPC similar to the others described (pipes, FIFOs, and message queues). A semaphore is a counter used to provide access to a shared data object for multiple processes.\n\n\nThe Single UNIX Specification includes an alternative set of semaphore interfaces that were originally part of its real-time extensions. These interfaces are discussed in \nSection 15.10\n.\n\n\nTo obtain a shared resource, a process needs to do the following:\n\n\n\n\nTest the semaphore that controls the resource.\n\n\nIf the value of the semaphore is positive, the process can use the resource. In this case, the process decrements the semaphore value by 1, indicating that it has used one unit of the resource.\n\n\nOtherwise, if the value of the semaphore is 0, the process goes to sleep until the semaphore value is greater than 0. When the process wakes up, it returns to step 1.\n\n\n\n\nWhen a process is done with a shared resource that is controlled by a semaphore, the semaphore value is incremented by 1. If any other processes are asleep, waiting for the semaphore, they are awakened.\n\n\nTo implement semaphores correctly, the test of a semaphore\u2019s value and the decrementing of this value must be an atomic operation. For this reason, semaphores are normally implemented inside the kernel.\n\n\nA common form of semaphore is called a \nbinary semaphore\n. It controls a single resource, and its value is initialized to 1. In general, however, a semaphore can be initialized to any positive value, with the value indicating how many units of the shared resource are available for sharing.\n\n\n[p566-570]\n\n\nTiming Comparison of Semaphores, Record Locking, and Mutexes\n\n\nIf we are sharing a single resource among multiple processes, we can use one of three\ntechniques to coordinate access:\n\n\n\n\nA semaphore\n\n\nRecord locking\n\n\nA mutex that is mapped into the address spaces of both processes\n\n\n\n\nIt\u2019s interesting to compare the timing differences between the three techniques:\n\n\n\n\n\n\nSemaphore\n. With a semaphore, we create a semaphore set consisting of a single member and initialize the semaphore\u2019s value to 1.\n\n\n\n\nTo allocate the resource, we call semop with a \nsem_op\n of \u22121;\n\n\nTo release the resource, we perform a \nsem_op\n of +1.\n\n\n\n\nWe also specify \nSEM_UNDO\n with each operation, to handle the case of a process that terminates without releasing its resource.\n\n\n\n\n\n\nRecord locking\n. With record locking, we create an empty file and use the first byte of the file (which need not exist) as the lock byte.\n\n\n\n\nTo allocate the resource, we obtain a write lock on the byte;\n\n\nTo release it, we unlock the byte.\n\n\n\n\nThe record locking properties guarantee that if a process terminates while holding a lock, the kernel automatically releases the lock.\n\n\n\n\n\n\nMutex\n. To use a mutex, we need both processes to map the same file into their address spaces and initialize a mutex at the same offset in the file using the \nPTHREAD_PROCESS_SHARED\n mutex attribute.\n\n\n\n\nTo allocate the resource, we lock the mutex;\n\n\nTo release the resource, we unlock the mutex.\n\n\n\n\nIf a process terminates without releasing the mutex, recovery is difficult unless we use a robust mutex (\npthread_mutex_consistent\n function discussed in Section 12.4.1).\n\n\n\n\n\n\nThe following table shows the time required to perform these three locking techniques on Linux. In each case, the resource was allocated and then released 1,000,000 times. This was done simultaneously by three different processes. The times are the totals in seconds for all three processes.\n\n\n\n\n\n\n\n\nOperation\n\n\nUser\n\n\nSystem\n\n\nClock\n\n\n\n\n\n\n\n\n\n\nsemaphores with undo\n\n\n0.50\n\n\n6.08\n\n\n7.55\n\n\n\n\n\n\nadvisory record locking\n\n\n0.51\n\n\n9.06\n\n\n4.38\n\n\n\n\n\n\nmutex in shared memory\n\n\n0.21\n\n\n0.40\n\n\n0.25\n\n\n\n\n\n\n\n\nOn Linux, record locking is faster than semaphores, but mutexes in shared memory outperform both semaphores and record locking. If we\u2019re locking a single resource and don\u2019t need all the fancy features of XSI semaphores, record locking is preferred over semaphores. The reasons are that it is much simpler to use, it is faster (on this platform), and the system takes care of any lingering locks when a process terminates.  Even though using a mutex in shared memory is the fastest option on this platform, we still prefer to use record locking, unless performance is the primary concern. There are two reasons for this. First, recovery from process termination is more difficult using a mutex in memory shared among multiple processes. Second, the process-shared mutex attribute isn\u2019t universally supported yet. In older versions of the Single UNIX Specification, it was optional. Although it is still optional in SUSv4, it is now required by all XSI-conforming implementations. Of the four platforms covered in this text, only Linux 3.2.0 and Solaris 10 currently support the\nprocess-shared mutex attribute.\n\n\nShared Memory\n\n\nPOSIX Semaphores\n\n\nClient\u2013Server Properties\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np537 on pipes.\n\n\n\n\nWhen we\u2019re writing to a pipe (or FIFO), the constant \nPIPE_BUF\n specifies the kernel\u2019s pipe buffer size. A write of \nPIPE_BUF\n bytes or less will not be interleaved with the writes from other processes to the same pipe (or FIFO). But if multiple processes are writing to a pipe (or FIFO), and if we write more than \nPIPE_BUF\n bytes, the data might be interleaved with the data from the other writers.\n\n\n\n\nWhat does \"interleaved\" mean here?\n\n\np548 on coprocess.\n\n\n\n\nThe Bourne shell, the Bourne-again shell, and the C shell don\u2019t provide a way to connect processes together as coprocesses.\n\n\n\n\nThe Bourne-again shell has no coprocess?\n\n\nSolution:\n\n\nCoprocess has been added to Bash 4.0 in 2009:\n\n\n\n\nStackoverflow", 
            "title": "Chapter 15. Interprocess Communication"
        }, 
        {
            "location": "/apue/ch16/", 
            "text": "Chapter 16. Network IPC: Sockets", 
            "title": "Chapter 16. Network IPC: Sockets"
        }, 
        {
            "location": "/apue/ch17/", 
            "text": "Chapter 17. Advanced IPC", 
            "title": "Chapter 17. Advanced IPC"
        }, 
        {
            "location": "/lkd/", 
            "text": "LKD\n\n\n\n\nChapter 1. Introduction to the Linux Kernel\n\n\nChapter 2. Getting Started with the Kernel\n\n\nChapter 3. Process Management\n\n\nChapter 4. Process Scheduling\n\n\nChapter 5. System Calls\n\n\nChapter 6. Kernel Data Structures\n\n\nChapter 7. Interrupts and Interrupt Handlers\n\n\nChapter 8. Bottom Halves and Deferring Work\n\n\nChapter 9. An Introduction to Kernel Synchronization\n\n\nChapter 10. Kernel Synchronization Methods\n\n\nChapter 11. Timers and Time Management\n\n\nChapter 12. Memory Management\n\n\nChapter 13. The Virtual Filesystem\n\n\nChapter 14. The Block I/O Layer\n\n\nChapter 15. The Process Address Space\n\n\nChapter 16. The Page Cache and Page Writeback", 
            "title": "Contents"
        }, 
        {
            "location": "/lkd/ch1/", 
            "text": "Chapter 1. Introduction to the Linux Kernel\n\n\nOverview of Operating Systems and Kernels\n\n\nIn Linux, we can generalize that each processor is doing exactly one of three things at any given moment:\n\n\n\n\nIn user-space, executing user code in a process\n\n\nIn kernel-space, in process context, executing on behalf of a specific process\n\n\nIn kernel-space, in interrupt context, not associated with a process, handling an interrupt\n\n\n\n\nLinux Versus Classic Unix Kernels\n\n\nNotable differences exist between the Linux kernel and classic Unix systems:\n\n\n\n\nLinux supports the dynamic loading of kernel modules.Although the Linux kernel is monolithic, it can dynamically load and unload kernel code on demand.\n\n\nLinux has symmetrical multiprocessor (SMP) support.\n\n\nThe Linux kernel is preemptive.\n\n\nLinux takes an interesting approach to thread support: It does not differentiate between threads and normal processes.To the kernel, all processes are the same (some just happen to share resources).\n\n\nLinux provides an object-oriented device model with device classes, hot-pluggable events, and a user-space device filesystem (sysfs).\n\n\nLinux ignores some common Unix features that the kernel developers consider poorly designed, such as STREAMS, or standards that are impossible to cleanly implement.\n\n\nLinux is free in every sense of the word\n\n\n\n\nLinux Kernel Versions\n\n\nLinux kernels come in two flavors: stable and development. \n\n\n\n\nThe Linux Kernel Development Community\n\n\nThe main forum for this community is the Linux Kernel Mailing List (oft-shortened to \nlkml\n). Subscription information is available at \nhttp://vger.kernel.org\n.", 
            "title": "Chapter 1. Introduction to the Linux Kernel"
        }, 
        {
            "location": "/lkd/ch2/", 
            "text": "Chapter 2. Getting Started with the Kernel\n\n\nObtaining the Kernel Source\n\n\nUsing Git\n\n\n$ \ngit clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git\n\n\n\n\n\nInstalling the Kernel Source\n\n\n$ \ntar xvjf linux-x.y.z.tar.bz2\n\n\n\n\n\nUsing Patches\n\n\nThroughout the Linux kernel community, patches are the \nlingua franca\n of communication. You will distribute your code changes in patches and receive code from others as patches. Incremental patches provide an easy way to move from one kernel tree to the next\n\n\n$ \npatch \u2013p1 \n ../patch-x.y.z\n\n\n\n\n\nThe Kernel Source Tree\n\n\n\n\n\n\n\n\nDirectory\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\narch\n\n\nArchitecture-specific source\n\n\n\n\n\n\nblock\n\n\nBlock I/O layer\n\n\n\n\n\n\ncrypto\n\n\nCrypto API\n\n\n\n\n\n\nDocumentation\n\n\nKernel source documentation\n\n\n\n\n\n\ndrivers\n\n\nDevice drivers\n\n\n\n\n\n\nfirmware\n\n\nDevice firmware needed to use certain drivers\n\n\n\n\n\n\nfs\n\n\nThe VFS and the individual filesystems\n\n\n\n\n\n\ninclude\n\n\nKernel headers\n\n\n\n\n\n\ninit\n\n\nKernel boot and initialization\n\n\n\n\n\n\nipc\n\n\nInterprocess communication code\n\n\n\n\n\n\nkernel\n\n\nCore subsystems, such as the scheduler\n\n\n\n\n\n\nlib\n\n\nHelper routines\n\n\n\n\n\n\nmm\n\n\nMemory management subsystem and the VM\n\n\n\n\n\n\nnet\n\n\nNetworking subsystem\n\n\n\n\n\n\nsamples\n\n\nSample, demonstrative code\n\n\n\n\n\n\nscripts\n\n\nScripts used to build the kernel\n\n\n\n\n\n\nsecurity\n\n\nLinux Security Module\n\n\n\n\n\n\nsound\n\n\nSound subsystem\n\n\n\n\n\n\nusr\n\n\nEarly user-space code (called initramfs)\n\n\n\n\n\n\ntools\n\n\nTools helpful for developing Linux\n\n\n\n\n\n\nvirt\n\n\nVirtualization infrastructure\n\n\n\n\n\n\n\n\nBuilding the Kernel\n\n\nConfiguring the Kernel\n\n\n$ \nmake config  \n# text-based\n\n\n$ \nmake menuconfig  \n# ncurses-based\n\n\n$ \nmake gconfig  \n# gtk+-based\n\n\n\n\n\n\nCreates a configuration based on the defaults for your architecture:\n\n\n$ \nmake defconfig\n\n\n\n\n\nAfter making changes to your configuration file, or when using an existing configuration\nfile on a new kernel tree, you can validate and update the configuration:\n\n\n$ \nmake oldconfig\n\n\n\n\n\nYou should always run this before building a kernel.\n\n\nAfter the kernel configuration is set, you can build it with a single command:\n\n\n$ \nmake\n\n\n\n\n\nSpawning Multiple Build Jobs\n\n\nTo build the kernel with multiple make jobs, use\n\n\n$ \nmake -jn\n\n\n\n\n\nHere, \nn\n is the number of jobs to spawn. \n\n\nInstalling the New Kernel\n\n\nHow it is installed is architecture- and boot loader-dependent.\n\n\nAs an example, on an x86 system using grub, you would copy \narch/i386/boot/bzImage\n to /boot, name it something like vmlinuz-\nversion\n, and edit \n/boot/grub/grub.conf\n, adding a new entry for the new kernel. \n\n\nInstalling modules is automated and architecture-independent. As root, run:\n\n\n% make modules_install\n\n\n\n\n\n\nA Beast of a Different Nature\n\n\n\n\nThe kernel has access to neither the C library nor the standard C headers.\n\n\nThe kernel is coded in GNU C.\n\n\nThe kernel lacks the memory protection afforded to user-space.\n\n\nThe kernel cannot easily execute floating-point operations.\n\n\nThe kernel has a small per-process fixed-size stack.\n\n\nBecause the kernel has asynchronous interrupts, is preemptive, and supports SMP, synchronization and concurrency are major concerns within the kernel.\n\n\nPortability is important.\n\n\n\n\nNo libc or Standard Headers\n\n\nUnlike a user-space application, the kernel is not linked against the standard C library. The primary reason is speed and size. The full C library\u2014or even a decent subset of it; it is too large and too inefficient for the kernel.\n\n\nMany of the usual libc functions are implemented inside the kernel. For example, the common string manipulation functions are in \nlib/string.c\n. Just include the header file \nlinux/string.h\n and have at them.\n\n\nA set of architecture-specific header files are located in \narch/\narchitecture\n/include/asm\n in the kernel source tree. For example, if compiling for the x86 architecture, your architecture-specific headers are in \narch/x86/include/asm\n. Source code includes these headers via just the \nasm/\n prefix, for example \nasm/ioctl.h\n.\n\n\nprintk()\n\n\nOf the missing functions, the most familiar is \nprintf(\n). The kernel does not have access to \nprintf()\n, but it does provide \nprintk()\n, which works pretty much the same as its more familiar cousin. The \nprintk()\n function copies the formatted string into the kernel log buffer, which is normally read by the syslog program. Usage is similar to \nprintf()\n:\n\n\nprintk\n(\nHello world! A string \n%s\n and an integer \n%d\n\\n\n,\n \nstr\n,\n \ni\n);\n\n\n\n\n\n\nOne notable difference is that \nprintk()\n enables you to specify a priority flag.This flag is used by syslogd to decide where to display kernel messages.\n\n\nprintk\n(\nKERN_ERR\n \nthis is an error!\n\\n\n);\n\n\n\n\n\n\nNote there is no comma between \nKERN_ERR\n and the printed message. The priority flag is a preprocessor-define representing a string literal, which is concatenated onto the printed message during compilation.\n\n\nGNU C\n\n\nThe kernel is not programmed in strict ANSI C. The kernel developers make use of various language extensions available in \ngcc\n. They use both ISO C991 and GNU C extensions to the C language. \n\n\nInline Functions\n\n\nBoth C99 and GNU C support \ninline functions\n. An inline function is inserted inline into each function call site. This eliminates the overhead of function invocation and return (register saving and restore) and allows for potentially greater optimization as the compiler can optimize both the caller and the called function as one. Kernel developers use inline functions for small time-critical functions.\n\n\nAn inline function is declared when the keywords \nstatic\n and inline are used as part of the function definition. For example\n\n\nstatic\n \ninline\n \nvoid\n \nwolf\n(\nunsigned\n \nlong\n \ntail_size\n)\n\n\n\n\n\n\nInline Assembly\n\n\nThe gcc C compiler enables the embedding of assembly instructions in otherwise normal C functions.\n\n\nunsigned\n \nint\n \nlow\n,\n \nhigh\n;\n\n\nasm\n \nvolatile\n(\nrdtsc\n \n:\n \n=a\n \n(\nlow\n),\n \n=d\n \n(\nhigh\n));\n\n\n/* low and high now contain the lower and upper 32-bits of the 64-bit tsc */\n\n\n\n\n\n\nBranch Annotation\n\n\nThe gcc C compiler has a built-in directive that optimizes conditional branches as either very likely taken or very unlikely taken. The kernel wraps the directive in easy-to-use macros, \nlikely()\n and \nunlikely()\n. \n\n\nNo Memory Protection\n\n\nWhen a user-space application attempts an illegal memory access, the kernel can trap the error, send the \nSIGSEGV\n signal, and kill the process. If the kernel attempts an illegal memory access, however, the results are less controlled. Memory violations in the kernel result in an \noops\n, which is a major kernel error. \n\n\nNo (Easy) Use of Floating Point\n\n\nWhen using floating-point instructions kernel normally catches a trap and then initiates the transition from integer to floating point mode. Unlike user-space, the kernel does not have the luxury of seamless support for floating point because it cannot easily trap itself. Using a floating point inside the kernel requires manually saving and restoring the floating point registers. Except in the rare cases, no floating-point operations are in the kernel.\n\n\nSmall, Fixed-Size Stack\n\n\nUser-space has a large stack that can dynamically grow. \n\n\nThe kernel stack is neither large nor dynamic; it is small and fixed in size. The exact size of the kernel\u2019s stack varies by architecture. On x86, the stack size is configurable at compile-time and can be either 4KB or 8KB.\n\n\nSynchronization and Concurrency\n\n\nA number of properties of the kernel allow for concurrent access of shared resources and thus require synchronization to prevent races.\n\n\n\n\nLinux is a preemptive multitasking operating system. Processes are scheduled and rescheduled at the whim of the kernel\u2019s process scheduler.The kernel must synchronize between these tasks.\n\n\nLinux supports symmetrical multiprocessing (SMP).Therefore, without proper protection, kernel code executing simultaneously on two or more processors can concurrently access the same resource.\n\n\nInterrupts occur asynchronously with respect to the currently executing code.  Therefore, without proper protection, an interrupt can occur in the midst of accessing a resource, and the interrupt handler can then access the same resource.\n\n\nThe Linux kernel is preemptive. Therefore, without protection, kernel code can be preempted in favor of different code that then accesses the same resource.\n\n\n\n\nTypical solutions to race conditions include spinlocks and semaphores.\n\n\nImportance of Portability\n\n\nLinux is a portable operating system and should remain one. This means that architecture-independent C code must correctly compile and run on a wide range of systems, and that architecturedependent code must be properly segregated in system-specific directories in the kernel source tree.", 
            "title": "Chapter 2. Getting Started with the Kernel"
        }, 
        {
            "location": "/lkd/ch3/", 
            "text": "Chapter 3. Process Management\n\n\nThis chapter introduces the concept of the \nprocess\n. The process management is a crucial part of any operating system kernel, including Linux.\n\n\nThe Process\n\n\nA process is a program (object code stored on some media) in the midst of execution.\n\n\nBesides the executing program code (\ntext section\n in Unix), processes also include a set of resources:\n\n\n\n\nOpen files\n\n\nPending signals\n\n\nInternal kernel data\n\n\nProcessor state\n\n\nMemory address space with one or more memory mappings\n\n\nThread(s) of execution\n\n\nData section containing global variables\n\n\n\n\nThreads of execution\n\n\nThreads of execution, often shortened to \nthreads\n,  are the objects of activity within the process.\n\n\nEach thread includes:\n\n\n\n\nProgram counter\n\n\nProcess stack\n\n\nSet of processor registers\n\n\n\n\nThe kernel schedules individual threads, not processes. \nLinux does not differentiate between threads and processes. To Linux, a thread is just a special kind of process.\n\n\nVirtualized processor and virtual memory\n\n\nOn modern operating systems, processes provide two virtualizations: a \nvirtualized processor\n and \nvirtual memory\n.\n\n\n\n\nThe virtual processor gives the process the illusion that it alone monopolizes the system, despite possibly sharing the processor among hundreds of other processes. See \nChapter 4. Process Scheduling\n.\n\n\nVirtual memory lets the process allocate and manage memory as if it alone owned all the memory in the system. See \nChapter 12. Memory Management\n\n\n\n\nThreads share the virtual memory abstraction\n, whereas each receives its own virtualized processor.\n\n\nLife of a process\n\n\nA process is an active program and related resources:\n\n\n\n\nTwo or more processes can exist that are executing the \nsame\n program.\n\n\nTwo or more processes can exist that share various resources, such as open files or an address space.\n\n\n\n\nfork, exec, exit and wait\n\n\nIn Linux, the \nfork()\n system call creates a new process by duplicating an existing one.\n\n\n\n\nThe process that calls \nfork()\n is the parent, whereas the new process is the child.\n\n\nThe parent resumes execution and the child starts execution at the same place: where the call to \nfork()\n returns.\n\n\nThe \nfork()\n system call \nreturns from the kernel twice: once in the parent process and again in the newborn child.\n\n\n\n\nThe \nexec()\n family of function calls creates a new address space and loads a new program into the newborn child immediately after a fork. In contemporary Linux kernels, \nfork()\n is actually implemented via the \nclone()\n system call\n, which is discussed in a following section.\n\n\nThe \nexit()\n system call terminates the process and frees all its resources. A parent process can inquire about the status of a terminated child via the \nwait4()\n system call. A process can wait for the termination of a specific process. \nWhen a process exits, it is placed into a special zombie state that represents terminated processes until the parent calls \nwait()\n or \nwaitpid()\n.\n The kernel implements the \nwait4()\n system call. Linux systems, via the C library, typically provide the \nwait()\n, \nwaitpid()\n, \nwait3()\n, and \nwait4()\n functions.\n\n\nProcess Descriptor and the Task Structure\n\n\nAnother name for a process is a \ntask\n. The Linux kernel internally refers to processes as tasks. In this book, the terms are used interchangeably, though \n\"task\" generally refers to a process from the kernel\u2019s point of view.\n\n\nThe kernel stores the list of processes in a circular doubly linked list called the \ntask list\n.\n\n\nA \nprocess descriptor\n of the type \nstruct task_struct\n (defined in \nlinux/sched.h\n) is an element in the task list. It contains all the information about a specific process.\n\n\nThe \ntask_struct\n is a relatively large data structure, at around 1.7 kilobytes on a 32-bit machine. The process descriptor contains the data that describes the executing program: open files, the process\u2019s address space, pending signals, the process\u2019s state, etc. See the figure below.\n\n\n\n\nAllocating the Process Descriptor\n\n\nThe \ntask_struct\n structure is allocated via the \nslab allocator\n to provide object reuse and cache coloring (see \nChapter 12\n). The structure \nstruct thread_info\n lives at the bottom of the stack (for stacks that grow down) and at the top of the stack (for stacks that grow up)\n\n\n\n\nErrata\n: \"struct thread_struct\" should read \"struct thread_info\"\n\n\nThe \nthread_info\n structure is defined on x86 in \nasm/thread_info.h\n (see below code). Each task\u2019s \nthread_info\n structure is allocated at the end of its stack.The task element of the structure is a pointer to the task\u2019s actual \ntask_struct\n:\n\n\n\n\narch/x86/include/asm/thread_info.h\n\n\n\n\nstruct\n \nthread_info\n \n{\n\n    \nstruct\n \ntask_struct\n \n*\ntask\n;\n\n    \nstruct\n \nexec_domain\n \n*\nexec_domain\n;\n\n    \n__u32\n \nflags\n;\n\n    \n__u32\n \nstatus\n;\n\n    \n__u32\n \ncpu\n;\n\n    \nint\n \npreempt_count\n;\n\n    \nmm_segment_t\n \naddr_limit\n;\n\n    \nstruct\n \nrestart_block\n \nrestart_block\n;\n\n    \nvoid\n \n*\nsysenter_return\n;\n\n    \nint\n \nuaccess_err\n;\n\n\n};\n\n\n\n\n\n\nStoring the Process Descriptor\n\n\nThe \nprocess identification\n (PID) is numerical value, represented by the \nopaque type\n \npid_t\n (typically \nint\n), for the system to identify processes. The default maximum value is only 32,768 (that of a \nshort int\n), although the value optionally can be increased as high as four million (this is controlled in \nlinux/threads.h\n). The kernel stores this value as \npid\n inside each process descriptor. [p26]\n\n\nLarge servers may require many more than 32,768 (maximum value) processes. \nThe lower the value, the sooner the values will wrap around, destroying the useful notion that higher values indicate later-run processes than lower values.\n The administrator may increase the maximum value via \n/proc/sys/kernel/pid_max\n.\n\n\nInside the kernel, tasks are typically referenced directly by a pointer to their \ntask_struct\n structure. In fact, most kernel code that deals with processes works directly with \nstruct task_struct\n. Consequently, it is useful to be able to quickly look up the process descriptor of the currently executing task, which is done via the \ncurrent\n macro. This macro must be independently implemented by each architecture:\n\n\n\n\nSome architectures save a pointer to the \ntask_struct\n structure of the currently running process in a register, enabling for efficient access.\n\n\nOther architectures, such as x86 (which has few registers to waste), make use of the fact that struct \nthread_info\n is stored on the kernel stack to calculate the location of \nthread_info\n and subsequently the \ntask_struct\n.\n\n\n\n\nThe \ncurrent_thread_info()\n function\n\n\nOn x86, \ncurrent\n is calculated by masking out the 13 least-significant bits of the stack pointer to obtain the \nthread_info\n structure. This is done by the \ncurrent_thread_info()\n function (\narch/x86/include/asm/thread_info.h#L184\n). The assembly is shown here:\n\n\nmovl\n \n$\n-\n8192\n,\n \n%\neax\n\n\nandl\n \n%\nesp\n,\n \n%\neax\n\n\n\n\n\n\nThis assumes that the stack size is 8KB. When 4KB stacks are enabled, 4096 is used in lieu of 8192.\n\n\ncurrent\n dereferences the task member of \nthread_info\n to return the \ntask_struct\n:\n\n\n\n\ninclude/asm-generic/current.h\n\n\n\n\ncurrent_thread_info\n()\n-\ntask\n;\n\n\n\n\n\n\nProcess State\n\n\nThe \nstate\n field of the process descriptor describes the current condition of the process.\n\n\n\n\nEach process on the system is in exactly one of five different states. This value is represented by one of five flags:\n\n\n\n\nTASK_RUNNING\n: The process is runnable; it is either currently running or on a runqueue waiting to run. This is the only possible state for a process executing in user-space; it can also apply to a process in kernel-space that is actively running.\n\n\nTASK_INTERRUPTIBLE\n: The process is sleeping (blocked), waiting for some condition to exist. The process also awakes prematurely and becomes runnable if it receives a signal.\n\n\nTASK_UNINTERRUPTIBLE\n: This state is identical to \nTASK_INTERRUPTIBLE\n except that it does not wake up and become runnable if it receives a signal. This is used in situations where the process must wait without interruption or when the event is expected to occur quite quickly. Because the task does not respond to signals in this state, \nTASK_UNINTERRUPTIBLE\n is less often used than \nTASK_INTERRUPTIBLE\n.\n\n\n__TASK_TRACED\n: The process is being traced by another process, such as a debugger, via \nptrace\n.\n\n\n__TASK_STOPPED\n: Process execution has stopped; the task is not running nor is it eligible to run. This occurs if the task receives the \nSIGSTOP\n, \nSIGTSTP\n, \nSIGTTIN\n, or \nSIGTTOU\n signal or if it receives any signal while it is being debugged.\n\n\n\n\nManipulating the Current Process State\n\n\nKernel code often needs to change a process\u2019s state. The preferred mechanism is using:\n\n\nset_task_state\n(\ntask\n,\n \nstate\n);\n \n/* set task \u2018task\u2019 to state \u2018state\u2019 */\n\n\n\n\n\n\nThis function sets the given task to the given state. If applicable, it also provides a memory barrier to force ordering on other processors (only needed on SMP systems). Otherwise, it is equivalent to:\n\n\ntask\n-\nstate\n \n=\n \nstate\n;\n\n\n\n\n\n\nThe method \nset_current_state(state)\n is synonymous to \nset_task_state(current, state)\n. See \nlinux/sched.h\n for the implementation of these and related functions.\n\n\n\n\ninclude/linux/sched.h#L226\n\n\n\n\nProcess Context\n\n\nThe program code is read in from an \nexecutable file\n and executed within the program\u2019s address space.\n\n\n\n\nUser-space\n: Normal program execution occurs in user-space.\n\n\nKernel-space\n: When a program executes a system call or triggers an exception, it enters kernel-space. At this point, the kernel is said to be \"executing on behalf of the process\" and is in \nprocess context\n. When in process context, the \ncurrent\n macro is valid.\n\n\nOther than process context there is \ninterrupt context\n (discussed in \nChapter 7\n. In interrupt context, the system is not running on behalf of a process but is executing an interrupt handler. No process is tied to interrupt handlers.\n\n\n\n\n\n\n\n\nUpon exiting the kernel, the process resumes execution in user-space, unless a higher-priority process has become runnable in the interim, in which case the scheduler is invoked to select the higher priority process.\n\n\nA process can begin executing in kernel-space only through one of the following well-defined interfaces:\n\n\n\n\nSystem calls\n\n\nException handlers\n\n\n\n\nThe Process Family Tree\n\n\nAll processes are descendants of the \ninit\n process (PID 1). The kernel starts init in the last step of the boot process. The init process reads the system \ninitscripts\n and executes more programs, eventually completing the boot process.\n\n\n\n\nEvery process on the system has exactly one \nparent\n.\n\n\nEvery process has zero or more \nchildren\n.\n\n\nProcesses that are all direct children of the same parent are called \nsiblings\n.\n\n\n\n\n\n\n[UTLK p87-88]\n\n\nThe pointers (\nnext\n and \nprev\n) in a \nlist_head\n field store the addresses of other \nlist_head\n fields rather than the addresses of the whole data structures in which the \nlist_head\n structure is included. See figure below:\n\n\n\n\n\n\ninclude/linux/list.h\n\n\n\n\n\n\nThe relationship between processes is stored in the process descriptor.\n\n\nEach \ntask_struct\n (\ninclude/linux/sched.h#L1170\n) has:\n\n\n\n\nparent\n: pointer to the parent's \ntask_struct\n\n\nchildren\n: list of children (\nstruct list_head\n)\n\n\n\n\nTo obtain the process descriptor of a given process's parent:\n\n\nstruct\n \ntask_struct\n \n*\nmy_parent\n \n=\n \ncurrent\n-\nparent\n;\n\n\n\n\n\n\nTo iterate over a process\u2019s children:\n\n\nstruct\n \ntask_struct\n \n*\ntask\n;\n\n\nstruct\n \nlist_head\n \n*\nlist\n;\n\n\n\nlist_for_each\n(\nlist\n,\n \ncurrent\n-\nchildren\n)\n \n{\n\n    \ntask\n \n=\n \nlist_entry\n(\nlist\n,\n \nstruct\n \ntask_struct\n,\n \nsibling\n);\n\n    \n/* task now points to one of current\u2019s children */\n\n\n}\n\n\n\n\n\n\n\n\nlist_for_each\n: \ninclude/linux/list.h#L367\n\n\n\n\nThe \ninit\n task\u2019s process descriptor is statically allocated as \ninit_task\n. The following code will always succeed:\n\n\nstruct\n \ntask_struct\n \n*\ntask\n;\n\n\n\nfor\n \n(\ntask\n \n=\n \ncurrent\n;\n \ntask\n \n!=\n \ninit_task\n;\n \ntask\n \n=\n \ntask\n-\nparent\n)\n\n\n;\n\n\n/* task now points to init */\n\n\n\n\n\n\nYou can follow the process hierarchy from any one process in the system to any other.  Oftentimes, it is desirable simply to iterate over all processes in the system. This is easy because the task list is a circular, doubly linked list.\n\n\nTo obtain the next task in the list, given any valid task, use:\n\n\nlist_entry\n(\ntask\n-\ntasks\n.\nnext\n,\n \nstruct\n \ntask_struct\n,\n \ntasks\n)\n\n\n\n\n\n\nTo obtain the previous task works the same way:\n\n\nlist_entry\n(\ntask\n-\ntasks\n.\nprev\n,\n \nstruct\n \ntask_struct\n,\n \ntasks\n)\n\n\n\n\n\n\n\n\nlist_entry\n: \ninclude/linux/list.h\n\n\n\n\nThese two routines are provided by the macros \nnext_task(task)\n and \nprev_task(task)\n. (See \nDoubts and Solutions\n)\n\n\nThe macro \nfor_each_process(task)\n iterates over the entire task list. On each iteration, task points to the next task in the list:\n\n\nstruct\n \ntask_struct\n \n*\ntask\n;\n\n\n\nfor_each_process\n(\ntask\n)\n \n{\n\n    \n/* this pointlessly prints the name and PID of each task */\n\n    \nprintk\n(\n%s[%d]\n\\n\n,\n \ntask\n-\ncomm\n,\n \ntask\n-\npid\n);\n\n\n}\n\n\n\n\n\n\n\n\nfor_each_process\n: \ninclude/linux/sched.h#L2139\n\n\n\n\nIt is expensive to iterate over every task in a system with many processes; code should have good reason (and no alternative) before doing so.\n\n\nProcess Creation\n\n\nMost operating systems implement a \nspawn\n mechanism to create a new process in a new address space, read in an executable, and begin executing it. Unix separates these steps into two distinct functions: \nfork()\n and \nexec()\n.\n\n\n\n\nfork()\n: creates a child process that is a copy of the current task. It differs from the parent only in its PID, its PPID (parent\u2019s PID), and certain resources and statistics (e.g. pending signals) which are not inherited.\n\n\nexec()\n: loads a new executable into the address space and begins executing it.\n\n\n\n\nCopy-on-Write\n\n\nIf upon \nfork()\n all resources owned by the parent are duplicated and the copy is given to the child, it is naive and inefficient in that it copies much data that might otherwise be shared. Worse still, if the new process were to immediately execute a new image, all that copying would go to waste.\n\n\nIn Linux, \nfork()\n is implemented through the use of copy-on-write pages.\n\n\nCopy-on-write\n (COW) can delay or prevent copying data. Rather than duplicating the process address space, the parent and the child can share a single copy.\n\n\n\n\nIf the data is written to, it is marked and a duplicate is made and each process receives a unique copy. The duplication of resources occurs only when they are written; until then, they are shared read-only.\n\n\nIn the case that the pages are never written (if \nexec()\n is called immediately after \nfork()\n), they never need to be copied.\n\n\n\n\nThe only overhead incurred by \nfork()\n is the duplication of the parent\u2019s page tables and the creation of a unique process descriptor for the child. In the common case that a process executes a new executable image immediately after forking, this optimization prevents the wasted copying of large amounts of data (with the address space, easily tens of megabytes). This is an important optimization because the Unix philosophy encourages quick process execution.\n\n\nForking\n\n\nLinux implements \nfork()\n via the \nclone()\n system call which takes a series of flags that specify which resources the parent and child process should share.\n\n\n\n\nThe \nfork()\n, \nvfork()\n, and \n__clone()\n library calls all invoke the \nclone()\n system call with the requisite flags.\n\n\nThe \nclone()\n system call calls \ndo_fork()\n.\n\n\n\n\nThe bulk of the work in forking is handled by \ndo_fork()\n, which is defined in \nkernel/fork.c\n. \ndo_fork()\n function calls \ncopy_process()\n and then starts the process running.\n\n\n\n\ndo_fork()\n: \nkernel/fork.c#L1354\n\n\ncopy_process()\n: \nkernel/fork.c#L957\n\n\n\n\nThe interesting work is done by \ncopy_process()\n:\n\n\n\n\nIt calls \ndup_task_struct()\n that creates following for the new process with identical values to those of the current task:\n\n\nKernel stack\n\n\nthread_info\n structure\n\n\ntask_struct\n\n\n(At this point, the child and parent process descriptors are identical)\n\n\n\n\n\n\nIt then checks that the new child will not exceed the resource limits on the number of processes for the current user.\n\n\nVarious members of the process descriptor are cleared or set to initial values, \nto differentiate the child from its parent.\n\n\nMembers of the process descriptor not inherited are primarily statistically information.\n\n\nThe bulk of the values in \ntask_struct\n remain unchanged.\n\n\n\n\n\n\nThe child\u2019s state is set to \nTASK_UNINTERRUPTIBLE\n to ensure that it does not yet run.\n\n\nIt calls \ncopy_flags()\n to update the flags member of the \ntask_struct\n (per process flags: \ninclude/linux/sched.h#L1693\n).\n\n\nThe \nPF_SUPERPRIV\n flag, which denotes whether a task used superuser privileges, is cleared\n\n\nThe \nPF_FORKNOEXEC\n flag, which denotes a process that has not called \nexec()\n, is set.\n\n\n\n\n\n\nIt calls \nalloc_pid()\n to assign an available PID to the new task.\n\n\nDepending on the flags passed to \nclone()\n, \ncopy_process()\n either duplicates or shares:\n\n\nOpen files\n\n\nFilesystem information\n\n\nSignal handlers\n\n\nProcess address space\n\n\nNamespace\n\n\n(These resources are typically shared between threads in a given process; otherwise they are unique and thus copied here)\n\n\n\n\n\n\nFinally, \ncopy_process()\n cleans up and returns to the caller \na pointer to the new child\n.\n\n\n\n\nBack in \ndo_fork()\n, if \ncopy_process()\n returns successfully, the new child is woken up and run.\n\n\nDeliberately, the kernel runs the child process first. In the case of the child calling \nexec()\n immediately, this eliminates any copy-on-write overhead that would occur if the parent ran first and began writing to the address space.\n\n\nvfork()\n\n\nThe \nvfork()\n system call has the same effect as \nfork()\n, except that the page table entries of the parent process are not copied. The child executes as the sole thread in the parent\u2019s address space, and the parent is blocked until the child either calls \nexec()\n or exits. The child is not allowed to write to the address space. [p33]\n\n\nToday, with copy-on-write and child-runs-first semantics, the only benefit to \nvfork()\n is not copying the parent page tables entries. [p33]\n\n\nThe \nvfork()\n system call is implemented via a special flag to the \nclone()\n system call:\n\n\n\n\nIn \ncopy_process()\n, the \ntask_struct\n member \nvfork_done\n is set to NULL.\n\n\nIn \ndo_fork()\n, if the special flag was given, \nvfork_done\n is pointed at a specific address.\n\n\nAfter the child is first run, the parent (instead of returning) waits for the child to signal it through the \nvfork_done\n pointer.\n\n\nIn the \nmm_release()\n function, which is used when a task exits a memory address space, \nvfork_done\n is checked to see whether it is NULL. If it is not, the parent is signaled.\n\n\nBack in \ndo_fork()\n, the parent wakes up and returns.\n\n\n\n\nIf this all goes as planned, the child is now executing in a new address space, and the parent is again executing in its original address space. The overhead is lower, but the implementation is not pretty.\n\n\nThe Linux Implementation of Threads\n\n\n\n\nThreads are a programming abstraction that provide multiple threads of execution within the same program in a shared memory address space.\n\n\nThreads can also share open files and other resources.\n\n\nThreads enable \nconcurrent programming\n and, on multiple processor systems, true \nparallelism\n.\n\n\n\n\nLinux has a unique implementation of threads:\n\n\n\n\nTo the Linux kernel, there is no concept of a thread. Linux implements all threads as standard processes.\n\n\nThe kernel does not provide any special scheduling semantics or data structures to represent threads. Instead, a thread is merely a process that shares certain resources with other processes.\n\n\nEach thread has a unique \ntask_struct\n and appears to the kernel as a normal process. Threads just happen to share resources, such as an address space, with other processes.\n\n\n\n\nThis approach to threads contrasts greatly with operating systems such as Microsoft Windows or Sun Solaris, which have explicit kernel support for threads (and sometimes call threads lightweight processes). [p34]\n\n\nCreating Threads\n\n\nThreads are created the same as normal tasks, with the exception that the \nclone()\n system call is passed flags corresponding to the specific resources to be shared:\n\n\nclone\n(\nCLONE_VM\n \n|\n \nCLONE_FS\n \n|\n \nCLONE_FILES\n \n|\n \nCLONE_SIGHAND\n,\n \n0\n);\n\n\n\n\n\n\nThe above code is identical to \nfork()\n except that the address space (\nCLONE_VM\n), filesystem resources (\nCLONE_FS\n), file descriptors (\nCLONE_FILES\n), and signal handlers (\nCLONE_SIGHAND\n) are shared.\n\n\nfork()\n can be implemented as:\n\n\nclone\n(\nSIGCHLD\n,\n \n0\n);\n\n\n\n\n\n\nvfork()\n is implemented as:\n\n\nclone\n(\nCLONE_VFORK\n \n|\n \nCLONE_VM\n \n|\n \nSIGCHLD\n,\n \n0\n);\n\n\n\n\n\n\nThe flags, which are defined in \nlinux/sched.h\n (\ninclude/linux/sched.h#L5\n),  to \nclone()\n specify the behavior of the new process and detail what resources the parent and child will share.\n\n\n\n\n\n\n\n\nFlag\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nCLONE_FILES\n\n\nParent and child share open files.\n\n\n\n\n\n\nCLONE_FS\n\n\nParent and child share filesystem information.\n\n\n\n\n\n\nCLONE_IDLETASK\n\n\nSet PID to zero (used only by the idle tasks).\n\n\n\n\n\n\nCLONE_NEWNS\n\n\nCreate a new namespace for the child.\n\n\n\n\n\n\nCLONE_PARENT\n\n\nChild is to have same parent as its parent.\n\n\n\n\n\n\nCLONE_PTRACE\n\n\nContinue tracing child.\n\n\n\n\n\n\nCLONE_SETTID\n\n\nWrite the TID back to user-space.\n\n\n\n\n\n\nCLONE_SETTLS\n\n\nCreate a new TLS (thread-local storage) for the child.\n\n\n\n\n\n\nCLONE_SIGHAND\n\n\nParent and child share signal handlers and blocked signals.\n\n\n\n\n\n\nCLONE_SYSVSEM\n\n\nParent and child share System V SEM_UNDO semantics.\n\n\n\n\n\n\nCLONE_THREAD\n\n\nParent and child are in the same thread group.\n\n\n\n\n\n\nCLONE_VFORK\n\n\nvfork() was used and the parent will sleep until the child wakes it.\n\n\n\n\n\n\nCLONE_UNTRACED\n\n\nDo not let the tracing process force CLONE_PTRACE on the child.\n\n\n\n\n\n\nCLONE_STOP\n\n\nStart process in the TASK_STOPPED state.\n\n\n\n\n\n\nCLONE_CHILD_CLEARTID\n\n\nClear the TID in the child.\n\n\n\n\n\n\nCLONE_CHILD_SETTID\n\n\nSet the TID in the child.\n\n\n\n\n\n\nCLONE_PARENT_SETTID\n\n\nSet the TID in the parent.\n\n\n\n\n\n\nCLONE_VM\n\n\nParent and child share address space.\n\n\n\n\n\n\n\n\nKernel Threads\n\n\nKernel threads\n are standard processes that exist solely in kernel-space. They are useful for the kernel to perform some operations in the background.\n\n\nDifference from normal threads:\n\n\n\n\nKernel threads do not have an address space. Their \nmm\n pointer, which points at their address space, is \nNULL\n.\n\n\nKernel threads operate only in kernel-space and do not context switch into user-space.\n\n\n\n\nSimilarity with normal threads:\n\n\n\n\nKernel threads are schedulable and preemptable.\n\n\n\n\nLinux delegates several tasks to kernel threads, most notably the \nflush\n tasks and the \nksoftirqd\n task. Use \nps -ef\n command to see them.\n\n\n\n\nKernel threads are created on system boot by other kernel threads.\n\n\nA kernel thread can be created only by another kernel thread. The kernel handles this automatically by forking all new kernel threads off of the \nkthreadd\n kernel process.\n\n\n\n\nThe interfaces of kernel threads defined in \nlinux/kthread.h\n (\ninclude/linux/kthread.h\n)\n\n\nkthread_create()\n spawns a new kernel thread from an existing one:\n\n\nstruct task_struct *kthread_create(int (*threadfn)(void *data),\n                                   void *data,\n                                   const char namefmt[],\n                                   ...)\n\n\n\n\n\nThe new task is created via the \nclone()\n system call by the \nkthread\n kernel process:\n\n\n\n\nThe new process will run the \nthreadfn\n function, which is passed the data argument.\n\n\nThe process will be named \nnamefmt\n, which takes printf-style formatting arguments in the variable argument list.\n\n\nThe process is created in an unrunnable state; it will not start running until explicitly woken up via \nwake_up_process()\n.\n\n\n\n\nA process can be created and made runnable with a single function, \nkthread_run()\n:\n\n\nstruct\n \ntask_struct\n \n*\nkthread_run\n(\nint\n \n(\n*\nthreadfn\n)(\nvoid\n \n*\ndata\n),\n\n                                \nvoid\n \n*\ndata\n,\n\n                                \nconst\n \nchar\n \nnamefmt\n[],\n\n                                \n...)\n\n\n\n\n\n\nThis routine (\nkthread_run()\n), implemented as a macro, simply calls both \nkthread_create()\n and \nwake_up_process()\n:\n\n\n#define kthread_run(threadfn, data, namefmt, ...)                 \\\n\n\n({                                                                \\\n\n\n    struct task_struct *k;                                        \\\n\n\n                                                                  \\\n\n\n    k = kthread_create(threadfn, data, namefmt, ## __VA_ARGS__);  \\\n\n\n    if (!IS_ERR(k))                                               \\\n\n\n        wake_up_process(k);                                       \\\n\n\n    k;                                                            \\\n\n\n})\n\n\n\n\n\n\nWhen started, a kernel thread continues to exist until it calls \ndo_exit()\n or another part of the kernel calls \nkthread_stop()\n, passing in the address of the \ntask_struct\n structure returned by \nkthread_create()\n:\n\n\nint\n \nkthread_stop\n(\nstruct\n \ntask_struct\n \n*\nk\n)\n\n\n\n\n\n\nProcess Termination\n\n\nWhen a process terminates, the kernel releases the resources owned by the process and notifies the child\u2019s parent of its demise.\n\n\nSelf-induced process termination occurs when the process calls the \nexit()\n system call, which is either:\n\n\n\n\nExplicitly: the process calls \nexit()\n system call.\n\n\nImplicitly: the process return from the main subroutine of any program. The C compiler places a call to \nexit()\n after \nmain()\n returns.\n\n\n\n\nInvoluntary process termination occurs when the process receives a signal or exception it cannot handle or ignore.\n\n\nRegardless of how a process terminates, the bulk of the work is handled by \ndo_exit()\n, defined in \nkernel/exit.c\n (\nkernel/exit.c#L900\n), which does the following:\n\n\n\n\nIt sets the \nPF_EXITING\n flag in the flags member of the \ntask_struct\n.\n\n\nIt calls \ndel_timer_sync()\n to remove any kernel timers. Upon return, it is guaranteed that no timer is queued and that no timer handler is running.\n\n\nIf BSD process accounting is enabled, \ndo_exit()\n calls \nacct_update_integrals()\n to write out accounting information.\n\n\nIt calls \nexit_mm()\n to release the \nmm_struct\n held by this process. If no other process is using this address space (if the address space is not shared) the kernel then destroys it.\n\n\nIt calls \nexit_sem()\n. If the process is queued waiting for an IPC semaphore, it is dequeued here.\n\n\nIt then calls \nexit_files()\n and \nexit_fs()\n to decrement the usage count of objects related to file descriptors and filesystem data, respectively.\n\n\nIt sets the task\u2019s exit code (stored in the \nexit_code\n member of the \ntask_struct\n) to that provided by \nexit()\n or whatever kernel mechanism forced the termination. \nThe exit code is stored here for optional retrieval by the parent.\n\n\nIt send signals and reparents children:\n\n\nCalls \nexit_notify()\n to send signals to the task\u2019s parent\n\n\nReparents any of the task\u2019s children to another thread in their thread group or the init process\n\n\nSets the task\u2019s exit state (stored in \nexit_state\n in the \ntask_struct\n structure) to \nEXIT_ZOMBIE\n.\n\n\n\n\n\n\nIt calls \nschedule()\n to switch to a new process.\n\n\nBecause the process is now not schedulable, this is the last code the task will ever execute. \ndo_exit()\n never returns.\n\n\n\n\n\n\n\n\nAt this point:\n\n\n\n\nAll objects associated with the task (assuming the task was the sole user) are freed.\n\n\nThe task is not runnable (and no longer has an address space in which to run) and is in the \nEXIT_ZOMBIE\n exit state.\n\n\nThe only memory it occupies is its kernel stack, the \nthread_info\n structure, and the \ntask_struct\n structure.\n\n\nThe task exists solely to provide information to its parent. After the parent retrieves the information, or notifies the kernel that it is uninterested, the remaining memory held by the process is freed and returned to the system for use.\n\n\n\n\nRemoving the Process Descriptor\n\n\nAfter \ndo_exit()\n completes, the process descriptor for the terminated process still exists, but the process is a zombie and is unable to run.\n\n\nCleaning up after a process and removing its process descriptor are separate steps. This enables the system to obtain information about a child process after it has terminated.\n\n\nThe terminated child\u2019s \ntask_struct\n is deallocated after any of the following:\n\n\n\n\nThe parent has obtained information on its terminated child.\n\n\nThe parent has signified to the kernel that it does not care (about the terminated child).\n\n\n\n\nThe \nwait()\n family of functions are implemented via a system call \nwait4()\n.\n\n\nThe standard behavior is to suspend execution of the calling task until one of its children exits, at which time the function returns with the PID of the exited child. On return, a pointer (as an argument to a \nwait()\n function) holds the exit code of the terminated child. [p38]\n\n\nrelease_task()\n is invoked to finally deallocate the process descriptor:\n\n\n\n\nIt calls \n__exit_signal()\n, which calls \n__unhash_process()\n, which in turns calls detach_pid() to remove the process from the pidhash and remove the process from the task list.\n\n\n__exit_signal()\n releases any remaining resources used by the now dead process and finalizes statistics and bookkeeping.\n\n\nIf the task was the last member of a thread group, and the leader is a zombie, then \nrelease_task()\n notifies the zombie leader\u2019s parent.\n\n\nrelease_task()\n calls \nput_task_struct()\n to free the pages containing the process\u2019s kernel stack and \nthread_info\n structure and deallocate the slab cache containing the \ntask_struct\n.\n\n\n\n\nAt this point, the process descriptor and all resources belonging solely to the process have been freed.\n\n\nThe Dilemma of the Parentless Task\n\n\nIf a parent exits before its children, any of its child tasks must be reparented to a new process, otherwise parentless terminated processes would forever remain zombies, wasting system memory.\n\n\nThe solution is to reparent a task\u2019s children on exit to another process in the current thread group, or (if that fails) the init process.\n\n\ndo_exit()\n calls \nexit_notify()\n, which calls \nforget_original_parent()\n, which calls \nfind_new_reaper()\n to perform the reparenting:\n\n\nstatic\n \nstruct\n \ntask_struct\n \n*\nfind_new_reaper\n(\nstruct\n \ntask_struct\n \n*\nfather\n)\n\n\n{\n\n    \nstruct\n \npid_namespace\n \n*\npid_ns\n \n=\n \ntask_active_pid_ns\n(\nfather\n);\n\n    \nstruct\n \ntask_struct\n \n*\nthread\n;\n\n\n    \nthread\n \n=\n \nfather\n;\n\n    \nwhile_each_thread\n(\nfather\n,\n \nthread\n)\n \n{\n\n      \nif\n \n(\nthread\n-\nflags\n \n \nPF_EXITING\n)\n\n          \ncontinue\n;\n\n      \nif\n \n(\nunlikely\n(\npid_ns\n-\nchild_reaper\n \n==\n \nfather\n))\n\n          \npid_ns\n-\nchild_reaper\n \n=\n \nthread\n;\n\n      \nreturn\n \nthread\n;\n\n    \n}\n\n\n    \nif\n \n(\nunlikely\n(\npid_ns\n-\nchild_reaper\n \n==\n \nfather\n))\n \n{\n\n        \nwrite_unlock_irq\n(\ntasklist_lock\n);\n\n        \nif\n \n(\nunlikely\n(\npid_ns\n \n==\n \ninit_pid_ns\n))\n\n        \npanic\n(\nAttempted to kill init!\n);\n\n\n        \nzap_pid_ns_processes\n(\npid_ns\n);\n\n        \nwrite_lock_irq\n(\ntasklist_lock\n);\n\n\n        \n/*\n\n\n        * We can not clear -\nchild_reaper or leave it alone.\n\n\n        * There may by stealth EXIT_DEAD tasks on -\nchildren,\n\n\n        * forget_original_parent() must move them somewhere.\n\n\n        */\n\n        \npid_ns\n-\nchild_reaper\n \n=\n \ninit_pid_ns\n.\nchild_reaper\n;\n\n    \n}\n\n\n    \nreturn\n \npid_ns\n-\nchild_reaper\n;\n\n\n}\n\n\n\n\n\n\nThe above code attempts to find and return another task in the process\u2019s thread group. If another task is not in the thread group, it finds and returns the \ninit\n process.\n\n\nAfter a suitable new parent for the children is found, each child needs to be located and reparented to \nreaper\n:\n\n\nreaper\n \n=\n \nfind_new_reaper\n(\nfather\n);\n\n\nlist_for_each_entry_safe\n(\np\n,\n \nn\n,\n \nfather\n-\nchildren\n,\n \nsibling\n)\n \n{\n\n    \np\n-\nreal_parent\n \n=\n \nreaper\n;\n\n    \nif\n \n(\np\n-\nparent\n \n==\n \nfather\n)\n \n{\n\n        \nBUG_ON\n(\np\n-\nptrace\n);\n\n        \np\n-\nparent\n \n=\n \np\n-\nreal_parent\n;\n\n    \n}\n\n    \nreparent_thread\n(\np\n,\n \nfather\n);\n\n\n}\n\n\n\n\n\n\nptrace_exit_finish()\n is then called to do the same reparenting but to a list of \nptraced\n children:\n\n\nvoid\n \nexit_ptrace\n(\nstruct\n \ntask_struct\n \n*\ntracer\n)\n\n\n{\n\n    \nstruct\n \ntask_struct\n \n*\np\n,\n \n*\nn\n;\n\n    \nLIST_HEAD\n(\nptrace_dead\n);\n\n\n    \nwrite_lock_irq\n(\ntasklist_lock\n);\n\n    \nlist_for_each_entry_safe\n(\np\n,\n \nn\n,\n \ntracer\n-\nptraced\n,\n \nptrace_entry\n)\n \n{\n\n        \nif\n \n(\n__ptrace_detach\n(\ntracer\n,\n \np\n))\n\n        \nlist_add\n(\np\n-\nptrace_entry\n,\n \nptrace_dead\n);\n\n    \n}\n\n    \nwrite_unlock_irq\n(\ntasklist_lock\n);\n\n\n    \nBUG_ON\n(\n!\nlist_empty\n(\ntracer\n-\nptraced\n));\n\n\n    \nlist_for_each_entry_safe\n(\np\n,\n \nn\n,\n \nptrace_dead\n,\n \nptrace_entry\n)\n \n{\n\n    \nlist_del_init\n(\np\n-\nptrace_entry\n);\n\n    \nrelease_task\n(\np\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWhen a task is \nptraced\n, it is temporarily reparented to the debugging process. When the task\u2019s parent exits, however, it must be reparented along with its other siblings. In previous kernels, this resulted in a loop over every process in the system looking for children. The solution is simply to keep a separate list of a process\u2019s children being ptraced, reducing the search for one\u2019s children from every process to just two relatively small lists\n\n\nAfter the process are successfully reparented, there is no risk of stray zombie processes. The \ninit\n process routinely calls \nwait()\n on its children, cleaning up any zombies assigned to it.\n\n\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\n\n\nThese two routines are provided by the macros \nnext_task(task)\n and \nprev_task(task)\n, respectively.\n\n\n\n\nI didn't find any relevant appearance for \nprev_task\n macro in the \nLinux 2.6.34.7 source code\n.", 
            "title": "Chapter 3. Process Management"
        }, 
        {
            "location": "/lkd/ch4/", 
            "text": "Chapter 4. Process Scheduling\n\n\nThis chapter discusses the \nprocess scheduler\n, the kernel subsystem that puts those processes to work.\n\n\nThe process scheduler (or simply the scheduler) divides the finite resource of processor time between the runnable processes on a system. It is responsible for best utilizing the system and giving users the impression that multiple processes are executing simultaneously. [p41]\n\n\nTo best utilize processor time, assuming there are runnable processes, a process should always be running. If there are more \nrunnable\n processes than processors in a system, some processes will not be running at a given moment. These processes are \nwaiting to run\n. Deciding which process runs next, given a set of runnable processes, is the fundamental decision that the scheduler must make.\n\n\nMultitasking\n\n\nA \nmultitasking\n operating system is one that can simultaneously interleave execution of more than one process.\n\n\n\n\nOn single processor machines, this gives the illusion of multiple processes running concurrently.\n\n\nOn multiprocessor machines, this enables processes to actually run concurrently, in parallel, on different processors.\n\n\n\n\nOn either type of machine, it also enables many processes to \nblock\n or \nsleep\n. Although these processes are in memory, they are not \nrunnable\n. These processes utilize the kernel to wait until some event (keyboard input, network data, passage of time, and so on) occurs. [p41]\n\n\nMultitasking operating systems come in two flavors:\n\n\n\n\nCooperative multitasking\n\n\nPreemptive multitasking\n\n\n\n\nPreemptive multitasking\n\n\nLinux, like all Unix variants and most modern operating systems, implements preemptive multitasking. In preemptive multitasking, the scheduler decides\nwhen a process is to cease running and a new process is to begin running.\n\n\n\n\nPreemption\n: the act of involuntarily suspending a running process.\n\n\nTimeslice\n of a process: the time the process runs before it is preempted is usually predetermined.\n\n\nManaging the timeslice enables the scheduler to make global scheduling decisions for the system and prevents any one process from monopolizing the processor.\n\n\nOn many modern operating systems, the timeslice is dynamically calculated as a function of process behavior and configurable system policy.\n\n\nLinux\u2019s unique \"fair\" scheduler does not employ timeslices \nper se\n, to interesting effect.\n\n\n\n\n\n\n\n\nCooperative multitasking\n\n\nIn cooperative multitasking, a process does not stop running until it voluntarily decides to do so. The act of a process voluntarily suspending itself is called \nyielding\n, but the operating system cannot enforce this.\n\n\nThe shortcomings of this approach are manifest:\n\n\n\n\nThe scheduler cannot make global decisions regarding how long processes run;\n\n\nProcesses can monopolize the processor for longer than the user desires;\n\n\nA hung process that never yields can potentially bring down the entire system.\n\n\n\n\n[p42]\n\n\nLinux\u2019s Process Scheduler\n\n\nFrom Linux\u2019s first version in 1991 through the 2.4 kernel series, the Linux scheduler was simple in design. It was easy to understand, but scaled poorly in light of many runnable processes or many processors.\n\n\nDuring the 2.5 kernel development series, the \nO(1) scheduler\n solved the shortcomings of the previous Linux scheduler and introduced powerful new features and performance characteristics. By introducing a constant-time algorithm for timeslice calculation and per-processor runqueues, it rectified the design limitations of the earlier scheduler.\n\n\nHowever, the O(1) scheduler had several pathological failures related to scheduling latency-sensitive applications (interactive processes). Thus, although the O(1) scheduler was ideal for large server workloads, which lack interactive processes, it performed below par on desktop systems, where interactive applications are the \nraison d\u2019\u00eatre\n.\n\n\nBeginning in the 2.6 kernel series, developers introduced new process schedulers aimed at improving the interactive performance of the O(1) scheduler. The most notable of these was the \nRotating Staircase Deadline\n scheduler, which introduced the concept of \nfair scheduling\n, borrowed from queuing theory, to Linux\u2019s process scheduler. This concept was the inspiration for the O(1) scheduler\u2019s eventual replacement in kernel version 2.6.23, the \nCompletely Fair Scheduler\n (CFS).\n\n\nThis chapter discusses the fundamentals of scheduler design and how they apply to the Completely Fair Scheduler and its goals, design, implementation, algorithms, and related system calls. We also discuss the O(1) scheduler because its implementation is a more \"classic\" Unix process scheduler model.\n\n\nPolicy\n\n\nPolicy is the behavior of the scheduler that determines what runs when.\n\n\nI/O-Bound Versus Processor-Bound Processes\n\n\nProcesses can be classified as either \nI/O-bound\n or \nprocessor-bound\n.\n\n\n\n\nAn \nI/O-bound process\n spends much of its time submitting and waiting on I/O requests. Such a process is runnable for only short durations, because it eventually blocks waiting on more I/O.\n\n\n\"I/O\" means any type of blockable resource, such as keyboard input or network I/O, and not just disk I/O. Most graphical user interface (GUI) applications are I/O-bound, even if they never read from or write to the disk, because they spend most of their time waiting on user interaction via the keyboard and mouse.\n\n\n\n\n\n\nProcessor-bound processes\n spend much of their time executing code. Thet tend to run until they are preempted because they do not block on I/O requests very often. System response does not dictate that the scheduler run them often. A scheduler policy for processor-bound processes tends to run such processes less frequently but for longer durations.\n\n\nExamples of processor-bound processes include: a program executing an infinite loop, \nssh-keygen\n, \nMATLAB\n.\n\n\n\n\n\n\n\n\nThese classifications are not mutually exclusive. Processes can exhibit both behaviors simultaneously:\n\n\n\n\nThe X Window server is both processor and I/O intense.\n\n\nA word processor can be I/O-bound but dive into periods of intense processor action.\n\n\n\n\nThe scheduling policy in a system must attempt to satisfy two conflicting goals:\n\n\n\n\nFast process response time (low latency)\n\n\nMaximal system utilization (high throughput)\n\n\n\n\nFavoring I/O-bound over processor-bound\n\n\nSchedulers often employ complex algorithms to determine the most worthwhile process to run while not compromising fairness to other processes with lower priority. [p43-44]\n\n\n\n\nThe scheduler policy in Unix systems tends to explicitly favor I/O-bound processes, thus providing good process response time.\n\n\nLinux, aiming to provide good interactive response and desktop performance, optimizes for process response (low latency), thus favoring I/O-bound processes over processor-bound processes. This is done in a creative manner that does not neglect processor-bound processes.\n\n\n\n\nProcess Priority\n\n\nThe \npriority-based\n scheduling is a common type of scheduling algorithm, which isn\u2019t exactly implemented on Linux. It means that processes with a higher priority run before those with a lower priority, whereas processes with the same priority are scheduled \nround-robin\n (one after the next, repeating). On some systems, processes with a higher priority also receive a longer timeslice. The runnable process with timeslice remaining and the highest priority always runs. [p44]\n\n\nnice value and real-time priority\n\n\nThe Linux kernel implements two separate priority ranges:\n\n\n\n\nnice value\n (a number from \u201320 to +19 with a default of 0) is the standard priority range used in all Unix systems:\n\n\nProcesses with a lower nice value (higher priority) receive a larger proportion of the system\u2019s processor, and vice versa.\n\n\nIn Linux, the nice value is a control over the \nproportion\n of timeslice. In other Unix-based systems, such as Mac OS X, the nice value is a control over the \nabsolute\n timeslice allotted to a process;\n\n\nThe \nps -el\n command lists processes with their nice values.\n\n\n\n\n\n\nReal-time priority\n (configurable values that by default range from 0 to 99)\n\n\nHigher real-time priority values correspond to a greater priority.\n\n\nAll real-time processes are at a higher priority than normal processes.\n\n\nLinux implements real-time priorities in accordance with the relevant Unix standards, specifically POSIX.1b.\n\n\nThe \nps -eo state,uid,pid,ppid,rtprio,time,comm\n command lists processes and their real-time priority. A value of \u201c-\u201d means the process is not real-time.\n\n\n\n\n\n\n\n\nTimeslice\n\n\nThe \ntimeslice\n is the numeric value that represents how long a task can run until it is preempted.\n\n\n\n\nToo long a timeslice causes the system to have poor interactive performance.\n\n\nToo short a timeslice causes significant amounts of processor time to be wasted on the overhead of switching processes.\n\n\n\n\nThe conflicting goals of I/O bound versus processor-bound processes:\n\n\n\n\nI/O-bound processes do not need longer timeslices (although they do like to run often)\n\n\nProcessor-bound processes crave long timeslices (to keep their caches hot).\n\n\n\n\nTimeslice on Linux\n\n\nLinux\u2019s CFS scheduler does not directly assign timeslices to processes, but assigns processes a \nproportion\n of the processor. The amount of processor time that a process receives is a function of the load of the system. This assigned proportion is further affected by each process\u2019s nice value. The nice value acts as a weight, changing the proportion of the processor time each process receives. Processes with higher nice values (a lower priority) receive a deflationary weight, yielding them a smaller proportion of the processor, and vice versa.\n\n\nWith the CFS scheduler, whether the process runs immediately (preempting the currently running process) is a function of how much of a proportion of the processor the newly runnable processor has consumed. If it has consumed a smaller proportion of the processor than the currently executing process, it runs immediately\n\n\nThe Scheduling Policy in Action\n\n\nConsider a system with two runnable tasks: a text editor (I/O-bound) and a video encoder (processor-bound). [p45-46]\n\n\nIdeally, the scheduler gives the text editor a larger proportion of the available processor than the video encoder, because the text editor is interactive. We have two goals for the text editor:\n\n\n\n\nWe want the text editor to have a large amount of processor time available to it; not because it needs a lot of processor (it does not) but because we want it to always have processor time available the moment it needs it.\n\n\nWe want the text editor to preempt the video encoder the moment it wakes up (say, when the user presses a key). This can ensure the text editor has good \ninteractive performance\n and is responsive to user input.\n\n\n\n\nHow the above two goals achieved\n\n\n\n\nInstead of assigning the text editor a specific priority and timeslice, the Linux guarantees the text editor a specific proportion of the processor. If the two are the only processes with same nice values, each would be guaranteed half of the processor\u2019s time (the proportion is 50%). Because the text editor spends most of its time blocked, waiting for user key presses, it does not use anywhere near 50% of the processor. Conversely, the video encoder is free to use more than its allotted 50%, enabling it to finish the encoding quickly.\n\n\nWhen the editor wakes up, CFS notes that it is allotted 50% of the processor but has used considerably less, and thus determines that the text editor has run for \nless time\n than the video encoder. Attempting to give all processes a fair share of the processor, it then preempts the video encoder and enables the text editor to run. [p46]\n\n\n\n\nThe Linux Scheduling Algorithm\n\n\nScheduler Classes\n\n\nThe Linux scheduler is modular, enabling different algorithms to schedule different types of processes.This modularity is called \nscheduler classes\n. The base scheduler code, which is defined in \nkernel/sched.c\n, iterates over each scheduler class in order of priority.The highest priority scheduler class that has a runnable process wins, selecting who runs next.\n\n\nThe Completely Fair Scheduler (CFS) is the registered scheduler class for normal processes, called \nSCHED_NORMAL\n in Linux (and \nSCHED_OTHER\n in POSIX).  CFS is defined in \nkernel/sched_fair.c\n. The rest of this section discusses the CFS algorithm.\n\n\nProcess Scheduling in Unix Systems\n\n\nTo discuss fair scheduling, we must first describe how traditional Unix systems schedule processes.\n\n\nModern process schedulers have two common concepts: process priority and timeslice. Processes with a higher priority run more frequently and (on many systems) receive a higher timeslice. On Unix, the priority is exported to user-space in the form of nice values. This in practice leads to several problems:\n\n\n\n\nMapping nice values onto timeslices requires a decision about what absolute timeslice to allot each nice value, which leads to suboptimal switching behavior. [p47]\n\n\nNicing (down) a process by a relative nice value has wildly different effects depending on the starting nice value. [p47-48]\n\n\nAbsolute timeslice timeslice must be some integer multiple of the timer tick, which introduces several problems. [p48]\n\n\nHandling process wake up in a priority-based scheduler that wants to optimize for interactive tasks may cause the scheduler providing one process an unfair amount of processor time, at the expense of the rest of the system. [p48]\n\n\n\n\nThe approach taken by CFS is a radical (for process schedulers) rethinking of timeslice allotment: Do away with timeslices completely and assign each process a proportion of the processor. CFS thus yields constant fairness but a variable switching rate.\n\n\nFair Scheduling\n\n\nCFS is based on a simple concept: Model process scheduling as if the system had an ideal, perfectly multitasking processor. In such a system, each process would receive 1/\nn\n of the processor\u2019s time, where \nn\n is the number of runnable processes, and we\u2019d schedule them for infinitely small durations, so that in any measurable period we\u2019d have run all \nn\n processes for the same amount of time. [p48]\n\n\nIt is not efficient to run processes for infinitely small durations; there is a switching cost to preempting one process for another: the overhead of swapping one process for another and the effects on caches. CFS will run each process for some amount of time, round-robin, selecting next the process that has run the least. Rather than assign each process a timeslice, CFS calculates how long a process should run as a function of the total number of runnable processes. Instead of using the nice value to calculate a timeslice, CFS uses the nice value to weight the proportion of processor a process is to receive. [p49]\n\n\nEach process runs for a \"timeslice\" proportional to its weight divided by the total weight of all runnable threads.\n CFS sets a target for its\napproximation of the \"infinitely small\" scheduling duration in perfect multitasking. This target is called the \ntargeted latency\n. Smaller targets yield better interactivity and a closer approximation to perfect multitasking, at the expense of higher switching costs and thus worse overall throughput.  CFS imposes a floor on the timeslice assigned to each process, called the \nminimum granularity\n (by default 1 millisecond). Even as the number of runnable processes approaches infinity, each will run for at least 1 millisecond, to ensure there is a ceiling on the incurred switching costs\n\n\nFor the nice value on weighting the proportion, consider the case of two runnable processes with disimilar nice values. One with the default nice value (zero) and one with a nice value of 5. In this case, the weights work out to about a 1\u20443 penalty for the nice-5 process. If our target latency is again 20 milliseconds, our two processes will receive 15 milliseconds and 5 milliseconds each of processor time, respectively. Put generally, the proportion of processor time that any process receives is determined only by the relative difference in niceness between it and the other runnable processes.  The nice values, instead of yielding additive increases to timeslices, yield geometric differences. [p49-50]\n\n\nThe Linux Scheduling Implementation\n\n\nCFS\u2019s actual implementation lives in \nkernel/sched_fair.c\n. Specifically,\nthis sections discusses four components of CFS:\n\n\n\n\nTime Accounting\n\n\nProcess Selection\n\n\nThe Scheduler Entry Point\n\n\nSleeping and Waking Up\n\n\n\n\nTime Accounting\n\n\nAll process schedulers must account for the time that a process runs. On each tick of the system clock, the timeslice is decremented by the tick period.When the timeslice reaches zero, the process is preempted in favor of another runnable process with a nonzero timeslice.\n\n\nThe Scheduler Entity Structure\n\n\nCFS does not have the notion of a timeslice, but it must still keep account for the time that each process runs. [p50]\n\n\nCFS uses the \nscheduler entity structure\n, \nstruct sched_entity\n, defined in \nlinux/sched.h\n (\ninclude/linux/sched.h#L1090\n), to keep track of process accounting:\n\n\nstruct\n \nsched_entity\n \n{\n\n    \nstruct\n \nload_weight\n \nload\n;\n\n    \nstruct\n \nrb_node\n \nrun_node\n;\n\n    \nstruct\n \nlist_head\n \ngroup_node\n;\n\n    \nunsigned\n \nint\n \non_rq\n;\n\n    \nu64\n \nexec_start\n;\n\n    \nu64\n \nsum_exec_runtime\n;\n\n    \nu64\n \nvruntime\n;\n\n    \nu64\n \nprev_sum_exec_runtime\n;\n\n    \nu64\n \nlast_wakeup\n;\n\n    \nu64\n \navg_overlap\n;\n\n    \nu64\n \nnr_migrations\n;\n\n    \nu64\n \nstart_runtime\n;\n\n    \nu64\n \navg_wakeup\n;\n\n\n\n/* many stat variables elided, enabled only if CONFIG_SCHEDSTATS is set */\n\n\n};\n\n\n\n\n\n\nThe scheduler entity structure is embedded in the process descriptor, \nstruct task_stuct\n, as a member variable named \nse\n (\ninclude/linux/sched.h#L1188\n).\n\n\nMapping of nice value to weight\n *\n\n\nThe mapping of nice to weight is defined in the \nprio_to_weight\n constant array (\nkernel/sched.c#L1362\n). The weight is roughly equivalent to \n1024/(1.25)^(nice)\n.\n\n\nstatic\n \nconst\n \nint\n \nprio_to_weight\n[\n40\n]\n \n=\n \n{\n\n \n/* -20 */\n     \n88761\n,\n     \n71755\n,\n     \n56483\n,\n     \n46273\n,\n     \n36291\n,\n\n \n/* -15 */\n     \n29154\n,\n     \n23254\n,\n     \n18705\n,\n     \n14949\n,\n     \n11916\n,\n\n \n/* -10 */\n      \n9548\n,\n      \n7620\n,\n      \n6100\n,\n      \n4904\n,\n      \n3906\n,\n\n \n/*  -5 */\n      \n3121\n,\n      \n2501\n,\n      \n1991\n,\n      \n1586\n,\n      \n1277\n,\n\n \n/*   0 */\n      \n1024\n,\n       \n820\n,\n       \n655\n,\n       \n526\n,\n       \n423\n,\n\n \n/*   5 */\n       \n335\n,\n       \n272\n,\n       \n215\n,\n       \n172\n,\n       \n137\n,\n\n \n/*  10 */\n       \n110\n,\n        \n87\n,\n        \n70\n,\n        \n56\n,\n        \n45\n,\n\n \n/*  15 */\n        \n36\n,\n        \n29\n,\n        \n23\n,\n        \n18\n,\n        \n15\n,\n\n\n};\n\n\n\n\n\n\nThe Virtual Runtime\n\n\nThe \nvruntime\n variable stores the \nvirtual runtime\n of a process, which is the actual runtime (the amount of time spent running) normalized (or weighted) by the number of runnable processes. The virtual runtime\u2019s units are nanoseconds and therefore \nvruntime\n is decoupled from the timer tick. Because processors are not capable of perfect multitasking and we must run each process in succession, CFS uses vruntime to account for how long a process has run and thus how much longer it ought to run.\n\n\nThe function \nupdate_curr()\n, defined in \nkernel/sched_fair.c\n (\nkernel/sched_fair.c#L518\n), manages this accounting:\n\n\nstatic\n \nvoid\n \nupdate_curr\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n)\n\n\n{\n\n    \nstruct\n \nsched_entity\n \n*\ncurr\n \n=\n \ncfs_rq\n-\ncurr\n;\n\n    \nu64\n \nnow\n \n=\n \nrq_of\n(\ncfs_rq\n)\n-\nclock\n;\n\n    \nunsigned\n \nlong\n \ndelta_exec\n;\n\n\n    \nif\n \n(\nunlikely\n(\n!\ncurr\n))\n\n        \nreturn\n;\n\n\n    \n/*\n\n\n     * Get the amount of time the current task was running\n\n\n     * since the last time we changed load (this cannot\n\n\n     * overflow on 32 bits):\n\n\n     */\n\n    \ndelta_exec\n \n=\n \n(\nunsigned\n \nlong\n)(\nnow\n \n-\n \ncurr\n-\nexec_start\n);\n\n    \nif\n \n(\n!\ndelta_exec\n)\n\n        \nreturn\n;\n\n\n    \n__update_curr\n(\ncfs_rq\n,\n \ncurr\n,\n \ndelta_exec\n);\n\n    \ncurr\n-\nexec_start\n \n=\n \nnow\n;\n\n\n    \nif\n \n(\nentity_is_task\n(\ncurr\n))\n \n{\n\n        \nstruct\n \ntask_struct\n \n*\ncurtask\n \n=\n \ntask_of\n(\ncurr\n);\n\n\n        \ntrace_sched_stat_runtime\n(\ncurtask\n,\n \ndelta_exec\n,\n \ncurr\n-\nvruntime\n);\n\n        \ncpuacct_charge\n(\ncurtask\n,\n \ndelta_exec\n);\n\n        \naccount_group_exec_runtime\n(\ncurtask\n,\n \ndelta_exec\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nupdate_curr()\n calculates the execution time of the current process and stores that value in \ndelta_exec\n. It then passes that runtime to \n__update_curr()\n, which weights the time by the number of runnable processes. The current process\u2019s vruntime is then incremented by the weighted value:\n\n\n/*\n\n\n * Update the current task\ns runtime statistics. Skip current tasks that\n\n\n * are not in our scheduling class.\n\n\n */\n\n\nstatic\n \ninline\n \nvoid\n\n\n__update_curr\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\ncurr\n,\n\n          \nunsigned\n \nlong\n \ndelta_exec\n)\n\n\n{\n\n    \nunsigned\n \nlong\n \ndelta_exec_weighted\n;\n\n\n    \nschedstat_set\n(\ncurr\n-\nexec_max\n,\n \nmax\n((\nu64\n)\ndelta_exec\n,\n \ncurr\n-\nexec_max\n));\n\n\n    \ncurr\n-\nsum_exec_runtime\n \n+=\n \ndelta_exec\n;\n\n    \nschedstat_add\n(\ncfs_rq\n,\n \nexec_clock\n,\n \ndelta_exec\n);\n\n    \ndelta_exec_weighted\n \n=\n \ncalc_delta_fair\n(\ndelta_exec\n,\n \ncurr\n);\n\n\n    \ncurr\n-\nvruntime\n \n+=\n \ndelta_exec_weighted\n;\n\n    \nupdate_min_vruntime\n(\ncfs_rq\n);\n\n\n}\n\n\n\n\n\n\nupdate_curr()\n is invoked periodically by the system timer and also whenever a process becomes runnable or blocks, becoming unrunnable. In this manner, vruntime is an accurate measure of the runtime of a given process and an indicator of what process should run next.\n\n\nThe \ncalc_delta_fair()\n function\n\n\n__update_curr()\n calls \ncalc_delta_fair()\n, which in turn calls \ncalc_delta_mine()\n (if \nse-\nload.weight\n does not equal \nNICE_0_LOAD\n) to calculate the weighted value:\n\n\nkernel/sched_fair.c#L431\n\n\n/*\n\n\n * delta /= w\n\n\n */\n\n\nstatic\n \ninline\n \nunsigned\n \nlong\n\n\ncalc_delta_fair\n(\nunsigned\n \nlong\n \ndelta\n,\n \nstruct\n \nsched_entity\n \n*\nse\n)\n\n\n{\n\n    \nif\n \n(\nunlikely\n(\nse\n-\nload\n.\nweight\n \n!=\n \nNICE_0_LOAD\n))\n\n        \ndelta\n \n=\n \ncalc_delta_mine\n(\ndelta\n,\n \nNICE_0_LOAD\n,\n \nse\n-\nload\n);\n\n\n    \nreturn\n \ndelta\n;\n\n\n}\n\n\n\n\n\n\nkernel/sched.c#L1300\n\n\n/*\n\n\n * delta *= weight / lw\n\n\n */\n\n\nstatic\n \nunsigned\n \nlong\n\n\ncalc_delta_mine\n(\nunsigned\n \nlong\n \ndelta_exec\n,\n \nunsigned\n \nlong\n \nweight\n,\n\n        \nstruct\n \nload_weight\n \n*\nlw\n)\n\n\n{\n\n    \nu64\n \ntmp\n;\n\n\n    \nif\n \n(\n!\nlw\n-\ninv_weight\n)\n \n{\n\n        \nif\n \n(\nBITS_PER_LONG\n \n \n32\n \n \nunlikely\n(\nlw\n-\nweight\n \n=\n \nWMULT_CONST\n))\n\n            \nlw\n-\ninv_weight\n \n=\n \n1\n;\n\n        \nelse\n\n            \nlw\n-\ninv_weight\n \n=\n \n1\n \n+\n \n(\nWMULT_CONST\n-\nlw\n-\nweight\n/\n2\n)\n\n                \n/\n \n(\nlw\n-\nweight\n+\n1\n);\n\n    \n}\n\n\n    \ntmp\n \n=\n \n(\nu64\n)\ndelta_exec\n \n*\n \nweight\n;\n\n    \n/*\n\n\n     * Check whether we\nd overflow the 64-bit multiplication:\n\n\n     */\n\n    \nif\n \n(\nunlikely\n(\ntmp\n \n \nWMULT_CONST\n))\n\n        \ntmp\n \n=\n \nSRR\n(\nSRR\n(\ntmp\n,\n \nWMULT_SHIFT\n/\n2\n)\n \n*\n \nlw\n-\ninv_weight\n,\n\n            \nWMULT_SHIFT\n/\n2\n);\n\n    \nelse\n\n        \ntmp\n \n=\n \nSRR\n(\ntmp\n \n*\n \nlw\n-\ninv_weight\n,\n \nWMULT_SHIFT\n);\n\n\n    \nreturn\n \n(\nunsigned\n \nlong\n)\nmin\n(\ntmp\n,\n \n(\nu64\n)(\nunsigned\n \nlong\n)\nLONG_MAX\n);\n\n\n}\n\n\n\n\n\n\nThis can be summarized as:\n\n\ndelta_exec_weighted = delta_exec * NICE_0_LOAD / se-\nload\n\n\n\n\n\nFor division details, see \nExplanation of the calc_delta_mine function\n.\n\n\nProcess Selection\n\n\nCFS attempts to balance a process\u2019s virtual runtime with a simple rule: \nwhen deciding what process to run next, it picks the process with the smallest \nvruntime\n.\n\n\nCFS uses a \nred-black tree\n to manage the list of runnable processes and efficiently find the process with the smallest \nvruntime\n. A red-black tree, called an \nrbtree\n in Linux (\ninclude/linux/rbtree.h\n, \nlib/rbtree.c\n), is a type of \nself-balancing binary search tree\n. It is a data structure that store nodes of arbitrary data, identified by a specific key, and that they enable efficient search for a given key. Specifically, obtaining a node identified by a given key is logarithmic in time as a function of total nodes in the tree.\n\n\nPicking the Next Task\n\n\nThe process that CFS wants to run next, which is the process with the smallest \nvruntime\n, is the leftmost node in the tree. If you follow the tree from the root down through the left child, and continue moving to the left until you reach a leaf node, you find the process with the smallest \nvruntime\n. CFS\u2019s process selection algorithm is thus summed up as \"run the process represented by the leftmost node in the rbtree.\" [p53]\n\n\nThe function that performs this selection is \n__pick_next_entity()\n, defined in \nkernel/sched_fair.c\n(\nkernel/sched_fair.c#L377\n):\n\n\nstatic\n \nstruct\n \nsched_entity\n \n*\n__pick_next_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n)\n\n\n{\n\n    \nstruct\n \nrb_node\n \n*\nleft\n \n=\n \ncfs_rq\n-\nrb_leftmost\n;\n\n\n    \nif\n \n(\n!\nleft\n)\n\n        \nreturn\n \nNULL\n;\n\n\n    \nreturn\n \nrb_entry\n(\nleft\n,\n \nstruct\n \nsched_entity\n,\n \nrun_node\n);\n\n\n}\n\n\n\n\n\n\nNote that \n__pick_next_entity()\n does not actually traverse the tree to find the leftmost node, because the value is cached by \nrb_leftmost\n, though it is efficient to walk the tree to find the leftmost node (\nO(height of tree)\n, which is \nO(log N)\n for \nN\n nodes if the tree is balanced).\n\n\nThe return value from this function is the process that CFS next runs. If the function returns NULL, there is no leftmost node, and thus no nodes in the tree. In that case, there are no runnable processes, and CFS schedules the idle task.\n\n\nAdding Processes to the Tree\n\n\nCFS adds processes to the rbtree and caches the leftmost node, when a process becomes runnable (wakes up) or is first created via \nfork()\n. Adding processes to the tree is performed by \nenqueue_entity()\n:\n\n\nkernel/sched_fair.c#L773\n\n\nstatic\n \nvoid\n\n\nenqueue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n,\n \nint\n \nflags\n)\n\n\n{\n\n    \n/*\n\n\n     * Update the normalized vruntime before updating min_vruntime\n\n\n     * through callig update_curr().\n\n\n     */\n\n    \nif\n \n(\n!\n(\nflags\n \n \nENQUEUE_WAKEUP\n)\n \n||\n \n(\nflags\n \n \nENQUEUE_MIGRATE\n))\n\n        \nse\n-\nvruntime\n \n+=\n \ncfs_rq\n-\nmin_vruntime\n;\n\n\n    \n/*\n\n\n     * Update run-time statistics of the \ncurrent\n.\n\n\n     */\n\n    \nupdate_curr\n(\ncfs_rq\n);\n\n    \naccount_entity_enqueue\n(\ncfs_rq\n,\n \nse\n);\n\n\n    \nif\n \n(\nflags\n \n \nENQUEUE_WAKEUP\n)\n \n{\n\n        \nplace_entity\n(\ncfs_rq\n,\n \nse\n,\n \n0\n);\n\n        \nenqueue_sleeper\n(\ncfs_rq\n,\n \nse\n);\n\n    \n}\n\n\n    \nupdate_stats_enqueue\n(\ncfs_rq\n,\n \nse\n);\n\n    \ncheck_spread\n(\ncfs_rq\n,\n \nse\n);\n\n    \nif\n \n(\nse\n \n!=\n \ncfs_rq\n-\ncurr\n)\n\n        \n__enqueue_entity\n(\ncfs_rq\n,\n \nse\n);\n\n\n}\n\n\n\n\n\n\nThis function updates the runtime and other statistics and then invokes \n__enqueue_entity()\n to perform the actual heavy lifting of inserting the entry into the red-black tree.\n\n\nkernel/sched_fair.c#L328\n\n\n/*\n\n\n * Enqueue an entity into the rb-tree:\n\n\n */\n\n\nstatic\n \nvoid\n \n__enqueue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n)\n\n\n{\n\n    \nstruct\n \nrb_node\n \n**\nlink\n \n=\n \ncfs_rq\n-\ntasks_timeline\n.\nrb_node\n;\n\n    \nstruct\n \nrb_node\n \n*\nparent\n \n=\n \nNULL\n;\n\n    \nstruct\n \nsched_entity\n \n*\nentry\n;\n\n    \ns64\n \nkey\n \n=\n \nentity_key\n(\ncfs_rq\n,\n \nse\n);\n\n    \nint\n \nleftmost\n \n=\n \n1\n;\n\n\n    \n/*\n\n\n     * Find the right place in the rbtree:\n\n\n     */\n\n    \nwhile\n \n(\n*\nlink\n)\n \n{\n\n        \nparent\n \n=\n \n*\nlink\n;\n\n        \nentry\n \n=\n \nrb_entry\n(\nparent\n,\n \nstruct\n \nsched_entity\n,\n \nrun_node\n);\n\n        \n/*\n\n\n         * We dont care about collisions. Nodes with\n\n\n         * the same key stay together.\n\n\n         */\n\n        \nif\n \n(\nkey\n \n \nentity_key\n(\ncfs_rq\n,\n \nentry\n))\n \n{\n\n            \nlink\n \n=\n \nparent\n-\nrb_left\n;\n\n        \n}\n \nelse\n \n{\n\n            \nlink\n \n=\n \nparent\n-\nrb_right\n;\n\n            \nleftmost\n \n=\n \n0\n;\n\n        \n}\n\n    \n}\n\n\n    \n/*\n\n\n     * Maintain a cache of leftmost tree entries (it is frequently\n\n\n     * used):\n\n\n     */\n\n    \nif\n \n(\nleftmost\n)\n\n        \ncfs_rq\n-\nrb_leftmost\n \n=\n \nse\n-\nrun_node\n;\n\n\n    \nrb_link_node\n(\nse\n-\nrun_node\n,\n \nparent\n,\n \nlink\n);\n\n    \nrb_insert_color\n(\nse\n-\nrun_node\n,\n \ncfs_rq\n-\ntasks_timeline\n);\n\n\n}\n\n\n\n\n\n\nThis function traverses the tree in the \nwhile()\n loop to search for a matching key (inserted process\u2019s \nvruntime\n). It moves to the left child if the key is smaller than the current node\u2019s key and to the right child if the key is larger.  If it ever moves to the right, even once, it knows the inserted process cannot be the new leftmost node, and it sets leftmost to zero. If it moves only to the left, \nleftmost\n remains one, and we have a new leftmost node and can update the cache by setting \nrb_leftmost\n to the inserted process. When out of the loop, the function calls \nrb_link_node()\n on the parent node, making the inserted process the new child. The function \nrb_insert_color()\n updates the self-balancing properties of the tree.\n\n\nRemoving Processes from the Tree\n\n\nCFS removes processes from the red-black tree when a process blocks (becomes unrunnable) or terminates (ceases to exist):\n\n\nkernel/sched_fair.c#L815\n\n\nstatic\n \nvoid\n\n\ndequeue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n,\n \nint\n \nsleep\n)\n\n\n{\n\n    \n/*\n\n\n     * Update run-time statistics of the \ncurrent\n.\n\n\n     */\n\n    \nupdate_curr\n(\ncfs_rq\n);\n\n\n    \nupdate_stats_dequeue\n(\ncfs_rq\n,\n \nse\n);\n\n    \nclear_buddies\n(\ncfs_rq\n,\n \nse\n);\n\n\n    \nif\n \n(\nse\n \n!=\n \ncfs_rq\n-\ncurr\n)\n\n        \n__dequeue_entity\n(\ncfs_rq\n,\n \nse\n);\n\n    \naccount_entity_dequeue\n(\ncfs_rq\n,\n \nse\n);\n\n    \nupdate_min_vruntime\n(\ncfs_rq\n);\n\n\n    \n/*\n\n\n     * Normalize the entity after updating the min_vruntime because the\n\n\n     * update can refer to the -\ncurr item and we need to reflect this\n\n\n     * movement in our normalized position.\n\n\n     */\n\n    \nif\n \n(\n!\nsleep\n)\n\n        \nse\n-\nvruntime\n \n-=\n \ncfs_rq\n-\nmin_vruntime\n;\n\n\n}\n\n\n\n\n\n\nSimilarly, the real work is performed by a helper function, \n__dequeue_entity()\n:\n\n\nstatic\n \nvoid\n \n__dequeue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n)\n\n\n{\n\n    \nif\n \n(\ncfs_rq\n-\nrb_leftmost\n \n==\n \nse\n-\nrun_node\n)\n \n{\n\n        \nstruct\n \nrb_node\n \n*\nnext_node\n;\n\n\n        \nnext_node\n \n=\n \nrb_next\n(\nse\n-\nrun_node\n);\n\n        \ncfs_rq\n-\nrb_leftmost\n \n=\n \nnext_node\n;\n\n    \n}\n\n\n    \nrb_erase\n(\nse\n-\nrun_node\n,\n \ncfs_rq\n-\ntasks_timeline\n);\n\n\n}\n\n\n\n\n\n\nRemoving a process from the tree is much simpler because the rbtree implementation provides the \nrb_erase()\n function that performs all the work. The rest of this function updates the \nrb_leftmost\n cache. If the process-to-remove is the leftmost node, the function invokes \nrb_next()\n to find what would be the next node in an in-order traversal. This is what will be the leftmost node when the current leftmost node is removed.\n\n\nThe Scheduler Entry Point\n\n\nThe main entry point into the process schedule is the function \nschedule()\n, defined in \nkernel/sched.c\n (\nkernel/sched.c#L3701\n). This is the function that the rest of the kernel uses to invoke the process scheduler, deciding which process to run and then running it.\n\n\nschedule()\n is generic to scheduler classes. It finds the highest priority scheduler class with a runnable process and asks it what to run next.\n Thus, \nschedule()\n is simple. The only important part of the function is its invocation of \npick_next_task()\n, defined in \nkernel/sched.c\n (\nkernel/sched.c#L3670\n), which goes through each scheduler class, starting with the highest priority, and selects the highest priority process in the highest priority class:\n\n\n/*\n\n\n * Pick up the highest-prio task:\n\n\n */\n\n\nstatic\n \ninline\n \nstruct\n \ntask_struct\n \n*\n\n\npick_next_task\n(\nstruct\n \nrq\n \n*\nrq\n)\n\n\n{\n\n    \nconst\n \nstruct\n \nsched_class\n \n*\nclass\n;\n\n    \nstruct\n \ntask_struct\n \n*\np\n;\n\n\n    \n/*\n\n\n     * Optimization: we know that if all tasks are in\n\n\n     * the fair class we can call that function directly:\n\n\n     */\n\n    \nif\n \n(\nlikely\n(\nrq\n-\nnr_running\n \n==\n \nrq\n-\ncfs\n.\nnr_running\n))\n \n{\n\n        \np\n \n=\n \nfair_sched_class\n.\npick_next_task\n(\nrq\n);\n\n        \nif\n \n(\nlikely\n(\np\n))\n\n            \nreturn\n \np\n;\n\n    \n}\n\n\n    \nclass\n \n=\n \nsched_class_highest\n;\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \np\n \n=\n \nclass\n-\npick_next_task\n(\nrq\n);\n\n        \nif\n \n(\np\n)\n\n            \nreturn\n \np\n;\n\n        \n/*\n\n\n         * Will never be NULL as the idle class always\n\n\n         * returns a non-NULL p:\n\n\n         */\n\n        \nclass\n \n=\n \nclass\n-\nnext\n;\n\n    \n}\n\n\n}\n\n\n\n\n\n\nNote the optimization at the beginning of the function. CFS is the scheduler class for normal processes, and most systems run mostly normal processes, there is a small hack to quickly select the next CFS-provided process if the number of runnable processes is equal to the number of CFS runnable processes (which suggests that all runnable processes are provided by CFS).\n\n\nThe core of the function is the \nfor()\n loop, which iterates over each class in priority order, starting with the highest priority class. Each class implements the \npick_next_task()\n function, which returns a pointer to its next runnable process or, if there is not one, \nNULL\n.The first class to return a non-\nNULL\n value has selected the next runnable process. CFS\u2019s implementation of \npick_next_task()\n calls \npick_next_entity()\n, which in turn calls the \n__pick_next_entity()\n function (see \nPicking the Next Task\n in the previous section).\n\n\nfair_sched_class\n scheduler class\n *\n\n\nfair_sched_class\n is a \nstruct sched_class\n (defined in \ninclude/linux/sched.h\n) structure defined in \nkernel/sched_fair.c\n (\nkernel/sched_fair.c#L3688\n). \nkernel/sched_fair.c\n is included by \nkernel/sched.c\n (\nkernel/sched.c#L1936\n), so \nfair_sched_class\n is avaialble to the \npick_next_task\n function in \n/kernel/sched.c\n.\n\n\nSleeping and Waking Up\n\n\nTasks that are sleeping (blocked) are in a special non-runnable state. [p58]\n\n\nA task sleeps while it is waiting for some event, which may be:\n\n\n\n\na specified amount of time;\n\n\nmore data from a file I/O;\n\n\nanother hardware event\n\n\n\n\nA task can also involuntarily go to sleep when it tries to obtain a contended semaphore in the kernel.\n\n\nWhatever the case, the kernel behavior is the same. The task does the following in turn:\n\n\n\n\nmarks itself as sleeping,\n\n\nputs itself on a wait queue,\n\n\nremoves itself from the red-black tree of runnable,\n\n\nand calls \nschedule()\n to select a new process to execute.\n\n\n\n\nWaking back up is the inverse: The task is set as runnable, removed from the wait queue, and added back to the red-black tree.\n\n\nTwo states are associated with sleeping:\n\n\n\n\nTASK_INTERRUPTIBLE\n\n\nTASK_UNINTERRUPTIBLE\n\n\n\n\nThey differ only in that tasks in the \nTASK_UNINTERRUPTIBLE\n state ignore signals, whereas tasks in the \nTASK_INTERRUPTIBLE\n state wake up prematurely and respond to a signal if one is issued. Both types of sleeping tasks sit on a wait queue, waiting for an event to occur, and are not runnable.\n\n\nWait Queues\n\n\nSleeping is handled via wait queues. A wait queue is a simple list of processes waiting for an event to occur.\n\n\nWait queues are represented in the kernel by \nwake_queue_head_t\n. They are created statically via \nDECLARE_WAITQUEUE()\n or dynamically via \ninit_waitqueue_head()\n. Processes put themselves on a wait queue and mark themselves not runnable. When the event associated with the wait queue occurs, the processes on the queue are awakened.\n\n\nIt is important to implement sleeping and waking correctly, to avoid race conditions. Otherwise, it is possible to go to sleep after the condition becomes true, in which case the task might sleep indefinitely. Therefore, the recommended method for sleeping in the kernel is a bit more complicated:\n\n\n/* `q\n is the wait queue we wish to sleep on */\n\n\nDEFINE_WAIT\n(\nwait\n);\n\n\n\nadd_wait_queue\n(\nq\n,\n \nwait\n);\n\n\nwhile\n \n(\n!\ncondition\n)\n \n{\n \n/* condition is the event that we are waiting for */\n\n    \nprepare_to_wait\n(\nq\n,\n \nwait\n,\n \nTASK_INTERRUPTIBLE\n);\n\n    \nif\n \n(\nsignal_pending\n(\ncurrent\n))\n\n        \n/* handle signal */\n\n    \nschedule\n();\n\n\n}\n\n\nfinish_wait\n(\nq\n,\n \nwait\n);\n\n\n\n\n\n\nThe task performs the following steps to add itself to a wait queue:\n\n\n\n\nCreates a wait queue entry via the macro \nDEFINE_WAIT()\n.\n\n\nAdds itself to a wait queue via \nadd_wait_queue()\n. This wait queue awakens the process when the condition for which it is waiting occurs. Of course, there needs to be code elsewhere that calls wake_up() on the queue when the event actually does occur.\n\n\nCalls \nprepare_to_wait()\n to change the process state to either \nTASK_INTERRUPTIBLE\n or \nTASK_UNINTERRUPTIBLE\n. This function also adds the task back to the wait queue if necessary, which is needed on subsequent iterations of the loop.\n\n\nIf the state is set to \nTASK_INTERRUPTIBLE\n, a signal wakes the process up. This is called a \nspurious wake up\n (a wake-up not caused by the occurrence of the event). So check and handle signals.\n\n\nWhen the task awakens, it again checks whether the condition is true. If it is, it exits the loop. Otherwise, it again calls \nschedule()\n and repeats.\n\n\nAfter the condition is true, the task sets itself to \nTASK_RUNNING\n and removes itself from the wait queue via \nfinish_wait()\n.\n\n\n\n\nIf the condition occurs before the task goes to sleep, the loop terminates, and the task does not erroneously go to sleep. Note that kernel code often has to perform various other tasks in the body of the loop. For example, it might need to release locks before calling \nschedule()\n and reacquire them after or react to other events.\n\n\nThe function \ninotify_read()\n in \nfs/notify/inotify/inotify_user.c\n, which handles reading from the inotify file descriptor, is a straightforward example of using wait queues:\n\n\nstatic\n \nssize_t\n \ninotify_read\n(\nstruct\n \nfile\n \n*\nfile\n,\n \nchar\n \n__user\n \n*\nbuf\n,\n\n                \nsize_t\n \ncount\n,\n \nloff_t\n \n*\npos\n)\n\n\n{\n\n    \nstruct\n \nfsnotify_group\n \n*\ngroup\n;\n\n    \nstruct\n \nfsnotify_event\n \n*\nkevent\n;\n\n    \nchar\n \n__user\n \n*\nstart\n;\n\n    \nint\n \nret\n;\n\n    \nDEFINE_WAIT\n(\nwait\n);\n\n\n    \nstart\n \n=\n \nbuf\n;\n\n    \ngroup\n \n=\n \nfile\n-\nprivate_data\n;\n\n\n    \nwhile\n \n(\n1\n)\n \n{\n\n        \nprepare_to_wait\n(\ngroup\n-\nnotification_waitq\n,\n \nwait\n,\n \nTASK_INTERRUPTIBLE\n);\n\n\n        \nmutex_lock\n(\ngroup\n-\nnotification_mutex\n);\n\n        \nkevent\n \n=\n \nget_one_event\n(\ngroup\n,\n \ncount\n);\n\n        \nmutex_unlock\n(\ngroup\n-\nnotification_mutex\n);\n\n\n        \nif\n \n(\nkevent\n)\n \n{\n\n            \nret\n \n=\n \nPTR_ERR\n(\nkevent\n);\n\n            \nif\n \n(\nIS_ERR\n(\nkevent\n))\n\n                \nbreak\n;\n\n            \nret\n \n=\n \ncopy_event_to_user\n(\ngroup\n,\n \nkevent\n,\n \nbuf\n);\n\n            \nfsnotify_put_event\n(\nkevent\n);\n\n            \nif\n \n(\nret\n \n \n0\n)\n\n                \nbreak\n;\n\n            \nbuf\n \n+=\n \nret\n;\n\n            \ncount\n \n-=\n \nret\n;\n\n            \ncontinue\n;\n\n        \n}\n\n\n        \nret\n \n=\n \n-\nEAGAIN\n;\n\n        \nif\n \n(\nfile\n-\nf_flags\n \n \nO_NONBLOCK\n)\n\n            \nbreak\n;\n\n        \nret\n \n=\n \n-\nEINTR\n;\n\n        \nif\n \n(\nsignal_pending\n(\ncurrent\n))\n\n            \nbreak\n;\n\n\n        \nif\n \n(\nstart\n \n!=\n \nbuf\n)\n\n            \nbreak\n;\n\n\n        \nschedule\n();\n\n    \n}\n\n\n    \nfinish_wait\n(\ngroup\n-\nnotification_waitq\n,\n \nwait\n);\n\n    \nif\n \n(\nstart\n \n!=\n \nbuf\n \n \nret\n \n!=\n \n-\nEFAULT\n)\n\n        \nret\n \n=\n \nbuf\n \n-\n \nstart\n;\n\n    \nreturn\n \nret\n;\n\n\n}\n\n\n\n\n\n\nSome notes of the function above:\n\n\n\n\nIt checks for the condition in the body of the \nwhile()\n loop, instead of in the \nwhile()\n statement itself, since checking the condition is complicated and requires grabbing locks.\n\n\nThe loop is terminated via \nbreak\n.\n\n\n\n\nWaking Up\n\n\nwake_up()\n wakes up all the tasks waiting on the given wait queue. It does the following:\n\n\n\n\nCalls \ntry_to_wake_up()\n, which sets the task\u2019s state to \nTASK_RUNNING\n\n\nCalls \nenqueue_task()\n to add the task to the red-black tree\n\n\nSets \nneed_resched\n if the awakened task\u2019s priority is higher than the priority of the current task. \nThe code that causes the event to occur typically calls \nwake_up()\n itself\n.\n\n\nFor example, when data arrives from the hard disk, the VFS calls \nwake_up()\n on the wait queue that holds the processes waiting for the data.\n\n\n\n\n\n\n\n\nSince there are spurious wake-ups, just because a task is awakened does not mean that the event for which the task is waiting has occurred. Sleeping should always be handled in a loop that ensures that the condition for which the task is waiting has indeed occurred.\nThe figure below depicts the relationship between each scheduler state.\n\n\n\n\nPreemption and Context Switching\n\n\nContext switching, the switching from one runnable task to another, is handled by the \ncontext_switch()\n function defined in \nkernel/sched.c\n. It is called by \nschedule()\n when a new process has been selected to run. It does two basic jobs:\n\n\n\n\nCalls \nswitch_mm()\n, declared in \nasm/mmu_context.h\n, to switch the virtual memory mapping from the previous process\u2019s to that of the new process.\n\n\nCalls \nswitch_to()\n, declared in \nasm/system.h\n, to switch the processor state from the previous process\u2019s to the current\u2019s. This involves saving and restoring stack information and the processor registers and any other architecture-specific state that must be managed and restored on a per-process basis.\n\n\n\n\nThe \nneed_resched\n flag *\n\n\nThe kernel must know when to call \nschedule()\n. If it called \nschedule()\n only when code explicitly did so, user-space programs could run indefinitely.\n\n\nThe kernel provides the \nneed_resched\n flag to signify whether a reschedule should be performed.\n\n\n\n\nThis flag is set by \nscheduler_tick()\n (in timer interrupt handler, see \nThe Timer Interrupt Handler\n) when a process should be preempted.\n\n\nThis flag is set by \ntry_to_wake_up()\n when a process that has a higher priority than the currently running process is awakened.\n\n\n\n\nThe kernel checks the flag, sees that it is set, and calls \nschedule()\n to switch to a new process. The flag is a message to the kernel that the scheduler should be invoked as soon as possible because another process deserves to run.\n\n\nUpon returning to user-space or returning from an interrupt, the \nneed_resched\n flag is checked. If it is set, the kernel invokes the scheduler before continuing.\n\n\nThe table below lists functions for accessing and manipulating \nneed_resched\n:\n\n\n\n\n\n\n\n\nFunction\n\n\nPurpose\n\n\n\n\n\n\n\n\n\n\nset_tsk_need_resched()\n\n\nSet the \nneed_resched\n flag in the given process.\n\n\n\n\n\n\nclear_tsk_need_resched()\n\n\nClear the \nneed_resched\n flag in the given process.\n\n\n\n\n\n\nneed_resched()\n\n\nTest the value of the \nneed_resched\n flag; return true if set and false otherwise.\n\n\n\n\n\n\n\n\nThe flag is per-process, and not simply global, because it is faster to access a value in the process descriptor (because of the speed of current and high probability of it being cache hot) than a global variable. Historically, the flag was global before the 2.2 kernel. In 2.2 and 2.4, the flag was an int inside the \ntask_struct\n. In 2.6, it was moved into a single bit of a special flag variable inside the \nthread_info\n structure (\narch/x86/include/asm/thread_info.h#L26\n).\n\n\nUser Preemption\n\n\nUser preemption occurs when the kernel is about to return to user-space, \nneed_resched\n is set, and therefore, the scheduler is invoked. If the kernel is returning to user-space, it knows it is in a safe quiescent state. In other words, if it is safe to continue executing the current task, it is also safe to pick a new task to execute.\n\n\nWhenever the kernel is preparing to return to user-space either on return from an interrupt or after a system call, the value of \nneed_resched\n is checked. If it is set, the scheduler is invoked to select a new (more fit) process to execute. Both the return paths for return from interrupt and return from system call are architecture-dependent and typically implemented in assembly in \nentry.S\n (which, aside from kernel entry code, also contains kernel exit code).\n\n\nIn conclusion, user preemption can occur:\n\n\n\n\nWhen returning to user-space from a system call\n\n\nWhen returning to user-space from an interrupt handler\n\n\n\n\nKernel Preemption\n\n\nIn non-preemptive kernels, kernel code runs until completion. That is, the scheduler cannot reschedule a task while it is in the kernel: kernel code is\nscheduled cooperatively, not preemptively. Kernel code runs until it finishes (returns to user-space) or explicitly blocks.\n\n\nThe Linux kernel (since 2.6), unlike most other Unix variants and many other operating systems, is a fully preemptive kernel. It is possible to preempt a task at any point, so long as the kernel is in a state in which it is safe to reschedule.\n\n\nThe kernel can preempt a task running in the kernel so long as it does not hold a lock. Locks are used as markers of regions of non-preemptibility. \nBecause the kernel is SMP-safe, if a lock is not held, the current code is reentrant and capable of being preempted.\n\n\nThe preemption counter \npreempt_count\n *\n\n\nTo support kernel preemption, preemption counter, \npreempt_count\n (\narch/x86/include/asm/thread_info.h#L32\n), was added to each process\u2019s \nthread_info\n. This counter begins at zero and increments once for each lock that is acquired and decrements once for each lock that is released.When the counter is zero, the kernel is preemptible. Upon return from interrupt, if returning to kernel-space, the kernel checks the values of \nneed_resched\n and \npreempt_count\n:\n\n\n\n\nIf \nneed_resched\n is set and \npreempt_count\n is zero, then a more important task is runnable, and it is safe to preempt. Thus, the scheduler is invoked.\n\n\nIf \npreempt_count\n is nonzero, a lock is held, and it is unsafe to reschedule. In that case, the interrupt returns as usual to the currently executing task.\n\n\n\n\nEnabling and disabling kernel preemption is sometimes required in kernel code (discussed in \nChapter 9\n).\n\n\nExplicit kernel preemption\n *\n\n\nKernel preemption can also occur explicitly, when a task in ther kernel does either of the following:\n\n\n\n\nBlocks,\n\n\nExplicitly calls \nschedule()\n.\n\n\n\n\nThis form of kernel preemption has always been supported because no additional logic is required to ensure that the kernel is in a state that is safe to preempt. It is assumed that the code that explicitly calls \nschedule()\n knows it is safe to reschedule.\n\n\nIn conclusion, kernel preemption can occur:\n\n\n\n\nWhen an interrupt handler exits, before returning to kernel-space\n\n\nWhen kernel code becomes preemptible again\n\n\nIf a task in the kernel explicitly calls \nschedule()\n\n\nIf a task in the kernel blocks (which results in a call to \nschedule()\n)\n\n\n\n\nReal-Time Scheduling Policies\n\n\nLinux provides two real-time scheduling policies:\n\n\n\n\nSCHED_FIFO\n\n\nSCHED_RR\n\nThe normal, not real-time scheduling policy is \nSCHED_NORMAL\n.\n\n\n\n\nVia the \nscheduling classes\n framework, these real-time policies are managed not by the Completely Fair Scheduler, but by a special real-time scheduler, defined in \nkernel/sched_rt.c\n.\n\n\nThe \nSCHED_FIFO\n policy *\n\n\nSCHED_FIFO\n implements a simple first-in, first-out scheduling algorithm without timeslices.\n\n\n\n\nA runnable \nSCHED_FIFO\n task is always scheduled over any \nSCHED_NORMAL\n tasks.\n\n\nWhen a \nSCHED_FIFO\n task becomes runnable, it continues to run until it blocks or explicitly yields the processor; it has no timeslice and can run indefinitely\n\n\nOnly a higher priority \nSCHED_FIFO\n or \nSCHED_RR\n task can preempt a \nSCHED_FIFO\n task.\n\n\nTwo or more \nSCHED_FIFO\n tasks at the same priority run round-robin, but only yielding the processor when they explicitly choose to do so.\n\n\nIf a \nSCHED_FIFO\n task is runnable, all other tasks at a lower priority cannot run until the \nSCHED_FIFO\n task becomes unrunnable.\n\n\n\n\nThe \nSCHED_RR\n policy *\n\n\nSCHED_RR\n is identical to \nSCHED_FIFO\n except that each process can run only until it exhausts a predetermined timeslice. In other words, \nSCHED_RR\n is \nSCHED_FIFO\n with timeslices. It is a real-time, round-robin scheduling algorithm.\n\n\n\n\nWhen a \nSCHED_RR\n task exhausts its timeslice, any other real-time processes at its priority are scheduled round-robin. The timeslice is used to allow only rescheduling of same-priority processes.\n\n\nAs with \nSCHED_FIFO\n, a higher-priority process always immediately preempts a lower-priority one, and a lower-priority process can never preempt a \nSCHED_RR\n task, even if its timeslice is exhausted.\n\n\n\n\nBoth real-time scheduling policies implement static priorities. The kernel does not calculate dynamic priority values for real-time tasks.This ensures that a real-time process at a given priority always preempts a process at a lower priority.\n\n\nHard real-time and soft real-time\n\n\n\n\nSoft real-time\n means that the kernel tries to schedule applications within timing deadlines, but the kernel does not promise to always achieve these goals.\n\n\nHard real-time\n systems are guaranteed to meet any scheduling requirements within certain limits.\n\n\n\n\nThe real-time scheduling policies in Linux provide soft real-time behavior. Linux makes no guarantees on the capability to schedule real-time tasks. Despite not having a design that guarantees hard real-time behavior, the real-time scheduling performance in Linux is quite good. The 2.6 Linux kernel is capable of meeting stringent timing requirements.\n\n\nReal-time priorities range inclusively from 0 to \nMAX_RT_PRIO\n - 1. By default, this range is 0 to 99, since \nMAX_RT_PRIO\n is 100. This priority space is shared with the nice values of \nSCHED_NORMAL\n tasks: They use the space from \nMAX_RT_PRIO\n to (\nMAX_RT_PRIO\n + 40).  By default, this means the \u201320 to +19 nice range maps directly onto the priority space from 100 to 139.\n\n\nDefault priority ranges:\n\n\n\n\n0 to 99: real-time priorities\n\n\n100 to 139: normal priorities\n\n\n\n\nScheduler-Related System Calls\n\n\nLinux provides a family of system calls for the management of scheduler parameters, which allow manipulation of process priority, scheduling policy, and processor affinity, \nyielding\n the processor to other tasks.\n\n\nThe table below lists the system calls with brief descriptions. Their implementation in the kernel is discussed in \nChapter 5\n.\n\n\n\n\n\n\n\n\nSystem Call\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nnice()\n\n\nSets a process\u2019s nice value\n\n\n\n\n\n\nsched_setscheduler()\n\n\nSets a process\u2019s scheduling policy\n\n\n\n\n\n\nsched_getscheduler()\n\n\nGets a process\u2019s scheduling policy\n\n\n\n\n\n\nsched_setparam()\n\n\nSets a process\u2019s real-time priority\n\n\n\n\n\n\nsched_getparam()\n\n\nGets a process\u2019s real-time priority\n\n\n\n\n\n\nsched_get_priority_max()\n\n\nGets the maximum real-time priority\n\n\n\n\n\n\nsched_get_priority_min()\n\n\nGets the minimum real-time priority\n\n\n\n\n\n\nsched_rr_get_interval()\n\n\nGets a process\u2019s timeslice value\n\n\n\n\n\n\nsched_setaffinity()\n\n\nSets a process\u2019s processor affinity\n\n\n\n\n\n\nsched_getaffinity()\n\n\nGets a process\u2019s processor affinity\n\n\n\n\n\n\nsched_yield()\n\n\nTemporarily yields the processor\n\n\n\n\n\n\n\n\nScheduling Policy and Priority-Related System Calls\n\n\n\n\nThe \nsched_setscheduler()\n and \nsched_getscheduler()\n system calls set and get a given process\u2019s scheduling policy and real-time priority. The major work  of these functions is merely to read or write the \npolicy\n and \nrt_priority\n values in the process\u2019s \ntask_struct\n. [p66]\n\n\nThe \nsched_setparam()\n and \nsched_getparam()\n system calls set and get a process\u2019s real-time priority. These calls merely encode \nrt_priority\n in a special \nsched_param\n structure (\ninclude/linux/sched.h#L46\n).\n\n\nThe calls \nsched_get_priority_max()\n and \nsched_get_priority_min()\n return the maximum and minimum priorities, respectively, for a given scheduling policy. The maximum priority for the real-time policies is \nMAX_USER_RT_PRIO\n minus one; the minimum is one.\n\n\nFor normal tasks, the \nnice()\n function increments the given process\u2019s static priority by the given amount.\n\n\nOnly root can provide a negative value, which lowers the nice value and increase the priority.\n\n\nThe \nnice()\n function calls the kernel\u2019s \nset_user_nice()\n function, which sets the \nstatic_prio\n and prio values in the task\u2019s \ntask_struct\n.\n\n\n\n\n\n\n\n\nProcessor Affinity System Calls\n\n\nThe Linux scheduler enforces hard processor affinity, which means that, aside from providing soft or natural affinity by attempting to keep processes on the same processor, the scheduler enables a user to enforce \"a task must remain on this subset of the available processors no matter what\".\n\n\nTThe hard affinity is stored as a bitmask in the task\u2019s \ntask_struct\n as \ncpus_allowed\n (\ninclude/linux/sched.h#L1210\n). The bitmask contains one bit per possible processor on the system. By default, all bits are set and, therefore, a process is potentially runnable on any processor. The following system calls set and get the bitmask:\n\n\n\n\nsched_setaffinity()\n sets a different bitmask of any combination of one or more bits.\n\n\nsched_getaffinity()\n returns the current \ncpus_allowed\n bitmask.\n\n\n\n\nThe kernel enforces hard affinity in a simple manner:\n\n\n\n\nWhen a process is initially created, it inherits its parent\u2019s affinity mask. Because the parent is running on an allowed processor, the child thus runs on an allowed processor.\n\n\nWhen a processor\u2019s affinity is changed, the kernel uses the \nmigration threads\n to push the task onto a legal processor. (See \nDoubts and Solutions\n)\n\n\nThe load balancer pulls tasks to only an allowed processor\n\n\n\n\nTherefore, a process only ever runs on a processor whose bit is set in the \ncpus_allowed\n field of its process descriptor.\n\n\nYielding Processor Time\n\n\nLinux provides the \nsched_yield()\n system call as a mechanism for a process to explicitly yield the processor to other waiting processes.\n\n\n\n\nsched_yield()\n removes the process from the active array (where it currently is, because it is running) and inserting it into the expired array. This has the effect of not only preempting the process and putting it at the end of its priority list, but also putting it on the expired list, which guarantees it will not run for a while.\n\n\nFor real-time tasks, which never expire, \nsched_yield()\n merely move them to the end of their priority list (and not insert them into the expired array).\n\n\n\n\n\n\n\n\nApplications and even kernel code should be certain they truly want to give up the processor before calling \nsched_yield()\n.\n\n\nKernel code, as a convenience, can call \nyield()\n, which ensures that the task\u2019s state is \nTASK_RUNNING\n and then call \nsched_yield()\n. User-space applications use the \nsched_yield()\n system call.\n\n\nConclusion\n\n\nMeeting the demands of process scheduling is nontrivial. A large number of runnable processes, scalability concerns, trade-offs between latency and throughput, and the demands of various workloads make a one-size-fits-all algorithm hard to achieve. Linux kernel\u2019s new CFS process scheduler, comes close to appeasing all parties and providing an optimal solution for most use cases with good scalability. [p67]\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np66 on Processor Affinity. \"migration threads\" and \"load balancer\" is not detailed.", 
            "title": "Chapter 4. Process Scheduling"
        }, 
        {
            "location": "/lkd/ch5/", 
            "text": "Chapter 5. System Calls\n\n\n\n\nLook at \nioctl()\n as an example of what not to do (when implementing a system call).\n\nRobert Love\n\n\n\n\nIn any modern operating system, the kernel provides a set of interfaces by which processes running in user-space can interact with the system. These interfaces give applications: [p69]\n\n\n\n\ncontrolled access to hardware,\n\n\na mechanism with which to create new processes and communicate with existing ones,\n\n\nand the capability to request other operating system resources.\n\n\n\n\nThe existence of these interfaces, and the fact that applications are not free to directly do whatever they want, is key to providing a stable system\n\n\nCommunicating with the Kernel\n\n\nSystem calls provide a layer between the hardware and user-space processes, which serves three primary purposes:\n\n\n\n\nProviding an abstracted hardware interface for userspace.\n\n\nFor example, when reading or writing from a file, applications are not concerned with the type of disk, media, or even the type of filesystem on which the file resides.\n\n\n\n\n\n\nEnsuring system security and stability.\n The kernel acts as a middleman between system resources and user-space, so it can arbitrate access based on permissions, users, and other criteria.\n\n\nFor example, this arbitration prevents applications from incorrectly using hardware, stealing other processes\u2019 resources, or otherwise doing harm to the system.\n\n\n\n\n\n\nA single common layer between user-space and the rest of the system allows for the virtualized system provided to processes.\n  It would be impossible to implement multitasking and virtual memory if applications were free to access access system resources without the kernel\u2019s knowledge. [p69]\n\n\n\n\nIn Linux, system calls are the only means user-space has of interfacing with the kernel and the only legal entry point into the kernel other than exceptions and traps. Other interfaces, such as device files or \n/proc\n, are ultimately accessed via system calls. Interestingly, Linux implements far fewer system calls than most systems.\n\n\nAPIs, POSIX, and the C Library\n\n\nAPIs *\n\n\nApplications are typically programmed against an Application Programming Interface (API) implemented in user-space, not directly to system calls, because no direct correlation is needed between the interfaces used by applications and the actual interface provided by the kernel.\n\n\nAn API defines a set of programming interfaces used by applications. Those interfaces can be:\n\n\n\n\nimplemented as a system call,\n\n\nimplemented through multiple system calls, or\n\n\nimplemented without the use of system calls at all.\n\n\n\n\nThe same API can exist on multiple systems and provide the same interface to applications while the implementation of the API itself can differ greatly from system to system.\n\n\nThe figure below shows relationship between a POSIX API, the C library, and system calls.\n\n\n\n\nPOSIX *\n\n\nThe most common APIs in the Unix world is based on POSIX. Technically, POSIX is composed of a series of standards from the \nIEEE\n that aim to provide a portable operating system standard roughly based on Unix. Linux strives to be POSIX- and SUSv3-compliant where applicable.\n\n\nOn most Unix systems, the POSIX-defined API calls have a strong correlation to the system calls. Some systems that are rather un-Unix, such as Microsoft Windows, offer POSIX-compatible libraries. [p70]\n\n\nThe C Library *\n\n\nThe system call interface in Linux, as with most Unix systems, is provided in part by the C library.\n\n\nThe C library implements the main API on Unix systems, including:\n\n\n\n\nThe standard C library\n\n\nThe system call interface\n\n\n\n\nThe C library is used by all C programs and, because of C\u2019s nature, is easily wrapped by other programming languages for use in their programs. The C library additionally provides the majority of the POSIX API.\n\n\nFrom the application programmer\u2019s point of view, system calls are irrelevant; all the programmer is concerned with is the API. Conversely, the kernel is concerned only with the system calls; what library calls and applications make use of the system calls is not of the kernel\u2019s concern. Nonetheless, it is important for the kernel to keep track of the potential uses of a system call and keep the system call as general and flexible as possible.\n\n\nA meme related to interfaces in Unix is \"Provide mechanism, not policy\". In other words, Unix system calls exist to provide a specific function in an abstract sense. The manner in which the function is used is not any of the kernel\u2019s business.\n\n\nSyscalls\n\n\nSystem calls\n (often called \nsyscalls\n in Linux) are typically accessed via function calls defined in the C library.\n\n\n\n\nThe functions can define zero, one, or more arguments (inputs) and might result in one or more side effects.\n\n\nAlthough nearly all system calls have a side effect (that is, they result in some change of the system\u2019s state), a few syscalls, such as \ngetpid()\n, merely return some data from the kernel.\n\n\n\n\n\n\nSystem calls also provide a return value of type \nlong\n (for compatibility with 64-bit architectures) that signifies success or error.\n\n\nUsually, although not always, a negative return value denotes an error.\n\n\nA return value of zero is usually (not always) a sign of success.\n\n\nThe C library (when a system call returns an error) writes a special error code into the global \nerrno\n variable, which can be translated into human-readable errors via library functions such as \nperror()\n.\n\n\n\n\n\n\nSystem calls have a defined behavior. (see the following example)\n\n\n\n\nThe system call \ngetpid()\n is defined to return an integer that is the current process\u2019s PID. The implementation of this syscall in the kernel is simple:\n\n\nSYSCALL_DEFINE0\n(\ngetpid\n)\n\n\n{\n\n    \nreturn\n \ntask_tgid_vnr\n(\ncurrent\n);\n \n// returns current-\ntgid\n\n\n}\n\n\n\n\n\n\nThe definition says nothing of the implementation. The kernel must provide the intended behavior of the system call but is free to do so with whatever implementation it wants as long as the result is correct. [p72]\n\n\nSYSCALL_DEFINE0\n is simply a macro that defines a system call with no parameters (hence the 0). The expanded code looks like this:\n\n\ninclude/linux/syscalls.h\n\n\nasmlinkage\n \nlong\n \nsys_getpid\n(\nvoid\n);\n\n\n\n\n\n\n\n\nThe \nasmlinkage\n modifier on the function definition is a directive to tell the compiler to look only on the stack for this function\u2019s arguments. This is a required modifier for all system calls.\n\n\nThe function returns a \nlong\n. For compatibility between 32- and 64-bit systems, system calls defined to return an \nint\n in user-space return a \nlong\n in the kernel.\n\n\nThe naming convention taken with all system calls in Linux is: System call \nbar()\n is implemented in the kernel as function \nsys_bar()\n.\n\n\n\n\nSystem Call Numbers\n\n\nIn Linux, each system call is assigned a unique \nsyscall number\n that is used to reference a specific system call. When a user-space process executes a system call, the syscall number identifies which syscall was executed; the process does not refer to the syscall by name.\n\n\n\n\nWhen assigned, the syscall number cannot change; otherwise, compiled applications will break.\n\n\nIf a system call is removed, its system call number cannot be recycled, or previously compiled code would aim to invoke one system call but would in reality invoke another.\n\n\nLinux provides a \"not implemented\" system call, \nsys_ni_syscall()\n, which does nothing except return \nENOSYS\n, the error corresponding to an invalid system call. This function is used to \"plug the hole\" in the rare event that a syscall is removed or otherwise made unavailable.\n\n\n\n\nThe kernel keeps a list of all registered system calls in the system call table, stored in \nsys_call_table\n, on x86-64 it is defined in \narch/x86/kernel/syscall_64.c\n.\n\n\nThe system call numbers are defined in the file \ninclude/asm-generic/unistd.h\n.\n\n\nSystem Call Performance\n\n\nSystem calls in Linux are faster than in many other operating systems, because of:\n\n\n\n\nLinux\u2019s fast context switch times: entering and exiting the kernel is a streamlined and simple affair\n\n\nSimplicity of the system call handler and the individual system calls themselves\n\n\n\n\nSystem Call Handler\n\n\nIt is not possible for user-space applications to execute kernel code directly. They cannot simply make a function call to a method existing in kernel-space because the kernel exists in a protected memory space. Otherwise, system security and stability would be nonexistent.\n\n\nUser-space applications signal the kernel that they want to execute a system call and have the system switch to kernel mode, where the system call can be executed in kernel-space by the kernel on behalf of the application. This mechanism is software interrupt: incur an exception, and the system will switch to kernel mode and execute the \nexception handler\n. The exception handler in this case is actually the \nsystem call handler\n.\n\n\nThe defined software interrupt on x86 is interrupt number 128, which is incurred via the \nint $0x80\n instruction. It triggers a switch to kernel mode and the execution of exception vector 128, which is the system call handler. The system call handler is the aptly named function \nsystem_call()\n. It is architecture-dependent; on x86-64 it is implemented in assembly in \nentry_64.S\n (\narch/x86/kernel/entry_64.S\n).\n\n\nRecently, x86 processors added a feature known as \nsysenter\n, which provides a faster, more specialized way of trapping into a kernel to execute a system call than using the \nint\n interrupt instruction. Support for this feature was quickly added to the kernel. Regardless of how the system call handler is invoked, however, the important notion is that somehow user-space causes an exception or trap to enter the kernel.\n\n\nDenoting the Correct System Call\n\n\nFor more details of Linux system call from the assembly perspective, see \nInterfacing with Linux\n.\n\n\nSimply entering kernel-space alone is not sufficient: the system call number must be passed into the kernel.\n\n\nOn x86, the syscall number is passed to the kernel via the \neax\n register:\n\n\n\n\nBefore causing the trap into the kernel, user-space sticks in \neax\n the number corresponding to the desired system call.\n\n\nThe system call handler then reads the value from \neax\n\n\n\n\nThe \nsystem_call()\n function checks the validity of the given system call number by comparing it to \nNR_syscalls\n. If it is larger than or equal to \nNR_syscalls\n, the function returns -\nENOSYS\n. Otherwise, the specified system call is invoked:\n\n\narch/x86/kernel/entry_64.S#L487\n\n\ncall\n \n*\nsys_call_table\n(,\n%rax\n,\n8\n)\n\n\n\n\n\n\nBecause each element in the system call table is 64 bits (8 bytes), the kernel multiplies the given system call number by eight to arrive at its location in the system call table. On x86-32, the code is similar, with the 8 replaced by 4.\n\n\n\n\nParameter Passing\n\n\nIn addition to the system call number, most syscalls require that one or more parameters be passed to them. User-space must relay the parameters to the kernel during the trap. The easiest way to do this is similar to how the syscall number is passed: The parameters are stored in registers. On x86-32, the registers \nebx\n, \necx\n, \nedx\n, \nesi\n, and \nedi\n contain, in order, the first five arguments. In the unlikely case of six or more arguments, a single register is used to hold a pointer to user-space where all the parameters are stored.\n\n\nThe return value is sent to user-space also via register. On x86, it is written into the \neax\n register.\n\n\nSystem Call Implementation\n\n\nThe actual implementation of a system call in Linux does not need to be concerned with the behavior of the system call handler. Thus, adding a new system call to Linux is relatively easy. The hard work lies in designing and implementing the system call; registering it with the kernel is simple.\n\n\nImplementing System Calls\n\n\nThe first step in implementing a system call is defining its purpose and the syscall should have exactly one purpose. Multiplexing syscalls (a single system call that does wildly different things depending on a flag argument) is discouraged in Linux. \nioctl()\n is an example of what \nnot\n to do.\n\n\nThink of the new system call\u2019s arguments, return value, and error codes. The system call should have a clean and simple interface with the smallest number of arguments possible.The semantics and behavior of a system call are important; they must not change, because existing applications will come to rely on them. Many system calls provide a flag argument to address forward compatibility. The flag is not used to multiplex different behavior across a single system call (which is not acceptable), but to enable new functionality and options without breaking backward compatibility or needing to add a new system call. [p75]\n\n\nDesign the system call to be as general as possible with an eye toward the future. \nThe \npurpose\n of the system call will remain constant but its \nuses\n may change.\n Remember the Unix motto: \"Provide mechanism, not policy.\" [p75]\n\n\nWhen you write a system call, you need to realize the need for portability and robustness, not just today but in the future.The basic Unix system calls have survived this test of time; most of them are just as useful and applicable today as they were 30 years ago!\n\n\nVerifying the Parameters\n\n\nSystem calls must carefully verify all their parameters to ensure that they are valid, legal and correct to guarantee the system\u2019s security and stability. [p75]\n\n\nOne of the most important checks is the validity of any pointers that the user provides. Before following a pointer into user-space, the system must ensure that:\n\n\n\n\nThe pointer points to a region of memory in user-space. Processes must not be able to trick the kernel into reading data in kernel-space on their behalf.\n\n\nThe pointer points to a region of memory in the process\u2019s address space.The process must not be able to trick the kernel into reading someone else\u2019s data.\n\n\nThe process must not be able to bypass memory access restrictions. If reading, the memory is marked readable. If writing, the memory is marked writable. If executing, the memory is marked executable.\n\n\n\n\nThe kernel provides two methods for performing the requisite checks and the desired copy to and from user-space. \nNote kernel code must never blindly follow a pointer into user-space. One of these two methods must always be used.\n\n\n\n\ncopy_to_user()\n is for writing into user-space. It takes three parameters:\n\n\nThe first argument is the destination memory address in the process\u2019s address space.\n\n\nThe second argument is the source pointer in kernel-space.\n\n\nThe third argument is the size in bytes of the data to copy.\n\n\n\n\n\n\ncopy_from_user()\n is for reading from user-space. It is analogous to \ncopy_to_user()\n. The function reads from the second parameter into the first parameter the number of bytes specified in the third parameter.\n\n\n\n\nBoth of these functions return the number of bytes they failed to copy on error. On success, they return zero. It is standard for the syscall to return \n-EFAULT\n in the case of such an error.\n\n\nThe following example \nsilly_copy()\n uses both \ncopy_from_user()\n and \ncopy_to_user()\n. It copies data from its first parameter into its second. This is suboptimal in that it involves an intermediate and extraneous copy into kernel-space for no gain. But it helps illustrate the point:\n\n\n/*\n\n\n* silly_copy - pointless syscall that copies the len bytes from\n\n\n* \u2018src\u2019 to \u2018dst\u2019 using the kernel as an intermediary in the copy.\n\n\n* Intended as an example of copying to and from the kernel.\n\n\n*/\n\n\nSYSCALL_DEFINE3\n(\nsilly_copy\n,\n\n                \nunsigned\n \nlong\n \n*\n,\n \nsrc\n,\n\n                \nunsigned\n \nlong\n \n*\n,\n \ndst\n,\n\n                \nunsigned\n \nlong\n \nlen\n)\n\n\n{\n\n    \nunsigned\n \nlong\n \nbuf\n;\n\n\n    \n/* copy src, which is in the user\u2019s address space, into buf */\n\n    \nif\n \n(\ncopy_from_user\n(\nbuf\n,\n \nsrc\n,\n \nlen\n))\n\n        \nreturn\n \n-\nEFAULT\n;\n\n\n    \n/* copy buf into dst, which is in the user\u2019s address space */\n\n    \nif\n \n(\ncopy_to_user\n(\ndst\n,\n \nbuf\n,\n \nlen\n))\n\n        \nreturn\n \n-\nEFAULT\n;\n\n\n    \n/* return amount of data copied */\n\n    \nreturn\n \nlen\n;\n\n\n}\n\n\n\n\n\n\nBoth \ncopy_to_user()\n and \ncopy_from_user()\n may block. This occurs, for example, if the page containing the user data is not in physical memory but is swapped to disk. In that case, the process sleeps until the page fault handler can bring the page from the swap file on disk into physical memory.\n\n\nA final possible check is for valid permission. In older versions of Linux, it was standard for syscalls that require root privilege to use \nsuser()\n. This function merely checked whether a user was root; this is now removed and a finer-grained \u201ccapabilities\u201d system is in place.\n\n\nThe new system enables specific access checks on specific resources. A call to \ncapable()\n with a valid capabilities flag returns nonzero if the caller holds the specified capability and zero otherwise. For example, \ncapable(CAP_SYS_NICE)\n checks whether the caller has the ability to modify nice values of other processes. By default, the superuser possesses all capabilities and nonroot possesses none.\n\n\nThe following example is the \nreboot()\n system call. Note how its first step is ensuring that the calling process has the \nCAP_SYS_REBOOT\n. If that one conditional statement were removed, any process could reboot the system.\n\n\nkernel/sys.c#L368\n\n\nSYSCALL_DEFINE4\n(\nreboot\n,\n \nint\n,\n \nmagic1\n,\n \nint\n,\n \nmagic2\n,\n \nunsigned\n \nint\n,\n \ncmd\n,\n\n        \nvoid\n \n__user\n \n*\n,\n \narg\n)\n\n\n{\n\n    \nchar\n \nbuffer\n[\n256\n];\n\n    \nint\n \nret\n \n=\n \n0\n;\n\n\n    \n/* We only trust the superuser with rebooting the system. */\n\n    \nif\n \n(\n!\ncapable\n(\nCAP_SYS_BOOT\n))\n\n        \nreturn\n \n-\nEPERM\n;\n\n\n    \n/* For safety, we require \nmagic\n arguments. */\n\n    \nif\n \n(\nmagic1\n \n!=\n \nLINUX_REBOOT_MAGIC1\n \n||\n\n        \n(\nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2\n \n\n                    \nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2A\n \n\n            \nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2B\n \n\n                    \nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2C\n))\n\n        \nreturn\n \n-\nEINVAL\n;\n\n\n    \n/* Instead of trying to make the power_off code look like\n\n\n     * halt when pm_power_off is not set do it the easy way.\n\n\n     */\n\n    \nif\n \n((\ncmd\n \n==\n \nLINUX_REBOOT_CMD_POWER_OFF\n)\n \n \n!\npm_power_off\n)\n\n        \ncmd\n \n=\n \nLINUX_REBOOT_CMD_HALT\n;\n\n\n    \nmutex_lock\n(\nreboot_mutex\n);\n\n    \nswitch\n \n(\ncmd\n)\n \n{\n\n    \ncase\n \nLINUX_REBOOT_CMD_RESTART\n:\n\n        \nkernel_restart\n(\nNULL\n);\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_CAD_ON\n:\n\n        \nC_A_D\n \n=\n \n1\n;\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_CAD_OFF\n:\n\n        \nC_A_D\n \n=\n \n0\n;\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_HALT\n:\n\n        \nkernel_halt\n();\n\n        \ndo_exit\n(\n0\n);\n\n        \npanic\n(\ncannot halt\n);\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_POWER_OFF\n:\n\n        \nkernel_power_off\n();\n\n        \ndo_exit\n(\n0\n);\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_RESTART2\n:\n\n        \nif\n \n(\nstrncpy_from_user\n(\nbuffer\n[\n0\n],\n \narg\n,\n \nsizeof\n(\nbuffer\n)\n \n-\n \n1\n)\n \n \n0\n)\n \n{\n\n            \nret\n \n=\n \n-\nEFAULT\n;\n\n            \nbreak\n;\n\n        \n}\n\n        \nbuffer\n[\nsizeof\n(\nbuffer\n)\n \n-\n \n1\n]\n \n=\n \n\\0\n;\n\n\n        \nkernel_restart\n(\nbuffer\n);\n\n        \nbreak\n;\n\n\n\n#ifdef CONFIG_KEXEC\n\n    \ncase\n \nLINUX_REBOOT_CMD_KEXEC\n:\n\n        \nret\n \n=\n \nkernel_kexec\n();\n\n        \nbreak\n;\n\n\n#endif\n\n\n\n#ifdef CONFIG_HIBERNATION\n\n    \ncase\n \nLINUX_REBOOT_CMD_SW_SUSPEND\n:\n\n        \nret\n \n=\n \nhibernate\n();\n\n        \nbreak\n;\n\n\n#endif\n\n\n    \ndefault\n:\n\n        \nret\n \n=\n \n-\nEINVAL\n;\n\n        \nbreak\n;\n\n    \n}\n\n    \nmutex_unlock\n(\nreboot_mutex\n);\n\n    \nreturn\n \nret\n;\n\n\n}\n\n\n\n\n\n\nSee \nlinux/capability.h\n (\ninclude/linux/capability.h\n) for a list of all capabilities and what rights they entail.\n\n\nSystem Call Context\n\n\nThe kernel is in process context during the execution of a system call (\nChapter 3\n). The \ncurrent\n pointer points to the current task, which is the process that issued the syscall.\n\n\nIn process context, the kernel is capable of sleeping (for example, if the system call blocks on a call or explicitly calls \nschedule()\n) and is fully preemptible. These two points are important:\n\n\n\n\nThe capability to sleep\n means that system calls can make use of the majority of the kernel\u2019s functionality.\n\n\nThe capability to sleep greatly simplifies kernel programming (\nChapter 7\n)\n\n\nInterrupt handlers cannot sleep and thus are much more limited in what they can do than system calls running in process context.\n\n\n\n\n\n\nThe fact that \nprocess context is preemptible\n implies that, like user-space, the current task may be preempted by another task.\n\n\nBecause the new task may then execute the same system call, care must be exercised to ensure that system calls are reentrant.\n This is the same concern that symmetrical multiprocessing introduces. (Synchronizing reentrancy is covered in \nChapter 9\n).\n\n\n\n\n\n\n\n\nWhen the system call returns, control continues in \nsystem_call()\n, which ultimately switches to user-space and continues the execution of the user process.\n (\nFigure 5.2\n)\n\n\nFinal Steps in Binding a System Call\n\n\nIt is trivial to register a (official) system call after it is written:\n\n\n\n\nAdd an entry to the end of the system call table. This needs to be done for each architecture that supports the system call. The position of the syscall in the table, starting at zero, is its system call number.\n\n\nFor each supported architecture, define the syscall number in \nasm/unistd.h\n.\n\n\nCompile the syscall into the kernel image (as opposed to compiling as a module). This can be as simple as putting the system call in a relevant file in \nkernel/\n, such as \nsys.c\n, which is home to miscellaneous system calls.\n\n\n\n\nFor example of a fictional system call \nfoo()\n. We want to add \nsys_foo()\n to the system call table. For most architectures, the table is located in \nentry.S\n and looks like this (The new system call is then appended to the tail of this list):\n\n\nENTRY\n(\nsys_call_table\n)\n\n\n.\nlong\n \nsys_restart_syscall\n \n/* 0 */\n\n\n.\nlong\n \nsys_exit\n\n\n.\nlong\n \nsys_fork\n\n\n.\nlong\n \nsys_read\n\n\n.\nlong\n \nsys_write\n\n\n.\nlong\n \nsys_open\n \n/* 5 */\n\n\n...\n\n\n.\nlong\n \nsys_eventfd2\n\n\n.\nlong\n \nsys_epoll_create1\n\n\n.\nlong\n \nsys_dup3\n \n/* 330 */\n\n\n.\nlong\n \nsys_pipe2\n\n\n.\nlong\n \nsys_inotify_init1\n\n\n.\nlong\n \nsys_preadv\n\n\n.\nlong\n \nsys_pwritev\n\n\n.\nlong\n \nsys_rt_tgsigqueueinfo\n \n/* 335 */\n\n\n.\nlong\n \nsys_perf_event_open\n\n\n.\nlong\n \nsys_recvmmsg\n\n\n.\nlong\n \nsys_foo\n\n\n\n\n\n\nThough not explicitly specified, the system call is then given the next subsequent syscall number (338, in this case).\n\n\n\n\nFor each architecture you want to support, the system call must be added to the architecture\u2019s system call table.\n\n\nThe system call does not need to receive the same syscall number under each architecture, as the system call number is part of the architecture\u2019s unique ABI.\n\n\nUsually, you would want to make the system call available to each architecture.\n\n\nNote the convention of placing the number in a comment every five entries; this makes it easy to find out which syscall is assigned which number.\n\n\n\n\nNext, the system call number is added to \nasm/unistd.h\n like below:\n\n\n/*\n\n\n* This file contains the system call numbers.\n\n\n*/\n\n\n#define __NR_restart_syscall 0\n\n\n#define __NR_exit 1\n\n\n#define __NR_fork 2\n\n\n#define __NR_read 3\n\n\n#define __NR_write 4\n\n\n#define __NR_open 5\n\n\n...\n\n\n#define __NR_signalfd4 327\n\n\n#define __NR_eventfd2 328\n\n\n#define __NR_epoll_create1 329\n\n\n#define __NR_dup3 330\n\n\n#define __NR_pipe2 331\n\n\n#define __NR_inotify_init1 332\n\n\n#define __NR_preadv 333\n\n\n#define __NR_pwritev 334\n\n\n#define __NR_rt_tgsigqueueinfo 335\n\n\n#define __NR_perf_event_open 336\n\n\n#define __NR_recvmmsg 337\n\n\n#define __NR_foo\n\n\n\n\n\n\nFinally, the actual \nfoo()\n system call is implemented. Because the system call must be compiled into the core kernel image in all configurations, in this example we define it in \nkernel/sys.c\n. You should put it wherever the function is most relevant; for example, if the function is related to scheduling, you could define it in \nkernel/sched.c\n.\n\n\n#include \nasm/page.h\n\n\n\n/*\n\n\n* sys_foo \u2013 everyone\u2019s favorite system call.\n\n\n*\n\n\n* Returns the size of the per-process kernel stack.\n\n\n*/\n\n\nasmlinkage\n \nlong\n \nsys_foo\n(\nvoid\n)\n\n\n{\n\n    \nreturn\n \nTHREAD_SIZE\n;\n\n\n}\n\n\n\n\n\n\nBoot this kernel and user-space can invoke the \nfoo()\n system call\n\n\nAccessing the System Call from User-Space\n\n\nThe C library provides support for system calls. User applications can pull in function prototypes from the standard headers and link with the C library to use your system call. [p81]\n\n\nLinux provides a set of macros for wrapping access to system calls. It sets up the register contents and issues the trap instructions. These macros are named \n_syscalln()\n, where \nn\n is between 0 and 6. The number corresponds to the number of parameters passed into the syscall, because the macro needs to know how many parameters to push into registers.\n\n\nFor example, consider the system call \nopen()\n, defined as\n\n\nlong\n \nopen\n(\nconst\n \nchar\n \n*\nfilename\n,\n \nint\n \nflags\n,\n \nint\n \nmode\n)\n\n\n\n\n\n\nThe syscall macro to use this system call without explicit library support would be:\n\n\n#define __NR_open 5\n\n\n_syscall3\n(\nlong\n,\n \nopen\n,\n \nconst\n \nchar\n \n*\n,\n \nfilename\n,\n \nint\n,\n \nflags\n,\n \nint\n,\n \nmode\n)\n\n\n\n\n\n\nThe application can simply call \nopen()\n.\n\n\nAn macro has 2 + 2 \u00d7 \nn\n parameters:\n\n\n\n\nThe first parameter corresponds to the return type of the syscall.\n\n\nThe second is the name of the system call.\n\n\nThe remainder are type and name for each parameter in order of the system call.\n\n\n\n\nThe \n__NR_open\n (\narch/x86/include/asm/unistd_64.h#L19\n) is defined in \nasm/unistd.h\n; it is the system call number.\n\n\nThe \n_syscall3\n macro expands into a C function with inline assembly;\n the assembly performs the steps discussed in the previous section to push the system call number and parameters into the correct registers and issue the software interrupt to trap into the kernel. \nPlacing this macro in an application is all that is required to use the \nopen()\n system call.\n\n\nFor example of the \nfoo()\n system call, we can use it from an application like this:\n\n\n#define __NR_foo 283\n\n\n__syscall0\n(\nlong\n,\n \nfoo\n)\n\n\n\nint\n \nmain\n \n()\n\n\n{\n\n    \nlong\n \nstack_size\n;\n\n    \nstack_size\n \n=\n \nfoo\n \n();\n\n    \nprintf\n \n(\nThe kernel stack size is %ld\n\\n\n,\n \nstack_size\n);\n\n    \nreturn\n \n0\n;\n\n\n}\n\n\n\n\n\n\nWhy Not to Implement a System Call\n\n\nAdding new syscall is not encouraged, and you should otherwise exercise caution and restraint in adding one. [p82]o\n\n\nThe followings are pros and cons of implementing a new interface as a syscall:\n\n\n\n\nPros:\n\n\nSystem calls are simple to implement and easy to use.\n\n\nSystem call performance on Linux is fast.\n\n\n\n\n\n\nCons:\n\n\nYou need a syscall number, which needs to be officially assigned to you.\n\n\nAfter the system call is in a stable series kernel, it is written in stone. The interface cannot change without breaking user-space applications.\n\n\nEach architecture needs to separately register the system call and support it.\n\n\nSystem calls are not easily used from scripts and cannot be accessed directly from the filesystem.\n\n\nBecause you need an assigned syscall number, it is hard to maintain and use a system call outside of the master kernel tree.\n\n\nFor simple exchanges of information, a system call is overkill.\n\n\n\n\n\n\n\n\nThe alternatives to implementing a syscall:\n\n\n\n\nImplement a device node and \nread()\n and \nwrite()\n to it. Use \nioctl()\n to manipulate specific settings or retrieve specific information.\n\n\nCertain interfaces, such as semaphores, can be represented as file descriptors and manipulated as such.\n\n\nAdd the information as a file to the appropriate location in sysfs\n\n\n\n\nThe slow rate of addition of new system calls is a sign that Linux is a relatively stable and feature-complete operating system. [p83]\n\n\nConclusion\n\n\nIn this chapter discusses what system calls are and how they relate to library calls and the application programming interface (API). This includes how the Linux kernel implements system calls and the chain of events required to execute a system call: trapping into the kernel, transmitting the syscall number and any arguments, executing the correct system call function, and returning to user-space with the syscall\u2019s return value. [p83]", 
            "title": "Chapter 5. System Calls"
        }, 
        {
            "location": "/lkd/ch6/", 
            "text": "Chapter 6. Kernel Data Structures\n\n\nThis chapter introduces several built-in data structures for use in Linux kernel code: [p85]\n\n\n\n\nLinked lists\n\n\nQueues\n\n\nMaps\n\n\nBinary trees\n\n\n\n\nThese generic data structures are provided to encourage code reuse. Kernel developers should use these data structures whenever possible and not \"roll your own\" solutions.\n\n\nLinked Lists\n\n\nAs the simplest and most common data structure in the Linux kernel, a \nlinked list\n is a data structure that allows the storage and manipulation of a variable number of \nelements\n, called the \nnodes\n of the list.\n\n\nUnlike in a static array, the elements in a linked list are dynamically created and inserted into the list, which enables the management of a varying number of elements unknown at compile time. The elements do not necessarily occupy contiguous regions in memory and thus need to be linked together (each element in the list contains a pointer to the \nnext\n element).\n\n\nSingly and Doubly Linked Lists\n\n\nThe simplest data structure for a linked list is like:\n\n\n/* an element in a linked list */\n\n\nstruct\n \nlist_element\n \n{\n\n    \nvoid\n \n*\ndata\n;\n \n/* the payload */\n\n    \nstruct\n \nlist_element\n \n*\nnext\n;\n \n/* pointer to the next element */\n\n\n};\n\n\n\n\n\n\nThe following figure shows a linked list:\n\n\n\n\n\n\nA \nsingly linked lists\n: each element does not have a pointer to the \nprevious\n element.\n\n\nA \ndoubly linked lists\n: each element also contains a pointer to the \nprevious\n element (linked both forward and backward).\n\n\n\n\nA data structure representing a doubly linked list would look similar to this:\n\n\n/* an element in a linked list */\n\n\nstruct\n \nlist_element\n \n{\n\n    \nvoid\n \n*\ndata\n;\n \n/* the payload */\n\n    \nstruct\n \nlist_element\n \n*\nnext\n;\n \n/* pointer to the next element */\n\n    \nstruct\n \nlist_element\n \n*\nprev\n;\n \n/* pointer to the previous element */\n\n\n};\n\n\n\n\n\n\nThe following figure shows doubly linked list:\n\n\n\n\nCircular Linked Lists\n\n\nNormally, the last element in a linked list has no next element, so it is set to point to a special value, such as \nNULL\n. In a \ncircular linked list\n, last element does not point to a special value, but points back to the first value.\n\n\nCircular linked lists can come in both doubly and singly linked versions. In a circular doubly linked list, the first node\u2019s \"previous\" pointer points at the last node.\n\n\nThe following two figures are singly and doubly circular linked lists, respectively:\n\n\n\n\n\n\nMoving Through a Linked List\n\n\nTo move through a linked list, simply follow the next pointer of an element, and visit the next element. This is linear movement.\n\n\nLinked lists are ill-suited for use cases where random access is an important operation.\n Instead, you use linked lists when iterating over the whole list is important and the dynamic addition and removal of elements is required.\n\n\nIn linked list implementations:\n\n\n\n\nThe first element is often represented by a special pointer, \nhead\n, that enables easy access to the \"start\" of the list.\n\n\nIn a noncircular-linked list, the last element is delineated by its next pointer being \nNULL\n.\n\n\nIn a circular-linked list, the last element is delineated because it points to the \nhead\n element.\n\n\n\n\n[p87-88]\n\n\nThe Linux Kernel\u2019s Implementation\n\n\nThe Linux kernel\u2019s implementation is unique, in comparison to most linked list implementations including those described in the previous sections.\n\n\nThe common pattern for storing this structure in a linked list is to embed the list pointer in the structure. For example, to describe that member of the \nCanidae\n family:\n\n\nstruct\n \nfox\n \n{\n\n    \nunsigned\n \nlong\n \ntail_length\n;\n \n/* length in centimeters of tail */\n\n    \nunsigned\n \nlong\n \nweight\n;\n \n/* weight in kilograms */\n\n    \nbool\n \nis_fantastic\n;\n \n/* is this fox fantastic? */\n\n    \nstruct\n \nfox\n \n*\nnext\n;\n \n/* next fox in linked list */\n\n    \nstruct\n \nfox\n \n*\nprev\n;\n \n/* previous fox in linked list */\n\n\n};\n\n\n\n\n\n\nThe Linux kernel approach is different. Instead of turning the structure into a linked list, the Linux approach is to \"\nembed a linked list node in the structure\n\".\n\n\nThe Linked List Structure\n\n\nThe linked-list code is declared in the header file \nlinux/list.h\n (\ninclude/linux/list.h#L19\n) and the data structure is simple:\n\n\nstruct\n \nlist_head\n \n{\n\n    \nstruct\n \nlist_head\n \n*\nnext\n\n    \nstruct\n \nlist_head\n \n*\nprev\n;\n\n\n};\n\n\n\n\n\n\nThe utility is in \nhow\n the \nlist_head\n structure is used:\n\n\nstruct\n \nfox\n \n{\n\n    \nunsigned\n \nlong\n \ntail_length\n;\n \n/* length in centimeters of tail */\n\n    \nunsigned\n \nlong\n \nweight\n;\n \n/* weight in kilograms */\n\n    \nbool\n \nis_fantastic\n;\n \n/* is this fox fantastic? */\n\n    \nstruct\n \nlist_head\n \nlist\n;\n \n/* list of all fox structures */\n\n\n};\n\n\n\n\n\n\nWith this, \nlist.next\n in fox points to the next element, and \nlist.prev\n in fox points to the previous.\n\n\nThe kernel provides a family of routines to manipulate linked lists (for example, the \nlist_add()\n method adds a new node to an existing linked list). These methods accept only \nlist_head\n structures. \nUsing the macro \ncontainer_of()\n, we can easily find the parent structure containing any given member variable. In C, the offset of a given variable into a structure is fixed by the ABI at compile time.\n\n\ninclude/linux/kernel.h#L709\n\n\n#define container_of(ptr, type, member) ({ \\\n\n\n        const typeof( ((type *)0)-\nmember ) *__mptr = (ptr); \\\n\n\n        (type *)( (char *)__mptr - offsetof(type,member) );})\n\n\n\n\n\n\nUsing \ncontainer_of()\n, we can define a simple function to return the parent structure containing any \nlist_head\n:\n\n\ninclude/linux/list.h#L348\n\n\n#define list_entry(ptr, type, member) \\\n\n\n        container_of(ptr, type, member)\n\n\n\n\n\n\nWith \nlist_entry()\n, the kernel provides routines manipulate linked lists without knowing anything about the structures that the \nlist_head\n resides within.\n\n\nDefining a Linked List\n\n\nA \nlist_head\n is normally embedded inside your own structure:\n\n\nstruct\n \nfox\n \n{\n\n    \nunsigned\n \nlong\n \ntail_length\n;\n \n/* length in centimeters of tail */\n\n    \nunsigned\n \nlong\n \nweight\n;\n \n/* weight in kilograms */\n\n    \nbool\n \nis_fantastic\n;\n \n/* is this fox fantastic? */\n\n    \nstruct\n \nlist_head\n \nlist\n;\n \n/* list of all fox structures */\n\n\n};\n\n\n\n\n\n\nThe list needs to be initialized before it can be used. Because most of the elements of the linked list are created dynamically, the most common way of initializing the linked list is at runtime using \nINIT_LIST_HEAD\n:\n\n\nstruct\n \nfox\n \n*\nred_fox\n;\n\n\nred_fox\n \n=\n \nkmalloc\n(\nsizeof\n(\n*\nred_fox\n),\n \nGFP_KERNEL\n);\n\n\nred_fox\n-\ntail_length\n \n=\n \n40\n;\n\n\nred_fox\n-\nweight\n \n=\n \n6\n;\n\n\nred_fox\n-\nis_fantastic\n \n=\n \nfalse\n;\n\n\nINIT_LIST_HEAD\n(\nred_fox\n-\nlist\n);\n\n\n\n\n\n\nIf the structure is statically created at compile time, and you have a direct reference to it, you can simply do this (using \nLIST_HEAD_INIT\n):\n\n\nstruct\n \nfox\n \nred_fox\n \n=\n \n{\n\n    \n.\ntail_length\n \n=\n \n40\n,\n\n    \n.\nweight\n \n=\n \n6\n,\n\n    \n.\nlist\n \n=\n \nLIST_HEAD_INIT\n(\nred_fox\n.\nlist\n),\n\n\n};\n\n\n\n\n\n\nList Heads\n\n\nBut before we can use kernel\u2019s linked list routines to manage our structure, we need a canonical pointer to refer to the list as a whole: a \nhead\n pointer.\n\n\nSince each contains a \nlist_head\n, and we can iterate from any one node to the next. We need a special pointer that refers to your linked list, without being a list node itself. This special node is in fact a normal \nlist_head\n: [p90]\n\n\nstatic\n \nLIST_HEAD\n(\nfox_list\n);\n\n\n\n\n\n\nThis defines and initializes a \nlist_head\n named \nfox_list\n. The majority of the linked list routines accept one or two parameters: the \nhead\n node or the \nhead\n node plus an actual list node.\n\n\nManipulating Linked Lists\n\n\nThe kernel provides a family of functions to manipulate linked lists. They all take pointers to one or more \nlist_head\n structures. The functions are implemented as inline functions in generic C and can be found in \nlinux/list.h\n (\ninclude/linux/list.h\n).\n\n\nAll these functions are \nO(1)\n. This means they execute in constant time, regardless of the size of the list or any other inputs\n\n\nAdding a Node to a Linked List\n\n\nTo add a node to a linked list:\n\n\ninclude/linux/list.h#L64\n\n\nlist_add\n(\nstruct\n \nlist_head\n \n*\nnew\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function adds the new node to the given list immediately after the \nhead\n node. Because the list is circular and generally has no concept of first or last nodes, you can pass any element for head. If you pass the \"last\" element as \nhead\n, this function can be used to implement a stack.\n\n\nFor example, assume we had a new \nstruct fox\n to add to the \nfox_list\n list. We can do this:\n\n\nlist_add\n(\nf\n-\nlist\n,\n \nfox_list\n);\n\n\n\n\n\n\nTo add a node to the end of a linked list:\n\n\ninclude/linux/list.h#L78\n\n\nlist_add_tail\n(\nstruct\n \nlist_head\n \n*\nnew\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nIf you pass the \"first\" element as \nhead\n, this function can be used to implement a stack.\n\n\nDeleting a Node from a Linked List\n\n\nTo delete a node from a linked list, use \nlist_del()\n:\n\n\ninclude/linux/list.h#L103\n\n\nlist_del\n(\nstruct\n \nlist_head\n \n*\nentry\n)\n\n\n\n\n\n\nThis function removes the element entry from the list. Note that \nlist_del\n does not free any memory belonging to \nentry\n or the data structure in which it is embedded;\n this function merely removes the element from the list. After calling this, you would typically destroy your data structure and the \nlist_head\n inside it.\n\n\nFor example, to delete the fox node we previous added to \nfox_list\n:\n\n\nlist_del\n(\nf\n-\nlist\n);\n\n\n\n\n\n\nIt simply receives a specific node and modifies the pointers of the previous and subsequent nodes such that the given node is no longer part of the list. The implementation is instructive:\n\n\ninclude/linux/list.h#L90\n\n\nstatic\n \ninline\n \nvoid\n \n__list_del\n(\nstruct\n \nlist_head\n \n*\nprev\n,\n \nstruct\n \nlist_head\n \n*\nnext\n)\n\n\n{\n\n    \nnext\n-\nprev\n \n=\n \nprev\n;\n\n    \nprev\n-\nnext\n \n=\n \nnext\n;\n\n\n}\n\n\n\nstatic\n \ninline\n \nvoid\n \nlist_del\n(\nstruct\n \nlist_head\n \n*\nentry\n)\n\n\n{\n\n    \n__list_del\n(\nentry\n-\nprev\n,\n \nentry\n-\nnext\n);\n\n\n}\n\n\n\n\n\n\nTo delete a node from a linked list and reinitialize it, the kernel provides \nlist_del_init()\n:\n\n\ninclude/linux/list.h#L140\n\n\nlist_del_init\n(\nstruct\n \nlist_head\n \n*\nentry\n)\n\n\n\n\n\n\nThis function behaves the same as \nlist_del()\n, except it also reinitializes the given \nlist_head\n with the rationale that you no longer want the entry in the list, but you can reuse the data structure itself.\n\n\nMoving and Splicing Linked List Nodes\n\n\nTo move a node from one list to another:\n\n\ninclude/linux/list.h#L151\n\n\nlist_move\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function removes the list entry from its linked list and adds it to the given list after the \nhead\n element.\n\n\nTo move a node from one list to the end of another:\n\n\ninclude/linux/list.h#L162\n\n\nlist_move_tail\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function does the same as \nlist_move()\n, but inserts the list element before the head entry.\n\n\nTo check whether a list is empty:\n\n\ninclude/linux/list.h#L184\n\n\nlist_empty\n(\nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis returns nonzero if the given list is empty; otherwise, it returns zero.\n\n\nTo splice two unconnected lists together;\n\n\ninclude/linux/list.h#L290\n\n\nlist_splice\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function splices together two lists by inserting the list pointed to by \nlist\n to the given list after the element \nhead\n.\n\n\nTo splice two unconnected lists together and reinitialize the old list:\n\n\ninclude/linux/list.h#L302\n\n\nlist_splice_init\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function works the same as \nlist_splice()\n, except that the emptied list pointed to by \nlist\n is reinitialized.\n\n\nIf you already have the \nnext\n and \nprev\n pointers available, you can save a couple cycles (specifically, the dereferences to get the pointers) by calling the internal list functions directly. For example, rather than call \nlist_del(list)\n, you can call \n__list_del(prev, next)\n. [p92]\n\n\nQueues\n\n\nMaps\n\n\nBinary Trees\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np91 on \nlist_add\n and \nlist_add_tail\n:\n\n\n\n\nIf you do pass the \"last\" element, however, this function (\nlist_add\n) can be used to implement a stack\n...\nThis function (\nlist_add_tail\n) can be used to implement a queue, however, if you pass the \"first\" element.\n\n\n\n\nImplementation details are required to understand this.", 
            "title": "Chapter 6. Kernel Data Structures"
        }, 
        {
            "location": "/lkd/ch7/", 
            "text": "Chapter 7. Interrupts and Interrupt Handlers\n\n\nProcessors can be orders of magnitudes faster than the hardware they talk to; it is not ideal for the kernel to issue a request and wait for a response from slower hardware. Instead, the kernel must be free to go and handle other work, dealing with the hardware only after that hardware has actually completed its work. [p113]\n\n\nHow can the processor work with hardware without impacting the machine\u2019s overall performance? As one solution, \npolling\n incurs overhead, because it must occur repeatedly regardless of whether the hardware is active or ready. A better solution is to provide a mechanism for the hardware to signal to the kernel when attention is needed. This mechanism is called an \ninterrupt\n. This chapter dicusses interrupts and how the kernel responds to them, with special functions called \ninterrupt handlers\n.\n\n\nInterrupts\n\n\n\n\nInterrupts enable hardware to signal to the processor.\n\n\nFor example, as you type, the keyboard controller (the hardware device that manages the keyboard) issues an electrical signal to the processor to alert the operating system to newly available key presses. These electrical signals are interrupts. The processor receives the interrupt and signals the operating system to enable the operating system to respond to the new data.\n\n\n\n\n\n\nHardware devices generate interrupts asynchronously\n (with respect to the processor clock). Consequently, the kernel can be interrupted at any time to process interrupts.\n\n\n\n\nAn interrupt is produced by electronic signals from hardware devices and directed into input pins on an interrupt controller (a simple chip that multiplexes multiple interrupt lines into a single line to the processor):\n\n\n\n\nUpon receiving an interrupt, the interrupt controller sends a signal to the processor.\n\n\nThe processor detects this signal and interrupts its current execution to handle the interrupt.\n\n\nThe processor can then notify the operating system that an interrupt has occurred, and the operating system can handle the interrupt appropriately.\n\n\n\n\nDifferent devices are associated with different interrupts using a \nunique value\n associated with each interrupt. This enables the operating system to differentiate between interrupts and to know which hardware device caused which interrupt. In turn, the operating system can service each interrupt with its corresponding handler.\n\n\nThese interrupt values are often called \ninterrupt request\n (\nIRQ\n) lines:\n\n\n\n\nEach IRQ line is assigned a numeric value. For example, on the classic PC, IRQ zero is the timer interrupt and IRQ one is the keyboard interrupt.\n\n\nSome interrupts are dynamically assigned, such as interrupts associated with devices on the PCI bus. Other non-PC architectures have similar dynamic assignments for interrupt values.\n\n\nThe kernel knows that a specific interrupt is associated with a specific device, and the kernel knows this. The hardware then issues interrupts to get the kernel\u2019s attention.\n\n\n\n\nExceptions and Interrupts *\n\n\nExceptions\n are often discussed at the same time as interrupts. Unlike interrupts, exceptions occur synchronously with respect to the processor clock; they are often called \nsynchronous interrupts\n. Exceptions are produced by the processor while executing instructions either in response to a programming error (e.g. divide by zero) or abnormal conditions that must be handled by the kernel (e.g. a page fault). Because many processor architectures handle exceptions in a similar manner to interrupts, the kernel infrastructure for handling the two is similar.\n\n\nSimple definitions of the two:\n\n\n\n\nInterrupts\n: asynchronous interrupts generated by hardware.\n\n\nExceptions\n: synchronous interrupts generated by the processor.\n\n\n\n\nSystem calls (one type of exception) on the x86 architecture are implemented by the issuance of a software interrupt, which traps into the kernel and causes execution of a special system call handler. Interrupts work in a similar way, except hardware (not software) issues interrupts.\n\n\nInterrupt Handlers\n\n\nAn \ninterrupt handler\n or \ninterrupt service routine\n (ISR) is the function that the kernel runs in response to a specific interrupt:\n\n\n\n\nEach device that generates interrupts has an associated interrupt handler.\n\n\nThe interrupt handler for a device is part of the device\u2019s \ndriver\n (the kernel code that manages the device).\n\n\n\n\nIn Linux, interrupt handlers are normal C functions, which match a specific prototype and thus enables the kernel to pass the handler information in a standard way. What differentiates interrupt handlers from other kernel functions is that the kernel invokes them in response to interrupts and that they run in a special context called \ninterrupt context\n. This special context is occasionally called \natomic context\n because code executing in this context is unable to block.\n\n\nBecause an interrupt can occur at any time, an interrupt handler can be executed at any time. It is imperative that the handler runs quickly, to resume execution of the interrupted code as soon as possible. It is important that\n\n\n\n\nTo the hardware: the operating system services the interrupt without delay.\n\n\nTo the rest of the system: the interrupt handler executes in as short a period as possible.\n\n\n\n\nAt the very least, an interrupt handler\u2019s job is to acknowledge the interrupt\u2019s receipt to the hardware. However, interrupt handlers can oftern have a large amount of work to perform.\n\n\nTop Halves Versus Bottom Halves\n\n\nThese two goals of an interrupt handler conflict with one another:\n\n\n\n\nExecute quickly\n\n\nPerform a large amount of work\n\n\n\n\nBecause of these competing goals, the processing of interrupts is split into two parts, or \nhalves\n:\n\n\n\n\nTop half.\n The interrupt handler is the top half.  The top half is run immediately upon receipt of the interrupt and performs only the work that is time-critical, such as acknowledging receipt of the interrupt or resetting the hardware.\n\n\nBottom half.\n Work that can be performed later is deferred until the bottom half. The bottom half runs in the future, at a more convenient time, with all interrupts enabled.\n\n\n\n\nLinux provides various mechanisms for implementing bottom halves (discussed in \nChapter 8\n).\n\n\nFor example using the network card:\n\n\n\n\nWhen network cards receive packets from the network, the network cards immediately issue an interrupt. This optimizes network throughput and latency and avoids timeouts. [p115]\n\n\nThe kernel responds by executing the network card\u2019s registered interrupt.\n\n\nThe interrupt runs, acknowledges the hardware, copies the new networking packets into main memory, and readies the network card for more packets. These jobs are the important, time-critical, and hardware-specific work.\n\n\nThe kernel generally needs to quickly copy the networking packet into main memory because the network data buffer on the networking card is fixed and miniscule in size, particularly compared to main memory. Delays in copying the packets can result in a buffer overrun, with incoming packets overwhelming the networking card\u2019s buffer and thus packets being dropped.\n\n\nAfter the networking data is safely in the main memory, the interrupt\u2019s job is done, and it can return control of the system to whatever code was interrupted when the interrupt was generated.\n\n\n\n\n\n\nThe rest of the processing and handling of the packets occurs later, in the bottom half.\n\n\n\n\nThis chapter discusses the top half. The next chapter covers the bottom.\n\n\nRegistering an Interrupt Handler\n\n\nEach device has one associated driver. If that device uses interrupts (and most do),that driver must register one interrupt handler.\n\n\nDrivers can register an interrupt handler and enable a given interrupt line for handling with the function \nrequest_irq()\n, which is declared in \nlinux/interrupt.h\n:\n\n\ninclude/linux/interrupt.h#L117\n\n\n/* request_irq: allocate a given interrupt line */\n\n\nint\n \nrequest_irq\n(\nunsigned\n \nint\n \nirq\n,\n\n                \nirq_handler_t\n \nhandler\n,\n\n                \nunsigned\n \nlong\n \nflags\n,\n\n                \nconst\n \nchar\n \n*\nname\n,\n\n                \nvoid\n \n*\ndev\n)\n\n\n\n\n\n\n\n\nThe first parameter, \nirq\n, specifies the interrupt number to allocate\n\n\nFor some devices (e.g. legacy PC devices such as the system timer or keyboard), this value is typically hard-coded.\n\n\nFor most other devices, it is probed or otherwise determined programmatically and dynamically.\n\n\n\n\n\n\nThe second parameter, \nhandler\n, is a function pointer to the actual interrupt handler that services this interrupt. This function is invoked whenever the operating system receives the interrupt.\n\n\n\n\ninclude/linux/interrupt.h#L80\n\n\ntypedef\n \nirqreturn_t\n \n(\n*\nirq_handler_t\n)(\nint\n,\n \nvoid\n \n*\n);\n\n\n\n\n\n\nNote the specific prototype of the handler function: It takes two parameters and has a return value of \nirqreturn_t\n.\n\n\nInterrupt Handler Flags\n\n\nThe third parameter, \nflags\n, can be either zero or a bit mask of one or more of the flags defined in \nlinux/interrupt.h\n. The most important of these flags are:\n\n\ninclude/linux/interrupt.h#L56\n\n\n\n\n\n\nIRQF_DISABLED\n.\n\n\n\n\nWhen set, this flag instructs the kernel to disable all interrupts when executing this interrupt handler.\n\n\nWhen unset, interrupt handlers run with all interrupts except their own enabled.\n\n\n\n\nMost interrupt handlers do not set this flag, as disabling all interrupts is bad form. Its use is reserved for performance-sensitive interrupts that execute quickly. This flag is the current manifestation of the \nSA_INTERRUPT\n flag, which in the past distinguished between \"fast\" and \"slow\" interrupts.\n\n\n\n\n\n\nIRQF_SAMPLE_RANDOM\n. This flag specifies that interrupts generated by this device should contribute to the kernel \nentropy pool\n. The kernel entropy pool provides truly random numbers derived from various random events. If this flag is specified, the timing of interrupts from this device are fed to the pool as entropy. Do not set this if your device issues interrupts at a predictable rate (e.g. the system timer) or can be influenced by external attackers (e.g. a networking device). On the other hand, most other hardware generates interrupts at nondeterministic times and is therefore a good source of entropy.\n\n\n\n\nIRQF_TIMER\n. This flag specifies that this handler processes interrupts for the system timer.\n\n\nIRQF_SHARED\n. This flag specifies that the interrupt line can be shared among multiple interrupt handlers. Each handler registered on a given line must specify this flag; otherwise, only one handler can exist per line.\n\n\n\n\nThe fourth parameter, \nname\n, is name of the device associated with the interrupt. For example, this value for the keyboard interrupt on a PC is \"keyboard\". These text names are used by \n/proc/irq\n and \n/proc/interrupts\n.\n\n\nThe fifth parameter, \ndev\n, is used for shared interrupt lines. When an interrupt handler is freed, \ndev\n provides a unique cookie to enable the removal of only the desired interrupt handler from the interrupt line. Without this parameter, it would be impossible for the kernel to know which handler to remove on a given interrupt line. You can pass \nNULL\n here if the line is not shared, but you must pass a unique cookie if your interrupt line is shared. This pointer is also passed into the interrupt handler on each invocation. A common practice is to pass the driver\u2019s device structure:This pointer is unique and might be useful to have within the handlers.\n\n\nrequest_irq()\n returns zero on success and nonzero value indicates an error, in which case the specified interrupt handler was not registered. A common error is \n-EBUSY\n, which denotes that the given interrupt line is already in use (and either the current user or you did not specify \nIRQF_SHARED\n).\n\n\nrequest_irq()\n cannot be called from interrupt context (other situations where code cannot block), because it can block.  It is a common mistake to call \nrequest_irq()\n when it is unsafe to sleep. On registration, an entry corresponding to the interrupt is created in \n/proc/irq\n. The function \nproc_mkdir()\n creates new procfs entries. This function calls \nproc_create()\n to set up the new procfs entries, which in turn calls \nkmalloc()\n to allocate memory. \nkmalloc()\n can sleep (\nChapter 12\n).\n\n\nAn Interrupt Example\n\n\nIn a driver, requesting an interrupt line and installing a handler is done via \nrequest_irq()\n:\n\n\nif\n \n(\nrequest_irq\n(\nirqn\n,\n \nmy_interrupt\n,\n \nIRQF_SHARED\n,\n \nmy_device\n,\n \nmy_dev\n))\n \n{\n\n    \nprintk\n(\nKERN_ERR\n \nmy_device: cannot register IRQ %d\n\\n\n,\n \nirqn\n);\n\n    \nreturn\n \n-\nEIO\n;\n\n\n}\n\n\n\n\n\n\nIn this example:\n\n\n\n\nirqn\n is the requested interrupt line\n\n\nmy_interrupt\n is the handler;\n\n\nIRQF_SHARED\n specifies that the line can be shared;\n\n\nThe device is named \nmy_device\n;\n\n\nWe passed \nmy_dev\n for \ndev\n.\n\n\n\n\nOn failure, the code prints an error and returns. If the call returns zero, the handler has been successfully installed. From that point forward, the handler is invoked in response to an interrupt. It is important to initialize hardware and register an interrupt handler in the proper order to prevent the interrupt handler from running before the device is fully initialized.\n\n\nFreeing an Interrupt Handler\n\n\nWhen your driver unloads, you need to unregister your interrupt handler and disable the interrupt line, by calling:\n\n\ninclude/linux/interrupt.h#L147\n\n\nvoid\n \nfree_irq\n(\nunsigned\n \nint\n \nirq\n,\n \nvoid\n \n*\ndev\n)\n\n\n\n\n\n\n\n\nIf the specified interrupt line is not shared, this function removes the handler and disables the line.\n\n\nIf the interrupt line is shared, the handler identified via \ndev\n is removed, but the interrupt line is disabled only when the last handler is removed. With shared interrupt lines, a unique cookie is required to differentiate between the multiple handlers that can exist on a single line and enable \nfree_irq()\n to remove only the correct handler.\n\n\n\n\nIn either case (shared or unshared), if \ndev\n is non-\nNULL\n, it must match the desired handler. A call to \nfree_irq()\n must be made from process context.\n\n\nThe following table reviews the functions for registering and deregistering an interrupt handler.\n\n\n\n\n\n\n\n\nFunction\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nrequest_irq()\n\n\nRegister a given interrupt handler on a given interrupt line.\n\n\n\n\n\n\nfree_irq()\n\n\nUnregister a given interrupt handler; if no handlers remain on the line, the given interrupt line is disabled.\n\n\n\n\n\n\n\n\nWriting an Interrupt Handler", 
            "title": "Chapter 7. Interrupts and Interrupt Handlers"
        }, 
        {
            "location": "/lkd/ch8/", 
            "text": "Chapter 8. Bottom Halves and Deferring Work", 
            "title": "Chapter 8. Bottom Halves and Deferring Work"
        }, 
        {
            "location": "/lkd/ch9/", 
            "text": "Chapter 9. An Introduction to Kernel Synchronization", 
            "title": "Chapter 9. An Introduction to Kernel Synchronization"
        }, 
        {
            "location": "/lkd/ch10/", 
            "text": "Chapter 10. Kernel Synchronization Methods", 
            "title": "Chapter 10. Kernel Synchronization Methods"
        }, 
        {
            "location": "/lkd/ch11/", 
            "text": "Chapter 11. Timers and Time Management", 
            "title": "Chapter 11. Timers and Time Management"
        }, 
        {
            "location": "/lkd/ch12/", 
            "text": "Chapter 12. Memory Management\n\n\nUnlike user-space, the kernel is not always afforded the capability to easily allocate memory. This chapter discusses how the kernel handles memory and the methods used to obtain memory inside the kernel.\n\n\nPage\n\n\nTo kernel, physical pages are the basic unit of memory management. Although the processor\u2019s smallest addressable unit is a byte or a word, the \nmemory management unit\n (MMU, the hardware that manages memory and performs virtual to physical address translations) typically deals in pages. Therefore, the MMU maintains the system\u2019s page tables with page-sized granularity. In terms of virtual memory, pages are the smallest unit.\n\n\nEach architecture defines its own page size. Many architectures even support multiple page sizes.\n\n\n\n\nMost 32-bit architectures have 4KB pages;\n\n\nMost 64-bit architectures have 8KB pages.\n\n\n\n\nThis implies that on a machine with 4KB pages and 1GB of memory, physical memory is divided into 262,144 distinct pages.\n\n\nThe kernel represents every physical page on the system with a \nstruct page\n structure.  This structure is defined in \nlinux/mm_types.h\n (\ninclude/linux/mm_types.h\n). The following is a simplified the definition (two confusing unions are removed):\n\n\ninclude/linux/mm_types.h#L34\n\n\nstruct\n \npage\n \n{\n\n    \nunsigned\n \nlong\n \nflags\n;\n\n    \natomic_t\n \n_count\n;\n\n    \natomic_t\n \n_mapcount\n;\n\n    \nunsigned\n \nlong\n \nprivate\n;\n\n    \nstruct\n \naddress_space\n \n*\nmapping\n;\n\n    \npgoff_t\n \nindex\n;\n\n    \nstruct\n \nlist_head\n \nlru\n;\n\n    \nvoid\n \n*\nvirtual\n;\n\n\n};\n\n\n\n\n\n\n\n\nThe \nflags\n field stores the status of the page, such as whether the page is dirty or whether it is locked in memory. Bit flags represent the various values, so at least 32 different flags are simultaneously available. The flag values are defined in \nlinux/page-flags.h\n (\ninclude/linux/page-flags.h\n).\n\n\nThe \n_count\n field stores the usage count of the page: how many references there are to this page.\n\n\nIf \n_count\n's value is negative one (-1) indicates that no one is using the page, and it becomes available for use in a new allocation.\n\n\nKernel code should not check this field directly but instead use the function \npage_count()\n, which takes a page structure as its sole parameter. \npage_count()\n returns zero to indicate free and a positive nonzero integer when the page is in use.\n\n\nA page may be used by the page cache (in which case the \nmapping\n field points to the \naddress_space\n object associated with this page), as private data (pointed at by \nprivate\n), or as a mapping in a process\u2019s page table.\n\n\n\n\n\n\nThe \nvirtual\n field is the page\u2019s virtual address. Normally, this is simply the address of the page in virtual memory.\n\n\nSome memory (called high memory) is not permanently mapped in the kernel\u2019s address space. In that case, this field is \nNULL\n, and the page must be dynamically mapped if needed.\n\n\n\n\n\n\n\n\nThe \npage\n structure is associated with physical pages, not virtual pages; what the structure describes is transient at best. Even if the data contained in the page continues to exist, it might not always be associated with the same \npage\n structure because of swapping and so on. \nThe kernel uses this data structure to describe the associated physical page. The data structure\u2019s goal is to describe physical memory, not the data contained therein.\n\n\nThe kernel uses this structure to keep track of all the pages in the system, because the kernel needs to know whether a page is free (whether the page is not allocated). If a page is not free, the kernel needs to know who owns the page. Possible owners include (but not limited to):\n\n\n\n\nUser-space processes,\n\n\nDynamically allocated kernel data,\n\n\nStatic kernel code,\n\n\nPage cache.\n\n\n\n\nSince an instance of this structure is allocated for each physical page in the system. How bad (or good) the space consumption is from all these pages?  Assume \nstruct page\n consumes 40 bytes of memory, the system has 8KB physical pages, and the system has 4GB of physical memory. In that case, there are about 524,288 pages and page structures on the system. The page structures consume 20MB: perhaps a surprisingly large number in absolute terms, but only a small fraction of a percent relative to the system\u2019s 4GB. This is not too high a cost for managing all the system\u2019s physical pages.\n\n\nZones\n\n\nThe kernel cannot treat all pages as identical due to hardware limitations. Some pages, because of their physical address in memory, cannot be used for certain tasks. Thus, the kernel divides pages into different \nzones\n. The kernel uses the zones to group pages of similar properties.\n\n\nLinux has to deal with two shortcomings of hardware with respect to memory addressing:\n\n\n\n\nSome hardware devices can perform \nDMA\n (direct memory access) to only certain memory addresses.\n\n\nSome architectures can physically addressing larger amounts of memory than they can virtually address. Consequently, some memory is not permanently mapped into the kernel address space.\n\n\n\n\nDue to these contraints, Linux has four primary memory zones:\n\n\n\n\nZONE_DMA\n. This zone contains pages that can undergo DMA.\n\n\nZONE_DMA32\n. Like ZOME_DMA, this zone contains pages that can undergo DMA. Unlike \nZONE_DMA\n, these pages are accessible only by 32-bit devices. On some architectures, this zone is a larger subset of memory.\n\n\nZONE_NORMAL\n. This zone contains normal, regularly mapped, pages.\n\n\nZONE_HIGHMEM\n. This zone contains \"high memory\", which are pages not permanently mapped into the kernel\u2019s address space.\n\n\n\n\nThese zones are defined in \nlinux/mmzone.h\n (\ninclude/linux/mmzone.h\n)\n\n\nThe layout of the memory zones is architecture-dependent. For example:\n\n\n\n\nSome architectures can perform DMA into any memory address. In those architectures, \nZONE_DMA\n is empty and \nZONE_NORMAL\n is used for allocations regardless of their use.\n\n\nOn the x86 architecture, \nISA\n devices cannot perform DMA into the full 32-bit address space1 because ISA devices can access only the first 16MB of physical memory. Consequently, \nZONE_DMA\n on x86 consists of all memory in the range 0MB\u201316MB.\n\n\n\n\nZONE_HIGHMEM\n works similarly. On 32-bit x86 systems, \nZONE_HIGHMEM\n is all memory above the physical 896MB mark. On other architectures, \nZONE_HIGHMEM\n is empty because all memory is directly mapped. The memory contained in \nZONE_HIGHMEM\n is called \nhigh memory\n. The rest of the system\u2019s memory is called \nlow memory\n.\n\n\nZONE_NORMAL\n is the remainder after the previous two zones claim their requisite shares. On x86, \nZONE_NORMAL\n is all physical memory from 16MB to 896MB. On other architectures, \nZONE_NORMAL\n is all available memory.\n\n\nThe following table is a listing of each zone and its consumed pages on x86-32.\n\n\n\n\n\n\n\n\nZone\n\n\nDescription\n\n\nPhysical Memory\n\n\n\n\n\n\n\n\n\n\nZONE_DMA\n\n\nDMA-able pages\n\n\n 16MB\n\n\n\n\n\n\nZONE_NORMAL\n\n\nNormally addressable pages\n\n\n16\u2013896MB\n\n\n\n\n\n\nZONE_HIGHMEM\n\n\nDynamically mapped pages\n\n\n 896MB\n\n\n\n\n\n\n\n\nLinux partitions pages into zones to have a pooling in place to satisfy allocations as needed. For example, with a \nZONE_DMA\n pool, the kernel has the capability to satisfy memory allocations needed for DMA. If such memory is needed, the kernel can simply pull the required number of pages from \nZONE_DMA\n. The zones do not have any physical relevance but are simply logical groupings used by the kernel to keep track of pages.\n\n\nAlthough some allocations may require pages from a particular zone, other allocations may pull from multiple zones. For example:\n\n\n\n\nAn allocation for DMA-able memory must originate from \nZONE_DMA\n\n\nA normal allocation can come from \nZONE_DMA\n or \nZONE_NORMAL\n but not both; allocations cannot cross zone boundaries. The kernel prefers to satisfy normal allocations from the normal zone to save the pages in \nZONE_DMA\n for allocations that need it. [p234]\n\n\n\n\nNot all architectures define all zones. For example, a 64-bit architecture such as Intel\u2019s x86-64 can fully map and handle 64-bits of memory.Thus, x86-64 has no \nZONE_HIGHMEM\n and all physical memory is contained within \nZONE_DMA\n and \nZONE_NORMAL\n.\n\n\nEach zone is represented by struct zone, which is defined in \nlinux/mmzone.h\n:\n\n\ninclude/linux/mmzone.h#L280\n\n\nstruct\n \nzone\n \n{\n\n    \nunsigned\n \nlong\n \nwatermark\n[\nNR_WMARK\n];\n\n    \nunsigned\n \nlong\n \nlowmem_reserve\n[\nMAX_NR_ZONES\n];\n\n    \nstruct\n \nper_cpu_pageset\n \npageset\n[\nNR_CPUS\n];\n\n    \nspinlock_t\n \nlock\n;\n\n    \nstruct\n \nfree_area\n \nfree_area\n[\nMAX_ORDER\n]\n\n    \nspinlock_t\n \nlru_lock\n;\n\n    \nstruct\n \nzone_lru\n \n{\n\n        \nstruct\n \nlist_head\n \nlist\n;\n\n        \nunsigned\n \nlong\n \nnr_saved_scan\n;\n\n    \n}\n \nlru\n[\nNR_LRU_LISTS\n];\n\n    \nstruct\n \nzone_reclaim_stat\n \nreclaim_stat\n;\n\n    \nunsigned\n \nlong\n \npages_scanned\n;\n\n    \nunsigned\n \nlong\n \nflags\n;\n\n    \natomic_long_t\n \nvm_stat\n[\nNR_VM_ZONE_STAT_ITEMS\n];\n\n    \nint\n \nprev_priority\n;\n\n    \nunsigned\n \nint\n \ninactive_ratio\n;\n\n    \nwait_queue_head_t\n \n*\nwait_table\n;\n\n    \nunsigned\n \nlong\n \nwait_table_hash_nr_entries\n;\n\n    \nunsigned\n \nlong\n \nwait_table_bits\n;\n\n    \nstruct\n \npglist_data\n \n*\nzone_pgdat\n;\n\n    \nunsigned\n \nlong\n \nzone_start_pfn\n;\n\n    \nunsigned\n \nlong\n \nspanned_pages\n;\n\n    \nunsigned\n \nlong\n \npresent_pages\n;\n\n    \nconst\n \nchar\n \n*\nname\n;\n\n\n};\n\n\n\n\n\n\n\n\nThe \nlock\n field is a spin lock that protects the structure from concurrent access. It protects just the structure and not all the pages that reside in the zone. A specific lock does not protect individual pages, although parts of the kernel may lock the data that happens to reside in said pages.\n\n\nThe \nwatermark\n array holds the minimum, low, and high watermarks for this zone. The kernel uses watermarks to set benchmarks for suitable per-zone memory consumption. [p235]\n\n\nThe \nname\n field is a NULL-terminated string representing the name of this zone. The kernel initializes this value during boot in \nmm/page_alloc.c\n, and the three zones are given the names DMA, Normal, and HighMem.\n\n\n\n\nGetting Pages\n\n\nThis section discusses the interfaces the kernel implements to enable you to allocate and free memory within the kernel.\n\n\nThe kernel provides one low-level mechanism for requesting memory, along with several interfaces to access it. All these interfaces allocate memory with page-sized granularity and are declared in \nlinux/gfp.h\n (\ninclude/linux/gfp.h\n). The core function is:\n\n\nstruct\n \npage\n \n*\n \nalloc_pages\n(\ngfp_t\n \ngfp_mask\n,\n \nunsigned\n \nint\n \norder\n)\n\n\n\n\n\n\nThis allocates 2\norder\n (\n1 \n order\n) contiguous physical pages and returns a pointer to the first page\u2019s \npage\n structure; on error it returns \nNULL\n.\n\n\nYou can convert a given page to its logical address with the function:\n\n\nvoid\n \n*\n \npage_address\n(\nstruct\n \npage\n \n*\npage\n)\n\n\n\n\n\n\nThis returns a pointer to the logical address where the given physical page currently resides.\n\n\nIf you have no need for the actual \nstruct page\n, you can call:\n\n\nunsigned\n \nlong\n \n__get_free_pages\n(\ngfp_t\n \ngfp_mask\n,\n \nunsigned\n \nint\n \norder\n)\n\n\n\n\n\n\nThis function works the same as \nalloc_pages()\n, except that it directly returns the logical address of the first requested page. Because the pages are contiguous, the other pages simply follow from the first.\n\n\nIf you need only one page, two functions are implemented as wrappers to save you a bit of typing:\n\n\nstruct\n \npage\n \n*\n \nalloc_page\n(\ngfp_t\n \ngfp_mask\n)\n\n\nunsigned\n \nlong\n \n__get_free_page\n(\ngfp_t\n \ngfp_mask\n)\n\n\n\n\n\n\nThese functions work the same but pass zero for the order (2\n0\n = one page).\n\n\nGetting Zeroed Pages\n\n\nIf you need the returned page filled with zeros, use the function:\n\n\nunsigned\n \nlong\n \nget_zeroed_page\n(\nunsigned\n \nint\n \ngfp_mask\n)\n\n\n\n\n\n\nThis function works the same as \n__get_free_page()\n, except that the allocated page is then zero-filled (every bit of every byte is unset). This is useful for pages given to userspace because the random garbage in an allocated page is not so random; it might contain sensitive data. All data must be zeroed or otherwise cleaned before it is returned to userspace to ensure system security is not compromised.\n\n\nThe following table is a listing of all the low-level page allocation methods.\n\n\n\n\n\n\n\n\nFlag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nalloc_page(gfp_mask)\n\n\nAllocates a single page and returns a pointer to its first page\u2019s \npage\n structure\n\n\n\n\n\n\nalloc_pages(gfp_mask, order)\n\n\nAllocates 2\norder\n pages and returns a pointer to the first page\u2019s \npage\n structure\n\n\n\n\n\n\n__get_free_page(gfp_mask)\n\n\nAllocates a single page and returns a pointer to its logical address\n\n\n\n\n\n\n__get_free_pages(gfp_mask, order)\n\n\nAllocates 2\norder\n pages and returns a pointer to the first page\u2019s logical address\n\n\n\n\n\n\nget_zeroed_page(gfp_mask)\n\n\nAllocates a single page, zero its contents and returns a pointer to its logical address\n\n\n\n\n\n\n\n\nFreeing Pages\n\n\nA family of functions enables you to free allocated pages when you no longer need them:\n\n\nvoid\n \n__free_pages\n(\nstruct\n \npage\n \n*\npage\n,\n \nunsigned\n \nint\n \norder\n)\n\n\nvoid\n \nfree_pages\n(\nunsigned\n \nlong\n \naddr\n,\n \nunsigned\n \nint\n \norder\n)\n\n\nvoid\n \nfree_page\n(\nunsigned\n \nlong\n \naddr\n)\n\n\n\n\n\n\nBe careful to free only pages you allocate. Passing the wrong \nstruct page\n or address, or the incorrect order, can result in corruption. [p237]\n\n\nFor example, we want to allocate eight pages:\n\n\nunsigned\n \nlong\n \npage\n;\n\n\npage\n \n=\n \n__get_free_pages\n(\nGFP_KERNEL\n,\n \n3\n);\n\n\nif\n \n(\n!\npage\n)\n \n{\n\n    \n/* insufficient memory: you must handle this error! */\n\n    \nreturn\n \n-\nENOMEM\n;\n\n\n}\n\n\n/* \npage\n is now the address of the first of eight contiguous pages ... */\n\n\n\n\n\n\nFree the eight pages, after we are done using them:\n\n\nfree_pages\n(\npage\n,\n \n3\n);\n\n\n/*\n\n\n* our pages are now freed and we should no\n\n\n* longer access the address stored in \npage\n\n\n*/\n\n\n\n\n\n\nThe \nGFP_KERNEL\n parameter is an example of a \ngfp_mask\n flag (discussed shortly).\n\n\nA kernel allocation can fail, and your code must check for and handle such errors after the call to \n__get_free_pages()\n. \nIt therefore often makes sense to allocate your memory at the start of the routine to make handling the error easier.\n [p237]\n\n\nThese low-level page functions are useful when you need page-sized chunks of physically contiguous pages, especially if you need exactly a single page or two. For more general byte-sized allocations, the kernel provides \nkmalloc()\n.\n\n\nkmalloc()\n\n\nThe \nkmalloc()\n function is similar to user-space\u2019s \nmalloc()\n, with the exception of the additional flags parameter. The \nkmalloc()\n function is a simple interface for obtaining kernel memory in byte-sized chunks. If you need whole pages, the previously discussed interfaces might be a better choice. For most kernel allocations, \nkmalloc()\n is the preferred interface.\n\n\nThe function is declared in \nlinux/slab.h\n (\ninclude/linux/slab.h\n):\n\n\ninclude/linux/slab_def.h#L128\n\n\nvoid\n \n*\n \nkmalloc\n(\nsize_t\n \nsize\n,\n \ngfp_t\n \nflags\n)\n\n\n\n\n\n\nThe \nkmalloc()\n function returns a pointer to a region of memory that is at least \nsize\n bytes in length. It may allocate more than you asked, although you have no way of knowing how much more. Because the kernel allocator is page-based, some allocations may be rounded up to fit within the available memory. The kernel never returns less memory than requested. If the kernel is unable to find at least the requested amount, the allocation fails and the function returns \nNULL\n. The region of memory allocated is physically contiguous. Kernel allocations always succeed, unless an insufficient amount of memory is available. Thus, you must check for \nNULL\n after all calls to \nkmalloc()\n and handle the error appropriately.\n\n\nFor example:\n\n\nstruct\n \ndog\n \n*\np\n;\n\n\np\n \n=\n \nkmalloc\n(\nsizeof\n(\nstruct\n \ndog\n),\n \nGFP_KERNEL\n);\n\n\nif\n \n(\n!\np\n)\n\n    \n/* handle error ... */\n\n\n\n\n\n\nIf the \nkmalloc()\n call succeeds, \np\n now points to a block of memory that is at least the requested size.The \nGFP_KERNEL\n flag specifies the behavior of the memory allocator while trying to obtain the memory to return to the caller of \nkmalloc()\n.\n\n\ngfp_mask\n Flags\n\n\nFlags are represented by the \ngfp_t\n type, which is defined in \nlinux/types.h\n (\ninclude/linux/types.h#L179\n) as an \nunsigned int\n. \ngfp\n stands for \n__get_free_pages()\n (discussed earlier).\n\n\nThe flags are broken up into three categories:\n\n\n\n\nAction modifiers\n specify \nhow\n the kernel is supposed to allocate the requested memory. In certain situations, only certain methods can be employed to allocate memory. For example, interrupt handlers must instruct the kernel not to sleep (because interrupt handlers cannot reschedule) while allocating memory.\n\n\nZone modifiers\n specify from \nwhere\n (from which zones) to allocate memory.\n\n\nType\n specify a combination of action and zone modifiers for a certain type of memory allocation. This simplifies the specification of multiple modifiers; instead of providing a combination of action and zone modifiers, you can specify just one type flag. The \nGFP_KERNEL\n is a type flag, which is used for code in process context inside the kernel.\n\n\n\n\nAction Modifiers\n\n\nAll the flags are declared in \nlinux/gfp.h\n (\ninclude/linux/gfp.h\n). The file\n\nlinux/slab.h\n (\ninclude/linux/slab.h\n) includes this header.\n\n\nThe table below is a list of the action modifiers.\n\n\n\n\n\n\n\n\nFlag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n__GFP_WAIT\n\n\nThe allocator can sleep.\n\n\n\n\n\n\n__GFP_HIGH\n\n\nThe allocator can access emergency pools.\n\n\n\n\n\n\n__GFP_IO\n\n\nThe allocator can start disk I/O.\n\n\n\n\n\n\n__GFP_FS\n\n\nThe allocator can start filesystem I/O.\n\n\n\n\n\n\n__GFP_COLD\n\n\nThe allocator should use cache cold pages.\n\n\n\n\n\n\n__GFP_NOWARN\n\n\nThe allocator does not print failure warnings.\n\n\n\n\n\n\n__GFP_REPEAT\n\n\nThe allocator repeats the allocation if it fails, but the allocation can potentially fail.\n\n\n\n\n\n\n__GFP_NOFAIL\n\n\nThe allocator indefinitely repeats the allocation. The allocation cannot fail.\n\n\n\n\n\n\n__GFP_NORETRY\n\n\nThe allocator never retries if the allocation fails.\n\n\n\n\n\n\n__GFP_NOMEMALLOC\n\n\nThe allocator does not fall back on reserves.\n\n\n\n\n\n\n__GFP_HARDWALL\n\n\nThe allocator enforces \"hardwall\" \ncpuset\n boundaries.\n\n\n\n\n\n\n__GFP_RECLAIMABLE\n\n\nThe allocator marks the pages reclaimable.\n\n\n\n\n\n\n__GFP_COMP\n\n\nThe allocator adds compound.\n\n\n\n\n\n\n\n\nThese allocations can be specified together. For example:\n\n\nptr\n \n=\n \nkmalloc\n(\nsize\n,\n \n__GFP_WAIT\n \n|\n \n__GFP_IO\n \n|\n \n__GFP_FS\n);\n\n\n\n\n\n\nThis call instructs the page allocator (ultimately \nalloc_pages()\n) that the allocation can block, perform I/O, and perform filesystem operations. This gives the kernel great freedom in how it can find the free memory to satisfy the allocation.\n\n\nZone Modifiers\n\n\nZone modifiers specify from which memory zone the allocation should originate. Though allocations can be fulfilled from any zone, the kernel prefers \nZONE_NORMAL\n to ensure that the other zones have free pages when they are needed.\n\n\nThere are only three zone modifiers because there are only three zones other than \nZONE_NORMAL\n, as in the following table:\n\n\n\n\n\n\n\n\nFlag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n__GFP_DMA\n\n\nAllocates only from \nZONE_DMA\n\n\n\n\n\n\n__GFP_DMA32\n\n\nAllocates only from \nZONE_DMA32\n\n\n\n\n\n\n__GFP_HIGHMEM\n\n\nAllocates from \nZONE_HIGHMEM\n or \nZONE_NORMAL\n\n\n\n\n\n\n\n\n\n\nThe \n__GFP_DMA\n flag forces the kernel to satisfy the request from \nZONE_DMA\n.\n\n\nThe \n__GFP_HIGHMEM\n flag instructs the allocator to satisfy the request from either \nZONE_NORMAL\n or (preferentially) \nZONE_HIGHMEM\n.\n\n\n\n\nIf neither flag is specified, the kernel fulfills the allocation from either \nZONE_DMA\n or \nZONE_NORMAL\n, with a strong preference to satisfy the allocation from \nZONE_NORMAL\n.\n\n\nYou cannot specify \n__GFP_HIGHMEM\n to either \n__get_free_pages()\n or \nkmalloc()\n, because these both return a logical address, and not a \npage\n structure. It is possible that these functions would allocate memory not currently mapped in the kernel\u2019s virtual address space and thus, does not have a logical address. Only \nalloc_pages()\n can allocate high memory.\n\n\nThe majoriy of allocations will not specify a zone modifier because \nZONE_NORMAL\n is sufficient.\n\n\nType Flags\n\n\nThe type flags specify the required action and zone modifiers to fulfill a particular type of transaction. Therefore, kernel code tends to use the correct type flag and not specify the myriad of other flags it might need. This is both simpler and less error-prone.\n\n\nThe table below is a list of the type flags:\n\n\n\n\n\n\n\n\nFlag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGFP_ATOMIC\n\n\nThe allocation is high priority and must not sleep. This is the flag to use in interrupt handlers, in bottom halves, while holding a spinlock, and in other situations where you cannot sleep.\n\n\n\n\n\n\nGFP_NOWAIT\n\n\nLike \nGFP_ATOMIC\n, except that the call will not fallback on emergency memory pools. This increases the liklihood of the memory allocation failing.\n\n\n\n\n\n\nGFP_NOIO\n\n\nThis allocation can block, but must not initiate disk I/O. This is the flag to use in block I/O code when you cannot cause more disk I/O, which might lead to some unpleasant recursion.\n\n\n\n\n\n\nGFP_NOFS\n\n\nThis allocation can block and can initiate disk I/O, if it must, but it will not initiate a filesystem operation. This is the flag to use in filesystem code when you cannot start another filesystem operation.\n\n\n\n\n\n\nGFP_KERNEL\n\n\nThis is a normal allocation and might block. This is the flag to use in process context code when it is safe to sleep. The kernel will do whatever it has to do to obtain the memory requested by the caller. This flag should be your default choice.\n\n\n\n\n\n\nGFP_USER\n\n\nThis is a normal allocation and might block. This flag is used to allocate memory for user-space processes.\n\n\n\n\n\n\nGFP_HIGHUSER\n\n\nThis is an allocation from \nZONE_HIGHMEM\n and might block. This flag is used to allocate memory for user-space processes.\n\n\n\n\n\n\nGFP_DMA\n\n\nThis is an allocation from \nZONE_DMA\n. Device drivers that need DMA-able memory use this flag, usually in combination with one of the preceding flags.\n\n\n\n\n\n\n\n\nThe following table shows which modifiers are associated with each type flag:\n\n\n\n\n\n\n\n\nFlag\n\n\nModifier Flags\n\n\n\n\n\n\n\n\n\n\nGFP_NOFS\n\n\n(\nGFP_WAIT \n \nGFP_IO)\n\n\n\n\n\n\nGFP_KERNEL\n\n\n(\nGFP_WAIT \n \nGFP_IO \n \nGFP_FS)\n\n\n\n\n\n\nGFP_USER\n\n\n(\nGFP_WAIT \n \nGFP_IO \n \nGFP_FS)\n\n\n\n\n\n\nGFP_HIGHUSER\n\n\n(\nGFP_WAIT \n \nGFP_IO \n \nGFP_FS \n \nGFP_HIGHMEM)\n\n\n\n\n\n\nGFP_DMA\n\n\n__GFP_DMA\n\n\n\n\n\n\n\n\n\n\n\n\nThe \nGFP_KERNEL\n flag. This flag is used in vast majority of allocations. The resulting allocation is a normal priority allocation that might sleep. Because the call can block, this flag can be used only from process context that can safely reschedule (no locks are held and so on.) Because this flag does not make any stipulations as to how the kernel may obtain the requested memory, the memory allocation has a high probability of succeeding.\n\n\n\n\n\n\nThe \nGFP_ATOMIC\n flag. Because this flag specifies a memory allocation that cannot sleep, the allocation is restrictive in the memory it can obtain for the caller. If no sufficiently sized contiguous chunk of memory is available, the kernel is not likely to free memory because it cannot put the caller to sleep. Conversely, the \nGFP_KERNEL\n allocation can put the caller to sleep to swap inactive pages to disk, flush dirty pages to disk, and so on. Because \nGFP_ATOMIC\n cannot perform any of these actions, it has less of a chance of succeeding (at least when memory is low) compared to \nGFP_KERNEL\n allocations. Nonetheless, the \nGFP_ATOMIC\n flag is the only option when the current code cannot sleep, such as with interrupt handlers, softirqs, and tasklets.\n\n\n\n\n\n\nAllocations initiated with \nGFP_NOIO\n and \nGFP_NOFS\n might block, but they refrain from performing certain other operations.\n\n\n\n\nThe \nGFP_NOIO\n allocation does not initiate any disk I/O whatsoever to fulfill the request.\n\n\nThe \nGFP_NOFS\n allocation might initiate disk I/O, but does not initiate filesystem I/O.\n\n\n\n\nThey are needed for certain low-level block I/O or filesystem code. For example, \na common path in the filesystem code allocated memory without the \nGFP_NOFS\n flag, the allocation could result in more filesystem operations, which may beget other allocations. This could continue indefinitely. Such filesystem code that invokes the allocator must ensure that the allocator also does not execute itself, or else the allocation can create a deadlock.\n\n\nThe \nGFP_DMA\n flag specifes that the allocator must satisfy the request from \nZONE_DMA\n. This flag is used by device drivers, which need DMA-able memory for their devices. Normally, you combine this flag with the \nGFP_ATOMIC\n or \nGFP_KERNEL\n flag.\n\n\nThe majority of the code uses either \nGFP_KERNEL\n or \nGFP_ATOMIC\n. Regardless of the allocation type, you must check for and handle failures.\n\n\nBelow is a list of the common situations and the flags to use.\n\n\n\n\n\n\n\n\nSituation\n\n\nSolution\n\n\n\n\n\n\n\n\n\n\nProcess context, can sleep\n\n\nUse \nGFP_KERNEL\n.\n\n\n\n\n\n\nProcess context, cannot sleep\n\n\nUse \nGFP_ATOMIC\n, or perform your allocations with \nGFP_KERNEL\n at an earlier or later point when you can sleep.\n\n\n\n\n\n\nInterrupt handler\n\n\nUse \nGFP_ATOMIC\n.\n\n\n\n\n\n\nSoftirq\n\n\nUse \nGFP_ATOMIC\n.\n\n\n\n\n\n\nTasklet\n\n\nUse \nGFP_ATOMIC\n.\n\n\n\n\n\n\nNeed DMA-able memory, can sleep\n\n\nUse \n(GFP_DMA  \n GFP_KERNEL)\n.\n\n\n\n\n\n\nNeed DMA-able memory, cannot sleep\n\n\nUse \n(GFP_DMA \n GFP_ATOMIC)\n, or perform your allocation at an earlier point when you can sleep.\n\n\n\n\n\n\n\n\nkfree()\n\n\nThe counterpart to \nkmalloc()\n is \nkfree()\n, declared in \nlinux/slab.h\n:\n\n\ninclude/linux/slab.h#L144\n\n\nvoid\n \nkfree\n(\nconst\n \nvoid\n \n*\nptr\n)\n\n\n\n\n\n\nThe \nkfree()\n method frees a block of memory previously allocated with \nkmalloc()\n.\n\n\nDo not call this function on memory not previously allocated with \nkmalloc(\n), or on memory that has already been freed. Doing so is a bug, resulting in bad behavior such as freeing memory belonging to another part of the kernel.\n\n\nAs in user-space, be careful to balance your allocations with your deallocations to prevent memory leaks and other bugs.  \nkfree(NULL)\n is explicitly checked for and safe.\n\n\n[p243]\n\n\nvmalloc()\n\n\nThe \nvmalloc()\n function works in a similar fashion to \nkmalloc()\n, except \nvmalloc()\n allocates memory that is only virtually contiguous and not necessarily physically contiguous. This is similar to user-space \nmalloc()\n, the returned pages by which are contiguous within the virtual address space, but necessarily contiguous in physical RAM.\n\n\nThe \nvmalloc()\n function ensures that the pages are physically contiguous by by allocating potentially noncontiguous chunks of physical memory and \"fixing up\" the page tables to map the memory into a contiguous chunk of the logical address space.\n\n\n\n\nUsually, only hardware devices require physically contiguous memory allocations, because they live on the other side of the memory management unit and do not understand virtual addresses.\n\n\nBlocks of memory used only by software (e.g.process-related buffers) are fine using memory that is only virtually contiguous. In your programming, you never know the difference. All memory appears to the kernel as logically contiguous.\n\n\n\n\nThough physically contiguous memory is required in only certain cases, most kernel code uses \nkmalloc()\n and not \nvmalloc()\n to obtain memory primarily for performance. The \nvmalloc()\n function, to make nonphysically contiguous pages contiguous in the virtual address space, must specifically set up the page table entries. Worse, pages obtained via \nvmalloc()\n must be mapped by their individual pages (because they are not physically contiguous), which results in much greater \nTLB thrashing\n than you see when directly mapped memory is used.  Because of these concerns, \nvmalloc()\n is used only when absolutely necessary (typically, to obtain large regions of memory). For example, when modules are dynamically inserted into the kernel, they are loaded into memory created via \nvmalloc()\n.\n\n\nThe \nvmalloc()\n function is declared in \nlinux/vmalloc.h\n and defined in \nmm/vmalloc.c\n. Its usage is identical to user-space\u2019s \nmalloc()\n:\n\n\ninclude/linux/vmalloc.h#L53\n\n\nvoid\n \n*\n \nvmalloc\n(\nunsigned\n \nlong\n \nsize\n)\n\n\n\n\n\n\n\n\nThe function returns a pointer to at least \nsize\n bytes of virtually contiguous memory.\n\n\nOn error, the function returns \nNULL\n.\n\n\nThe function might sleep and thus cannot be called from interrupt context or other situations in which blocking is not permissible.\n\n\n\n\nTo free an allocation obtained via \nvmalloc()\n, use:\n\n\ninclude/linux/vmalloc.h#L62\n\n\nvoid\n \nvfree\n(\nconst\n \nvoid\n \n*\naddr\n)\n\n\n\n\n\n\n\n\nThis function frees the block of memory beginning at \naddr\n that was previously allocated via \nvmalloc()\n.\n\n\nThe function can sleep and thus cannot be called from interrupt context.\n\n\nIt has no return value\n\n\n\n\n[p245]\n\n\nSlab Layer\n\n\nFree Lists *\n\n\nTo facilitate frequent allocations and deallocations of data, programmers often introduce \nfree lists\n. A free list contains a block of available, already allocated, data structures:\n\n\n\n\nWhen code requires a new instance of a data structure, it can grab one of the structures off the free list rather than allocate the sufficient amount of memory and set it up for the data structure.\n\n\nWhen the data structure is no longer needed, it is returned to the free list instead of deallocated.\n\n\n\n\nIn this sense, the free list acts as an object cache, caching a frequently used type of object.\n\n\nA main problem with free lists in the kernel is that there exists no global control. When available memory is low, there is no way for the kernel to communicate to every free list that it should shrink the sizes of its cache to free up memory. The kernel has no understanding of the random free lists at all.To remedy this and to consolidate code, the Linux kernel provides the \nslab layer\n (also called the \nslab allocator\n). The slab layer acts as a generic data structure-caching layer.\n\n\nSlab Layer: generic data structure-caching layer *\n\n\nThe concept of a slab allocator was first implemented in Sun Microsystem\u2019s SunOS 5.4 operating system. The Linux data structure caching layer shares the same name and basic design.\n\n\nThe slab layer attempts to leverage several basic tenets:\n\n\n\n\nFrequently used data structures tend to be allocated and freed often, so cache them.\n\n\nFrequent allocation and deallocation can result in memory fragmentation (the inability to find large contiguous chunks of available memory).To prevent this, the cached free lists are arranged contiguously. Because freed data structures return to the free list, there is no resulting fragmentation.\n\n\nThe free list provides improved performance during frequent allocation and deallocation because a freed object can be immediately returned to the next allocation.\n\n\nIf the allocator is aware of concepts such as object size, page size, and total cache size, it can make more intelligent decisions.\n\n\nIf part of the cache is made per-processor (separate and unique to each processor on the system), allocations and frees can be performed without an SMP lock.\n\n\nIf the allocator is NUMA-aware, it can fulfill allocations from the same memory node as the requestor.\n\n\nStored objects can be colored to prevent multiple objects from mapping to the same cache lines.\n\n\n\n\nThe slab layer in Linux was designed and implemented with these premises in mind.\n\n\nDesign of the Slab Layer\n\n\n\n\nCaches\n. The slab layer divides different objects into groups called caches, each of which stores a different type of object. \nThere is one cache per object type.\n\n\nFor example, one cache is for process descriptors (a free list of \ntask_struct\n structures), whereas another cache is for inode objects (\nstruct inode\n).\n\n\nThe \nkmalloc()\n interface is built on top of the slab layer, using a family of general purpose caches.\n\n\n\n\n\n\nSlabs\n. The caches are divided into slabs.The slabs are composed of one or more physically contiguous pages.\n\n\nSlabs are typically composed of only a single page.\n\n\nEach cache may consist of multiple slabs.\n\n\n\n\n\n\nObjects\n. Each slab contains some number of objects, which are the data structures being cached.\n\n\nEach slab is in one of three states: full, partial, or empty:\n\n\nA \nfull slab\n has no free objects. (All objects in the slab are allocated.)\n\n\nAn \nempty slab\n has no allocated objects. (All objects in the slab are free.)\n\n\nA \npartial slab\n has some allocated objects and some free objects.\n\n\n\n\n\n\n\n\nWhen some part of the kernel requests a new object:\n\n\n\n\nThe request is satisfied from a partial slab, if one exists.\n\n\nOtherwise, the request is satisfied from an empty slab.\n\n\nIf there exists no empty slab, one is created.\n\n\n\n\nObviously, a full slab can never satisfy a request because it does not have any free objects. This strategy reduces fragmentation.\n\n\n\n\n\n\n\n\n\n\nThe following figure diagrams the relationship between caches, slabs, and objects.\n\n\n\n\nFor example of the \ninode\n structure, the in-memory representation of a disk inode (\nChapter 13\n). These structures are frequently created and destroyed, so it makes sense to manage them via the slab allocator.\n\n\n\n\nstruct inode\n is allocated from the \ninode_cachep\n cache (such a naming convention is standard.). This cache is made up of a lot of slabs because there are a lot of objects and each slab contains as many \nstruct inode\n objects as possible.\n\n\n\n\nWhen the kernel requests a new \ninode\n structure, the kernel returns a pointer to:\n\n\n\n\nAn already allocated but unused structure from a partial slab, or,\n\n\nAn empty slab, if there is no partial slab\n\n\n\n\nWhen the kernel is done using the \ninode\n object, the slab allocator marks the object as free.\n\n\n\n\n\n\nEach cache is represented by a \nkmem_cache\n structure, which contains three lists (stored inside a \nkmem_list3\n structure, which is defined in \nmm/slab.c\n)\n\n\n\n\nslabs_full\n\n\nslabs_partial\n\n\nslabs_empty\n\n\n\n\nThese lists contain all the slabs associated with the cache.\n\n\nA slab descriptor \nstruct slab\n represents each slab:\n\n\nstruct\n \nslab\n \n{\n\n    \nstruct\n \nlist_head\n \nlist\n;\n \n/* full, partial, or empty list */\n\n    \nunsigned\n \nlong\n \ncolouroff\n;\n \n/* offset for the slab coloring */\n\n    \nvoid\n \n*\ns_mem\n;\n \n/* first object in the slab */\n\n    \nunsigned\n \nint\n \ninuse\n;\n \n/* allocated objects in the slab */\n\n    \nkmem_bufctl_t\n \nfree\n;\n \n/* first free object, if any */\n\n\n};\n\n\n\n\n\n\nSlab descriptors are allocated either outside the slab in a general cache or inside the slab itself, at the beginning. The descriptor is stored inside the slab if the total size of the slab is sufficiently small, or if internal slack space is sufficient to hold the descriptor.\n\n\nThe slab allocator creates new slabs by interfacing with the low-level kernel page allocator via \n__get_free_pages()\n:\n\n\nmm/slab.c#L1609\n\n\nstatic\n \nvoid\n \n*\nkmem_getpages\n(\nstruct\n \nkmem_cache\n \n*\ncachep\n,\n \ngfp_t\n \nflags\n,\n \nint\n \nnodeid\n)\n\n\n{\n\n    \nstruct\n \npage\n \n*\npage\n;\n\n    \nvoid\n \n*\naddr\n;\n\n    \nint\n \ni\n;\n\n\n    \nflags\n \n|=\n \ncachep\n-\ngfpflags\n;\n\n    \nif\n \n(\nlikely\n(\nnodeid\n \n==\n \n-\n1\n))\n \n{\n\n        \naddr\n \n=\n \n(\nvoid\n*\n)\n__get_free_pages\n(\nflags\n,\n \ncachep\n-\ngfporder\n);\n\n        \nif\n \n(\n!\naddr\n)\n\n            \nreturn\n \nNULL\n;\n\n        \npage\n \n=\n \nvirt_to_page\n(\naddr\n);\n\n    \n}\n \nelse\n \n{\n\n        \npage\n \n=\n \nalloc_pages_node\n(\nnodeid\n,\n \nflags\n,\n \ncachep\n-\ngfporder\n);\n\n        \nif\n \n(\n!\npage\n)\n\n            \nreturn\n \nNULL\n;\n\n        \naddr\n \n=\n \npage_address\n(\npage\n);\n\n    \n}\n\n\n    \ni\n \n=\n \n(\n1\n \n \ncachep\n-\ngfporder\n);\n\n    \nif\n \n(\ncachep\n-\nflags\n \n \nSLAB_RECLAIM_ACCOUNT\n)\n\n        \natomic_add\n(\ni\n,\n \nslab_reclaim_pages\n);\n\n    \nadd_page_state\n(\nnr_slab\n,\n \ni\n);\n\n    \nwhile\n \n(\ni\n--\n)\n \n{\n\n      \nSetPageSlab\n(\npage\n);\n\n      \npage\n++\n;\n\n    \n}\n\n    \nreturn\n \naddr\n;\n\n\n}\n\n\n\n\n\n\nThis function uses \n__get_free_pages()\n to allocate memory sufficient to hold the\ncache:\n\n\n\n\nThe first parameter \ncachep\n points to the specific cache that needs more pages.\n\n\nThe second parameter \nflags\n points to the flags given to \n__get_free_pages()\n. It adds default flags that the cache requires to the \nflags\n parameter.\n\n\nThe third parameter \nnodeid\n makes the allocator \nNUMA\n-aware. When \nnodeid\n is not negative one, the allocator attempts to fulfill the allocation from the same memory node that requested the allocation. This provides better performance on NUMA systems, in which accessing memory outside your node results in a performance penalty.\n\n\n\n\nA simplified version \nkmem_getpages()\n that ignores NUMA-aware code (for educational purpose) is like:\n\n\nstatic\n \ninline\n \nvoid\n \n*\n \nkmem_getpages\n(\nstruct\n \nkmem_cache\n \n*\ncachep\n,\n \ngfp_t\n \nflags\n)\n\n\n{\n\n    \nvoid\n \n*\naddr\n;\n\n    \nflags\n \n|=\n \ncachep\n-\ngfpflags\n;\n\n    \naddr\n \n=\n \n(\nvoid\n*\n)\n \n__get_free_pages\n(\nflags\n,\n \ncachep\n-\ngfporder\n);\n\n\n    \nreturn\n \naddr\n;\n\n\n}\n\n\n\n\n\n\nMemory is freed by \nkmem_freepages()\n, which calls \nfree_pages()\n on the given cache\u2019s pages.\n\n\nThe point of the slab layer is to refrain from allocating and freeing pages. In turn, the slab layer invokes the page allocation function only when there does not exist any partial or empty slabs in a given cache.The freeing function is called only when available memory grows low and the system is attempting to free memory, or when a cache is explicitly destroyed.\n\n\nThe slab layer is managed on a per-cache basis through a simple interface, which is exported to the entire kernel. The interface enables the creation and destruction of new caches and the allocation and freeing of objects within the caches. The sophisticated management of caches and the slabs within is entirely handled by the internals of the slab layer. After you create a cache, the slab layer works just like a specialized allocator for the specific type of object.\n\n\nSlab Allocator Interface\n\n\nA new cache is created via \nkmem_cache_create()\n:\n\n\n/mm/slab.c#L2098\n\n\nstruct\n \nkmem_cache\n \n*\n \nkmem_cache_create\n(\nconst\n \nchar\n \n*\nname\n,\n\n                                      \nsize_t\n \nsize\n,\n\n                                      \nsize_t\n \nalign\n,\n\n                                      \nunsigned\n \nlong\n \nflags\n,\n\n                                      \nvoid\n \n(\n*\nctor\n)(\nvoid\n \n*\n));\n\n\n\n\n\n\n\n\nThe first parameter \nname\n is a string storing the name of the cache.\n\n\nThe second parameter \nsize\n is the size of each element in the cache.\n\n\nThe third parameter \nalign\n is the offset of the first object within a slab, which ensures a particular alignment within the page. A value of zero results in the standard alignment.\n\n\nThe \nflags\n parameter specifies optional settings controlling the cache\u2019s behavior. It can be zero, specifying no special behavior, or one or more of the following flags OR\u2019ed together:\n\n\nSLAB_HWCACHE_ALIGN\n instructs the slab layer to align each object within a slab to a cache line, which prevents \"false sharing\" (two or more objects mapping to the same cache line despite existing at different addresses in memory).\n\n\nThis improves performance but comes at a cost of increased \nmemory footprint\n because the stricter alignment results in more wasted slack space.\n\n\nHow large the increase in memory consumption is depends on the size of the objects and how they naturally align with respect to the system\u2019s cache lines. For frequently used caches in performance-critical code, setting this option is a good idea.\n\n\n\n\n\n\nSLAB_POISON\n causes the slab layer to fill the slab with a known value (\na5a5a5a5\n). This is called \npoisoning\n and is useful for catching access to uninitialized memory.\n\n\nSLAB_RED_ZONE\n causes the slab layer to insert \"red zones\" around the allocated memory to help detect buffer overruns.\n\n\nSLAB_PANIC\n causes the slab layer to panic if the allocation fails. This flag is useful when the allocation must not fail, e.g. allocating the VMA structure cache (\nChapter 15\n) during bootup.\n\n\nSLAB_CACHE_DMA\n instructs the slab layer to allocate each slab in DMA-able memory. This is needed if the allocated object is used for DMA and must\nreside in \nZONE_DMA\n; otherwise do not set it.\n\n\n\n\n\n\nThe final parameter \nctor\n is a constructor for the cache. The constructor is called whenever new pages are added to the cache. In practice, caches in the Linux kernel do not often utilize a constructor.\n\n\n\n\nkmem_cache_destroy\n destroy a cache:\n\n\nmm/slab.c#L2543\n\n\nint\n \nkmem_cache_destroy\n(\nstruct\n \nkmem_cache\n \n*\ncachep\n)\n\n\n\n\n\n\nThis function is invoked from module shutdown code in modules that create their own caches. It must not be called from interrupt context because it may sleep.The caller of this function must ensure two conditions before invoking this function:\n\n\n\n\nAll slabs in the cache are empty. Indeed, if an object in one of the slabs were still allocated and in use, how could the cache be destroyed?\n\n\nNo one accesses the cache during and after a call to \nkmem_cache_destroy()\n. The caller must ensure this synchronization\n\n\n\n\nAllocating from the Cache\n\n\n[p250]\n\n\nExample of Using the Slab Allocator\n\n\n[p251]\n\n\nStatically Allocating on the Stack\n\n\nUser-space can afforded large, dynamically growing stack, whereas the the kernel\u2019s stack is small and fixed.\n\n\nThe size of the per-process kernel stacks depends on both the architecture and a compile-time\noption. Historically, the kernel stack has been two pages per process.This is usually:\n\n\n\n\n8KB for 32-bit architectures (with 4KB pages)\n\n\n16KB for 64-bit architectures (wtih 8KB pages)\n\n\n\n\nSingle-Page Kernel Stacks\n\n\nEarly in the 2.6 kernel series, an option was introduced to move to single-page kernel stacks, where each process is given only a single page (4KB on 32-bit architectures and 8KB on 64-bit architectures). This was done for two reasons:\n\n\n\n\nIt results in a page with less memory consumption per process.\n\n\nAs uptime increases, it becomes increasingly hard to find two physically contiguous unallocated pages. Physical memory becomes fragmented, and the resulting VM pressure from allocating a single new process is expensive.\n\n\n\n\nThere is one more complication. \nEach process\u2019s entire call chain has to fit in its kernel stack.\n Historically, however, interrupt handlers also used the kernel stack of the process they interrupted, thus they too had to fit. This was efficient and simple, but it placed even tighter constraints on the already meager kernel stack. When the stack moved to only a single page, interrupt handlers no longer fit.\n\n\nInterrupt stacks\n\n\nTo rectify this problem, the kernel developers implemented a new feature: interrupt stacks. \nInterrupt stacks provide a single per-processor stack used for interrupt handlers. With this option, interrupt handlers no longer share the kernel stack of the interrupted process. \n Instead, they use their own stacks. This consumes only a single page per processor.\n\n\nTo summarize, kernel stacks are either one or two pages, depending on compile-time configuration options. The stack can therefore range from 4KB to 16KB. Historically, interrupt handlers shared the stack of the interrupted process. When single page stacks are enabled, interrupt handlers are given their own stacks. In any case, unbounded recursion and \nalloca()\n are obviously not allowed.\n\n\nPlaying Fair on the Stack\n\n\nIn any given function, you must keep stack usage to a minimum. You should keep the sum of all local (automatic) variables in a function to a maximum of a couple hundred bytes. Performing a large static allocation on the stack (e.g. a large array or structure) is dangerous. Otherwise, stack allocations are performed in the kernel just as in user-space.\n\n\nStack overflows occur silently and will\nundoubtedly result in problems. Because the kernel does not make any effort to manage\nthe stack, when the stack overflows, the excess data simply spills into whatever exists at\nthe tail end of the stack, the first thing of which is the \nthread_info\n structure, which is allocated at the end of each process\u2019s kernel stack (\nChapter 3\n).\n\n\nBeyond the stack, any kernel data might lurk.At best, the machine will crash when the stack overflows. At worst, the overflow will silently corrupt data. Therefore, it is wise to use a dynamic allocation scheme (discussed perviouly in this chapter) for any large memory allocations.\n\n\nHigh Memory Mappings\n\n\nBy definition, pages in high memory might not be permanently mapped into the kernel\u2019s (virtual) address space. Thus, pages obtained via \nalloc_pages()\n with the \n__GFP_HIGHMEM\n flag might not have a logical address (see relevant text in \nZone Modifers\n subsection).\n\n\nOn the x86 architecture, all physical memory beyond the 896MB mark is high memory and is not permanently or automatically mapped into the kernel\u2019s address space, despite x86 processors being capable of physically addressing up to 4GB (64GB with \nPAE\n) of physical RAM. After they are allocated, these pages must be mapped into the kernel\u2019s logical address space. On x86, pages in high memory are mapped somewhere between the 3GB and 4GB mark.\n\n\nPermanent Mappings\n\n\nTo map a given page structure into the kernel\u2019s address space, use this function, declared in \nlinux/highmem.h\n:\n\n\ninclude/linux/highmem.h#L58\n\n\nvoid\n \n*\nkmap\n(\nstruct\n \npage\n \n*\npage\n)\n\n\n\n\n\n\nThis function works on either high or low memory:\n\n\n\n\nIf the \npage\n structure belongs to a page in low memory, the page\u2019s virtual address is simply returned.\n\n\nIf the page resides in high memory, a permanent mapping is created and the address is returned.\n\n\n\n\nThe function may sleep, so \nkmap()\n works only in process context.\n\n\nBecause the number of permanent mappings are limited, high memory should be unmapped when no longer needed. This is done via the \nkunmap\n function, which unmaps the given page:\n\n\nvoid\n \nkunmap\n(\nstruct\n \npage\n \n*\npage\n)\n\n\n\n\n\n\nTemporary Mappings\n\n\nWhen a mapping must be created but the current context cannot sleep, the kernel provides \ntemporary mappings\n (also called \natomic mappings\n). The kernel can atomically map a high memory page into one of the reserved mappings (which can hold temporary mappings). Consequently, a temporary mapping can be used in places that cannot sleep, such as interrupt handlers, because obtaining the mapping never blocks.\n\n\nSetting up a temporary mapping is done via \nkmap_atomic()\n:\n\n\ninclude/linux/highmem.h#L68\n\n\nvoid\n \n*\nkmap_atomic\n(\nstruct\n \npage\n \n*\npage\n,\n \nenum\n \nkm_type\n \ntype\n)\n\n\n\n\n\n\n\n\nThe \ntype\n parameter is one of the following enumerations defined in \nasm-generic/kmap_types.h\n, which describe the purpose of the temporary mapping.\n\n\n\n\ninclude/asm-generic/kmap_types.h\n\n\nenum\n \nkm_type\n \n{\n\n    \nKM_BOUNCE_READ\n,\n\n    \nKM_SKB_SUNRPC_DATA\n,\n\n    \nKM_SKB_DATA_SOFTIRQ\n,\n\n    \nKM_USER0\n,\n\n    \nKM_USER1\n,\n\n    \nKM_BIO_SRC_IRQ\n,\n\n    \nKM_BIO_DST_IRQ\n,\n\n    \nKM_PTE0\n,\n\n    \nKM_PTE1\n,\n\n    \nKM_PTE2\n,\n\n    \nKM_IRQ0\n,\n\n    \nKM_IRQ1\n,\n\n    \nKM_SOFTIRQ0\n,\n\n    \nKM_SOFTIRQ1\n,\n\n    \nKM_SYNC_ICACHE\n,\n\n    \nKM_SYNC_DCACHE\n,\n\n    \nKM_UML_USERCOPY\n,\n\n    \nKM_IRQ_PTE\n,\n\n    \nKM_NMI\n,\n\n    \nKM_NMI_PTE\n,\n\n    \nKM_TYPE_NR\n\n\n};\n\n\n\n\n\n\nThis function does not block and thus can be used in interrupt context and other places that cannot reschedule. It also disables kernel preemption, which is needed because the mappings are unique to each processor and a reschedule might change which task is running on which processor.\n\n\nThe mapping is undone via:\n\n\nvoid\n \nkunmap_atomic\n(\nvoid\n \n*\nkvaddr\n,\n \nenum\n \nkm_type\n \ntype\n)\n\n\n\n\n\n\nThis function also does not block. In many architectures it does not do anything at all except enable kernel preemption, because a temporary mapping is valid only until the next temporary mapping. Thus, the kernel can just \"forget about\" the \nkmap_atomic()\n mapping, and \nkunmap_atomic()\n does not need to do anything special. The next atomic mapping then simply overwrites the previous one.\n\n\nPer-CPU Allocations\n\n\nModern SMP-capable operating systems use per-CPU data (data that is unique to a given processor). Typically, per-CPU data is stored in an array. Each item in the array corresponds to a possible processor on the system. The current processor number indexes this array (from 2.4 to 2.6 kernel). [p255] You declare the data as:\n\n\nunsigned\n \nlong\n \nmy_percpu\n[\nNR_CPUS\n];\n\n\n\n\n\n\nThen you can access it as:\n\n\nint\n \ncpu\n;\n\n\n\ncpu\n \n=\n \nget_cpu\n();\n \n/* get current processor and disable kernel preemption */\n\n\nmy_percpu\n[\ncpu\n]\n++\n;\n \n/* ... or whatever */\n\n\nprintk\n(\nmy_percpu on cpu=%d is %lu\n\\n\n,\n \ncpu\n,\n \nmy_percpu\n[\ncpu\n]);\n\n\nput_cpu\n();\n \n/* enable kernel preemption */\n\n\n\n\n\n\nNo lock is required because this data is unique to the current processor. If no processor touches this data except the current, no concurrency concerns exist, and the current processor can safely access the data without lock.\n\n\nKernel preemption is the only concern with per-CPU data, which poses two problems:\n\n\n\n\nIf your code is preempted and reschedules on another processor, the \ncpu\n variable is no longer valid because it points to the wrong processor. (In general, code cannot sleep after obtaining the current processor.)\n\n\nIf another task preempts your code, it can concurrently access \nmy_percpu\n on the same processor, which is a race condition.\n\n\n\n\nThe call \nget_cpu()\n, on top of returning the current processor number, also disables kernel preemption. The corresponding call to \nput_cpu()\n enables kernel preemption. If you use a call to \nsmp_processor_id()\n to get the current processor number, kernel preemption is not disabled. Always use the aforementioned methods to remain safe.\n\n\nThe New \npercpu\n Interface\n\n\nThe 2.6 kernel introduced a new interface, \npercpu\n, for creating and manipulating per-CPU data. This interface generalizes the previous example. Creation and manipulation of per-CPU data is simplified with this new approach.\n\n\nThe previously discussed method of creating and accessing per-CPU data is still valid and accepted. This new interface, however, grew out of the needs for a simpler and more powerful method for manipulating per-CPU data on large symmetrical multiprocessing computers.\n\n\nThe header \nlinux/percpu.h\n (\ninclude/linux/percpu.h\n) declares all the routines. You can find the actual definitions there, in \nmm/slab.c\n, and in \nasm/percpu.h\n.\n\n\nPer-CPU Data at Compile-Time\n\n\nDefine a per-CPU variable at compile time:\n\n\nDEFINE_PER_CPU\n(\ntype\n,\n \nname\n);\n\n\n\n\n\n\nThis creates an instance of a variable of type \ntype\n, named \nname\n, for each processor on the system. If you need a declaration of the variable elsewhere, to avoid compile warnings, use the following macro:\n\n\nDECLARE_PER_CPU\n(\ntype\n,\n \nname\n);\n\n\n\n\n\n\nYou can manipulate the variables with the \nget_cpu_var()\n and \nput_cpu_var()\n routines. A call to \nget_cpu_var()\n returns an lvalue for the given variable on the current processor. It also disables preemption, which \nput_cpu_var()\n correspondingly enables.\n\n\nget_cpu_var\n(\nname\n)\n++\n;\n \n/* increment name on this processor */\n\n\nput_cpu_var\n(\nname\n);\n \n/* done; enable kernel preemption */\n\n\n\n\n\n\nYou can obtain the value of another processor\u2019s per-CPU data, too:\n\n\nper_cpu\n(\nname\n,\n \ncpu\n)\n++\n;\n \n/* increment name on the given processor */\n\n\n\n\n\n\nYou need to be careful with this approach because \nper_cpu()\n neither disables kernel preemption nor provides any sort of locking mechanism.The lockless nature of per-CPU data exists only if the current processor is the only manipulator of the data. If other processors touch other processors\u2019 data, you need locks. \nChapter 9\n and \nChapter 10\n discuss locking.\n\n\nThese compile-time per-CPU examples do not work for modules because the linker actually creates them in a unique executable section (\n.data.percpu\n). If you need to access per-CPU data from modules, or if you need to create such data dynamically, you cannot use compile-time per-CPU data.\n\n\nPer-CPU Data at Runtime\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np235 on zones:\n\n\n\n\nA specific lock does not protect individual pages, although parts of the kernel may lock the data that happens to reside in said pages.\n\n\n\n\np244 on \nvmalloc()\n:\n\n\n\n\nThe \nvmalloc()\n function, to make nonphysically contiguous pages contiguous in the virtual address space, must specifically set up the page table entries. Worse, pages obtained via \nvmalloc()\n must be mapped by their individual pages (because they are not physically contiguous), which results in much greater \nTLB thrashing\n than you see when directly mapped memory is used.\n\n\n\n\np248 on slab descriptors:\n\n\n\n\nThe descriptor is stored inside the slab if the total size of the slab is sufficiently small, or if internal slack space is sufficient to hold the descriptor.\n\n\n\n\np249 on \nkmem_getpages()\n:\n\n\n\n\nFor educational purposes, we can ignore the NUMA-aware code and write a simple \nkmem_getpages()\n:\n\n\n\n\nstatic\n \ninline\n \nvoid\n \n*\n \nkmem_getpages\n(\nstruct\n \nkmem_cache\n \n*\ncachep\n,\n \ngfp_t\n \nflags\n)\n\n\n{\n\n    \nvoid\n \n*\naddr\n;\n\n    \nflags\n \n|=\n \ncachep\n-\ngfpflags\n;\n\n    \naddr\n \n=\n \n(\nvoid\n*\n)\n \n__get_free_pages\n(\nflags\n,\n \ncachep\n-\ngfporder\n);\n\n\n    \nreturn\n \naddr\n;\n\n\n}\n\n\n\n\n\n\nThe \"educational\" code merely wraps around \n__get_free_pages\n without any slab related code. WTF?\n\n\np250 on flags to \nkmem_cache_create()\n:\n\n\n\n\nSLAB_HWCACHE_ALIGN\n instructs the slab layer to align each object within a slab to a cache line, which prevents \"false sharing\" (two or more objects mapping to the same cache line despite existing at different addresses in memory). This improves performance but comes at a cost of increased memory footprint because the stricter alignment results in more wasted slack space. How large the increase in memory consumption is depends on the size of the objects and how they naturally align with respect to the system\u2019s cache lines. For frequently used caches in performance-critical code, setting this option is a good idea; otherwise, think twice.\n\n\n\n\np253 on single-page kernel stacks\n\n\n\n\nWhen single page stacks are enabled, interrupt handlers are given their own stacks. In any case, unbounded recursion and \nalloca()\n are obviously not allowed.\n\n\n\n\nWhat is unbounded recursion and \nalloca()\n?", 
            "title": "Chapter 12. Memory Management"
        }, 
        {
            "location": "/lkd/ch13/", 
            "text": "Chapter 13. The Virtual Filesystem\n\n\n\n\nAlthough the kernel developers may shun C++ and other explicitly object-oriented languages, thinking in terms of objects is often useful.\n\nRobert Love\n\n\n\n\nThe \nVirtual Filesystem\n (VFS), sometimes called the \nVirtual File Switch\n is the subsystem of the kernel that implements the file and filesystem-related interfaces to user-space. All filesystems rely on the VFS not only to coexist but also to interoperate. This enables programs to use standard Unix system calls to read and write to different filesystems, even on different media.\n\n\nCommon Filesystem Interface\n\n\nThe VFS is the glue that enables system calls such as \nopen()\n, \nread()\n, and \nwrite()\n to work regardless of the filesystem or underlying physical medium. The system calls work between these different filesystems and media; we can use standard system calls to copy or move files from one filesystem to another. Modern operating systems, such as Linux, abstract access to the filesystems via a virtual interface that such interoperation and generic access is possible. [p262]\n\n\nNew filesystems and new varieties of storage media can find their way into Linux, and programs need not be rewritten or even recompiled.\n\n\nThe VFS and the block I/O layer (\nChapter 14\n) provide the abstractions, interfaces, and glue that allow user-space programs to issue generic system calls to access files via a uniform naming policy on any filesystem, which itself exists on any storage medium.\n\n\nFilesystem Abstraction Layer\n\n\nSuch a generic interface for any type of filesystem is feasible only because the kernel implements an abstraction layer around its low-level filesystem interface. This abstraction layer enables Linux to support different filesystems, even if they differ in supported features or behavior.\n\n\nThis is possible because the VFS provides a common file model that can represent any filesystem\u2019s general feature set and behavior. It is biased toward Unix-style filesystems. Regardless, wildly differing filesystem types are still supportable in Linux, from DOS\u2019s FAT to Windows\u2019s NTFS to many Unix-style and Linux-specific filesystems.\n\n\nThe abstraction layer works by defining the basic conceptual interfaces and data structures that all filesystems support. The actual filesystem code hides the implementation details. To the VFS layer and the rest of the kernel, each filesystem looks the same. They all support notions such as files and directories, and they all support operations such as creating and deleting files.\n\n\nThe result is a general abstraction layer that enables the kernel to support many types of filesystems easily and cleanly.The filesystems are programmed to provide the abstracted interfaces and data structures the VFS expects; in turn, the kernel easily works with any filesystem and the exported user-space interface seamlessly works on any filesystem.\n\n\nNothing in the kernel needs to understand the underlying details of the filesystems, except the filesystems themselves. For example, consider a simple user-space program that does:\n\n\nret\n \n=\n \nwrite\n \n(\nfd\n,\n \nbuf\n,\n \nlen\n);\n\n\n\n\n\n\nThis system call writes the \nlen\n bytes pointed to by \nbuf\n into the current position in the file represented by the file descriptor \nfd\n.\n\n\n\n\nThis system call is first handled by a generic \nsys_write()\n system call that determines the actual file writing method for the filesystem\non which \nfd\n resides.\n\n\nThe generic write system call then invokes this method, which is part\nof the filesystem implementation, to write the data to the media (or whatever this filesystem\ndoes on write).\n\n\n\n\nThe following figure shows the flow from user-space\u2019s \nwrite()\n call through the data arriving on the physical media. On one side of the system call is the generic VFS interface, providing the frontend to user-space; on the other side of the system call is the filesystem-specific backend, dealing with the implementation details.\n\n\n\n\nUnix Filesystems\n\n\nHistorically, Unix has provided four basic filesystem-related abstractions:\n\n\n\n\nFiles\n\n\nDirectory entries\n\n\ninodes\n\n\nMount points\n\n\n\n\nFilesystem and namespace *\n\n\nA \nfilesystem\n is a hierarchical storage of data adhering to a specific structure. Filesystems contain files, directories, and associated control information. Typical operations performed on filesystems are creation, deletion, and mounting. In Unix, filesystems are mounted at a specific mount point in a global hierarchy known as a \nnamespace\n. (Linux has made this hierarchy per-process, to give a unique namespace to each process.  Because each process inherits its parent\u2019s namespace unless you specify otherwise, there is seemingly one global namespace.) This enables all mounted filesystems to appear as entries in a single tree.\n\n\nContrast this single, unified tree with the behavior of DOS and Windows, which break the file namespace up into drive letters, such as \nC:\n. This breaks the namespace up among device and partition boundaries, \"leaking\" hardware details into the filesystem abstraction. As this delineation may be arbitrary and even confusing to the user, it is inferior to Linux\u2019s unified namespace\n\n\nFiles and directories *\n\n\nA \nfile\n is an ordered string of bytes. The first byte marks the beginning of the file, and the last byte marks the end of the file. Each file is assigned a human-readable name for identification by both the system and the user. Typical file operations are read, write, create, and delete. The Unix concept of the file is in stark contrast to record-oriented filesystems, such as OpenVMS\u2019s Files-11. \nRecord-oriented filesystems\n provide a richer, more structured representation of files than Unix\u2019s simple byte-stream abstraction, at the cost of simplicity and flexibility.\n\n\nFiles are organized in directories. A \ndirectory\n is analogous to a folder and usually contains related files. Directories can also contain other directories, called subdirectories. In this fashion, directories may be nested to form paths. Each component of a path is called a directory entry. A path example is \n/home/wolfman/butter\n: the root directory \n/\n, the directories \nhome\n and \nwolfman\n, and the file \nbutter\n are all directory entries, called \ndentries\n. In Unix, directories are actually normal files that simply list the files contained therein. Because a directory is a file to the VFS, the same operations performed on files can be performed on directories.\n\n\nFile metadata, inode and superblock *\n\n\nUnix systems separate the concept of a file from any associated information about it, such as access permissions, size, owner, creation time, and so on. This information is sometimes called \nfile metadata\n (data about the file\u2019s data) and is stored in a separate data structure from the file, called the \ninode\n. This name is short for index node, although these days the term inode is much more ubiquitous.\n\n\nAll this information is tied together with the filesystem\u2019s own control information, which is stored in the \nsuperblock\n. The superblock is a data structure containing information about the filesystem as a whole. Sometimes the collective data is referred to as \nfilesystem metadata\n. Filesystem metadata includes information about both the individual files and the filesystem as a whole.\n\n\nTraditionally, Unix filesystems implement these notions as part of their physical on-disk layout. For example, file information is stored as an inode in a separate block on the disk; directories are files; control information is stored centrally in a superblock, and so on. The Unix file concepts are \nphysically mapped\n on to the storage medium.\n\n\nThe Linux VFS is designed to work with filesystems that understand and implement such concepts. Non-Unix filesystems, such as FAT or NTFS, still work in Linux, but their filesystem code must provide the appearance of these concepts. For example, even if a filesystem does not support distinct inodes, it must assemble the inode data structure in memory as if it did. Or if a filesystem treats directories as a special object, to the VFS they must represent directories as mere files. Often, this involves some special processing done on-the-fly by the non-Unix filesystems to cope with the Unix paradigm and the requirements of the VFS. Such filesystems still work, however, and the overhead is not unreasonable.\n\n\nVFS Objects and Their Data Structures\n\n\nThe VFS is object-oriented. A family of data structures represents the common file model. These data structures are akin to objects. Because the kernel is programmed strictly in C, without the benefit of a language directly supporting object-oriented paradigms, the data structures are represented as C structures. The structures contain both data and pointers to filesystem-implemented functions that operate on the data.\n\n\nThe four primary object types of the VFS are:\n\n\n\n\nThe \nsuperblock\n object, which represents a specific mounted filesystem.\n\n\nThe \ninode\n object, which represents a specific file.\n\n\nThe \ndentry\n object, which represents a directory entry, which is a single component of a path.\n\n\nThe \nfile\n object, which represents an open file as associated with a process.\n\n\n\n\nBecause the VFS treats directories as normal files, there is not a specific directory object. A dentry represents a component in a path, which might include a regular file. In other words, a dentry is not the same as a directory, but a directory is just another kind of file.\n\n\nAn \noperations\n object is contained within each of these primary objects. These objects describe the methods that the kernel invokes against the primary objects:\n\n\n\n\nThe \nsuper_operations\n object, which contains the methods that the kernel can invoke on a specific filesystem, such as \nwrite_inode()\n and \nsync_fs()\n.\n\n\nThe \ninode_operations\n object, which contains the methods that the kernel can invoke on a specific file, such as \ncreate()\n and \nlink()\n.\n\n\nThe \ndentry_operations\n object, which contains the methods that the kernel can invoke on a specific directory entry, such as \nd_compare()\n and \nd_delete()\n.\n\n\nThe \nfile_operations\n object, which contains the methods that a process can invoke on an open file, such as \nread()\n and \nwrite()\n.\n\n\n\n\nThe operations objects are implemented as a structure of pointers to functions that operate on the parent object. For many methods, the objects can inherit a generic function if basic functionality is sufficient. Otherwise, the specific instance of the particular filesystem fills in the pointers with its own filesystem-specific methods.\n\n\nNote that objects refer to structures, not explicit class types, such as those in C++ or Java. These structures, however, represent specific instances of an object, their associated data, and methods to operate on themselves. They are very much objects.\n\n\nThe VFS is comprised of a couple more than the primary objects previously discussed:\n\n\n\n\nEach registered filesystem is represented by a \nfile_system_type\n structure. This object describes the filesystem and its capabilities.\n\n\nEach mount point is represented by the \nvfsmount\n structure. This structure contains information about the mount point, such as its location and mount flags.\n\n\n\n\nTwo per-process structures, which describe the filesystem and files associated with a process, are respectively, the \nfs_struct\n structure and the \nfile\n structure. The rest of this chapter discusses these objects and the role they play in implementing the VFS layer.\n\n\nThe superblock object is implemented by each filesystem and is used to store information\ndescribing that specific filesystem. This object usually corresponds to the filesystem\nsuperblock or the filesystem control block, which is stored in a special sector on disk (hence\nthe object\u2019s name). Filesystems that are not disk-based (a virtual memory\u2013based filesystem,\nsuch as sysfs) generate the superblock on-the-fly and store it in memory.\n\n\nThe superblock object is represented by struct \nsuper_block\n and defined in \nlinux/fs.h\n:\n\n\ninclude/linux/fs.h#L1319\n\n\nstruct\n \nsuper_block\n \n{\n\n    \nstruct\n \nlist_head\n \ns_list\n;\n \n/* list of all superblocks */\n\n    \ndev_t\n \ns_dev\n;\n \n/* identifier */\n\n    \nunsigned\n \nlong\n \ns_blocksize\n;\n \n/* block size in bytes */\n\n    \nunsigned\n \nchar\n \ns_blocksize_bits\n;\n \n/* block size in bits */\n\n    \nunsigned\n \nchar\n \ns_dirt\n;\n \n/* dirty flag */\n\n    \nunsigned\n \nlong\n \nlong\n \ns_maxbytes\n;\n \n/* max file size */\n\n    \nstruct\n \nfile_system_type\n \ns_type\n;\n \n/* filesystem type */\n\n    \nstruct\n \nsuper_operations\n \ns_op\n;\n \n/* superblock methods */\n\n    \nstruct\n \ndquot_operations\n \n*\ndq_op\n;\n \n/* quota methods */\n\n    \nstruct\n \nquotactl_ops\n \n*\ns_qcop\n;\n \n/* quota control methods */\n\n    \nstruct\n \nexport_operations\n \n*\ns_export_op\n;\n \n/* export methods */\n\n    \nunsigned\n \nlong\n \ns_flags\n;\n \n/* mount flags */\n\n    \nunsigned\n \nlong\n \ns_magic\n;\n \n/* filesystem\u2019s magic number */\n\n    \nstruct\n \ndentry\n \n*\ns_root\n;\n \n/* directory mount point */\n\n    \nstruct\n \nrw_semaphore\n \ns_umount\n;\n \n/* unmount semaphore */\n\n    \nstruct\n \nsemaphore\n \ns_lock\n;\n \n/* superblock semaphore */\n\n    \nint\n \ns_count\n;\n \n/* superblock ref count */\n\n    \nint\n \ns_need_sync\n;\n \n/* not-yet-synced flag */\n\n    \natomic_t\n \ns_active\n;\n \n/* active reference count */\n\n    \nvoid\n \n*\ns_security\n;\n \n/* security module */\n\n    \nstruct\n \nxattr_handler\n \n**\ns_xattr\n;\n \n/* extended attribute handlers */\n\n    \nstruct\n \nlist_head\n \ns_inodes\n;\n \n/* list of inodes */\n\n    \nstruct\n \nlist_head\n \ns_dirty\n;\n \n/* list of dirty inodes */\n\n    \nstruct\n \nlist_head\n \ns_io\n;\n \n/* list of writebacks */\n\n    \nstruct\n \nlist_head\n \ns_more_io\n;\n \n/* list of more writeback */\n\n    \nstruct\n \nhlist_head\n \ns_anon\n;\n \n/* anonymous dentries */\n\n    \nstruct\n \nlist_head\n \ns_files\n;\n \n/* list of assigned files */\n\n    \nstruct\n \nlist_head\n \ns_dentry_lru\n;\n \n/* list of unused dentries */\n\n    \nint\n \ns_nr_dentry_unused\n;\n \n/* number of dentries on list */\n\n    \nstruct\n \nblock_device\n \n*\ns_bdev\n;\n \n/* associated block device */\n\n    \nstruct\n \nmtd_info\n \n*\ns_mtd\n;\n \n/* memory disk information */\n\n    \nstruct\n \nlist_head\n \ns_instances\n;\n \n/* instances of this fs */\n\n    \nstruct\n \nquota_info\n \ns_dquot\n;\n \n/* quota-specific options */\n\n    \nint\n \ns_frozen\n;\n \n/* frozen status */\n\n    \nwait_queue_head_t\n \ns_wait_unfrozen\n;\n \n/* wait queue on freeze */\n\n    \nchar\n \ns_id\n[\n32\n];\n \n/* text name */\n\n    \nvoid\n \n*\ns_fs_info\n;\n \n/* filesystem-specific info */\n\n    \nfmode_t\n \ns_mode\n;\n \n/* mount permissions */\n\n    \nstruct\n \nsemaphore\n \ns_vfs_rename_sem\n;\n \n/* rename semaphore */\n\n    \nu32\n \ns_time_gran\n;\n \n/* granularity of timestamps */\n\n    \nchar\n \n*\ns_subtype\n;\n \n/* subtype name */\n\n    \nchar\n \n*\ns_options\n;\n \n/* saved mount options */\n\n\n};\n\n\n\n\n\n\nThe code for creating, managing, and destroying superblock objects lives in \nfs/super.c\n. A superblock object is created and initialized via the \nalloc_super()\n function. When mounted, a filesystem invokes this function, reads its superblock off of the disk, and fills in its superblock object.\n\n\nThe most important item in the superblock object is \ns_op\n, which is a pointer to the superblock operations table. The superblock operations table is represented by \nstruct super_operations\n and is defined in \nlinux/fs.h\n, which looks like this:\n\n\nstruct\n \nsuper_operations\n \n{\n\n    \nstruct\n \ninode\n \n*\n(\n*\nalloc_inode\n)(\nstruct\n \nsuper_block\n \n*\nsb\n);\n\n    \nvoid\n \n(\n*\ndestroy_inode\n)(\nstruct\n \ninode\n \n*\n);\n\n    \nvoid\n \n(\n*\ndirty_inode\n)\n \n(\nstruct\n \ninode\n \n*\n);\n\n    \nint\n \n(\n*\nwrite_inode\n)\n \n(\nstruct\n \ninode\n \n*\n,\n \nint\n);\n\n    \nvoid\n \n(\n*\ndrop_inode\n)\n \n(\nstruct\n \ninode\n \n*\n);\n\n    \nvoid\n \n(\n*\ndelete_inode\n)\n \n(\nstruct\n \ninode\n \n*\n);\n\n    \nvoid\n \n(\n*\nput_super\n)\n \n(\nstruct\n \nsuper_block\n \n*\n);\n\n    \nvoid\n \n(\n*\nwrite_super\n)\n \n(\nstruct\n \nsuper_block\n \n*\n);\n\n    \nint\n \n(\n*\nsync_fs\n)(\nstruct\n \nsuper_block\n \n*\nsb\n,\n \nint\n \nwait\n);\n\n    \nint\n \n(\n*\nfreeze_fs\n)\n \n(\nstruct\n \nsuper_block\n \n*\n);\n\n    \nint\n \n(\n*\nunfreeze_fs\n)\n \n(\nstruct\n \nsuper_block\n \n*\n);\n\n    \nint\n \n(\n*\nstatfs\n)\n \n(\nstruct\n \ndentry\n \n*\n,\n \nstruct\n \nkstatfs\n \n*\n);\n\n    \nint\n \n(\n*\nremount_fs\n)\n \n(\nstruct\n \nsuper_block\n \n*\n,\n \nint\n \n*\n,\n \nchar\n \n*\n);\n\n    \nvoid\n \n(\n*\nclear_inode\n)\n \n(\nstruct\n \ninode\n \n*\n);\n\n    \nvoid\n \n(\n*\numount_begin\n)\n \n(\nstruct\n \nsuper_block\n \n*\n);\n\n    \nint\n \n(\n*\nshow_options\n)(\nstruct\n \nseq_file\n \n*\n,\n \nstruct\n \nvfsmount\n \n*\n);\n\n    \nint\n \n(\n*\nshow_stats\n)(\nstruct\n \nseq_file\n \n*\n,\n \nstruct\n \nvfsmount\n \n*\n);\n\n    \nssize_t\n \n(\n*\nquota_read\n)(\nstruct\n \nsuper_block\n \n*\n,\n \nint\n,\n \nchar\n \n*\n,\n \nsize_t\n,\n \nloff_t\n);\n\n    \nssize_t\n \n(\n*\nquota_write\n)(\nstruct\n \nsuper_block\n \n*\n,\n \nint\n,\n \nconst\n \nchar\n \n*\n,\n \nsize_t\n,\n \nloff_t\n);\n\n    \nint\n \n(\n*\nbdev_try_to_free_page\n)(\nstruct\n \nsuper_block\n*\n,\n \nstruct\n \npage\n*\n,\n \ngfp_t\n);\n\n\n};\n\n\n\n\n\n\nEach item in this structure is a pointer to a function that operates on a superblock object. The superblock operations perform low-level operations on the filesystem and its inodes.\n\n\nWhen a filesystem needs to perform an operation on its superblock, it follows the pointers from its superblock object to the desired method. For example, if a filesystem wanted to write to its superblock, it would invoke:\n\n\nsb\n-\ns_op\n-\nwrite_super\n(\nsb\n);\n\n\n\n\n\n\nIn this call, \nsb\n is a pointer to the filesystem\u2019s superblock. Following that pointer into \ns_op\n yields the superblock operations table and ultimately the desired \nwrite_super()\n function, which is then invoked. Note how the \nwrite_super()\n call must be passed a superblock, despite the method being associated with one. This is because of the lack of object-oriented support in C. In C++, a call such as the following would suffice:\n\n\nsb\n.\nwrite_super\n();\n\n\n\n\n\n\nIn C, there is no way for the method to easily obtain its parent, so you have to pass it.\n\n\nThe following are some of the superblock operations that are specified by \nsuper_operations\n:\n\n\n\n\nstruct inode * alloc_inode(struct super_block *sb)\n\n\nCreates and initializes a new inode object under the given superblock.\n\n\n\n\n\n\nvoid destroy_inode(struct inode *inode)\n\n\nDeallocates the given inode.\n\n\n\n\n\n\nvoid dirty_inode(struct inode *inode)\n\n\nInvoked by the VFS when an inode is dirtied (modified). Journaling filesystems such as ext3 and ext4 use this function to perform journal updates.\n\n\n\n\n\n\nvoid write_inode(struct inode *inode, int wait)\n\n\nWrites the given inode to disk. The \nwait\n parameter specifies whether the operation should be synchronous.\n\n\n\n\n\n\nvoid drop_inode(struct inode *inode)\n\n\nCalled by the VFS when the last reference to an inode is dropped. Normal Unix filesystems do not define this function, in which case the VFS simply deletes the inode.\n\n\n\n\n\n\nvoid delete_inode(struct inode *inode)\n\n\nDeletes the given inode from the disk.\n\n\n\n\n\n\nvoid put_super(struct super_block *sb)\n\n\nCalled by the VFS on unmount to release the given superblock object.The caller must hold the \ns_lock\n lock.\n\n\n\n\n\n\nvoid write_super(struct super_block *sb)\n\n\nUpdates the on-disk superblock with the specified superblock.The VFS uses this function to synchronize a modified in-memory superblock with the disk. The caller must hold the \ns_lock\n lock.\n\n\n\n\n\n\nint sync_fs(struct super_block *sb, int wait)\n\n\nSynchronizes filesystem metadata with the on-disk filesystem. The \nwait\n parameter specifies whether the operation is synchronous.\n\n\n\n\n\n\nvoid write_super_lockfs(struct super_block *sb)\n\n\nPrevents changes to the filesystem, and then updates the on-disk superblock with the specified superblock. It is currently used by LVM (the Logical Volume Manager).\n\n\n\n\n\n\nvoid unlockfs(struct super_block *sb)\n\n\nUnlocks the filesystem against changes as done by \nwrite_super_lockfs()\n.\n\n\n\n\n\n\nint statfs(struct super_block *sb, struct statfs *statfs)\n\n\nCalled by the VFS to obtain filesystem statistics. The statistics related to the given filesystem are placed in \nstatfs\n.\n\n\n\n\n\n\nint remount_fs(struct super_block *sb, int *flags, char *data)\n\n\nCalled by the VFS when the filesystem is remounted with new mount options.The caller must hold the \ns_lock\n lock.\n\n\n\n\n\n\nvoid clear_inode(struct inode *inode)\n\n\nCalled by the VFS to release the inode and clear any pages containing related data.\n\n\n\n\n\n\nvoid umount_begin(struct super_block *sb)\n\n\nCalled by the VFS to interrupt a mount operation. It is used by network filesystems, such as NFS.\n\n\n\n\n\n\n\n\nThe Superblock Object\n\n\nSuperblock Operations\n\n\nThe Inode Object\n\n\nInode Operations\n\n\nThe Dentry Object\n\n\nDentry State\n\n\nThe Dentry Cache\n\n\nDentry Operations\n\n\nThe File Object\n\n\nFile Operations\n\n\nData Structures Associated with Filesystems\n\n\nData Structures Associated with a Process", 
            "title": "Chapter 13. The Virtual Filesystem"
        }, 
        {
            "location": "/lkd/ch14/", 
            "text": "Chapter 14. The Block I/O Layer\n\n\nBlock devices\n are hardware devices distinguished by the random (not necessarily sequential) access of fixed-size chunks of data. The fixed-size chunks of data are called \nblocks\n. The most common block device is a hard disk, but many other block devices exist, such as floppy drives, Blu-ray readers, and flash memory. Notice how these are all devices on which you mount a filesystem; filesystems are the lingua franca of block devices.\n\n\nThe other basic type of device is a \ncharacter device\n. Character devices, or \nchar\n devices, are accessed as a stream of sequential data, one byte after another. Example character devices are serial ports and keyboards.\n\n\nCharacter Device vs. Block Device *\n\n\nIf the hardware device is accessed as a stream of data, it is implemented as a character device. On the other hand, if the device is accessed randomly (nonsequentially), it is a block device.\n\n\nThe difference comes down to whether the device accesses data randomly, in other words, whether the device can \nseek\n to one position from another. [p289]\n\n\n\n\nAs a driver, the keyboard provides a stream of data. The keyboard driver is thus a char device; the device provides a stream of characters that the user types onto the keyboard.\n\n\nA hard drive, conversely, is quite different. The hard drive\u2019s driver might ask to read the contents of one arbitrary block and then read the contents of a different block; the blocks need not be consecutive. The hard disk\u2019s data is accessed randomly, and not as a stream; therefore, the hard disk is a block device.\n\n\n\n\nManaging block devices in the kernel requires more care, preparation, and work than managing character devices. \nCharacter devices have only one position, the current one, whereas block devices must be able to navigate back and forth between any location on the media.\n\n\nThe kernel does not have to provide an entire subsystem dedicated to the management of character devices, but block devices receive exactly that. Such a subsystem is a necessity partly because of the complexity of block devices. A large reason for such extensive support is that block devices are quite performance sensitive; getting every last drop out of your hard disk is much more important than squeezing an extra percent of speed out of your keyboard. Furthermore, the complexity of block devices provides a lot of room for such optimizations.\n\n\nThe topic of this chapter is how the kernel manages block devices and their requests. This part of the kernel is known as the \nblock I/O layer\n.\n\n\nAnatomy of a Block Device\n\n\nSector *\n\n\nThe smallest addressable unit on a block device is a \nsector\n. Sector sizes are powers of two, but 512 bytes is the most common size. The sector size is a physical property of the device, and the sector is the fundamental unit of all block devices; the device cannot address or operate on a unit smaller than the sector, although many block devices can operate on multiple sectors at one time. Most block devices have 512-byte sectors, although other sizes are common. For example, many CD-ROM discs have 2-kilobyte sectors.\n\n\nBlock *\n\n\nThe \nblock\n is the smallest logically addressable unit for software.\n\n\nThe block is an abstraction of the filesystem; filesystems can be\naccessed only in multiples of a block. Although the physical device is addressable at the\nsector level, the kernel performs all disk operations in terms of blocks.\n\n\nBlock vs. Sector *\n\n\n\n\nThe block size can be no smaller than the sector and must be a multiple of a sector, because the device\u2019s smallest addressable unit is the sector.\n\n\nThe kernel (as with hardware and the sector) needs the block to be a power of two.\n\n\nThe kernel also requires that a block be no larger than the page size (\nChapter 12\n and \nChapter 19\n\n\n\n\nTherefore, block sizes are a power-of-two multiple of the sector size and are not greater than the page size. Common block sizes are 512 bytes, 1 kilobyte, and 4 kilobytes.\n\n\nConfusion of block and sector\n *\n\n\nSome people confusingly refer to sectors and blocks with different names:\n\n\n\n\nSectors, the smallest addressable unit to the device, are sometimes called \"hard sectors\" or \"device blocks\".\n\n\nBlocks, the smallest addressable unit to the filesystem, are sometimes referred to as \"filesystem blocks\" or \"I/O blocks\".\n\n\n\n\nThis chapter continues to call the two notions sectors and blocks, but you should keep these other terms in mind. Below is a diagram of the relationship between sectors and blocks:\n\n\n\n\nHard disk related terminology, such as clusters, \ncylinders\n, and heads are specific only to certain block devices and are mostly invisible to user-space software. The reason that the sector is important to the kernel is because all device I/O must be done in units of sectors. In turn, blocks, which is the higher-level concept used by the kernel, are built on top of sectors.\n\n\nBuffers and Buffer Heads\n\n\nWhen a block is stored in memory (e.g. after a read or pending a write), it is stored in a \nbuffer\n.  Each buffer is associated with exactly one block.The buffer serves as the object that represents a disk block in memory. A block is composed of one or more sectors but is no more than a page in size,  a single page can hold one or more blocks in memory. Because the kernel requires some associated control information to accompany the data (such as from which block device and which specific block the buffer is), each buffer is associated with a descriptor. This descriptor is called a \nbuffer head\n and is of type struct \nbuffer_head\n. The \nbuffer_head\n structure holds all the information that the kernel needs to manipulate buffers and is defined in \nlinux/buffer_head.h\n (\ninclude/linux/buffer_head.h\n).\n\n\ninclude/linux/buffer_head.h#L61\n\n\nstruct\n \nbuffer_head\n \n{\n\n    \nunsigned\n \nlong\n \nb_state\n;\n             \n/* buffer state flags */\n\n    \nstruct\n \nbuffer_head\n \n*\nb_this_page\n;\n   \n/* list of page\u2019s buffers */\n\n    \nstruct\n \npage\n \n*\nb_page\n;\n               \n/* associated page */\n\n    \nsector_t\n \nb_blocknr\n;\n                \n/* starting block number */\n\n    \nsize_t\n \nb_size\n;\n                     \n/* size of mapping */\n\n    \nchar\n \n*\nb_data\n;\n                      \n/* pointer to data within the page */\n\n    \nstruct\n \nblock_device\n \n*\nb_bdev\n;\n       \n/* associated block device */\n\n    \nbh_end_io_t\n \n*\nb_end_io\n;\n             \n/* I/O completion */\n\n    \nvoid\n \n*\nb_private\n;\n                   \n/* reserved for b_end_io */\n\n    \nstruct\n \nlist_head\n \nb_assoc_buffers\n;\n  \n/* associated mappings */\n\n    \nstruct\n \naddress_space\n \n*\nb_assoc_map\n;\n \n/* associated address space */\n\n    \natomic_t\n \nb_count\n;\n                  \n/* use count */\n\n\n};\n\n\n\n\n\n\nThe \nb_state\n field and \nbh_state_bits\n enumeration *\n\n\nThe \nb_state\n field specifies the state of this particular buffer. It can be one or more of the flags in the following table. The legal flags are stored in the \nbh_state_bits\n (\ninclude/linux/buffer_head.h#L19\n) enumeration, which is defined in \nlinux/buffer_head.h\n.\n\n\n\n\n\n\n\n\nStatus Flag\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nBH_Uptodate\n\n\nBuffer contains valid data.\n\n\n\n\n\n\nBH_Dirty\n\n\nBuffer is dirty. (The contents of the buffer are newer than the contents of the block on disk and therefore the buffer must eventually be written back to disk.)\n\n\n\n\n\n\nBH_Lock\n\n\nBuffer is undergoing disk I/O and is locked to prevent concurrent access.\n\n\n\n\n\n\nBH_Req\n\n\nBuffer is involved in an I/O request.\n\n\n\n\n\n\nBH_Mapped\n\n\nBuffer is a valid buffer mapped to an on-disk block.\n\n\n\n\n\n\nBH_New\n\n\nBuffer is newly mapped via \nget_block()\n and not yet accessed.\n\n\n\n\n\n\nBH_Async_Read\n\n\nBuffer is undergoing asynchronous read I/O via \nend_buffer_async_read()\n.\n\n\n\n\n\n\nBH_Async_Write\n\n\nBuffer is undergoing asynchronous write I/O via \nend_buffer_async_write()\n.\n\n\n\n\n\n\nBH_Delay\n\n\nBuffer does not yet have an associated on-disk block (delayed allocation).\n\n\n\n\n\n\nBH_Boundary\n\n\nBuffer forms the boundary of contiguous blocks; the next block is discontinuous.\n\n\n\n\n\n\nBH_Write_EIO\n\n\nBuffer incurred an I/O error on write.\n\n\n\n\n\n\nBH_Ordered\n\n\nOrdered write.\n\n\n\n\n\n\nBH_Eopnotsupp\n\n\nBuffer incurred a \"not supported\" error.\n\n\n\n\n\n\nBH_Unwritten\n\n\nSpace for the buffer has been allocated on disk but the actual data has not yet been written out.\n\n\n\n\n\n\nBH_Quiet\n\n\nSuppress errors for this buffer.\n\n\n\n\n\n\n\n\nThe \nbh_state_bits\n enumeration also contains a \nBH_PrivateStart\n flag (as the last value in the list). This is not a valid state flag but instead corresponds to the first usable bit of which other code can make use. All bit values equal to and greater than \nBH_PrivateStart\n are not used by the block I/O layer proper, so these bits are safe to use by individual drivers who want to store information in the \nb_state\n field. Drivers can base the bit values of their internal flags off this flag and rest assured that they are not encroaching on an official bit used by the block I/O layer.\n\n\nb_count\n\n\nThe \nb_count\n field is the buffer\u2019s usage count. The value is incremented and decremented by two inline functions defined in \nlinux/buffer_head.h\n:\n\n\ninclude/linux/buffer_head.h#L252\n\n\nstatic\n \ninline\n \nvoid\n \nget_bh\n(\nstruct\n \nbuffer_head\n \n*\nbh\n)\n\n\n{\n\n        \natomic_inc\n(\nbh\n-\nb_count\n);\n\n\n}\n\n\n\nstatic\n \ninline\n \nvoid\n \nput_bh\n(\nstruct\n \nbuffer_head\n \n*\nbh\n)\n\n\n{\n\n        \nsmp_mb__before_atomic_dec\n();\n\n        \natomic_dec\n(\nbh\n-\nb_count\n);\n\n\n}\n\n\n\n\n\n\n\n\nBefore manipulating a buffer head, you must increment its reference count via \nget_bh()\n to ensure that the buffer head is not deallocated out from under you.\n\n\nWhen finished with the buffer head, decrement the reference count via \nput_bh()\n.\n\n\n\n\nPhysical block, page and buffer *\n\n\n\n\nThe physical block on disk to which a given buffer corresponds is the \nb_blocknr\n-th logical block on the block device described by \nb_bdev\n.\n\n\nThe physical page in memory to which a given buffer corresponds is the page pointed to by \nb_page\n. More specifically, \nb_data\n is a pointer directly to the block (that exists somewhere in \nb_page\n), which is \nb_size\n bytes in length. Therefore, the block is located in memory starting at address \nb_data\n and ending at address (\nb_data\n + \nb_size\n).\n\n\n\n\nThe purpose of a buffer head is to describe this mapping between the on-disk block and the physical in-memory buffer (which is a sequence of bytes on a specific page). Acting as a descriptor of this buffer-to-block mapping is the data structure\u2019s only role in the kernel.\n\n\nProblems with buffer heads *\n\n\nBefore the 2.6 kernel, the buffer head was an important data structure. It was the unit of I/O in the kernel:\n\n\n\n\nDescribed the disk-blockto-physical-page mapping,\n\n\nActed as the container used for all block I/O.\n\n\n\n\nHowever, it had two primary problems:\n\n\n\n\nThe buffer head was a large and unwieldy data structure.\n It was neither clean nor simple to manipulate data in terms of buffer heads.\n\n\nInstead, the kernel prefers to work in terms of pages, which are simple and enable for greater performance.\n\n\nA large buffer head describing each individual buffer (which might be smaller than a page) was inefficient.\n\n\nConsequently, in the 2.6 kernel, much work has gone into making the kernel work directly with pages and address spaces instead of buffers. Some of this work is discussed in \nChapter 16\n \"The Page Cache and Page Writeback\", where the \naddress_space\n structure and the \npdflush\n daemons are discussed.\n\n\n\n\n\n\nBuffer heads describe only a single buffer.\n When used as the container for all I/O operations, the buffer head forces the kernel to break up potentially large block I/O operations into multiple \nbuffer_head\n structures. This results in needless overhead and space consumption.\n\n\nThe primary goal of the 2.5 development kernel was to introduce a new, flexible, and lightweight container, \nbio\n structure (discussed in the next section), for block I/O operations.", 
            "title": "Chapter 14. The Block I/O Layer"
        }, 
        {
            "location": "/lkd/ch15/", 
            "text": "Chapter 15. The Process Address Space\n\n\nChapter 12 Memory Management\n covers how the kernel manages physical memory.  In addition to managing its own memory, the kernel also has to manage the memory of user-space processes. This memory is called the \nprocess address space\n, which is the representation of memory given to each user-space process on the system.\n\n\nLinux is a virtual memory operating system:\n\n\n\n\nThe memory is virtualized among the processes on the system. An individual process\u2019s view of memory is as if it alone has full access to the system\u2019s physical memory.\n\n\nMore important, the address space of even a single process can be much larger than physical memory.\n\n\n\n\nThis chapter discusses how the kernel manages the process address space.\n\n\nAddress Spaces\n\n\nFlat and segmented address space *\n\n\nThe process address space consists of the virtual memory addressable by a process and the addresses within the virtual memory that the process is allowed to use. Each process is given a flat 32- or 64-bit address space, with the size depending on the architecture. The term \nflat\n denotes that the address space exists in a single range. (For example, a 32-bit address space extends from the address 0 to 4294967295.)\n\n\nSome operating systems provide a \nsegmented address space\n, with addresses existing not in a single linear range, but instead in multiple segments. Modern virtual memory operating systems generally have a flat memory model and not a segmented one.\n\n\nIn the flat memory model, the flat address space is unique to each process. A memory address in one process\u2019s address space is completely unrelated to that same memory address in another process\u2019s address space. Both processes can have different data at the same address in their respective address spaces.Alternatively, processes can elect to share their address space with other processes; these processes are known as as \nthreads\n.\n\n\nMemory areas*\n\n\nA memory address is a given value within the address space, such as \n4021f000\n. This particular value identifies a specific byte in a process\u2019s 32-bit address space. Although a process can address up to 4GB of memory (with a 32-bit address space), it doesn\u2019t have permission to access all of it.\n\n\nThese intervals of legal addresses (the process has permission to access), such as \n08048000-0804c000\n are called \nmemory areas\n. The process, through the kernel, can dynamically add and remove memory areas to its address space.\n\n\nThe process can access a memory address only in a valid memory area. Memory areas have associated permissions, such as readable, writable, and executable, that the associated process must respect. If a process accesses a memory address not in a valid memory area, or if it accesses a valid area in an invalid manner, the kernel kills the process with the dreaded \"Segmentation Fault\" message.\n\n\nMemory areas can contain the following things:\n\n\n\n\nA memory map of the executable file\u2019s code, called the \ntext section\n.\n\n\nA memory map of the executable file\u2019s initialized global variables, called the \ndata section\n.\n\n\nA memory map of the zero page (a page consisting of all zeros, used for purposes such as this) containing uninitialized global variables, called the \nbss section\n.\n\n\nThe term \"BSS\" is historical and stands for \nb\nlock \ns\ntarted by \ns\nymbol.\n\n\nUninitialized variables are not stored in the executable object because they do not have any associated value. But the C standard decrees that uninitialized global variables are assigned certain default values (all zeros), so the kernel loads the variables (without value) from the executable into memory and maps the zero page over the area, thereby giving the variables the value zero, without having to waste space in the object file with explicit initializations.\n\n\n\n\n\n\nA memory map of the zero page used for the process\u2019s user-space stack. (Do not confuse this with the process\u2019s \nkernel stack\n, which is separate and maintained and used by the kernel.)\n\n\nAn additional text, data, and bss section for each shared library, such as the C library and dynamic linker, loaded into the process\u2019s address space.\n\n\nAny memory mapped files.\n\n\nAny shared memory segments.\n\n\nAny anonymous memory mappings, such as those associated with \nmalloc()\n (newer versions of glibc implement \nmalloc()\n via \nmmap()\n, in addition to \nbrk()\n).\n\n\n\n\nThe Memory Descriptor\n\n\nThe kernel represents a process\u2019s address space with a data structure called the \nmemory descriptor\n. This structure contains all the information related to the process address space.\n\n\nThe memory descriptor is represented by \nstruct mm_struct\n and defined in \nlinux/mm_types.h\n (\ninclude/linux/mm_types.h\n):\n\n\ninclude/linux/mm_types.h#L222\n\n\nstruct\n \nmm_struct\n \n{\n\n    \nstruct\n \nvm_area_struct\n \n*\nmmap\n;\n \n/* list of memory areas */\n\n    \nstruct\n \nrb_root\n \nmm_rb\n;\n \n/* red-black tree of VMAs */\n\n    \nstruct\n \nvm_area_struct\n \n*\nmmap_cache\n;\n \n/* last used memory area */\n\n    \nunsigned\n \nlong\n \nfree_area_cache\n;\n \n/* 1st address space hole */\n\n    \npgd_t\n \n*\npgd\n;\n \n/* page global directory */\n\n    \natomic_t\n \nmm_users\n;\n \n/* address space users */\n\n    \natomic_t\n \nmm_count\n;\n \n/* primary usage counter */\n\n    \nint\n \nmap_count\n;\n \n/* number of memory areas */\n\n    \nstruct\n \nrw_semaphore\n \nmmap_sem\n;\n \n/* memory area semaphore */\n\n    \nspinlock_t\n \npage_table_lock\n;\n \n/* page table lock */\n\n    \nstruct\n \nlist_head\n \nmmlist\n;\n \n/* list of all mm_structs */\n\n    \nunsigned\n \nlong\n \nstart_code\n;\n \n/* start address of code */\n\n    \nunsigned\n \nlong\n \nend_code\n;\n \n/* final address of code */\n\n    \nunsigned\n \nlong\n \nstart_data\n;\n \n/* start address of data */\n\n    \nunsigned\n \nlong\n \nend_data\n;\n \n/* final address of data */\n\n    \nunsigned\n \nlong\n \nstart_brk\n;\n \n/* start address of heap */\n\n    \nunsigned\n \nlong\n \nbrk\n;\n \n/* final address of heap */\n\n    \nunsigned\n \nlong\n \nstart_stack\n;\n \n/* start address of stack */\n\n    \nunsigned\n \nlong\n \narg_start\n;\n \n/* start of arguments */\n\n    \nunsigned\n \nlong\n \narg_end\n;\n \n/* end of arguments */\n\n    \nunsigned\n \nlong\n \nenv_start\n;\n \n/* start of environment */\n\n    \nunsigned\n \nlong\n \nenv_end\n;\n \n/* end of environment */\n\n    \nunsigned\n \nlong\n \nrss\n;\n \n/* pages allocated */\n\n    \nunsigned\n \nlong\n \ntotal_vm\n;\n \n/* total number of pages */\n\n    \nunsigned\n \nlong\n \nlocked_vm\n;\n \n/* number of locked pages */\n\n    \nunsigned\n \nlong\n \nsaved_auxv\n[\nAT_VECTOR_SIZE\n];\n \n/* saved auxv */\n\n    \ncpumask_t\n \ncpu_vm_mask\n;\n \n/* lazy TLB switch mask */\n\n    \nmm_context_t\n \ncontext\n;\n \n/* arch-specific data */\n\n    \nunsigned\n \nlong\n \nflags\n;\n \n/* status flags */\n\n    \nint\n \ncore_waiters\n;\n \n/* thread core dump waiters */\n\n    \nstruct\n \ncore_state\n \n*\ncore_state\n;\n \n/* core dump support */\n\n    \nspinlock_t\n \nioctx_lock\n;\n \n/* AIO I/O list lock */\n\n    \nstruct\n \nhlist_head\n \nioctx_list\n;\n \n/* AIO I/O list */\n\n\n};\n\n\n\n\n\n\n\n\nThe \nmm_users\n field is the number of processes using this address space.\n\n\nFor example, if two threads share this address space, \nmm_users\n is equal to two.\n\n\n\n\n\n\nThe \nmm_count\n field is the primary reference count for the \nmm_struct\n.\n\n\nAll \nmm_users\n equate to one increment of \nmm_count\n. In the previous example, \nmm_count\n is only one. If nine threads shared an address space, \nmm_users\n would be nine, but again \nmm_count\n would be only one. Only when \nmm_users\n reaches zero (when all threads using an address space exit) is mm_count decremented. When \nmm_count\n finally reaches zero, there are no remaining references to this \nmm_struct\n, and it is freed.\n\n\nWhen the kernel operates on an address space and needs to bump its associated reference count, the kernel increments \nmm_count\n.\n\n\n\n\n\n\n\n\nHaving two counters enables the kernel to differentiate between the main usage counter (\nmm_count\n) and the number of processes using the address space (\nmm_users\n).\n\n\n\n\nThe \nmmap\n and \nmm_rb\n fields are different data structures that contain the same thing: all the memory areas in this address space.\n\n\nmmap\n stores them in a linked list.\n\n\nmm_rb\n stores them in a red-black tree. A red-black tree is a type of binary tree; like all binary trees, searching for a given element is an O(log \nn\n) operation.\n\n\n\n\n\n\n\n\nThis redundancy (two \nmmap\n and \nmm_rb\n data structures on the same data) are handy:\n\n\n\n\nThe \nmmap\n data structure, as a linked list, allows for simple and efficient traversing of all elements.\n\n\nThe \nmm_rb\n data structure, as a red-black tree, is more suitable to searching for a given element.\n\n\n\n\nThe kernel isn\u2019t duplicating the \nmm_struct\n structures; just the containing objects. Overlaying a linked list onto a tree, and using both to access the same set of data, is sometimes called a \nthreaded tree\n.\n\n\nAll of the \nmm_struct\n structures are strung together in a doubly linked list via the \nmmlist\n field. The initial element in the list is the \ninit_mm\n memory descriptor, which describes the address space of the \ninit\n process. The list is protected from concurrent access via the \nmmlist_lock\n, which is defined in \nkernel/fork.c\n.\n\n\nAllocating a Memory Descriptor\n\n\nThe memory descriptor associated with a given task is stored in the \nmm\n field of the task\u2019s process descriptor:\n\n\n\n\nThe process descriptor is represented by the \ntask_struct\n structure, defined in \nlinux/sched.h\n. Thus, \ncurrent-\nmm\n is the current process\u2019s memory descriptor.\n\n\nThe \ncopy_mm()\n function copies a parent\u2019s memory descriptor to its child during \nfork()\n.\n\n\nThe \nmm_struct\n structure is allocated from the \nmm_cachep\n slab cache via the \nallocate_mm()\n macro in \nkernel/fork.c\n.\n\n\nEach process receives a unique \nmm_struct\n and thus a unique process address space.\n\n\n\n\nProcesses may share their address spaces with their children via the \nCLONE_VM\n flag to \nclone()\n. The process is then called a \nthread\n. \nThis is essentially the only difference between normal processes and so-called threads in Linux (\nChapter 3\n); the Linux kernel does not otherwise differentiate between them. Threads are regular processes to the kernel that merely share certain resources.\n\n\nWhen \nCLONE_VM\n is specified, \nallocate_mm()\n is not called, and the process\u2019s \nmm\n field is set to point to the memory descriptor of its parent via this logic in \ncopy_mm()\n:\n\n\nif\n \n(\nclone_flags\n \n \nCLONE_VM\n)\n \n{\n\n    \n/*\n\n\n    * current is the parent process and\n\n\n    * tsk is the child process during a fork()\n\n\n    */\n\n    \natomic_inc\n(\ncurrent\n-\nmm\n-\nmm_users\n);\n\n    \ntsk\n-\nmm\n \n=\n \ncurrent\n-\nmm\n;\n\n\n}\n\n\n\n\n\n\nDestroying a Memory Descriptor\n\n\nWhen the process associated with a specific address space exits, \nexit_mm()\n, defined in \nkernel/exit.c\n, is invoked. This function performs some housekeeping and updates some statistics. It then calls \nmmput()\n, which decrements the memory descriptor\u2019s \nmm_users\n user counter. If the user count reaches zero, \nmmdrop()\n is called to decrement the \nmm_count\n usage counter. If that counter is finally zero, the \nfree_mm()\n macro is invoked to return the \nmm_struct\n to the \nmm_cachep\n slab cache via \nkmem_cache_free()\n, because the memory descriptor does not have any users.\n\n\nThe \nmm_struct\n and Kernel Threads\n\n\nKernel threads do not have a process address space and therefore do not have an associated memory descriptor.\n Thus, the \nmm\n field of a kernel thread\u2019s process descriptor is \nNULL\n.  This is the definition of a kernel thread: processes that have no user context.\n\n\nKernel threads do not ever access any userspace memory. Because kernel threads do not have any pages in user-space, they do not deserve their own memory descriptor and \npage tables\n (discussed later in the chapter). However, kernel threads need some of the data, such as the page tables, even to access kernel memory. To provide kernel threads the needed data, without wasting memory on a memory descriptor and page tables, or wasting processor cycles to switch to a new address space whenever a kernel thread begins running, kernel threads use the memory descriptor of whatever task ran previously:\n\n\n\n\nWhenever a process is scheduled, the process address space referenced by the process\u2019s \nmm\n field is loaded. The \nactive_mm\n field in the process descriptor is then updated to refer to the new address space.\n\n\nKernel threads do not have an address space and \nmm\n is \nNULL\n. Therefore, when a kernel thread is scheduled, the kernel notices that \nmm\n is \nNULL\n and keeps the previous process\u2019s address space loaded. The kernel then updates the \nactive_mm\n field of the kernel thread\u2019s process descriptor to refer to the previous process\u2019s memory descriptor.\n\n\nThe kernel thread can then use the previous process\u2019s page tables as needed. Because kernel threads do not access user-space memory, they make use of only the information in the address space pertaining to kernel memory, which is the same for all processes.\n\n\n\n\nVirtual Memory Areas\n\n\nThe memory area structure \nvm_area_struct\n represents memory areas, defined in \nlinux/mm_types.h\n. In the Linux kernel, memory areas are often called \nvirtual memory areas\n (\nVMA\ns).\n\n\nThe \nvm_area_struct\n structure describes a single memory area over a contiguous interval in a given address space:\n\n\n\n\nThe kernel treats each memory area as a unique memory object.\n\n\nEach memory area possesses certain properties, such as permissions and a set of associated operations.\n\n\n\n\nIn this manner, each VMA structure can represent different types of memory areas, e.g. memory-mapped files or the process\u2019s user-space stack. This is similar to the object-oriented approach taken by the VFS layer (\nChapter 13\n).\n\n\ninclude/linux/mm_types.h#L130\n\n\nstruct\n \nvm_area_struct\n \n{\n\n    \nstruct\n \nmm_struct\n \n*\nvm_mm\n;\n \n/* associated mm_struct */\n\n    \nunsigned\n \nlong\n \nvm_start\n;\n \n/* VMA start, inclusive */\n\n    \nunsigned\n \nlong\n \nvm_end\n;\n \n/* VMA end , exclusive */\n\n    \nstruct\n \nvm_area_struct\n \n*\nvm_next\n;\n \n/* list of VMA\u2019s */\n\n    \npgprot_t\n \nvm_page_prot\n;\n \n/* access permissions */\n\n    \nunsigned\n \nlong\n \nvm_flags\n;\n \n/* flags */\n\n    \nstruct\n \nrb_node\n \nvm_rb\n;\n \n/* VMA\u2019s node in the tree */\n\n    \nunion\n \n{\n \n/* links to address_space-\ni_mmap or i_mmap_nonlinear */\n\n    \nstruct\n \n{\n\n            \nstruct\n \nlist_head\n \nlist\n;\n\n            \nvoid\n \n*\nparent\n;\n\n            \nstruct\n \nvm_area_struct\n \n*\nhead\n;\n\n        \n}\n \nvm_set\n;\n\n        \nstruct\n \nprio_tree_node\n \nprio_tree_node\n;\n\n    \n}\n \nshared\n;\n\n    \nstruct\n \nlist_head\n \nanon_vma_node\n;\n \n/* anon_vma entry */\n\n    \nstruct\n \nanon_vma\n \n*\nanon_vma\n;\n \n/* anonymous VMA object */\n\n    \nstruct\n \nvm_operations_struct\n \n*\nvm_ops\n;\n \n/* associated ops */\n\n    \nunsigned\n \nlong\n \nvm_pgoff\n;\n \n/* offset within file */\n\n    \nstruct\n \nfile\n \n*\nvm_file\n;\n \n/* mapped file, if any */\n\n    \nvoid\n \n*\nvm_private_data\n;\n \n/* private data */\n\n\n};\n\n\n\n\n\n\nEach memory descriptor is associated with a unique interval in the process\u2019s address space.\n\n\n\n\nThe \nvm_start\n field is the initial (lowest) address in the interval. (inclusive start)\n\n\nThe \nvm_end\n field is the first byte after the final (highest) address in the interval. (exclusive end)\n\n\n\n\nvm_end - vm_start\n is the length in bytes of the memory area, which exists over the interval \n[vm_start, vm_end)\n. Intervals in different memory areas in the same address space cannot overlap.\n\n\nThe \nvm_mm\n field points to this VMA\u2019s associated \nmm_struct\n. Each VMA is unique to the \nmm_struct\n with which it is associated:\n\n\n\n\nTherefore, even if two separate processes map the same file into their respective address spaces, each has a unique \nvm_area_struct\n to identify its unique memory area.\n\n\nConversely, two threads that share an address space also share all the \nvm_area_struct\n structures therein.\n\n\n\n\nVMA Flags\n\n\nThe \nvm_flags\n field contains bit flags, defined in \nlinux/mm.h\n, that specify the behavior of and provide information about the pages contained in the memory area. Unlike permissions associated with a specific physical page, the VMA flags specify behavior for which the kernel is responsible, not the hardware. \nvm_flags\n contains information that relates to the memory area as a whole (each page), not specific individual pages.\n\n\nThe following table is a listing of the possible \nvm_flags\n values.\n\n\n\n\n\n\n\n\nFlag\n\n\nEffect on the VMA and Its Pages\n\n\n\n\n\n\n\n\n\n\nVM_READ\n\n\nPages can be read from.\n\n\n\n\n\n\nVM_WRITE\n\n\nPages can be written to.\n\n\n\n\n\n\nVM_EXEC\n\n\nPages can be executed.\n\n\n\n\n\n\nVM_SHARED\n\n\nPages are shared.\n\n\n\n\n\n\nVM_MAYREAD\n\n\nThe \nVM_READ\n flag can be set.\n\n\n\n\n\n\nVM_MAYWRITE\n\n\nThe \nVM_WRITE\n flag can be set.\n\n\n\n\n\n\nVM_MAYEXEC\n\n\nThe \nVM_EXEC\n flag can be set.\n\n\n\n\n\n\nVM_MAYSHARE\n\n\nThe \nVM_SHARE\n flag can be set.\n\n\n\n\n\n\nVM_GROWSDOWN\n\n\nThe area can grow downward.\n\n\n\n\n\n\nVM_GROWSUP\n\n\nThe area can grow upward.\n\n\n\n\n\n\nVM_SHM\n\n\nThe area is used for shared memory.\n\n\n\n\n\n\nVM_DENYWRITE\n\n\nThe area maps an unwritable file.\n\n\n\n\n\n\nVM_EXECUTABLE\n\n\nThe area maps an executable file.\n\n\n\n\n\n\nVM_LOCKED\n\n\nThe pages in this area are locked.\n\n\n\n\n\n\nVM_IO\n\n\nThe area maps a device\u2019s I/O space.\n\n\n\n\n\n\nVM_SEQ_READ\n\n\nThe pages seem to be accessed sequentially.\n\n\n\n\n\n\nVM_RAND_READ\n\n\nThe pages seem to be accessed randomly.\n\n\n\n\n\n\nVM_DONTCOPY\n\n\nThis area must not be copied on \nfork()\n.\n\n\n\n\n\n\nVM_DONTEXPAND\n\n\nThis area cannot grow via \nmremap()\n.\n\n\n\n\n\n\nVM_RESERVED\n\n\nThis area must not be swapped out.\n\n\n\n\n\n\nVM_ACCOUNT\n\n\nThis area is an accounted VM object.\n\n\n\n\n\n\nVM_HUGETLB\n\n\nThis area uses hugetlb pages.\n\n\n\n\n\n\nVM_NONLINEAR\n\n\nThis area is a nonlinear mapping.\n\n\n\n\n\n\n\n\n\n\nThe \nVM_READ\n, \nVM_WRITE\n, and \nVM_EXEC\n flags specify the usual read, write, and execute permissions for the pages in this particular memory area. They are combined as needed to form the appropriate access permissions that a process accessing this VMA must respect. For example:\n\n\nThe object code for a process might be mapped with \nVM_READ\n and \nVM_EXEC\n but not \nVM_WRITE\n.\n\n\nThe data section from an executable object would be mapped \nVM_READ\n and \nVM_WRITE\n, but \nVM_EXEC\n would make little sense.\n\n\nA read-only memory mapped data file would be mapped with only the \nVM_READ\n flag.\n\n\n\n\n\n\nThe \nVM_SHARED\n flag specifies whether the memory area contains a mapping that is shared among multiple processes.\n\n\nIf the flag is set, it is intuitively called a \nshared mapping\n.\n\n\nIf the flag is not set, only a single process can view this particular mapping, and it is called a \nprivate mapping\n.\n\n\n\n\n\n\nThe \nVM_IO\n flag specifies that this memory area is a mapping of a device\u2019s I/O space. This field is typically set by device drivers when \nmmap()\n is called on their I/O space. It specifies, among other things, that the memory area must not be included in any process\u2019s core dump.\n\n\nThe \nVM_RESERVED\n flag specifies that the memory region must not be swapped out. It is also used by device driver mappings.\n\n\nThe \nVM_SEQ_READ\n flag indicates that the application is performing sequential (i.e. linear and contiguous) reads in this mapping. \nThe kernel can then opt to increase the read-ahead performed on the backing file.\n\n\nThe \nVM_RAND_READ\n flag specifies that the application is performing relatively random (i.e. not sequential) reads in this mapping. The kernel can then opt to decrease or disable read-ahead on the backing file.\n\n\n\n\nThese flags (\nVM_SEQ_READ\n and \nVM_RAND_READ\n flags) are set via the \nmadvise()\n system call with the \nMADV_SEQUENTIAL\n and \nMADV_RANDOM\n flags, respectively:\n\n\n\n\nRead-ahead is the act of reading sequentially ahead of requested data, in hopes that the additional data will be needed soon. This is beneficial if applications are reading data sequentially.\n\n\nIf data access patterns are random, however, read-ahead is not effective.\n\n\n\n\nVMA Operations\n\n\nThe \nvm_ops\n field in the \nvm_area_struct\n structure points to the table of operations associated with a given memory area, which the kernel can invoke to manipulate the VMA. The \nvm_area_struct\n acts as a generic object for representing any type of memory area, and the operations table describes the specific methods that can operate on this particular instance of the object.\n\n\nThe operations table is represented by struct \nvm_operations_struct\n and is defined in \nlinux/mm.h\n:\n\n\ninclude/linux/mm.h#L185\n\n\nstruct\n \nvm_operations_struct\n \n{\n\n    \nvoid\n \n(\n*\nopen\n)\n \n(\nstruct\n \nvm_area_struct\n \n*\n);\n\n    \nvoid\n \n(\n*\nclose\n)\n \n(\nstruct\n \nvm_area_struct\n \n*\n);\n\n    \nint\n \n(\n*\nfault\n)\n \n(\nstruct\n \nvm_area_struct\n \n*\n,\n \nstruct\n \nvm_fault\n \n*\n);\n\n    \nint\n \n(\n*\npage_mkwrite\n)\n \n(\nstruct\n \nvm_area_struct\n \n*\nvma\n,\n \nstruct\n \nvm_fault\n \n*\nvmf\n);\n\n    \nint\n \n(\n*\naccess\n)\n \n(\nstruct\n \nvm_area_struct\n \n*\n,\n \nunsigned\n \nlong\n \n,\n\n    \nvoid\n \n*\n,\n \nint\n,\n \nint\n);\n\n\n};\n\n\n\n\n\n\n\n\nvoid open(struct vm_area_struct *area)\n. This function is invoked when the given memory area is added to an address space.\n\n\nvoid close(struct vm_area_struct *area)\n. This function is invoked when the given memory area is removed from an\naddress space.\n\n\nint fault(struct vm_area_sruct *area, struct vm_fault *vmf)\n. This function is invoked by the page fault handler when a page that is not present in physical memory is accessed.\n\n\nint page_mkwrite(struct vm_area_sruct *area, struct vm_fault *vmf)\n. This function is invoked by the page fault handler when a page that was read-only is being made writable.\n\n\nint access(struct vm_area_struct *vma, unsigned long address, void *buf, int len, int write)\n. This function is invoked by \naccess_process_vm()\n when \nget_user_pages()\n fails.\n\n\n\n\nLists and Trees of Memory Areas\n\n\nAs discussed earlier, memory areas are accessed via both the \nmmap\n and the \nmm_rb\n fields of the memory descriptor. These two data structures independently point to all the memory area objects associated with the memory descriptor. They both contain pointers to the same \nvm_area_struct\n structures, represented in different ways.\n\n\nThe first field, \nmmap\n, links together all the memory area objects in a singly linked list:\n\n\n\n\nEach \nvm_area_struct\n structure is linked into the list via its \nvm_next\n field.\n\n\nThe areas are sorted by ascending address.\n\n\nThe first memory area is the \nvm_area_struct\n structure to which mmap points.\n\n\nThe last structure points to \nNULL\n.\n\n\n\n\nThe second field, \nmm_rb\n, links together all the memory area objects in a red-black tree.\n\n\n\n\nThe root of the red-black tree is \nmm_rb\n\n\nEach \nvm_area_struct\n structure in this address space is linked to the tree via its \nvm_rb\n field.\n\n\n\n\nA \nred-black tree\n is a type of balanced binary tree.\n\n\n\n\nEach element in a red-black tree is called a node.\n\n\nThe initial node is called the root of the tree.\n\n\nMost nodes have two children: a left child and a right child. Some nodes have only one child, and the final nodes, called leaves, have no children. For any node, the elements to the left are smaller in value, whereas the elements to the right are larger in value. Furthermore, each node is assigned a color (red or black) according to two rules: The children of a red node are black, and every path through the tree from a node to a leaf must contain the same number of black nodes. The root node is always red.\n\n\nSearching of, insertion to, and deletion from the tree is an O(log(\nn\n)) operation.\n\n\n\n\nThe kernel uses the redundant data structures to provide optimal performance regardless of the operation performed on the memory areas:\n\n\n\n\nThe linked list is used when every node needs to be traversed.\n\n\nThe red-black tree is used when locating a specific memory area in the address space.\n\n\n\n\nMemory Areas in Real Life\n\n\nThis section discusses a particular process\u2019s address space and the memory areas inside, with the useful \n/proc\n filesystem and the \npmap(1)\n utility. The example is a simple userspace program which does nothing:\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nreturn\n \n0\n;\n\n\n}\n\n\n\n\n\n\nMemory areas in this process's address space include:\n\n\n\n\nThe text section, data section, and bss.\n\n\nAssuming this process is dynamically linked with the C library, these three memory areas also exist for \nlibc.so\n and again for \nld.so\n.\n\n\nThe process\u2019s stack.\n\n\n\n\nThe output from \n/proc/\npid\n/maps\n lists the memory areas in this process\u2019s address space:\n\n\n$ cat /proc/1426/maps\n00e80000-00faf000 r-xp 00000000 03:01 208530 /lib/tls/libc-2.5.1.so\n00faf000-00fb2000 rw-p 0012f000 03:01 208530 /lib/tls/libc-2.5.1.so\n00fb2000-00fb4000 rw-p 00000000 00:00 0\n08048000-08049000 r-xp 00000000 03:03 439029 /home/rlove/src/example\n08049000-0804a000 rw-p 00000000 03:03 439029 /home/rlove/src/example\n40000000-40015000 r-xp 00000000 03:01 80276 /lib/ld-2.5.1.so\n40015000-40016000 rw-p 00015000 03:01 80276 /lib/ld-2.5.1.so\n4001e000-4001f000 rw-p 00000000 00:00 0\nbfffe000-c0000000 rwxp fffff000 00:00 0\n\n\n\n\n\nThe data is in the form:\n\n\nstart-end permission offset major:minor inode file\n\n\n\n\n\nThe \npmap(1)\n utility (of the \nprocps\n package) formats this information in a bit more readable manner:\n\n\n$ pmap 1426\nexample[1426]\n00e80000    (1212 KB)   r-xp    (03:01 208530)  /lib/tls/libc-2.5.1.so\n00faf000    (12 KB)     rw-p    (03:01 208530)  /lib/tls/libc-2.5.1.so\n00fb2000    (8 KB)      rw-p    (00:00 0)\n08048000    (4 KB)      r-xp    (03:03 439029)  /home/rlove/src/example\n08049000    (4 KB)      rw-p    (03:03 439029)  /home/rlove/src/example\n40000000    (84 KB)     r-xp    (03:01 80276)   /lib/ld-2.5.1.so\n40015000    (4 KB)      rw-p    (03:01 80276)   /lib/ld-2.5.1.so\n4001e000    (4 KB)      rw-p    (00:00 0)\nbfffe000    (8 KB)      rwxp        (00:00 0)       [ stack ]\nmapped: 1340 KB writable/private: 40 KB shared: 0 KB\n\n\n\n\n\nDescription of the above output:\n\n\n\n\nThe first three rows are the text section, data section, and bss of \nlibc.so\n, the C library.\n\n\nThe next two rows are the text and data section of our executable object.\n\n\nThe following three rows are the text section, data section, and bss for \nld.so\n, the \ndynamic linker\n.\n\n\nThe last row is the process\u2019s stack.\n\n\n\n\nPermissions:\n\n\n\n\nThe text sections are all readable and executable, which is what you expect for object code.\n\n\nThe data section and bss (which both contain global variables) are marked readable and writable, but not executable.\n\n\nThe stack is readable, writable, and executable.\n\n\n\n\nSizes:\n\n\nThe entire address space takes up about 1340KB, but only 40KB are writable and private. If a memory region is shared or nonwritable, the kernel keeps only one copy of the backing file in memory. Since a nonwritable mapping can never be changed (the mapping is only read from), it is safe to load the image only once into memory. Therefore, the C library needs to occupy only 1212KB in physical memory (not 1212KB multiplied by every process using the library). Because this process has access to about 1340KB worth of data and code, yet consumes only about 40KB of physical memory, the space savings from such sharing is substantial.\n\n\nThe memory areas without a mapped file on device 00:00 and inode zere are the zero pages, each of which is a mapping that consists of all zeros. By mapping the zero page over a writable memory area, the area is in effect \"initialized\" to all zeros. This is important in that it provides a zeroed memory area, which is expected by the bss and stack. Because the mapping is not shared, as soon as the process writes to this data, a copy is made (\u00e0 la \ncopy-on-write\n) and the value updated from zero.\n\n\nEach of the memory areas associated with the process corresponds to a \nvm_area_struct\n structure. Because the process was not a thread, it has a unique \nmm_struct\n structure referenced from its \ntask_struct\n.\n\n\nManipulating Memory Areas\n\n\nThe kernel often has to perform operations on a memory area, e.g. checking whether a given address exists in a given VMA. These operations are frequent and form the basis of the \nmmap()\n routine (discussed later). Helper functions are defined to assist these jobs.\n\n\nThese functions are all declared in \nlinux/mm.h\n.\n\n\nfind_vma()\n\n\nThe kernel provides a function \nfind_vma()\n (\ninclude/linux/mm.h#L1335\n) for searching for the VMA in which a given memory address resides. It is defined in \nmm/mmap.c\n:\n\n\nstruct\n \nvm_area_struct\n \n*\n \nfind_vma\n(\nstruct\n \nmm_struct\n \n*\nmm\n,\n \nunsigned\n \nlong\n \naddr\n);\n\n\n\n\n\n\n\n\nThis function searches the given address space for the first memory area whose \nvm_end\n field is greater than \naddr\n. In other words, this function finds the first memory area that contains \naddr\n or begins at an address greater than \naddr\n.\n\n\nIf no such memory area exists, the function returns \nNULL\n. Otherwise, a pointer to the \nvm_area_struct\n structure is returned.\n\n\nBecause the returned VMA may start at an address greater than \naddr\n, the given address does not necessarily lie inside the returned VMA.\n\n\nThe result of the \nfind_vma()\n function is cached in the \nmmap_cache\n field of the memory descriptor.\n\n\nBecause of the probability of an operation on one VMA being followed by more operations on that same VMA, the cached results have a decent hit rate (about 30\u201340% in practice).  Checking the cached result is quick. If the given address is not in the cache, you must search the memory areas associated with this memory descriptor for a match, which is done via the red-black tree:\n\n\n\n\nmm/mmap.c#L1569\n\n\nstruct\n \nvm_area_struct\n \n*\nfind_vma\n(\nstruct\n \nmm_struct\n \n*\nmm\n,\n \nunsigned\n \nlong\n \naddr\n)\n\n\n{\n\n    \nstruct\n \nvm_area_struct\n \n*\nvma\n \n=\n \nNULL\n;\n\n\n    \nif\n \n(\nmm\n)\n \n{\n\n        \n/* Check the cache first. */\n\n        \n/* (Cache hit rate is typically around 35%.) */\n\n        \nvma\n \n=\n \nmm\n-\nmmap_cache\n;\n\n        \nif\n \n(\n!\n(\nvma\n \n \nvma\n-\nvm_end\n \n \naddr\n \n \nvma\n-\nvm_start\n \n=\n \naddr\n))\n \n{\n\n            \nstruct\n \nrb_node\n \n*\n \nrb_node\n;\n\n\n            \nrb_node\n \n=\n \nmm\n-\nmm_rb\n.\nrb_node\n;\n\n            \nvma\n \n=\n \nNULL\n;\n\n\n            \nwhile\n \n(\nrb_node\n)\n \n{\n\n                \nstruct\n \nvm_area_struct\n \n*\n \nvma_tmp\n;\n\n\n                \nvma_tmp\n \n=\n \nrb_entry\n(\nrb_node\n,\n\n                        \nstruct\n \nvm_area_struct\n,\n \nvm_rb\n);\n\n\n                \nif\n \n(\nvma_tmp\n-\nvm_end\n \n \naddr\n)\n \n{\n\n                    \nvma\n \n=\n \nvma_tmp\n;\n\n                    \nif\n \n(\nvma_tmp\n-\nvm_start\n \n=\n \naddr\n)\n\n                        \nbreak\n;\n\n                    \nrb_node\n \n=\n \nrb_node\n-\nrb_left\n;\n\n                \n}\n \nelse\n\n                    \nrb_node\n \n=\n \nrb_node\n-\nrb_right\n;\n\n            \n}\n\n            \nif\n \n(\nvma\n)\n\n                \nmm\n-\nmmap_cache\n \n=\n \nvma\n;\n\n        \n}\n\n    \n}\n\n    \nreturn\n \nvma\n;\n\n\n\n\n\n\n\n\nThe initial check of \nmmap_cache\n tests whether the cached VMA contains the desired address. Note that simply checking whether the VMA\u2019s \nvm_end\n field is bigger than \naddr\n would not ensure that this is the first such VMA that is larger than \naddr\n. Thus, for the cache to be useful here, the given \naddr\n must lie in (\nvma-\nvm_end \n addr \n vma-\nvm_start \n= addr\n) the VMA.\n\n\nIf the cache does not contain the desired VMA, the function must search the red-black tree:\n\n\nIf the current VMA\u2019s \nvm_end\n is larger than \naddr\n, the function follows the left child; otherwise, it follows the right child.\n\n\nThe function terminates as soon as a VMA is found that contains \naddr\n.\n\n\nIf such a VMA is not found, the function continues traversing the tree and returns the first VMA it found that starts after \naddr\n. If no VMA is ever found, \nNULL\n is returned.\n\n\n\n\n\n\n\n\nfind_vma_prev()\n\n\nThe \nfind_vma_prev()\n function works the same as \nfind_vma()\n, but it also returns the last VMA before addr. The function is also defined in \nmm/mmap.c\n and declared in \nlinux/mm.h\n:\n\n\nstruct\n \nvm_area_struct\n \n*\n \nfind_vma_prev\n(\nstruct\n \nmm_struct\n \n*\nmm\n,\n \nunsigned\n \nlong\n \naddr\n,\n\n                                      \nstruct\n \nvm_area_struct\n \n**\npprev\n)\n\n\n\n\n\n\nThe \npprev\n argument stores a pointer to the VMA preceding \naddr\n.\n\n\nfind_vma_intersection()\n\n\nThe \nfind_vma_intersection()\n function returns the first VMA that overlaps a given address interval. The function is defined in \nlinux/mm.h\n because it is inline:\n\n\nstatic\n \ninline\n \nstruct\n \nvm_area_struct\n \n*\n\n\nfind_vma_intersection\n(\nstruct\n \nmm_struct\n \n*\nmm\n,\n\n                      \nunsigned\n \nlong\n \nstart_addr\n,\n\n                      \nunsigned\n \nlong\n \nend_addr\n)\n\n\n{\n\n    \nstruct\n \nvm_area_struct\n \n*\nvma\n;\n\n\n    \nvma\n \n=\n \nfind_vma\n(\nmm\n,\n \nstart_addr\n);\n\n    \nif\n \n(\nvma\n \n \nend_addr\n \n=\n \nvma\n-\nvm_start\n)\n\n    \nvma\n \n=\n \nNULL\n;\n\n    \nreturn\n \nvma\n;\n\n\n}\n\n\n\n\n\n\nThe first parameter is the address space to search, \nstart_addr\n is the start of the interval, and \nend_addr\n is the end of the interval.\n\n\nIf \nfind_vma()\n returns \nNULL\n, so would \nfind_vma_intersection()\n. If \nfind_vma()\n returns a valid VMA, however, \nfind_vma_intersection()\n returns the same VMA only if it does not start after the end of the given address range. If the returned memory area does start after the end of the given address range, the function returns \nNULL\n.\n\n\nmmap()\n and \ndo_mmap()\n: Creating an Address Interval\n\n\nThe \ndo_mmap()\n function creates a new linear address interval. This function does not technically create a new VMA, because:\n\n\n\n\nIf the created address interval is adjacent to an existing address interval, and if they share the same permissions, the two intervals are merged into one.\n\n\nIf this is not possible, a new VMA is created.\n\n\n\n\nIn any case, \ndo_mmap()\n is the function used to add an address interval to a process\u2019s address space, whether that means expanding an existing memory area or creating a new one.\n\n\nThe \ndo_mmap()\n function is declared in \nlinux/mm.h\n:\n\n\ninclude/linux/mm.h#L1271\n\n\nunsigned\n \nlong\n \ndo_mmap\n(\nstruct\n \nfile\n \n*\nfile\n,\n \nunsigned\n \nlong\n \naddr\n,\n\n                      \nunsigned\n \nlong\n \nlen\n,\n \nunsigned\n \nlong\n \nprot\n,\n\n                      \nunsigned\n \nlong\n \nflag\n,\n \nunsigned\n \nlong\n \noffset\n)\n\n\n\n\n\n\n\n\nThis function maps the file specified by \nfile\n at offset \noffset\n for length \nlen\n.\n\n\nThe \nfile\n parameter can be \nNULL\n and \noffset\n can be zero, in which case the mapping will not be backed by a file. In that case, this is called an \nanonymous mapping\n.\n\n\nIf a \nfile\n and \noffset\n are provided, the mapping is called a \nfile-backed mapping\n.\n\n\n\n\n\n\nThe \naddr\n function optionally specifies the initial address from which to start the search for a free interval.\n\n\nThe \nprot\n parameter specifies the access permissions for pages in the memory area.The possible permission flags are defined in \nasm/mman.h\n and are unique to each supported architecture, although in practice each architecture defines the flags listed in the following table:\n\n\n\n\n\n\n\n\n\n\nFlag\n\n\nEffect on the Pages in the New Interval\n\n\n\n\n\n\n\n\n\n\nPROT_READ\n\n\nCorresponds to \nVM_READ\n\n\n\n\n\n\nPROT_WRITE\n\n\nCorresponds to \nVM_WRITE\n\n\n\n\n\n\nPROT_EXEC\n\n\nCorresponds to \nVM_EXEC\n\n\n\n\n\n\nPROT_NONE\n\n\nCannot access page\n\n\n\n\n\n\n\n\n\n\nThe \nflags\n parameter specifies flags that correspond to the remaining VMA flags. These flags specify the type and change the behavior of the mapping. They are also defined in \nasm/mman.h\n:\n\n\n\n\n\n\n\n\n\n\nFlag\n\n\nEffect on the New Interval\n\n\n\n\n\n\n\n\n\n\nMAP_SHARED\n\n\nThe mapping can be shared.\n\n\n\n\n\n\nMAP_PRIVATE\n\n\nThe mapping cannot be shared.\n\n\n\n\n\n\nMAP_FIXED\n\n\nThe new interval must start at the given address \naddr\n.\n\n\n\n\n\n\nMAP_ANONYMOUS\n\n\nThe mapping is not file-backed, but is anonymous.\n\n\n\n\n\n\nMAP_GROWSDOWN\n\n\nCorresponds to \nVM_GROWSDOWN\n.\n\n\n\n\n\n\nMAP_DENYWRITE\n\n\nCorresponds to \nVM_DENYWRITE\n.\n\n\n\n\n\n\nMAP_EXECUTABLE\n\n\nCorresponds to \nVM_EXECUTABLE\n.\n\n\n\n\n\n\nMAP_LOCKED\n\n\nCorresponds to \nVM_LOCKED\n.\n\n\n\n\n\n\nMAP_NORESERVE\n\n\nNo need to reserve space for the mapping.\n\n\n\n\n\n\nMAP_POPULATE\n\n\nPopulate (prefault) page tables.\n\n\n\n\n\n\nMAP_NONBLOCK\n\n\nDo not block on I/O.\n\n\n\n\n\n\n\n\n\n\nIf any of the parameters are invalid, \ndo_mmap()\n returns a negative value. Otherwise, a suitable interval in virtual memory is located.\n\n\nIf possible, the interval is merged with an adjacent memory area. Otherwise:\n\n\nA new \nvm_area_struct\n structure is allocated from the \nvm_area_cachep\n slab cache, and the new memory area is added to the address space\u2019s\nlinked list and red-black tree of memory areas via the \nvma_link()\n function.\n\n\nNext, the \ntotal_vm\n field in the memory descriptor is updated.\n\n\nFinally, the function returns the initial address of the newly created address interval.\n\n\n\n\n\n\n\n\nThe \ndo_mmap()\n functionality is exported to user-space via the \nmmap()\n system call, defined as:\n\n\nvoid\n \n*\n \nmmap2\n(\nvoid\n \n*\nstart\n,\n\n             \nsize_t\n \nlength\n,\n\n             \nint\n \nprot\n,\n\n             \nint\n \nflags\n,\n\n             \nint\n \nfd\n,\n\n             \noff_t\n \npgoff\n)\n\n\n\n\n\n\nThis system call is named \nmmap2()\n because it is the second variant of\nmmap()\n:\n\n\n\n\nThe original \nmmap()\n took an offset in bytes as the last parameter; the current \nmmap2()\n receives the offset in pages. This enables larger files with larger offsets to be mapped.\n\n\nThe original \nmmap()\n, as specified by POSIX, is available from the C library as \nmmap()\n, but is no longer implemented in the kernel proper, whereas the new version is available as \nmmap2()\n. Both library calls use the \nmmap2()\n system call, with the original \nmmap()\n converting the offset from bytes to pages.\n\n\n\n\nmunmap()\n and \ndo_munmap()\n: Removing an Address Interval\n\n\nThe \ndo_munmap()\n function removes an address interval from a specified process address space. The function is declared in \nlinux/mm.h\n:\n\n\ninclude/linux/mm.h#L1284\n\n\nint\n \ndo_munmap\n(\nstruct\n \nmm_struct\n \n*\nmm\n,\n \nunsigned\n \nlong\n \nstart\n,\n \nsize_t\n \nlen\n)\n\n\n\n\n\n\nThe first parameter \nmm\n specifies the address space from which the interval starting at address \nstart\n of length \nlen\n bytes is removed. On success, zero is returned. Otherwise, a negative error code is returned.\n\n\nAs the complement of the \nmmap()\n, the \nmunmap()\n system call is exported to user-space as a means to enable processes to remove address intervals from their address space:\n\n\nint\n \nmunmap\n(\nvoid\n \n*\nstart\n,\n \nsize_t\n \nlength\n)\n\n\n\n\n\n\nThe system call is defined in \nmm/mmap.c\n and acts as a simple wrapper to \ndo_munmap()\n:\n\n\nasmlinkage\n \nlong\n \nsys_munmap\n(\nunsigned\n \nlong\n \naddr\n,\n \nsize_t\n \nlen\n)\n\n\n{\n\n    \nint\n \nret\n;\n\n    \nstruct\n \nmm_struct\n \n*\nmm\n;\n\n    \nmm\n \n=\n \ncurrent\n-\nmm\n;\n\n    \ndown_write\n(\nmm\n-\nmmap_sem\n);\n\n    \nret\n \n=\n \ndo_munmap\n(\nmm\n,\n \naddr\n,\n \nlen\n);\n\n    \nup_write\n(\nmm\n-\nmmap_sem\n);\n\n    \nreturn\n \nret\n;\n\n\n}\n\n\n\n\n\n\nPage Tables\n\n\nAlthough applications operate on virtual memory mapped to physical addresses, processors operate directly on those physical addresses. Consequently, when an application accesses a virtual memory address, it must first be converted to a physical address before the processor can resolve the request. Performing this lookup is done via \npage tables\n. Page tables work by splitting the virtual address into chunks. Each chunk is used as an index into a table. The table points to either another table or the associated physical page.\n\n\nIn Linux, the page tables consist of three levels. The multiple levels enable a sparsely populated address space, even on 64-bit machines. If the page tables were implemented as a single static array, their size on even 32-bit architectures would be enormous. Linux uses three levels of page tables even on architectures that do not support three levels in hardware. (For example, some hardware uses only two levels or implements a hash in hardware.) Using three levels is a sort of \"greatest common denominator\": architectures with a less complicated implementation can simplify the kernel page tables as needed with compiler optimizations.\n\n\n\n\nThe top-level page table is the \npage global directory\n (PGD), which consists of an array of \npgd_t\n types. On most architectures, the \npgd_t\n type is an \nunsigned long\n.The entries in the PGD point to entries in the second-level directory, the PMD.\n\n\nThe second-level page table is the \npage middle directory\n (PMD), which is an array of \npmd_t\n types. The entries in the PMD point to entries in the PTE.\n\n\nThe final level is called simply the \npage table\n and consists of page table entries of type \npte_t\n. Page table entries point to physical pages.\n\n\nIn most architectures, page table lookups are handled (at least to some degree) by hardware.\n\n\nIn normal operation, hardware can handle much of the responsibility of using the page tables. [p321]\n\n\n\n\n\n\n\n\nThe following figure diagrams the flow of a virtual to physical address lookup using page tables.\n\n\n\n\n\n\n[UTLK p57-58]\n\n\nUp to version 2.6.10, the Linux paging model consisted of three paging levels. Starting with version 2.6.11, a four-level paging model has been adopted. The four types of page tables illustrated in the figure below:\n\n\n\n\n\n\n\n\nEach process has its own page tables (threads share them).The \npgd\n field of the memory descriptor points to the process\u2019s page global directory. Manipulating and traversing page tables requires the \npage_table_lock\n, which is located inside the associated memory descriptor.\n\n\nPage table data structures are quite architecture-dependent and thus are defined in \nasm/page.h\n.\n\n\n\n\nTranslation Lookaside Buffer *\n\n\nBecause nearly every access of a page in virtual memory must be resolved to its corresponding address in physical memory, the performance of the page tables is very critical. Unfortunately, looking up all these addresses in memory can not be done so quickly. To facilitate this, most processors implement a \ntranslation lookaside buffer\n (TLB), which acts as a hardware cache of virtual-to-physical mappings. When accessing a virtual address, the processor first checks whether the mapping is cached in the TLB:\n\n\n\n\nIf there is a hit, the physical address is immediately returned.\n\n\nIf there is a miss, the page tables are consulted for the corresponding physical address.\n\n\n\n\nFuture work of page tables *\n\n\nPage table management is still a critical and evolving\u2014part of the kernel. Changes to this area in 2.6 include allocating parts of the page table out of high memory. Future possibilities include shared page tables with copy-on-write semantics. In that scheme, page tables would be shared between parent and child across a \nfork()\n. When the parent or the child attempted to modify a particular page table entry, a copy would be created, and the two processes would no longer share that entry. Sharing page tables would remove the overhead of copying the page table entries on \nfork()\n.", 
            "title": "Chapter 15. The Process Address Space"
        }, 
        {
            "location": "/lkd/ch16/", 
            "text": "Chapter 16. The Page Cache and Page Writeback", 
            "title": "Chapter 16. The Page Cache and Page Writeback"
        }, 
        {
            "location": "/unp/", 
            "text": "UNP\n\n\n\n\nChapter 1. Introduction\n\n\nChapter 2. The Transport Layer: TCP, UDP, and SCTP\n\n\nChapter 3. Sockets Introduction\n\n\nChapter 4. Elementary TCP Sockets\n\n\nChapter 5. TCP Client/Server Example\n\n\nChapter 6. I/O Multiplexing: The select and poll Functions\n\n\nChapter 7. Socket Options", 
            "title": "Contents"
        }, 
        {
            "location": "/unp/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nIntroduction\n\n\nThe \nclient\n and \nserver\n organization is used by most network-awared applications. Some complex applications also require \nasynchronous callback\n communication, where the server initiates a message to the client.\n\n\nunp.h\n header\n\n\n\n\nunp.h\n\n\n\n\nA Simple Daytime Client\n\n\ndaytimetcpcli.c\n\n\n\n\n\nCreate TCP socket\n\n\nThe \nsocket\n function creates an Internet (\nAF_INET\n) stream (\nSOCK_STREAM\n) socket, which is a fancy name for a TCP socket. The function returns a small integer descriptor to identify the socket.\n\n\nSpecify server's IP address and port\n\n\nThe IP address (\nsin_addr\n) and port number (\nsin_port\n) fields in the Internet socket address structure (\nsockaddr_in\n) must be in specific formats:\n\n\n\n\nhtons\n (host to network short): converts the binary port number\n\n\ninet_pton\n (presentation to numeric): convert the ASCII command-line argument (such as \n206.62.226.35\n when we ran this example) into the proper format.\n\n\n\n\nbzero\n is not an ANSI C function, but is used in this book instead of the ANSI C \nmemset\n function, because \nbzero\n is easier to remember (with only two arguments) than \nmemset\n (with three arguments).\n\n\nEstablish connection with server\n\n\n\n\nconnect\n\n\n\n\nIn the \nunp.h\n header, \nSA\n is defined to be \nstruct sockaddr\n, a generic socket address structure.\n\n\nRead and display server's reply\n\n\nWe must be careful when using TCP because it is a \nbyte-stream\n protocol with no record boundaries. Since we cannot assume that the server's reply will be returned by a single \nread\n, we always need to code the \nread\n in a loop when reading from a TCP socket.\n\n\nTerminate program\n\n\nexit\n terminates the program. Unix always closes all open descriptors when a process terminates.\n\n\nProtocol Independence\n\n\nThe above program is protocol-depdent on IPv4.\n\n\nIt is better to make a program protocol-independent by using the \ngetaddrinfo\n function.\n\n\nError Handling: Wrapper Functions\n\n\nWe can shorten our programs by defining a \nwrapper function\n that performs the actual function call, tests the return value, and terminates on an error.\n\n\nsockfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n\n\n\n\nWith careful C coding, we could use macros instead of functions, providing a little run-time efficiency, but these wrapper functions are rarely the performance bottleneck of a program. This book uses these wrapper functions unless otherwise explicit error needs handling.\n\n\nUnix \nerrno\n Value\n\n\nThe value of \nerrno\n is set by a function only if an error occurs. All of the positive error values are constants with all-uppercase names beginning with \"E,\" and are normally defined in the \nsys/errno.h\n header. No error has a value of 0.\n\n\nStoring errno in a global variable does not work with multiple threads that share all global variables.\n\n\nA Simple Daytime Server\n\n\ndaytimetcpsrv.c\n\n\n\n\n\nCreate a TCP socket\n\n\nIdentical to the client code.\n\n\nBind server's well-known port to socket\n\n\n\n\nbind\n: the server's well-known port (13) is bound to the socket by calling \nbind\n\n\nINADDR_ANY\n allows the server to accept a client connection on any interface\n\n\n\n\nConvert socket to listening socket\n\n\n\n\nlisten\n: converts the socket into a listening socket, on which incoming connections from clients will be accepted by the kernel\n\n\nlistenfd\n in the code is called a \nlistening descriptor\n\n\n\n\nAccept client connection, send reply\n\n\n\n\naccept\n\n\nconnfd\n in the code is called a \nconnected descriptor\n for communication with the client. A new descriptor is returned by accept for each client that connects to our server.\n\n\n\n\nThis book uses this code style for infinite loop:\n\n\nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n    \n// . . .\n\n\n}\n\n\n\n\n\n\nsnprintf\n function\n\n\n\n\nsnprintf\n instead of \nsprintf\n\n\n\n\nSimilarly:\n\n\n\n\nfgets\n instead of \ngets\n\n\nstrncat\n or \nstrlcat\n instead of \nstrcat\n\n\nstrncpy\n or \nstrlcpy\n instead of a \nstrcpy\n\n\n\n\nTerminate connection\n\n\nclose\n initiates the normal TCP connection termination sequence: a FIN is sent in each direction and each FIN is acknowledged by the other end.\n\n\nThe server implemented in the above server code is:\n\n\n\n\nProtocol-dependent on IPv4\n\n\nHandles only one client at a time. If multiple client connections arrive at about the same time, the kernel queues them, up to some limit, and returns them to \naccept\n one at a time.\n\n\nCalled an \niterative server\n. A \nconcurrent server\n handles multiple clients at the same time.\n\n\n\n\nOSI Model\n\n\nSome terms mentioned:\n\n\n\n\nRaw socket\n: it is possible for an application to bypass the transport layer and use IPv4 or IPv6 directly\n\n\nXTI\n\n\n\n\nSockets provide the interface from the upper three layers of the OSI model into the transport layer:\n\n\n\n\nThe upper three layers handle all the details of the application. The lower four layers know little about the application, but handle all the communication details\n\n\nThe upper three layers form what is called a \nuser process\n while the lower four layers are normally provided as part of the operating system (OS) kernel\n\n\n\n\nBSD Networking History\n\n\nLinux does not fit into the Berkeley-derived classification: Its networking code and sockets API were developed from scratch.\n\n\nUnix Standards\n\n\nBackground on POSIX\n\n\n\n\nPOSIX: Portable Operating System Interface, developed by IEEE and adopted as standards by ISO and IEC (ISO/IEC)\n\n\n\n\nBackground on The Open Group\n\n\n\n\nSingle UNIX Specification\n\n\n\n\nInternet Engineering Task Force (IETF)\n\n\n64-Bit Architectures\n\n\n\n\nILP32\n: integers (I), long integers (L), and pointers (P) occupy 32 bits.\n\n\nLP64\n:only long integers (L) and pointers (P) require 64 bits.\n\n\n\n\nFrom a programming perspective, the LP64 model means we cannot assume that a pointer can be stored in an integer. We must also consider the effect of the LP64 model on existing APIs\n\n\nOn a 32-bit system, \nsize_t\n is a 32-bit value, but on a 64-bit system, it must be a 64-bit value, to take advantage of the larger addressing model. This means a 64-bit system will probably contain a typedef of \nsize_t\n to be an unsigned long.", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/unp/ch2/", 
            "text": "Chapter 2. The Transport Layer: TCP, UDP, and SCTP\n\n\nIntroduction\n\n\nThis chapter focuses on the transport layer: TCP, UDP, and Stream Control Transmission Protocol (SCTP). UDP is a simple, unreliable datagram protocol, while TCP is a sophisticated, reliable byte-stream protocol. SCTP is similar to TCP as a reliable transport protocol, but it also provides message boundaries, transport-level support for multihoming, and a way to minimize head-of-line blocking.\n\n\nThe Big Picture\n\n\nOverview of TCP/IP protocols:\n\n\n\n\n\n\n\n\nProtocol\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nIPv4\n\n\nInternet Protocol version 4. IPv4 uses 32-bit addresses and provides packet delivery service for TCP, UDP, SCTP, ICMP, and IGMP.\n\n\n\n\n\n\nIPv6\n\n\nInternet Protocol version 6. IPv6 uses 128-bit addresses.\n\n\n\n\n\n\nTCP\n\n\nTransmission Control Protocol. TCP is a connection-oriented protocol that provides a reliable, full-duplex byte stream to its users\n\n\n\n\n\n\nUDP\n\n\nUser Datagram Protocol. UDP is a connectionless protocol, and UDP sockets are an example of datagram sockets.\n\n\n\n\n\n\nSCTP\n\n\nStream Control Transmission Protocol. SCTP is a connection-oriented protocol that provides a reliable full-duplex association\n\n\n\n\n\n\nICMP\n\n\nInternet Control Message Protocol. ICMP handles error and control information between routers and hosts.\n\n\n\n\n\n\nIGMP\n\n\nInternet Group Management Protocol. IGMP is used with multicasting.\n\n\n\n\n\n\nARP\n\n\nAddress Resolution Protocol. ARP maps an IPv4 address into a hardware address (such as an Ethernet address). ARP is normally used on broadcast networks such as Ethernet, \ntoken ring\n, and \nFDDI\n, and is not needed on point-to-point networks.\n\n\n\n\n\n\nRARP\n\n\nReverse Address Resolution Protocol. RARP maps a hardware address into an IPv4 address. It is sometimes used when a diskless node is booting.\n\n\n\n\n\n\nICMPv6\n\n\nInternet Control Message Protocol version 6. ICMPv6 combines the functionality of ICMPv4, IGMP, and ARP.\n\n\n\n\n\n\nBPF\n\n\nBSD packet filter\n. This interface provides access to the datalink layer. It is normally found on Berkeley-derived kernels.\n\n\n\n\n\n\nDLPI\n\n\nDatalink provider interface\n.\n\n\n\n\n\n\n\n\nUser Datagram Protocol (UDP)\n\n\n\n\nLack of reliability\n\n\nEach UDP datagram has a length\n\n\nConnectionless\n service\n\n\n\n\nTransmission Control Protocol (TCP)\n\n\n\n\nConnection\n: TCP provides connections between clients and servers. A TCP client establishes a connection with a server, exchanges data across the connection, and then terminates the connection.\n\n\nReliability\n: TCP requires acknowledgment when sending data. If an acknowledgment is not received, TCP automatically retransmits the data and waits a longer amount of time.\n\n\nRound-trip time\n (RTT): TCP estimates RTT between a client and server dynamically so that it knows how long to wait for an acknowledgment.\n\n\nSequencing\n: TCP associates a sequence number with every byte (\nsegment\n, unit of data that TCP passes to IP.) it sends. TCP reorders out-of-order segments and discards duplicate segments.\n\n\nFlow control\n\n\nFull-duplex\n: an application can send and receive data in both directions on a given connection at any time.\n\n\n\n\nStream Control Transmission Protocol (SCTP)\n\n\nLike TCP, SCTP provides reliability, sequencing, flow control, and full-duplex data transfer.\n\n\nUnlike TCP, SCTP provides:\n\n\n\n\nAssociation\n instead of \"connection\": An association refers to a communication between two systems, which may involve more than two addresses due to multihoming.\n\n\nMessage-oriented\n: provides sequenced delivery of individual records. Like UDP, the length of a record written by the sender is passed to the receiving application.\n\n\nMultihoming\n: allows a single SCTP endpoint to support multiple IP addresses. This feature can provide increased robustness against network failure.\n\n\n\n\nTCP Connection Establishment and Termination\n\n\nThree-Way Handshake\n\n\n\n\n\n\nServer: \npassive open\n, by calling \nsocket\n, \nbind\n, and \nlisten\n\n\nClient: \nactive open\n, by calling \nconnect\n. The client TCP to send a \"synchronize\" (SYN) segment with no data but it contains client's initial sequence number for the data to be sent on the connection.\n\n\nServer: acknowledges (ACK) client's SYN. The server sends its SYN and the ACK of the client's SYN in a single segment which also contains its own SYN containing the initial sequence number for the data to be sent on the connection.\n\n\nClient: acknowledges the server's SYN.\n\n\n\n\nThe client's initial sequence number as \nJ\n and the server's initial sequence number as \nK\n. The acknowledgment number in an ACK is the next expected sequence number for the end sending the ACK. Since a SYN occupies one byte of the sequence number space, the acknowledgment number in the ACK of each SYN is the initial sequence number plus one.\n\n\nTCP Options\n\n\n\n\nMSS option. The TCP sending the SYN announces its \nmaximum segment size\n (the maximum amount of data that it is willing to accept in each TCP segment)on this connection.\n\n\nWindow scale option. [p38]\n\n\nTimestamp option\n\n\n\n\nTCP Connection Termination\n\n\n\n\nIt takes four segments to terminate a connection:\n\n\n\n\nOne end calls \nclose\n first by sending a FIN segment to mean it is finished sending data. This is called \nactive close\n.\n\n\nThe other end that receives the FIN performs the \npassive close\n. The received FIN is acknowledged by TCP (sending an ACK segment). The receipt of the FIN is also passed to the application as an end-of-file.\n\n\nSometime later, the application that received the end-of-file will close its socket. This causes its TCP to send a FIN.\n\n\nThe TCP on the system that receives this final FIN (the end that did the active close) acknowledges the FIN\n\n\n\n\nA FIN occupies one byte of sequence number space just like a SYN. Therefore, the ACK of each FIN is the sequence number of the FIN plus one.\n\n\nTCP State Transition Diagram\n\n\n\n\nThere are 11 different states defined for a connection and the rules of TCP dictate the transitions from one state to another, based on the current state and the segment received in that state.\n\n\nWatching the Packets\n\n\n\n\nThe client in this example announces an MSS of 536 (\nminimum reassembly buffer size\n) and the server announces an MSS of 1,460 (typical for IPv4 on an Ethernet). It is okay for the MSS to be different in each direction. The acknowledgment of the client's request is sent with the server's reply. This is called \npiggybacking\n and will normally happen when the time it takes the server to process the request and generate the reply is less than around 200 ms. \nWith TCP, there would be eight segments of overhead. If UDP was used, only two packets would be exchanged.\n\n\n\n\nUDP removes all the reliability that TCP provides to the application.\n\n\nUDP avoids the overhead of TCP connection establishment and connection termination.\n\n\n\n\nTIME_WAIT State\n\n\nThe end that performs the active close goes through the TIME_WAIT state. The duration that this endpoint remains in the TIME_WAIT state is twice the \nmaximum segment lifetime\n (MSL), sometimes called 2MSL, which is between 1 and 4 minutes. The MSL is the maximum amount of time that any given IP datagram can live in a network. The IPv4 TTL field  IPv6 hop limit field have a maximum value 255. The assumption is made that a packet with the maximum hop limit of 255 cannot exist in a network for more than MSL seconds. [p43]\n\n\nTCP must handle \nlost duplicates\n (or \nwandering duplicate\n).\n\n\nThere are two reasons for the TIME_WAIT state:\n\n\n\n\nTo implement TCP's full-duplex connection termination reliably. If TCP is performing all the work necessary to terminate both directions of data flow cleanly for a connection (its full-duplex close), then it must correctly handle the loss of any of these four segments.\n\n\nTo allow old duplicate segments to expire in the network. When we successfully establish a TCP connection, all old duplicates from previous \nincarnations\n of the connection have expired in the network.\n\n\n\n\nPort Numbers\n\n\nAll three transport layers (UDP, SCTP and TCP) use 16-bit integer port numbers to differentiate between processes.\n\n\n\n\nThe \nwell-known ports\n: 0 through 1023.\n\n\nThe \nregistered ports\n: 1024 through 49151\n\n\nThe \ndynamic ports\n or \nprivate ports\n, 49152 through 65535. Also called \nephemeral ports\n.\n\n\n\n\n\n\nSome notes from the figure above:\n\n\n\n\nOn Unix, \nreserved port\n is any port less than 1024. These ports can only be assigned to a socket by an appropriately privileged process. All the IANA well-known ports are reserved ports. The server allocating this port must have superuser privileges when it starts.\n\n\nHistorically, Berkeley-derived implementations (starting with 4.3BSD) have allocated \nephemeral ports\n in the range 1024\u20135000. Many newer systems allocate ephemeral ports differently to provide more ephemeral ports, either using the IANA-defined ephemeral range or a larger range\n\n\n\n\nSocket Pair\n\n\n\n\nSocket pair\n: the four-tuple that defines the two endpoints of a TCP connection: the local IP address, local port, foreign IP address, and foreign port. A socket pair uniquely identifies every TCP connection on a network.\n\n\nSocket\n: two values (an IP address and a port number) that identify each endpoint.\n\n\n\n\nTCP Port Numbers and Concurrent Servers\n\n\n[p52-55]\n\n\nBuffer Sizes and Limitations\n\n\nFigures: \nIPv4 Header\n, \nIPv6 Header\n\n\n\n\nMaximum size of an IPv4 datagram: 65,535 bytes (including the header), because of the 16-bit total length field.\n\n\nMaximum size of an IPv6 datagram: 65,575 bytes (including the 40-byte IPv6 header), because of the 16-bit payload length field. IPv6 has a jumbo payload option, which extends the payload length field to 32 bits, but this option is supported only on datalinks with a \nmaximum transmission unit\n (MTU) that exceeds 65,535.\n\n\nMTU\n (maximum transmission unit): dictated by the hardware. Ethernet MTU is 1,500 bytes; Point-to-point links have a configurable MTU.\n\n\nMinimum link MTU for IPv4: 68 bytes. This permits a maximum-sized IPv4 header (20 bytes of fixed header, 40 bytes of options)  and minimum-sized fragment (the fragment offset is in units of 8 bytes) \n[errata]\n\n\nMinimum link MTU for IPv6: 1,280 bytes.\n\n\n\n\n\n\nPath MTU\n: smallest MTU in the path between two hosts. Today, the Ethernet MTU of 1,500 bytes is often the path MTU. The path MTU need not be the same in both directions between any two hosts because routing in the Internet is often asymmetric.\n\n\nFragmentation\n is performed by both IPv4 and IPv6 when the size of an IP datagram to be sent out an interface exceeds the link MTU. The fragments are not normally \nreassembled\n until they reach the final destination.\n\n\nIPv4: hosts perform fragmentation on datagrams that they generate and routers perform fragmentation on datagrams that they forward\n\n\nIPv6: only hosts perform fragmentation on datagrams that they generate; routers do not fragment datagrams that they are forwarding\n\n\nIPv4 header contains fields to handle fragmentation. IPv6 contains an option header with the fragmentation information.\n\n\n\n\n\n\n\"Don't Fragment\" (DF) bit in IPv4 header specifies that this datagram must not be fragmented, either by the sending host or by any router. A router that receives an IPv4 datagram with the DF bit set whose size exceeds the outgoing link's MTU generates an ICMPv4 \"destination unreachable, fragmentation needed but DF bit set\" error message.\n\n\nSince IPv6 routers do not perform fragmentation, there is an implied DF bit with every IPv6 datagram. When an IPv6 router receives a datagram whose size exceeds the outgoing link's MTU, it generates an ICMPv6 \"packet too big\" error message\n\n\nPath MTU discovery\n uses IPv4 DF bit and its implied IPv6 counterpart. Path MTU discovery is optional with IPv4, but IPv6 implementations all either support path MTU discovery or always send using the minimum MTU. [p55]\n\n\n\n\n\n\nMinimum reassembly buffer size\n: the minimum datagram size that we are guaranteed any implementation must support.\n\n\nIPv4: 576 bytes. We have no idea whether a given destination can accept a 577-byte datagram or not. Therefore, many IPv4 applications that use UDP (e.g., DNS, RIP, TFTP, BOOTP, SNMP) prevent applications from generating IP datagrams that exceed this size.\n\n\nIPv6: 1,500 bytes\n\n\n\n\n\n\nTCP has a \nmaximum segment size\n (MSS) that announces to the peer TCP the maximum amount of TCP data that the peer can send per segment. We saw the MSS option on the SYN segments in \nFigure 2.5\n. The goal of the MSS is to tell the peer the actual value of the reassembly buffer size and to try to avoid fragmentation. The MSS is often set to the interface MTU minus the fixed sizes of the IP and TCP headers. On an Ethernet using IPv4, this would be 1,460, and on an Ethernet using IPv6, this would be 1,440. (The TCP header is 20 bytes for both, but the IPv4 header is 20 bytes and the IPv6 header is 40 bytes.)\n\n\nIPv4: The MSS value in the TCP MSS option is a 16-bit field, limiting the value to 65,535. The maximum amount of TCP data in an IPv4 datagram is 65,495 (65,535 minus the 20-byte IPv4 header and minus the 20-byte TCP header).\n\n\nIPv6: the maximum amount of TCP data in an IPv6 datagram without the jumbo payload option is 65,515 (65,535 minus the 20-byte TCP header). The MSS value of 65,535 is considered a special case that designates \"infinity.\" This value is used only if the jumbo payload option is being used, which requires an MTU that exceeds 65,535.\n\n\n\n\n\n\n\n\nTCP Output\n\n\nEvery TCP socket has a send buffer and we can change the size of this buffer with the \nSO_SNDBUF\n socket option. When an application calls \nwrite\n, the kernel copies all the data from the application buffer into the socket send buffer. If there is insufficient room in the socket buffer for all the application's data, the process is put to sleep. This assumes the normal default of a blocking socket. The kernel will not return from the write until the final byte in the application buffer has been copied into the socket send buffer. Therefore, \nthe successful return from a write to a TCP socket only tells us that we can reuse our application buffer. It does not tell us that either the peer TCP has received the data or that the peer application has received the data.\n\n\nTCP takes the data in the socket send buffer and sends it to the peer TCP.\n The peer TCP must acknowledge the data, and as the ACKs arrive from the peer, only then can our TCP discard the acknowledged data from the socket send buffer. TCP must keep a copy of our data until it is acknowledged by the peer.\n\n\nTCP sends the data to IP in MSS-sized or smaller chunks, prepending its TCP header to each segment, where the MSS is the value announced by the peer, or 536 if the peer did not send an MSS option. IP prepends its header, searches the routing table for the destination IP address, and passes the datagram to the appropriate datalink. IP might perform fragmentation before passing the datagram to the datalink, but one goal of the MSS option is to try to avoid fragmentation and newer implementations also use path MTU discovery. Each datalink has an output queue, and if this queue is full, the packet is discarded and an error is returned up the protocol stack [p58]\n\n\nUDP Output\n\n\nUDP socket doesn't have a socket send buffer, since it does not need to keep a copy of the application's data. It has a send buffer size (which we can change with the \nSO_SNDBUF\n socket option), but this is simply an upper limit on the maximum-sized UDP datagram that can be written to the socket. If an application writes a datagram larger than the socket send buffer size, \nEMSGSIZE\n is returned.\n\n\nUDP simply prepends its 8-byte header and passes the datagram to IP. IP determines the outgoing interface by performing the routing function, and then either adds the datagram to the datalink output queue (if it fits within the MTU) or fragments the datagram and adds each fragment to the datalink output queue (see \nUDP and IP Fragmentation in TCPv1\n). If a UDP application sends large datagrams, there is a much higher probability of (IP) fragmentation than with TCP.\n\n\nStandard Internet Services\n\n\nProtocol Usage by Common Internet Applications", 
            "title": "Chapter 2. The Transport Layer: TCP, UDP, and SCTP"
        }, 
        {
            "location": "/unp/ch3/", 
            "text": "Chapter 3. Sockets Introduction\n\n\nIntroduction\n\n\nThis chapter begins the description of the sockets API.\n\n\nSocket Address Structures\n\n\nThe name of socket address structures begin with \nsockaddr_\n and end with a unique suffix for each protocol suite.\n\n\nIPv4 Socket Address Structure\n\n\nAn IPv4 socket address structure, commonly called an \"Internet socket address structure\", is named \nsockaddr_in\n and is defined by including the \nnetinet/in.h\n header.\n\n\nstruct\n \nin_addr\n \n{\n\n  \nin_addr_t\n   \ns_addr\n;\n           \n/* 32-bit IPv4 address */\n\n                                \n/* network byte ordered */\n\n\n};\n\n\n\nstruct\n \nsockaddr_in\n \n{\n\n  \nuint8_t\n         \nsin_len\n;\n      \n/* length of structure (16) */\n\n  \nsa_family_t\n     \nsin_family\n;\n   \n/* AF_INET */\n\n  \nin_port_t\n       \nsin_port\n;\n     \n/* 16-bit TCP or UDP port number */\n\n                                \n/* network byte ordered */\n\n  \nstruct\n \nin_addr\n  \nsin_addr\n;\n     \n/* 32-bit IPv4 address */\n\n                                \n/* network byte ordered */\n\n  \nchar\n            \nsin_zero\n[\n8\n];\n  \n/* unused */\n\n\n};\n\n\n\n\n\n\n\n\nsin_len\n: the length field. We need never set it and need never examine it.\n\n\nThe four socket functions that pass a socket address structure from the process to the kernel, \nbind\n, \nconnect\n, \nsendto\n, and \nsendmsg\n, all go through the \nsockargs\n function in a Berkeley-derived implementation. This function copies the socket address structure from the process and explicitly sets its \nsin_len\n member to the size of the structure that was passed as an argument to these four functions. The five socket functions that pass a socket address structure from the kernel to the process, \naccept\n, \nrecvfrom\n, \nrecvmsg\n, \ngetpeername\n, and \ngetsockname\n, all set the \nsin_len\n member before returning to the process.\n\n\n\n\n\n\nPOSIX requires only three members in the structure: \nsin_family\n, \nsin_addr\n, and \nsin_port\n. Almost all implementations add the \nsin_zero\n member so that all socket address structures are at least 16 bytes in size.\n\n\nThe \nin_addr_t\n datatype must be an unsigned integer type of at least 32 bits, \nin_port_t\n must be an unsigned integer type of at least 16 bits, and \nsa_family_t\n can be any unsigned integer type. The latter is normally an 8-bit unsigned integer if the implementation supports the length field, or an unsigned 16-bit integer if the length field is not supported.\n\n\nBoth the IPv4 address and the TCP or UDP port number are always stored in the structure in \nnetwork byte order\n.\n\n\nThe \nsin_zero\n member is unused. By convention, we always set the entire structure to 0 before filling it in.\n\n\nSocket address structures are used only on a given host: The structure itself is not communicated between different hosts\n\n\n\n\nGeneric Socket Address Structure\n\n\nA socket address structures is always passed by reference when passed as an argument to any socket functions. But any socket function that takes one of these pointers as an argument must deal with socket address structures from any of the supported protocol families.\n\n\nA generic socket address structure in the \nsys/socket.h\n header:\n\n\nstruct\n \nsockaddr\n \n{\n\n  \nuint8_t\n      \nsa_len\n;\n\n  \nsa_family_t\n  \nsa_family\n;\n    \n/* address family: AF_xxx value */\n\n  \nchar\n         \nsa_data\n[\n14\n];\n  \n/* protocol-specific address */\n\n\n};\n\n\n\n\n\n\nThe socket functions are then defined as taking a pointer to the generic socket address structure, as shown here in the ANSI C function prototype for the \nbind\n function:\n\n\nint\n \nbind\n(\nint\n,\n \nstruct\n \nsockaddr\n \n*\n,\n \nsocklen_t\n);\n\n\n\n\n\n\nThis requires that any calls to these functions must cast the \npointer to the \nprotocol-specific socket address structure\n to be a \npointer to a \ngeneric socket address structure\n.\n\n\nFor example:\n\n\nstruct\n \nsockaddr_in\n  \nserv\n;\n      \n/* IPv4 socket address structure */\n\n\n\n/* fill in serv{} */\n\n\n\nbind\n(\nsockfd\n,\n \n(\nstruct\n \nsockaddr\n \n*\n)\n \nserv\n,\n \nsizeof\n(\nserv\n));\n\n\n\n\n\n\nIn Chapter 1 in our unp.h header\n, we define \nSA\n to be the string \nstruct sockaddr\n, just to shorten the code that we must write to cast these pointers.\n\n\n\n\nFrom an application programmer \u2019s point of view, \nthe only use of these generic socket address structures is to cast pointers to protocol-specific structures.\n\n\nFrom the kernel\u2019s perspective, another reason for using pointers to generic socket address structures as arguments is that the kernel must take the caller\u2019s pointer, cast it to a \nstruct sockaddr *\n, and then look at the value of \nsa_family\n to determine the type of the structure.\n\n\n\n\nIPv6 Socket Address Structure\n\n\nThe IPv6 socket address is defined by including the \nnetinet/in.h\n header:\n\n\nstruct\n \nin6_addr\n \n{\n\n  \nuint8_t\n  \ns6_addr\n[\n16\n];\n          \n/* 128-bit IPv6 address */\n\n                                 \n/* network byte ordered */\n\n\n};\n\n\n\n#define SIN6_LEN      \n/* required for compile-time tests */\n\n\n\nstruct\n \nsockaddr_in6\n \n{\n\n  \nuint8_t\n         \nsin6_len\n;\n      \n/* length of this struct (28) */\n\n  \nsa_family_t\n     \nsin6_family\n;\n   \n/* AF_INET6 */\n\n  \nin_port_t\n       \nsin6_port\n;\n     \n/* transport layer port# */\n\n                                 \n/* network byte ordered */\n\n  \nuint32_t\n        \nsin6_flowinfo\n;\n \n/* flow information, undefined */\n\n  \nstruct\n \nin6_addr\n \nsin6_addr\n;\n     \n/* IPv6 address */\n\n                                 \n/* network byte ordered */\n\n  \nuint32_t\n        \nsin6_scope_id\n;\n \n/* set of interfaces for a scope */\n\n\n};\n\n\n\n\n\n\n\n\nThe \nSIN6_LEN\n constant must be defined if the system supports the length member for socket address structures.\n\n\nThe IPv6 family is \nAF_INET6\n, whereas the IPv4 family is \nAF_INET\n\n\nThe members in this structure are ordered so that if the \nsockaddr_in6\n structure is 64-bit aligned, so is the 128-bit \nsin6_addr\n member.\n\n\nThe \nsin6_flowinfo\n member is divided into two fields:\n\n\nThe low-order 20 bits are the flow label\n\n\nThe high-order 12 bits are reserved\n\n\n\n\n\n\nThe \nsin6_scope_id\n identifies the scope zone in which a scoped address is meaningful, most commonly an interface index for a link-local address\n\n\n\n\nNew Generic Socket Address Structure\n\n\nA new generic socket address structure was defined as part of the IPv6 sockets API, to overcome some of the shortcomings of the existing \nstruct sockaddr\n. Unlike the \nstruct sockaddr\n, the new \nstruct sockaddr_storage\n is large enough to hold any socket address type supported by the system. The \nsockaddr_storage\n structure is defined by including the \nnetinet/in.h\n header:\n\n\nstruct\n \nsockaddr_storage\n \n{\n\n  \nuint8_t\n      \nss_len\n;\n       \n/* length of this struct (implementation dependent) */\n\n  \nsa_family_t\n  \nss_family\n;\n    \n/* address family: AF_xxx value */\n\n  \n/* implementation-dependent elements to provide:\n\n\n   * a) alignment sufficient to fulfill the alignment requirements of\n\n\n   *    all socket address types that the system supports.\n\n\n   * b) enough storage to hold any type of socket address that the\n\n\n   *    system supports.\n\n\n   */\n\n\n};\n\n\n\n\n\n\nThe \nsockaddr_storage\n type provides a generic socket address structure that is different from \nstruct sockaddr\n in two ways:\n\n\n\n\nIf any socket address structures that the system supports have alignment requirements, the \nsockaddr_storage\n provides the strictest alignment requirement.\n\n\nThe \nsockaddr_storage\n is large enough to contain any socket address structure that the system supports.\n\n\n\n\nThe fields of the \nsockaddr_storage\n structure are opaque to the user, except for \nss_family\n and \nss_len\n (if present). The \nsockaddr_storage\n must be cast or copied to the appropriate socket address structure for the address given in \nss_family\n to access any other fields.\n\n\nComparison of Socket Address Structures\n\n\nIn this figure, we assume that:\n\n\n\n\nSocket address structures all contain a one-byte length field\n\n\nThe family field also occupies one byte\n\n\nAny field that must be at least some number of bits is exactly that number of bits\n\n\n\n\n\n\nTo handle variable-length structures, whenever we pass a pointer to a socket address structure as an argument to one of the socket functions, we pass its length as another argument.\n\n\nValue-Result Arguments\n\n\nWhen a socket address structure is passed to any socket function, it is always passed by reference (a pointer to the structure is passed). The length of the structure is also passed as an argument.\n\n\nThe way in which the length is passed depends on which direction the structure is being passed:\n\n\n\n\nFrom the \nprocess to the kernel\n\n\nFrom the \nkernel to the process\n\n\n\n\nFrom process to kernel\n\n\nbind\n, \nconnect\n, and \nsendto\n functions pass a socket address structure from the process to the kernel.\n\n\nArumgents to these functions:\n\n\n\n\nThe pointer to the socket address structure\n\n\nThe integer size of the structure\n\n\n\n\nstruct\n \nsockaddr_in\n \nserv\n;\n\n\n\n/* fill in serv{} */\n\n\nconnect\n \n(\nsockfd\n,\n \n(\nSA\n \n*\n)\n \nserv\n,\n \nsizeof\n(\nserv\n));\n\n\n\n\n\n\n\n\nThe datatype for the size of a socket address structure is actually \nsocklen_t\n and not \nint\n, but the POSIX specification recommends that \nsocklen_t\n be defined as \nuint32_t\n.\n\n\nFrom kernel to process\n\n\naccept\n, \nrecvfrom\n, \ngetsockname\n, and \ngetpeername\n functions pass a socket address structure from the kernel to the process.\n\n\nArguments to these functions:\n\n\n\n\nThe pointer to the socket address structure\n\n\nThe pointer to an integer containing the size of the structure.\n\n\n\n\nstruct\n \nsockaddr_un\n  \ncli\n;\n   \n/* Unix domain */\n\n\nsocklen_t\n  \nlen\n;\n\n\n\nlen\n \n=\n \nsizeof\n(\ncli\n);\n         \n/* len is a value */\n\n\ngetpeername\n(\nunixfd\n,\n \n(\nSA\n \n*\n)\n \ncli\n,\n \nlen\n);\n\n\n/* len may have changed */\n\n\n\n\n\n\n\n\nValue-result argument\n (Figure 3.8): the size changes from an integer to be a pointer to an integer because the size is both \na value when the function is called and a result when the function returns.\n\n\n\n\nAs a \nvalue\n: it tells the kernel the size of the structure so that the kernel does not write past the end of the structure when filling it in\n\n\nAs a \nresult\n: it tells the process how much information the kernel actually stored in the structure\n\n\n\n\nFor two other functions that pass socket address structures, \nrecvmsg\n and \nsendmsg\n, the length field is not a function argument but a structure member.\n\n\nIf the socket address structure is fixed-length, the value returned by the kernel will always be that fixed size: 16 for an IPv4 \nsockaddr_in\n and 28 for an IPv6 \nsockaddr_in6\n. But with a variable-length socket address structure (e.g., a Unix domain \nsockaddr_un\n), the value returned can be less than the maximum size of the structure.\n\n\nThough the most common example of a value-result argument is the length of a returned socket address structure, we will encounter other value-result arguments in this text:\n\n\n\n\nThe middle three arguments for the \nselect\n function (Section 6.3)\n\n\nThe length argument for the \ngetsockopt\n function (Section 7.2)\n\n\nThe \nmsg_namelen\n and \nmsg_controllen\n members of the \nmsghdr\n structure, when used with \nrecvmsg\n (Section 14.5)\n\n\nThe \nifc_len\n member of the \nifconf\n structure (Figure 17.2)\n\n\nThe first of the two length arguments for the \nsysctl\n function (Section 18.4)\n\n\n\n\nByte Ordering Functions\n\n\nFor a 16-bit integer that is made up of 2 bytes, there are two ways to store the two bytes in memory:\n\n\n\n\nLittle-endian\n order: low-order byte is at the starting address.\n\n\nBig-endian\n order: high-order byte is at the starting address.\n\n\n\n\n\n\nThe figure shows the most significant bit (MSB) as the leftmost bit of the 16-bit value and the least significant bit (LSB) as the rightmost bit.\n\n\nThe terms \"little-endian\" and \"big-endian\" indicate which end of the multibyte value, the little end or the big end, is stored at the starting address of the value.\n\n\nHost byte order\n refer to the byte ordering used by a given system. The program below prints the host byte order:\n\n\nbyteorder.c\n\n\n\n\n\nWe store the two-byte value \n0x0102\n in the short integer and then look at the two consecutive bytes, \nc[0]\n (the address \nA\n) and \nc[1]\n (the address \nA+1\n) to determine the byte order.\n\n\nThe string \nCPU_VENDOR_OS\n is determined by the GNU \nautoconf\n program.\n\n\nfreebsd4 % byteorder\ni386-unknown-freebsd4.8: little-endian\n\nmacosx % byteorder\npowerpc-apple-darwin6.6: big-endian\n\nfreebsd5 % byteorder\nsparc64-unknown-freebsd5.1: big-endian\n\naix % byteorder\npowerpc-ibm-aix5.1.0.0: big-endian\n\nhpux % byteorder\nhppa1.1-hp-hpux11.11: big-endian\n\nlinux % byteorder\ni586-pc-linux-gnu: little-endian\n\nsolaris % byteorder\nsparc-sun-solaris2.9: big-endian\n\n\n\n\n\nNetworking protocols must specify a \nnetwork byte order\n. The sending protocol stack and the receiving protocol stack must agree on the order in which the bytes of these multibyte fields will be transmitted. \nThe Internet protocols use big-endian byte ordering for these multibyte integers.\n\n\nBut, both history and the POSIX specification say that certain fields in the socket address structures must be maintained in network byte order. We use the following four functions to convert between these two byte orders:\n\n\nunp_htons.h\n\n\n#include \nnetinet/in.h\n\n\n\nuint16_t\n \nhtons\n(\nuint16_t\n \nhost16bitvalue\n);\n\n\nuint32_t\n \nhtonl\n(\nuint32_t\n \nhost32bitvalue\n);\n\n\n\n/* Both return: value in network byte order */\n\n\n\nuint16_t\n \nntohs\n(\nuint16_t\n \nnet16bitvalue\n);\n\n\nuint32_t\n \nntohl\n(\nuint32_t\n \nnet32bitvalue\n);\n\n\n\n/* Both return: value in host byte order */\n\n\n\n\n\n\n\n\nh\n stands for \nhost\n\n\nn\n stands for \nnetwork\n\n\ns\n stands for \nshort\n (16-bit value, e.g. TCP or UDP port number)\n\n\nl\n stands for \nlong\n (32-bit value, e.g. IPv4 address)\n\n\n\n\nWhen using these functions, we do not care about the actual values (big-endian or little-endian) for the host byte order and the network byte order. What we must do is call the appropriate function to convert a given value between the host and network byte order. On those systems that have the same byte ordering as the Internet protocols (big-endian), these four functions are usually defined as null macros.\n\n\nWe use the term \"byte\" to mean an 8-bit quantity since almost all current computer systems use 8-bit bytes. Most Internet standards use the term \noctet\n instead of byte to mean an 8-bit quantity.\n\n\nBit ordering is an important convention in Internet standards, such as the the first 32 bits of the IPv4 header from RFC 791:\n\n\n 0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|Version|  IHL |Type of Service|           Total Length         |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n\n\n\n\nThis represents four bytes in the order in which they appear on the wire; the leftmost bit is the most significant. However, the numbering starts with zero assigned to the most significant bit.\n\n\nByte Manipulation Functions\n\n\nTwo types functions differ in whether they deal with null-terminated C strings:\n\n\n\n\nThe functions that operate on multibyte fields, without interpreting the data, and without assuming that the data is a null-terminated C string. These types of functions deal with socket address structures to manipulate fields such as IP addresses, which can contain bytes of 0, but are not C character strings.\n\n\nThe functions whose names begin with \nb\n (for byte) (from 4.2BSD)\n\n\nThe functions whose names begin with \nmem\n (for memory) (from ANSI C)\n\n\n\n\n\n\nThe functions that deal with null-terminated C character strings (beginning with \nstr\n (for string), defined by including the \nstring.h\n header)\n\n\n\n\nunp_bzero.h\n\n\n#include \nstrings.h\n\n\n\nvoid\n \nbzero\n(\nvoid\n \n*\ndest\n,\n \nsize_t\n \nnbytes\n);\n\n\nvoid\n \nbcopy\n(\nconst\n \nvoid\n \n*\nsrc\n,\n \nvoid\n \n*\ndest\n,\n \nsize_t\n \nnbytes\n);\n\n\nint\n \nbcmp\n(\nconst\n \nvoid\n \n*\nptr1\n,\n \nconst\n \nvoid\n \n*\nptr2\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: 0 if equal, nonzero if unequal */\n\n\n\n\n\n\nThe memory pointed to by the \nconst\n pointer is read but not modified by the function.\n\n\n\n\nbzero\n sets the specified number of bytes to 0 in the destination. We often use this function to initialize a socket address structure to 0.\n\n\nbcopy\n moves the specified number of bytes from the source to the destination.\n\n\nbcmp\n compares two arbitrary byte strings. The return value is zero if the two byte strings are identical; otherwise, it is nonzero\n\n\n\n\nunp_memset.h\n\n\n#include \nstring.h\n\n\n\nvoid\n \n*\nmemset\n(\nvoid\n \n*\ndest\n,\n \nint\n \nc\n,\n \nsize_t\n \nlen\n);\n\n\nvoid\n \n*\nmemcpy\n(\nvoid\n \n*\ndest\n,\n \nconst\n \nvoid\n \n*\nsrc\n,\n \nsize_t\n \nnbytes\n);\n\n\nint\n \nmemcmp\n(\nconst\n \nvoid\n \n*\nptr1\n,\n \nconst\n \nvoid\n \n*\nptr2\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: 0 if equal, \n0 or \n0 if unequal (see text) */\n\n\n\n\n\n\n\n\nmemset\n sets the specified number of bytes to the value \nc\n in the destination\n\n\nmemcpy\n is similar to \nbcopy\n, but the order of the two pointer arguments is swapped\n\n\nmemcmp\n compares two arbitrary byte strings\n\n\n\n\nNote:\n\n\n\n\n\n\nOne way to remember the order of the two pointers for \nmemcpy\n is to remember that they are written in the same left-to-right order as an assignment statement in C:\n\n\ndest = src;\n\n\n\n\n\n\n\n\n\nOne way to remember the order of the final two arguments to \nmemset\n is to realize that all of the ANSI C \nmemXXX\n functions require a length argument, and it is always the final argument. The comparison is done assuming the two unequal bytes are \nunsigned chars\n.\n\n\n\n\n\n\ninet_aton\n, \ninet_addr\n, and \ninet_ntoa\n Functions\n\n\nThese functions convert Internet addresses between ASCII strings (what humans prefer to use) and network byte ordered binary values (values that are stored in socket address structures).\n\n\nunp_inet_aton.h\n\n\n#include \narpa/inet.h\n\n\n\nint\n \ninet_aton\n(\nconst\n \nchar\n \n*\nstrptr\n,\n \nstruct\n \nin_addr\n \n*\naddrptr\n);\n\n\n/* Returns: 1 if string was valid, 0 on error */\n\n\n\nin_addr_t\n \ninet_addr\n(\nconst\n \nchar\n \n*\nstrptr\n);\n\n\n/* Returns: 32-bit binary network byte ordered IPv4 address; INADDR_NONE if error */\n\n\n\nchar\n \n*\ninet_ntoa\n(\nstruct\n \nin_addr\n \ninaddr\n);\n\n\n/* Returns: pointer to dotted-decimal string */\n\n\n\n\n\n\n\n\ninet_aton\n: converts the C character string pointed to by \nstrptr\n into its 32-bit binary network byte ordered value, which is stored through the pointer \naddrptr\n\n\ninet_addr\n: does the same conversion, returning the 32-bit binary network byte ordered value as the return value. It is deprecated and any new code should use \ninet_aton\n instead\n\n\ninet_ntoa\n: converts a 32-bit binary network byte ordered IPv4 address into its corresponding dotted-decimal string.\n\n\nThe string pointed to by the return value of the function resides in static memory.\n This means the function is not reentrant, which we will discuss in Section 11.18.\n\n\nThis function takes a structure as its argument, not a pointer to a structure. (Functions that take actual structures as arguments are rare. It is more common to pass a pointer to the structure.)\n\n\n\n\n\n\n\n\ninet_pton\n and \ninet_ntop\n Functions\n\n\nThese two functions are new with IPv6 and work with both IPv4 and IPv6 addresses. We use these two functions throughout the text. The letters \"p\" and \"n\" stand for \npresentation\n and \nnumeric\n. The presentation format for an address is often an ASCII string and the numeric format is the binary value that goes into a socket address structure.\n\n\nunp_inet_pton.h\n\n\n#include \narpa/inet.h\n\n\n\nint\n \ninet_pton\n(\nint\n \nfamily\n,\n \nconst\n \nchar\n \n*\nstrptr\n,\n \nvoid\n \n*\naddrptr\n);\n\n\n/* Returns: 1 if OK, 0 if input not a valid presentation format, -1 on error */\n\n\n\nconst\n \nchar\n \n*\ninet_ntop\n(\nint\n \nfamily\n,\n \nconst\n \nvoid\n \n*\naddrptr\n,\n \nchar\n \n*\nstrptr\n,\n \nsize_t\n \nlen\n);\n\n\n/* Returns: pointer to result if OK, NULL on error */\n\n\n\n\n\n\nArguments:\n\n\n\n\nfamily\n: is either \nAF_INET\n or \nAF_INET6\n. If \nfamily\n is not supported, both functions return an error with \nerrno\n set to \nEAFNOSUPPORT\n.\n\n\n\n\nFunctions:\n\n\n\n\ninet_pton\n: converts the string pointed to by \nstrptr\n, storing the binary result through the pointer \naddrptr\n. If successful, the return value is 1. If the input string is not a valid presentation format for the specified \nfamily\n, 0 is returned.\n\n\ninet_ntop\n does the reverse conversion, from numeric (\naddrptr\n) to presentation (\nstrptr\n).\n\n\nlen\n argument is the size of the destination. To help specify this size, the following two definitions are defined by including the \nnetinet/in.h\n header.\n\n\nIf \nlen\n is too small to hold the resulting presentation format, including the terminating null, a null pointer is returned and \nerrno\n is set to \nENOSPC\n.\n\n\nThe \nstrptr\n argument to \ninet_ntop\n cannot be a null pointer. The caller must allocate memory for the destination and specify its size. On success, this pointer is the return value of the function.\n\n\n\n\n\n\n\n\nSize definitions in \nnetinet/in.h\n header for the \nlen\n argument:\n\n\n#define INET_ADDRSTRLEN       16       \n/* for IPv4 dotted-decimal */\n\n\n#define INET6_ADDRSTRLEN      46       \n/* for IPv6 hex string */\n\n\n\n\n\n\nThe following figure summarizes the five functions on address conversion functions:\n\n\n\n\nEven if your system does not yet include support for IPv6, you can start using these newer functions by replacing calls of the form.\n\n\nReplacing \ninet_addr\n to \ninet_pton\n\n\nReplace:\n\n\nfoo\n.\nsin_addr\n.\ns_addr\n \n=\n \ninet_addr\n(\ncp\n);\n\n\n\n\n\n\nwith\n\n\ninet_pton\n(\nAF_INET\n,\n \ncp\n,\n \nfoo\n.\nsin_addr\n);\n\n\n\n\n\n\nReplacing \ninet_ntoa\n to \ninet_ntop\n\n\nReplace:\n\n\nptr = inet_ntoa(foo.sin_addr);\n\n\n\n\n\nwith\n\n\nchar\n \nstr\n[\nINET_ADDRSTRLEN\n];\n\n\nptr\n \n=\n \ninet_ntop\n(\nAF_INET\n,\n \nfoo\n.\nsin_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n));\n\n\n\n\n\n\nSimple definitions of \ninet_pton\n and \ninet_ntop\n that support IPv4\n\n\nlibfree/inet_pton_ipv4.c\n\n\nint\n\n\ninet_pton\n(\nint\n \nfamily\n,\n \nconst\n \nchar\n \n*\nstrptr\n,\n \nvoid\n \n*\naddrptr\n)\n\n\n{\n\n    \nif\n \n(\nfamily\n \n==\n \nAF_INET\n)\n \n{\n\n        \nstruct\n \nin_addr\n  \nin_val\n;\n\n\n        \nif\n \n(\ninet_aton\n(\nstrptr\n,\n \nin_val\n))\n \n{\n\n            \nmemcpy\n(\naddrptr\n,\n \nin_val\n,\n \nsizeof\n(\nstruct\n \nin_addr\n));\n\n            \nreturn\n \n(\n1\n);\n\n        \n}\n\n        \nreturn\n(\n0\n);\n\n    \n}\n\n    \nerrno\n \n=\n \nEAFNOSUPPORT\n;\n\n    \nreturn\n \n(\n-\n1\n);\n\n\n}\n\n\n\n\n\n\ninet_ntop_ipv4.c\n\n\nconst\n \nchar\n \n*\n\n\ninet_ntop\n(\nint\n \nfamily\n,\n \nconst\n \nvoid\n \n*\naddrptr\n,\n \nchar\n \n*\nstrptr\n,\n \nsize_t\n \nlen\n)\n\n\n{\n\n    \nconst\n \nu_char\n \n*\np\n \n=\n \n(\nconst\n \nu_char\n \n*\n)\n \naddrptr\n;\n\n\n    \nif\n \n(\nfamily\n \n==\n \nAF_INET\n)\n \n{\n\n        \nchar\n    \ntemp\n[\nINET_ADDRSTRLEN\n];\n\n\n        \nsnprintf\n(\ntemp\n,\n \nsizeof\n(\ntemp\n),\n \n%d.%d.%d.%d\n,\n\n                 \np\n[\n0\n],\n \np\n[\n1\n],\n \np\n[\n2\n],\n \np\n[\n3\n]);\n\n        \nif\n \n(\nstrlen\n(\ntemp\n)\n \n=\n \nlen\n)\n \n{\n\n            \nerrno\n \n=\n \nENOSPC\n;\n\n            \nreturn\n \n(\nNULL\n);\n\n        \n}\n\n        \nstrcpy\n(\nstrptr\n,\n \ntemp\n);\n\n        \nreturn\n \n(\nstrptr\n);\n\n    \n}\n\n    \nerrno\n \n=\n \nEAFNOSUPPORT\n;\n\n    \nreturn\n \n(\nNULL\n);\n\n\n}\n\n\n\n\n\n\nsock_ntop\n and Related Functions\n\n\nA basic problem with \ninet_ntop\n is that it requires the caller to pass a pointer to a binary address. This address is normally contained in a socket address structure, requiring the caller to know the format of the structure and the address family.\n\n\nFor IPv4:\n\n\nstruct\n \nsockaddr_in\n   \naddr\n;\n\n\ninet_ntop\n(\nAF_INET\n,\n \naddr\n.\nsin_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n));\n\n\n\n\n\n\nFor IPv6:\n\n\nstruct\n \nsockaddr_in6\n   \naddr6\n;\n\n\ninet_ntop\n(\nAF_INET6\n,\n \naddr6\n.\nsin6_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n));\n\n\n\n\n\n\nThis (above) makes our code protocol-dependent.\n\n\nTo solve this, we will write our own function named \nsock_ntop\n that takes a pointer to a socket address structure, looks inside the structure, and calls the appropriate function to return the presentation format of the address.\n\n\nunp_sock_ntop.h\n\n\n#include \nunp.h\n\n\n\nchar\n \n*\nsock_ntop\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n/* Returns: non-null pointer if OK, NULL on error */\n\n\n\n\n\n\nsockaddr\n points to a socket address structure whose length is \naddrlen\n. The function uses its own static buffer to hold the result and a pointer to this buffer is the return value. Notice that \nusing static storage for the result prevents the function from being \nre-entrant\n or \nthread-safe\n.\n\n\nPresentation format of \nsock_ntop\n\n\n\n\nIPv4: dotted-decimal form, followed by a terminator (colon), followed by the decimal port number, followed by a null character\n\n\nThe buffer size must be at least \nINET_ADDRSTRLEN\n plus 6 bytes for IPv4 (16 + 6 = 22)\n\n\n\n\n\n\nIPv6: hex string form of an IPv6 address surrounded by brackets, followed by a terminator (colon), followed by the decimal port number, followed by a\nnull character. Hence, the buffer size must be at least INET_ADDRSTRLEN plus 6 bytes\n\n\nThe buffer size must be at least \nINET6_ADDRSTRLEN\n plus 8 bytes for IPv6 (46 + 8 = 54)\n\n\n\n\n\n\n\n\nsock_ntop\n definition\n\n\n\n\nlib/sock_ntop.c\n\n\n\n\nThe source code for only the \nAF_INET\n case:\n\n\nchar\n \n*\n\n\nsock_ntop\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsa\n,\n \nsocklen_t\n \nsalen\n)\n\n\n{\n\n    \nchar\n        \nportstr\n[\n8\n];\n\n    \nstatic\n \nchar\n \nstr\n[\n128\n];\n       \n/* Unix domain is largest */\n\n\n    \nswitch\n \n(\nsa\n-\nsa_family\n)\n \n{\n\n    \ncase\n \nAF_INET\n:\n \n{\n\n        \nstruct\n \nsockaddr_in\n  \n*\nsin\n \n=\n \n(\nstruct\n \nsockaddr_in\n \n*\n)\n \nsa\n;\n\n\n        \nif\n \n(\ninet_ntop\n(\nAF_INET\n,\n \nsin\n-\nsin_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n))\n \n==\n \nNULL\n)\n\n            \nreturn\n(\nNULL\n);\n\n        \nif\n \n(\nntohs\n(\nsin\n-\nsin_port\n)\n \n!=\n \n0\n)\n \n{\n\n            \nsnprintf\n(\nportstr\n,\n \nsizeof\n(\nportstr\n),\n \n:%d\n,\n \nntohs\n(\nsin\n-\nsin_port\n));\n\n            \nstrcat\n(\nstr\n,\n \nportstr\n);\n\n        \n}\n\n        \nreturn\n(\nstr\n);\n\n    \n}\n\n  \n/* ... */\n\n\n\n\n\n\nRelated functions\n\n\nThere are a few other functions that we define to operate on socket address structures,\nand these will simplify the portability of our code between IPv4 and IPv6.\n\n\napue_sock_bind_wild.h\n\n\n#include \nunp.h\n\n\n\nint\n \nsock_bind_wild\n(\nint\n \nsockfd\n,\n \nint\n \nfamily\n);\n\n\n/* Returns: 0 if OK, -1 on error */\n\n\n\nint\n \nsock_cmp_addr\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr1\n,\n\n                  \nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr2\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: 0 if addresses are of the same family and ports are equal,\n\n\n   else nonzero\n\n\n*/\n\n\n\nint\n \nsock_cmp_port\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr1\n,\n\n                  \nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr2\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: 0 if addresses are of the same family and ports are equal,\n\n\n   else nonzero\n\n\n*/\n\n\n\nint\n \nsock_get_port\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: non-negative port number for IPv4 or IPv6 address, else -1 */\n\n\n\nchar\n \n*\nsock_ntop_host\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: non-null pointer if OK, NULL on error */\n\n\n\nvoid\n \nsock_set_addr\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n,\n\n                   \nvoid\n \n*\nptr\n);\n\n\nvoid\n \nsock_set_port\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n,\n\n                   \nint\n \nport\n);\n\n\nvoid\n \nsock_set_wild\n(\nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n\n\n\n\n\nsock_bind_wild\n: binds the wildcard address and an ephemeral port to a socket.\n\n\nsock_cmp_addr\n: compares the address portion of two socket address structures.\n\n\nsock_cmp_port\n: compares the port number of two socket address structures.\n\n\nsock_get_port\n: returns just the port number.\n\n\nsock_ntop_host\n: converts just the host portion of a socket address structure to presentation format (not the port number)\n\n\nsock_set_addr\n: sets just the address portion of a socket address structure to the value pointed to by \nptr\n.\n\n\nsock_set_port\n: sets just the port number of a socket address structure.\n\n\nsock_set_wild\n: sets the address portion of a socket address structure to the wildcard\n\n\n\n\nreadn\n, \nwriten\n, and \nreadline\n Functions\n\n\nStream sockets (e.g., TCP sockets) exhibit a behavior with the \nread\n and \nwrite\n functions that differs from normal file I/O. A \nread\n or \nwrite\n on a stream socket might input or output fewer bytes than requested, but this is not an error condition. \nThe reason is that buffer limits might be reached for the socket in the kernel. All that is required to input or output the remaining bytes is for the caller to invoke the \nread\n or \nwrite\n function again.\n This scenario is always a possibility on a stream socket with \nread\n, but is normally seen with \nwrite\n only if the socket is nonblocking.\n\n\nunp_readn.h\n\n\n#include \nunp.h\n\n\n\nssize_t\n \nreadn\n(\nint\n \nfiledes\n,\n \nvoid\n \n*\nbuff\n,\n \nsize_t\n \nnbytes\n);\n\n\nssize_t\n \nwriten\n(\nint\n \nfiledes\n,\n \nconst\n \nvoid\n \n*\nbuff\n,\n \nsize_t\n \nnbytes\n);\n\n\nssize_t\n \nreadline\n(\nint\n \nfiledes\n,\n \nvoid\n \n*\nbuff\n,\n \nsize_t\n \nmaxlen\n);\n\n\n\n/* All return: number of bytes read or written, \u20131 on error */\n\n\n\n\n\n\n\n\nlib/readn.c\n\n\nlib/writen.c\n\n\ntest/readline1.c\n\n\nlib/readline.c\n\n\n\n\n#include    \nunp.h\n\n\n\nssize_t\n                     \n/* Read \nn\n bytes from a descriptor. */\n\n\nreadn\n(\nint\n \nfd\n,\n \nvoid\n \n*\nvptr\n,\n \nsize_t\n \nn\n)\n\n\n{\n\n    \nsize_t\n  \nnleft\n;\n\n    \nssize_t\n \nnread\n;\n\n    \nchar\n    \n*\nptr\n;\n\n\n    \nptr\n \n=\n \nvptr\n;\n\n    \nnleft\n \n=\n \nn\n;\n\n    \nwhile\n \n(\nnleft\n \n \n0\n)\n \n{\n\n        \nif\n \n(\n \n(\nnread\n \n=\n \nread\n(\nfd\n,\n \nptr\n,\n \nnleft\n))\n \n \n0\n)\n \n{\n\n            \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n                \nnread\n \n=\n \n0\n;\n      \n/* and call read() again */\n\n            \nelse\n\n                \nreturn\n(\n-\n1\n);\n\n        \n}\n \nelse\n \nif\n \n(\nnread\n \n==\n \n0\n)\n\n            \nbreak\n;\n              \n/* EOF */\n\n\n        \nnleft\n \n-=\n \nnread\n;\n\n        \nptr\n   \n+=\n \nnread\n;\n\n    \n}\n\n    \nreturn\n(\nn\n \n-\n \nnleft\n);\n      \n/* return \n= 0 */\n\n\n}\n\n\n\n\n\n\nOur three functions look for the error \nEINTR\n (the system call was interrupted by a caught signal) and continue reading or writing if the error occurs. We handle the error here, instead of forcing the caller to call \nreadn\n or \nwriten\n again, since the purpose of these three functions is to prevent the caller from having to handle a short count.\n\n\nIn Section 14.3, we will mention that the \nMSG_WAITALL\n flag can be used with the \nrecv\n function to replace the need for a separate \nreadn\n function.\n\n\nIn \ntest/readline1.c\n, our \nreadline\n function calls the system\u2019s \nread\n function once for every byte of data. This is very inefficient, and why we\u2019ve commented the code to state it is \"PAINFULLY SLOW\".\n\n\nOur advice is to think in terms of buffers and not lines. Write your code to read buffers of data, and if a line is expected, check the buffer to see if it contains that line.\n\n\nlib/readline.c\n shows a faster version of the readline function, which uses its own buffering rather than stdio buffering. Most importantly, the state of readline\u2019s internal buffer is exposed, so callers have visibility into exactly what has been received.\n\n\nIn \nlib/readline.c\n, the internal function \nmy_read\n reads up to \nMAXLINE\n characters at a time and then returns them, one at a time. The only change to the \nreadline\n function itself is to call \nmy_read\n instead of \nread\n. A new function, \nreadlinebuf\n, exposes the internal buffer state so that callers can check and see if more data was received beyond a single line.\n\n\nUnfortunately, by using \nstatic\n variables in \nreadline.c\n to maintain the state information across successive calls, the functions are not \nre-entrant\n or \nthread-safe\n.", 
            "title": "Chapter 3. Sockets Introduction"
        }, 
        {
            "location": "/unp/ch4/", 
            "text": "Chapter 4. Elementary TCP Sockets\n\n\n\n\nIn C, we cannot represent a constant structure on the right-hand side of an assignment.\n\nUNP\n\n\n\n\nIntroduction\n\n\nThis chapter describes the elementary socket functions required to write a complete TCP client and server, along with concurrent servers, a common Unix technique for providing concurrency when numerous clients are connected to the same server at the same time. Each client connection causes the server to fork a new process just for that client. In this chapter, we consider only the one-process-per-client model using \nfork\n.\n\n\nThe figure below shows a timeline of the typical scenario that takes place between a TCP client and server. First, the server is started, then sometime later, a client is started that connects to the server. We assume that the client sends a request to the server, the server processes the request, and the server sends a reply back to the client. This continues until the client closes its end of the connection, which sends an end-of-file notification to the server. The server then closes its end of the connection and either terminates or waits for a new client connection.\n\n\n\n\nsocket\n Function\n\n\nTo perform network I/O, the first thing a process must do is call the \nsocket\n function, specifying the type of communication protocol desired (TCP using IPv4, UDP using IPv6, Unix domain stream protocol, etc.).\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nsocket\n \n(\nint\n \nfamily\n,\n \nint\n \ntype\n,\n \nint\n \nprotocol\n);\n\n\n\n/* Returns: non-negative descriptor if OK, -1 on error */\n\n\n\n\n\n\nArguments:\n\n\n\n\n\n\nfamily\n specifies the protocol family and is one of the constants in the table below. This argument is often referred to as \ndomain\n instead of \nfamily\n.\n\n\n\n\n\n\n\n\nfamily\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAF_INET\n\n\nIPv4 protocols\n\n\n\n\n\n\nAF_INET6\n\n\nIPv6 protocols\n\n\n\n\n\n\nAF_LOCAL\n\n\nUnix domain protocols (\nChapter 15\n)\n\n\n\n\n\n\nAF_ROUTE\n\n\nRouting sockets (\nChapter 18\n)\n\n\n\n\n\n\nAF_KEY\n\n\nKey socket (\nChapter 19\n)\n\n\n\n\n\n\n\n\n\n\n\n\nThe socket \ntype\n is one of the constants shown in table below:\n\n\n\n\n\n\n\n\ntype\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSOCK_STREAM\n\n\nstream socket\n\n\n\n\n\n\nSOCK_DGRAM\n\n\ndatagram socket\n\n\n\n\n\n\nSOCK_SEQPACKET\n\n\nsequenced packet socket\n\n\n\n\n\n\nSOCK_RAW\n\n\nraw socket\n\n\n\n\n\n\n\n\n\n\n\n\nThe \nprotocol\n argument to the \nsocket\n function should be set to the specific protocol type found in the table below, or 0 to select the system's default for the given combination of \nfamily\n and \ntype\n.\n\n\n\n\n\n\n\n\nprotocol\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nIPPROTO_TCP\n\n\nTCP transport protocol\n\n\n\n\n\n\nIPPROTO_UDP\n\n\nUDP transport protocol\n\n\n\n\n\n\nIPPROTO_SCTP\n\n\nSCTP transport protocol\n\n\n\n\n\n\n\n\n\n\n\n\nNot all combinations of socket \nfamily\n and \ntype\n are valid. The table below shows the valid combinations, along with the actual protocols that are valid for each pair. The boxes marked \"Yes\" are valid but do not have handy acronyms. The blank boxes are not supported.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAF_INET\n\n\nAF_INET6\n\n\nAF_LOCAL\n\n\nAF_ROUTE\n\n\nAF_KEY\n\n\n\n\n\n\nSOCK_STREAM\n\n\nTCP/SCTP\n\n\nTCP/SCTP\n\n\nYes\n\n\n\n\n\n\n\n\n\n\nSOCK_DGRAM\n\n\nUDP\n\n\nUDP\n\n\nYes\n\n\n\n\n\n\n\n\n\n\nSOCK_SEQPACKET\n\n\nSCTP\n\n\nSCTP\n\n\nYes\n\n\n\n\n\n\n\n\n\n\nSOCK_RAW\n\n\nIPv4\n\n\nIPv6\n\n\n\n\nYes\n\n\nYes\n\n\n\n\n\n\n\n\nNotes:\n\n\n\n\nYou may also encounter the corresponding \nPF_\nxxx\n constant as the first argument to socket. This is discussed in the next section in this Chapter.\n\n\nYou may encounter \nAF_UNIX\n (the historical Unix name) instead of \nAF_LOCAL\n (the POSIX name). This is discussed in \nChapter 15\n.\n\n\nLinux supports a new socket type, \nSOCK_PACKET\n, that provides access to the datalink, similar to BPF and DLPI (\nSection 2.2\n). This is discussed in \nChapter 29\n\n\nThe key socket, \nAF_KEY\n, is newer than the others. It provides support for cryptographic security. Similar to the way that a routing socket (\nAF_ROUTE\n) is an interface to the kernel's routing table, the key socket is an interface into the kernel's key table. This is discussed in \nChapter 19\n.\n\n\n\n\nOn success, the socket function returns a small non-negative integer value, similar to a file descriptor. We call this a \nsocket descriptor\n, or a \nsockfd\n. To obtain this socket descriptor, all we have specified is a protocol family (IPv4, IPv6, or Unix) and the socket type (stream, datagram, or raw). We have not yet specified either the local protocol address or the foreign protocol address.\n\n\nAF_\nxxx\n Versus \nPF_\nxxx\n\n\nThe \"\nAF_\n\" prefix stands for \"address family\" and the \"\nPF_\n\" prefix stands for \"protocol family.\" Historically, the intent was that a single protocol family might support multiple address families and that the \nPF_\n value was used to create the socket and the \nAF_\n value was used in socket address structures. But in actuality, a protocol family supporting multiple address families has never been supported and the \nsys/socket.h\n header defines the \nPF_\n value for a given protocol to be equal to the \nAF_\n value for that protocol. While there is no guarantee that this equality between the two will always be true, should anyone change this for existing protocols, lots of existing code would break.\n\n\nTo conform to existing coding practice, we use only the \nAF_\n constants in this text, although you may encounter the \nPF_\n value, mainly in calls to \nsocket\n.\n\n\n[p98-99]\n\n\nconnect\n Function\n\n\nThe \nconnect\n function is used by a TCP client to establish a connection with a TCP server.\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nconnect\n(\nint\n \nsockfd\n,\n \nconst\n \nstruct\n \nsockaddr\n \n*\nservaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n/* Returns: 0 if OK, -1 on error */\n\n\n\n\n\n\n\n\nsockfd\n is a socket descriptor returned by the \nsocket\n function.\n\n\nThe \nservaddr\n and \naddrlen\n arguments are a pointer to a socket address structure (which contains the IP address and port number of the server) and its size. (\nSection 3.3\n)\n\n\n\n\nThe client does not have to call \nbind\n before calling \nconnect\n: the kernel will choose both an ephemeral port and the source IP address if necessary.\n\n\nIn the case of a TCP socket, the connect function initiates TCP's three-way handshake (\nSection 2.6\n). The function returns only when the connection is established or an error occurs. There are several different error returns possible:\n\n\n\n\nIf the client TCP receives no response to its SYN segment, \nETIMEDOUT\n is returned.\n\n\nFor example, in 4.4BSD, the client sends one SYN when \nconnect\n is called, sends another SYN 6 seconds later, and sends another SYN 24 seconds later. If no response is received after a total of 75 seconds, the error is returned.\n\n\nSome systems provide administrative control over this timeout.\n\n\n\n\n\n\nIf the server's response to the client's SYN is a reset (RST), this indicates that no process is waiting for connections on the server host at the port specified (the server process is probably not running). This is a \nhard error\n and the error \nECONNREFUSED\n is returned to the client as soon as the RST is received. An RST is a type of TCP segment that is sent by TCP when something is wrong. Three conditions that generate an RST are:\n\n\nWhen a SYN arrives for a port that has no listening server.\n\n\nWhen TCP wants to abort an existing connection.\n\n\nWhen TCP receives a segment for a connection that does not exist.\n\n\n\n\n\n\nIf the client's SYN elicits an ICMP \"destination unreachable\" from some intermediate router, this is considered a \nsoft error\n. The client kernel saves the message but keeps sending SYNs with the same time between each SYN as in the first scenario. If no response is received after some fixed amount of time (75 seconds for 4.4BSD), the saved ICMP error is returned to the process as either \nEHOSTUNREACH\n or \nENETUNREACH\n. It is also possible that the remote system is not reachable by any route in the local system's forwarding table, or that the \nconnect\n call returns without waiting at all. Note that network unreachables are considered obsolete, and applications should just treat \nENETUNREACH\n and \nEHOSTUNREACH\n as the same error.\n\n\n\n\nExample: nonexistent host on the local subnet *\n\n\nWe run the client \ndaytimetcpcli\n (\nFigure 1.5\n) and specify an IP address that is on the local subnet (192.168.1/24) but the host ID (100) is nonexistent. When the client host sends out ARP requests (asking for that host to respond with its hardware address), it will never receive an ARP reply.\n\n\nsolaris % daytimetcpcli 192.168.1.100\n\n\nconnect error: Connection timed out\n\n\n\n\n\n\nWe only get the error after the connect times out. Notice that our \nerr_sys\n function prints the human-readable string associated with the \nETIMEDOUT\n error.\n\n\nExample: no server process running *\n\n\nWe specify a host (a local router) that is not running a daytime server:\n\n\nsolaris % daytimetcpcli 192.168.1.5\n\n\nconnect error: Connection refused\n\n\n\n\n\n\nThe server responds immediately with an RST.\n\n\nExample: destination not reachable on the Internet *\n\n\nOur final example specifies an IP address that is not reachable on the Internet. If we watch the packets with \ntcpdump\n, we see that a router six hops away returns an ICMP host unreachable error.\n\n\nsolaris % daytimetcpcli 192.3.4.5\n\n\nconnect error: No route to host\n\n\n\n\n\n\nAs with the \nETIMEDOUT\n error, \nconnect\n returns the \nEHOSTUNREACH\n error only after waiting its specified amount of time.\n\n\nIn terms of the TCP state transition diagram (\nFigure 2.4\n):\n\n\n\n\nconnect\n moves from the CLOSED state (the state in which a socket begins when it is created by the \nsocket\n function) to the SYN_SENT state, and then, on success, to the ESTABLISHED state.\n\n\nIf \nconnect\n fails, the socket is no longer usable and must be closed. We cannot call \nconnect\n again on the socket.\n\n\n\n\nIn \nFigure 11.10\n, we will see that when we call \nconnect\n in a loop, trying each IP address for a given host until one works, each time \nconnect\n fails, we must close the socket descriptor and call \nsocket\n again.\n\n\nbind\n Function\n\n\nThe \nbind\n function assigns a local protocol address to a socket. The protocol address is the combination of either a 32-bit IPv4 address or a 128-bit IPv6 address, along with a 16-bit TCP or UDP port number.\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nbind\n \n(\nint\n \nsockfd\n,\n \nconst\n \nstruct\n \nsockaddr\n \n*\nmyaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n/* Returns: 0 if OK,-1 on error */\n\n\n\n\n\n\n\n\nThe second argument \nmyaddr\n is a pointer to a protocol-specific addres\n\n\nThe third argument \naddrlen\n is the size of this address structure.\n\n\n\n\nWith TCP, calling \nbind\n lets us specify a port number, an IP address, both, or neither.\n\n\n\n\n\n\nServers bind their well-known port when they start.\n (\nFigure 1.9\n) If a TCP client or server does not do this, the kernel chooses an ephemeral port for the socket when either \nconnect\n or \nlisten\n is called.\n\n\n\n\nIt is normal for a TCP client to let the kernel choose an ephemeral port, unless the application requires a reserved port (\nFigure 2.10\n)\n\n\nHowever, it is rare for a TCP server to let the kernel choose an ephemeral port, since servers are known by their well-known port.\n\n\n\n\nExceptions to this rule are Remote Procedure Call (RPC) servers. They normally let the kernel choose an ephemeral port for their listening socket since this port is then registered with the RPC \nport mapper\n. Clients have to contact the port mapper to obtain the ephemeral port before they can connect to the server. This also applies to RPC servers using UDP.\n\n\n\n\n\n\nA process can bind a specific IP address to its socket.\n \nThe IP address must belong to an interface on the host.\n\n\n\n\nFor a TCP client, this assigns the source IP address that will be used for IP datagrams sent on the socket. Normally, a TCP client does not \nbind\n an IP address to its socket. The kernel chooses the source IP address when the socket is connected, based on the outgoing interface that is used, which in turn is based on the route required to reach the server\n\n\nFor a TCP server, this restricts the socket to receive incoming client connections destined only to that IP address. \nIf a TCP server does not \nbind\n an IP address to its socket, the kernel uses the destination IP address of the client's SYN as the server's source IP address.\n\n\n\n\n\n\n\n\nAs mentioned, calling \nbind\n lets us specify the IP address, the port, both, or neither. The following table summarizes the values to which we set \nsin_addr\n and \nsin_port\n, or \nsin6_addr\n and \nsin6_port\n, depending on the desired result.\n\n\n\n\n\n\n\n\nIP address\n\n\nPort\n\n\nResult\n\n\n\n\n\n\n\n\n\n\nWildcard\n\n\n0\n\n\nKernel chooses IP address and port\n\n\n\n\n\n\nWildcard\n\n\nnonzero\n\n\nKernel chooses IP address, process specifies port\n\n\n\n\n\n\nLocal IP address\n\n\n0\n\n\nProcess specifies IP address, kernel chooses port\n\n\n\n\n\n\nLocal IP address\n\n\nnonzero\n\n\nProcess specifies IP address and port\n\n\n\n\n\n\n\n\n\n\nIf we specify a port number of 0, the kernel chooses an ephemeral port when \nbind\n is called.\n\n\nIf we specify a wildcard IP address, the kernel does not choose the local IP address until either the socket is connected (TCP) or a datagram is sent on the socket (UDP).\n\n\n\n\nWildcard Address and \nINADDR_ANY\n *\n\n\nWith IPv4, the \nwildcard\n address is specified by the constant \nINADDR_ANY\n, whose value is normally 0. This tells the kernel to choose the IP address. \nFigure 1.9\n has the assignment:\n\n\n    \nstruct\n \nsockaddr_in\n   \nservaddr\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n \n(\nINADDR_ANY\n);\n     \n/* wildcard */\n\n\n\n\n\n\nWhile this works with IPv4, where an IP address is a 32-bit value that can be represented as a simple numeric constant (0 in this case), we cannot use this technique with IPv6, since the 128-bit IPv6 address is stored in a structure. \nIn C we cannot represent a constant structure on the right-hand side of an assignment.\n To solve this problem, we write:\n\n\nstruct\n \nsockaddr_in6\n    \nserv\n;\n\n\nserv\n.\nsin6_addr\n \n=\n \nin6addr_any\n;\n     \n/* wildcard */\n\n\n\n\n\n\nThe system allocates and initializes the \nin6addr_any\n variable to the constant \nIN6ADDR_ANY_INIT\n. The \nnetinet/in.h\n header contains the extern declaration for \nin6addr_any\n.\n\n\nThe value of \nINADDR_ANY\n (0) is the same in either network or host byte order, so the use of \nhtonl\n is not really required. But, since all the \nINADDR_\nconstants defined by the \nnetinet/in.h\n header are defined in host byte order, we should use \nhtonl\n with any of these constants.\n\n\nIf we tell the kernel to choose an ephemeral port number for our socket (by specifying a 0 for port number), \nbind\n does not return the chosen value. It cannot return this value since the second argument to \nbind\n has the \nconst\n qualifier. \nTo obtain the value of the ephemeral port assigned by the kernel, we must call \ngetsockname\n to return the protocol address.\n\n\nBinding a non-wildcard IP address *\n\n\nA common example of a process binding a non-wildcard IP address to a socket is a host that provides Web servers to multiple organizations:\n\n\n\n\nFirst, each organization has its own domain name, such as www.organization.com.\n\n\nNext, each organization's domain name maps into a different IP address, but typically on the same subnet.\n\n\n\n\nFor example, if the subnet is 198.69.10, the first organization's IP address could be 198.69.10.128, the next 198.69.10.129, and so on. All these IP addresses are then \naliased\n onto a single network interface (using the \nalias\n option of the \nifconfig\n command on 4.4BSD, for example) so that the IP layer will accept incoming datagrams destined for any of the aliased addresses. Finally, one copy of the HTTP server is started for each organization and each copy \nbind\ns only the IP address for that organization.\n\n\nAn alternative technique is to run a single server that binds the wildcard address. When a connection arrives, the server calls \ngetsockname\n to obtain the destination IP address from the client, which in our discussion above could be 198.69.10.128, 198.69.10.129, and so on. The server then handles the client request based on the IP address to which the connection was issued.\n\n\nOne advantage in binding a non-wildcard IP address is that the demultiplexing of a given destination IP address to a given server process is then done by the kernel.\n\n\nWe must be careful to distinguish between the interface on which a packet arrives versus the destination IP address of that packet. In \nSection 8.8\n, we will talk about the \nweak end system model\n and the \nstrong end system model\n. Most implementations employ the former, meaning it is okay for a packet to arrive with a destination IP address that identifies an interface other than the interface on which the packet arrives. (This assumes a multihomed host.) Binding a non-wildcard IP address restricts the datagrams that will be delivered to the socket based only on the destination IP address. It says nothing about the arriving interface, unless the host employs the strong end system model.\n\n\nA common error from bind is \nEADDRINUSE\n (\"Address already in use\"), which is detailed in \nSection 7.5\n when discussing the \nSO_REUSEADDR\n and \nSO_REUSEPORT\n socket options.\n\n\nlisten\n Function\n\n\nThe \nlisten\n function is called only by a TCP server and it performs two actions:\n\n\n\n\nThe \nlisten\n function converts an unconnected socket into a passive socket, indicating that the kernel should accept incoming connection requests directed to this socket. In terms of the TCP state transition diagram (\nFigure 2.4\n), the call to \nlisten\n moves the socket from the CLOSED state to the LISTEN state.\n\n\nWhen a socket is created by the \nsocket\n function (and before calling \nlisten\n), it is assumed to be an active socket, that is, a client socket that will issue a \nconnect\n.\n\n\n\n\n\n\nThe second argument \nbacklog\n to this function specifies the maximum number of connections the kernel should queue for this socket.\n\n\n\n\nThis function is normally called after both the \nsocket\n and \nbind\n functions and must be called before calling the \naccept\n function.\n\n\nConnection queues *\n\n\nTo understand the \nbacklog\n argument, we must realize that for a given listening socket, the kernel maintains two queues:\n\n\n\n\nAn \nincomplete connection queue\n, which contains an entry for each SYN that has arrived from a client for which the server is awaiting completion of the TCP three-way handshake. These sockets are in the \nSYN_RCVD\n state (\nFigure 2.4\n).\n\n\nA \ncompleted connection queue\n, which contains an entry for each client with whom the TCP three-way handshake has completed. These sockets are in the ESTABLISHED state (\nFigure 2.4\n).\n\n\n\n\nThese two queues are depicted in the figure below:\n\n\n\n\nWhen an entry is created on the incomplete queue, the parameters from the listen socket are copied over to the newly created connection. \nThe connection creation mechanism is completely automatic; the server process is not involved.\n\n\nPacket exchanges during conenction establishment *\n\n\nThe following figure depicts the packets exchanged during the connection establishment with these two queues:\n\n\n\n\n\n\nWhen a SYN arrives from a client, TCP creates a new entry on the incomplete queue and then responds with the second segment of the three-way handshake: the server's SYN with an ACK of the client's SYN (\nSection 2.6\n).\n\n\nThis entry will remain on the incomplete queue, until:\n\n\nThe third segment of the three-way handshake arrives (the client's ACK of the server's SYN), or\n\n\nThe entry times out. (Berkeley-derived implementations have a timeout of 75 seconds for these incomplete entries.)\n\n\n\n\n\n\nIf the three-way handshake completes normally, the entry moves from the incomplete queue to the end of the completed queue.\n\n\nWhen the process calls \naccept\n:\n\n\nThe first entry on the completed queue is returned to the process, or\n\n\nIf the queue is empty, the process is put to sleep until an entry is placed onto the completed queue.\n\n\n\n\n\n\n\n\nThe \nbacklog\n argument *\n\n\nSeveral points to consider when handling the two queues:\n\n\n\n\nSum of both queues\n. The \nbacklog\n argument to the \nlisten\n function has historically specified the maximum value for the sum of both queues.\n\n\nMultiplied by 1.5\n. Berkeley-derived implementations add a fudge factor to the \nbacklog\n: It is multiplied by 1.5.\n\n\nIf the \nbacklog\n specifies the maximum number of completed connections the kernel will queue for a socket, then the reason for the fudge factor is to take into account incomplete connections on the queue.\n\n\n\n\n\n\nDo not specify value of 0\n for \nbacklog\n, as different implementations interpret this differently (\nFigure 4.10\n). If you do not want any clients connecting to your listening socket, close the listening socket.\n\n\nOne RTT\n. If the three-way handshake completes normally (no lost segments and no retransmissions), an entry remains on the incomplete connection queue for one RTT.\n\n\nConfigurable maximum value\n. Many current systems allow the administrator to modify the maximum value for the \nbacklog\n. Historically, sample code always shows a \nbacklog\n of 5 (which is adequate today).\n\n\nWhat value should the application specify for the \nbacklog\n \n (5 is often inadequate)? There is no easy answer to this.\n\n\nHTTP servers now specify a larger value, but if the value specified is a constant in the source code, to increase the constant requires recompiling the server.\n\n\nAnother method is to allow a command-line option or an environment variable to override the default. It is always acceptable to specify a value that is larger than supported by the kernel, as the kernel should silently truncate the value to the maximum value that it supports, without returning an error. The following example is the wrapper function for \nlisten\n which allows the environment variable \nLISTENQ\n to override the value specified by the caller:\n\n\n\n\n\n\n\n\nlib/wrapsock.c#L166\n\n\nvoid\n\n\nListen\n(\nint\n \nfd\n,\n \nint\n \nbacklog\n)\n\n\n{\n\n    \nchar\n    \n*\nptr\n;\n\n\n        \n/* can override 2nd argument with environment variable */\n\n    \nif\n \n(\n \n(\nptr\n \n=\n \ngetenv\n(\nLISTENQ\n))\n \n!=\n \nNULL\n)\n\n        \nbacklog\n \n=\n \natoi\n(\nptr\n);\n\n\n    \nif\n \n(\nlisten\n(\nfd\n,\n \nbacklog\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nlisten error\n);\n\n\n}\n\n\n/* end Listen */\n\n\n\n\n\n\n\n\nFixed number of connections\n. Historically the reason for queuing a fixed number of connections is to handle the case of the server process being busy between successive calls to \naccept\n. This implies that of the two queues, the completed queue should normally have more entries than the incomplete queue. Again, busy Web servers have shown that this is false. The reason for specifying a large \nbacklog\n is because the incomplete connection queue can grow as client SYNs arrive, waiting for completion of the three-way handshake.\n\n\nNo RST sent if queues are full\n. If the queues are full when a client SYN arrives, TCP ignores the arriving SYN; it does not send an RST. This is because the condition is considered temporary, and the client TCP will retransmit its SYN, hopefully finding room on the queue in the near future. If the server TCP immediately responded with an RST, the client's \nconnect\n would return an error, forcing the application to handle this condition instead of letting TCP's normal retransmission take over. Also, the client could not differentiate between an RST in response to a SYN meaning \"there is no server at this port\" versus \"there is a server at this port but its queues are full.\"\n\n\nData queued in the socket's receive buffer\n. Data that arrives after the three-way handshake completes, but before the server calls \naccept\n, should be queued by the server TCP, up to the size of the connected socket's receive buffer.\n\n\n\n\nThe following figure shows actual number of queued connections for values of \nbacklog\n:\n\n\n\n\nSYN Flooding *\n\n\nSYN flooding\n is a type of attack (the attacker writes a program to send SYNs at a high rate to the victim) that attempts to fill the incomplete connection queue for one or more TCP ports. Additionally, the source IP address of each SYN is set to a random number (called \nIP spoofing\n) so that the server's SYN/ACK goes nowhere.This also prevents the server from knowing the real IP address of the attacker. By filling the incomplete queue with bogus SYNs, legitimate SYNs are not queued, providing a \ndenial of service\n to legitimate clients.\n\n\nThe \nlisten\n's \nbacklog\n argument should specify the maximum number of completed connections for a given socket that the kernel will queue. The purpose ofto limit completed connections is to stop the kernel from accepting new connection requests for a given socket when the application is not accepting them. If a system implements this interpretation, then the application need not specify huge \nbacklog\n values just because the server handles lots of client requests or to provide protection against SYN flooding. The kernel handles lots of incomplete connections, regardless of whether they are legitimate or from a hacker. But even with this interpretation, scenarios do occur where the traditional value of 5 is inadequate.\n\n\naccept\n Function\n\n\naccept\n is called by a TCP server to return the next completed connection from the front of the completed connection queue (\nFigure 4.7\n). If the completed connection queue is empty, the process is put to sleep (assuming the default of a blocking socket).\n\n\n#include \nsys/socket.h\n\n\n\nint\n \naccept\n \n(\nint\n \nsockfd\n,\n \nstruct\n \nsockaddr\n \n*\ncliaddr\n,\n \nsocklen_t\n \n*\naddrlen\n);\n\n\n\n/* Returns: non-negative descriptor if OK, -1 on error */\n\n\n\n\n\n\nThe \ncliaddr\n and \naddrlen\n arguments are used to return the protocol address of the connected peer process (the client). \naddrlen\n is a value-result argument (\nSection 3.3\n):\n\n\n\n\nBefore the call, we set the integer value referenced by *\naddrlen\n to the size of the socket address structure pointed to by \ncliaddr\n;\n\n\nOn return, this integer value contains the actual number of bytes stored by the kernel in the socket address structure.\n\n\n\n\nIf successful, \naccept\n returns a new descriptor automatically created by the kernel. This new descriptor refers to the TCP connection with the client.\n\n\n\n\nThe \nlistening socket\n is the first argument (\nsockfd\n) to \naccept\n (the descriptor created by \nsocket\n and used as the first argument to both \nbind\n and \nlisten\n).\n\n\nThe \nconnected socket\n is the return value from \naccept\n the connected socket.\n\n\n\n\nIt is important to differentiate between these two sockets:\n\n\n\n\nA given server normally creates only one listening socket, which then exists for the lifetime of the server.\n\n\nThe kernel creates one connected socket for each client connection that is accepted (for which the TCP three-way handshake completes).\n\n\nWhen the server is finished serving a given client, the connected socket is closed.\n\n\n\n\nThis function returns up to three values:\n\n\n\n\nAn integer return code that is either a new socket descriptor or an error indication,\n\n\nThe protocol address of the client process (through the \ncliaddr\n pointer),\n\n\nThe size of this address (through the \naddrlen\n pointer).\n\n\n\n\nIf we are not interested in having the protocol address of the client returned, we set both \ncliaddr\n and \naddrlen\n to null pointers. See \nintro/daytimetcpsrv.c\n.\n\n\nExample: Value-Result Arguments\n\n\nThe following code shows how to handle the value-result argument to \naccept\n by modifying the code from \nintro/daytimetcpsrv.c\n to print the IP address and port of the client:\n\n\n#include    \nunp.h\n\n\n#include    \ntime.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nlistenfd\n,\n \nconnfd\n;\n\n    \nsocklen_t\n           \nlen\n;\n\n    \nstruct\n \nsockaddr_in\n  \nservaddr\n,\n \ncliaddr\n;\n\n    \nchar\n                \nbuff\n[\nMAXLINE\n];\n\n    \ntime_t\n              \nticks\n;\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\n13\n);\n   \n/* daytime server */\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nlen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n        \nconnfd\n \n=\n \nAccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nlen\n);\n\n        \nprintf\n(\nconnection from %s, port %d\n\\n\n,\n\n               \nInet_ntop\n(\nAF_INET\n,\n \ncliaddr\n.\nsin_addr\n,\n \nbuff\n,\n \nsizeof\n(\nbuff\n)),\n\n               \nntohs\n(\ncliaddr\n.\nsin_port\n));\n\n\n        \nticks\n \n=\n \ntime\n(\nNULL\n);\n\n        \nsnprintf\n(\nbuff\n,\n \nsizeof\n(\nbuff\n),\n \n%.24s\n\\r\\n\n,\n \nctime\n(\nticks\n));\n\n        \nWrite\n(\nconnfd\n,\n \nbuff\n,\n \nstrlen\n(\nbuff\n));\n\n\n        \nClose\n(\nconnfd\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThis program does the following:\n\n\n\n\nNew declarations\n. Two new variables are defined:\n\n\nlen\n will be a value-result variable.\n\n\ncliaddr\n will contain the client's protocol address.\n\n\n\n\n\n\nAccept connection and print client's address\n.\n\n\nInitialize \nlen\n to the size of the socket address structure\n\n\nPass a pointer to the \ncliaddr\n structure and a pointer to \nlen\n as the second and third arguments to accept.\n\n\nCall \ninet_ntop\n (\nSection 3.7\n) to convert the 32-bit IP address in the socket address structure to a dotted-decimal ASCII string and call \nntohs\n (\nSection 3.4\n) to convert the 16-bit port number from network byte order to host byte order.\n\n\n\n\n\n\n\n\nRun this new server and then run our client on the same host, connecting to our server twice in a row:\n\n\nsolaris % daytimetcpcli 127.0.0.1\nThu Sep 11 12:44:00 2003\nsolaris % daytimetcpcli 192.168.1.20\nThu Sep 11 12:44:09 2003\n\n\n\n\n\nWe first specify the server's IP address as the loopback address (127.0.0.1) and then as its own IP address (192.168.1.20). Here is the corresponding server output:\n\n\nsolaris # daytimetcpsrv1\nconnection from 127.0.0.1, port 43388\nconnection from 192.168.1.20, port 43389\n\n\n\n\n\nSince our daytime client (\nFigure 1.5\n) does not call \nbind\n, the kernel chooses the source IP address based on the outgoing interface that is used (\nSection 4.4\n).\n\n\n\n\nIn the first case, the kernel sets the source IP address to the loopback address;\n\n\nIn the second case, it sets the address to the IP address of the Ethernet interface.\n\n\n\n\nWe can also see in this example that the ephemeral port chosen by the Solaris kernel is 43388, and then 43389\n\n\nThe pound sign (#) as the shell prompt indicates that our server must run with superuser privileges to bind the reserved port of 13. If we do not have superuser privileges, the call to \nbind\n will fail:\n\n\nsolaris % daytimetcpsrv1\nbind error: Permission denied\n\n\n\n\n\nfork\n and \nexec\n Functions\n\n\nConcurrent Servers\n\n\nThe server described in \nintro/daytimetcpsrv1.c\n is an \niterative server\n. But when a client request can take longer to service, we do not want to tie up a single server with one client; we want to handle multiple clients at the same time. The simplest way to write a concurrent server under Unix is to \nfork\n a child process to handle each client.\n\n\nThe following code shows the outline for a typical concurrent server:\n\n\npid_t\n \npid\n;\n\n\nint\n   \nlistenfd\n,\n  \nconnfd\n;\n\n\n\nlistenfd\n \n=\n \nSocket\n(\n \n...\n \n);\n\n\n    \n/* fill in sockaddr_in{} with server\ns well-known port */\n\n\nBind\n(\nlistenfd\n,\n \n...\n \n);\n\n\nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n\nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n    \nconnfd\n \n=\n \nAccept\n \n(\nlistenfd\n,\n \n...\n \n);\n    \n/* probably blocks */\n\n\n    \nif\n(\n \n(\npid\n \n=\n \nFork\n())\n \n==\n \n0\n)\n \n{\n\n       \nClose\n(\nlistenfd\n);\n    \n/* child closes listening socket */\n\n       \ndoit\n(\nconnfd\n);\n       \n/* process the request */\n\n       \nClose\n(\nconnfd\n);\n      \n/* done with this client */\n\n       \nexit\n(\n0\n);\n            \n/* child terminates */\n\n    \n}\n\n\n    \nClose\n(\nconnfd\n);\n         \n/* parent closes connected socket */\n\n\n}\n\n\n\n\n\n\n\n\nWhen a connection is established, \naccept\n returns, the server calls fork, and the child process services the client (on \nconnfd\n, the connected socket) and the parent process waits for another connection (on \nlistenfd\n, the listening socket). The parent closes the connected socket since the child handles the new client.\n\n\nWe assume that the function \ndoit\n does whatever is required to service the client. When this function returns, we explicitly \nclose\n the connected socket in the child. This is not required since the next statement calls \nexit\n, and part of process termination is to close all open descriptors by the kernel. Whether to include this explicit call to \nclose\n or not is a matter of personal programming taste.\n\n\n\n\nReference count of sockets *\n\n\nCalling \nclose\n on a TCP socket causes a FIN to be sent, followed by the normal TCP connection termination sequence. Why doesn't the \nclose\n of \nconnfd\n by the parent terminate its connection with the client? To understand what's happening, we must understand that every file or socket has a \nreference count\n. The reference count is maintained in the file table entry. This is a count of the number of descriptors that are currently open that refer to this file or socket. In the above code:\n\n\n\n\nAfter \nsocket\n returns, the file table entry associated with \nlistenfd\n has a reference count of 1.\n\n\nAfter \naccept\n returns, the file table entry associated with \nconnfd\n has a reference count of 1.\n\n\nBut, after \nfork\n returns, both descriptors are shared (duplicated) between the parent and child, so the file table entries associated with both sockets now have a reference count of 2. Therefore, when the parent closes \nconnfd\n, it just decrements the reference count from 2 to 1 and that is all.\n\n\nThe actual cleanup and de-allocation of the socket does not happen until the reference count reaches 0. This will occur at some time later when the child closes \nconnfd\n.\n\n\n\n\nVisualizing the sockets and connection *\n\n\nThe following figures visualize the sockets and connection in the code above:\n\n\nBefore call to \naccept\n returns, the server is blocked in the call to \naccept\n and the connection request arrives from the client:\n\n\n\n\nAter return from \naccept\n, the connection is accepted by the kernel and a new socket \nconnfd\n is created (this is a connected socket and data can now be read and written across the connection):\n\n\n\n\nAfter \nfork\n returns, both descriptors, \nlistenfd\n and \nconnfd\n, are shared (duplicated) between the parent and child:\n\n\n\n\nAfter the parent closes the connected socket and the child closes the listening socket:\n\n\n\n\nThis is the desired final state of the sockets. The child is handling the connection with the client and the parent can call \naccept\n again on the listening socket, to handle the next client connection.\n\n\nclose\n Function\n\n\nThe normal Unix \nclose\n function is also used to close a socket and terminate a TCP connection.\n\n\n#include \nunistd.h\n\n\n\nint\n \nclose\n \n(\nint\n \nsockfd\n);\n\n\n\n/* Returns: 0 if OK, -1 on error */\n\n\n\n\n\n\nThe default action of \nclose\n with a TCP socket is to mark the socket as closed and return to the process immediately. The socket descriptor is no longer usable by the process: It cannot be used as an argument to \nread\n or \nwrite\n. But, \nTCP will try to send any data that is already queued to be sent to the other end, and after this occurs, the normal TCP connection termination sequence takes place.\n\n\nSO_LINGER\n socket option (detailed in \nSection 7.5\n) lets us change this default action with a TCP socket.\n\n\nDescriptor Reference Counts\n\n\nAs mentioned in \nend of Section 4.8\n, when the parent process in our concurrent server \ncloses\n the connected socket, this just decrements the reference count for the descriptor. Since the reference count was still greater than 0, this call to close did not initiate TCP's four-packet connection termination sequence. This is the behavior we want with our concurrent server with the connected socket that is shared between the parent and child.\n\n\nIf we really want to send a FIN on a TCP connection, the \nshutdown\n function can be used (\nSection 6.6\n) instead of \nclose\n.\n\n\nBe aware if the parent does not call \nclose\n for each connected socket returned by \naccept\n:\n\n\n\n\nThe parent will eventually run out of descriptors\n (there is usually a limit to the number of descriptors that any process can have open at any time)\n\n\nNone of the client connections will be terminated.\n When the child closes the connected socket, its reference count will go from 2 to 1 and it will remain at 1 since the parent never \nclose\ns the connected socket. This will prevent TCP's connection termination sequence from occurring, and the connection will remain open.\n\n\n\n\ngetsockname\n and \ngetpeername\n Functions\n\n\n\n\ngetsockname\n returns the local protocol address associated with a socket.\n\n\ngetpeername\n returns the foreign protocol address associated with a socket.\n\n\n\n\n#include \nsys/socket.h\n\n\n\nint\n \ngetsockname\n(\nint\n \nsockfd\n,\n \nstruct\n \nsockaddr\n \n*\nlocaladdr\n,\n \nsocklen_t\n \n*\naddrlen\n);\n\n\nint\n \ngetpeername\n(\nint\n \nsockfd\n,\n \nstruct\n \nsockaddr\n \n*\npeeraddr\n,\n \nsocklen_t\n \n*\naddrlen\n);\n\n\n\n/* Both return: 0 if OK, -1 on error */\n\n\n\n\n\n\nThe \naddrlen\n argument for both functions is value-result argument: both functions fill in the socket address structure pointed to by localaddr or peeraddr.\n\n\nThe term \"name\" in the function name is misleading. \nThese two functions return the protocol address associated with one of the two ends of a network connection, which for IPV4 and IPV6 is the combination of an IP address and port number. These functions have nothing to do with domain names.\n\n\nThese two functions are required for the following reasons:\n\n\n\n\nAfter \nconnect\n successfully returns in a TCP client that does not call \nbind\n, \ngetsockname\n returns the local IP address and local port number assigned to the connection by the kernel.\n\n\nAfter calling \nbind\n with a port number of 0 (telling the kernel to choose the local port number), \ngetsockname\n returns the local port number that was assigned.\n\n\ngetsockname\n can be called to obtain the address family of a socket.\n\n\nIn a TCP server that \nbind\ns the wildcard IP address (\nintro/daytimetcpsrv.c\n), once a connection is established with a client (\naccept\n returns successfully), the server can call \ngetsockname\n to obtain the local IP address assigned to the connection. \nThe socket descriptor argument to \ngetsockname\n must be that of the connected socket, and not the listening socket.\n\n\nWhen a server is \nexec\ned by the process that calls \naccept\n, the only way the server can obtain the identity of the client is to call \ngetpeername\n. For example, \ninetd\n \nfork\ns and \nexec\ns a TCP server (follwing figure):\n\n\ninetd\n calls \naccept\n, which return two values: the connected socket descriptor (\nconnfd\n, return value of the function) and the \"peer's address\" (an Internet socket address structure) that contains the IP address and port number of the client.\n\n\nfork\n is called and a child of \ninetd\n is created, with a copy of the parent's memory image, so the socket address structure is available to the child, as is the connected socket descriptor (since the descriptors are shared between the parent and child).\n\n\nWhen the child \nexec\ns the real server (e.g. Telnet server that we show), the memory image of the child is replaced with the new program file for the Telnet server (the socket address structure containing the peer's address is lost), and the connected socket descriptor remains open across the \nexec\n. One of the first function calls performed by the Telnet server is \ngetpeername\n to obtain the IP address and port number of the client.\n\n\n\n\n\n\n\n\n\n\nIn this example, the Telnet server must know the value of \nconnfd\n when it starts. There are two common ways to do this.\n\n\n\n\nThe process calling \nexec\n pass it as a command-line argument to the newly \nexec\ned program.\n\n\nA convention can be established that a certain descriptor is always set to the connected socket before calling \nexec\n.\n\n\n\n\nThe second one is what \ninetd\n does, always setting descriptors 0, 1, and 2 to be the connected socket.\n\n\nExample: Obtaining the Address Family of a Socket\n\n\nThe \nsockfd_to_family\n function shown in the code below returns the address family of a socket.\n\n\nlib/sockfd_to_family.c\n\n\nint\n\n\nsockfd_to_family\n(\nint\n \nsockfd\n)\n\n\n{\n\n    \nstruct\n \nsockaddr_storage\n \nss\n;\n\n    \nsocklen_t\n   \nlen\n;\n\n\n    \nlen\n \n=\n \nsizeof\n(\nss\n);\n\n    \nif\n \n(\ngetsockname\n(\nsockfd\n,\n \n(\nSA\n \n*\n)\n \nss\n,\n \nlen\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nreturn\n(\nss\n.\nss_family\n);\n\n\n}\n\n\n\n\n\n\nThis program does the following:\n\n\n\n\nAllocate room for largest socket address structure\n. Since we do not know what type of socket address structure to allocate, we use a sockaddr_storage value, since it can hold any socket address structure supported by the system.\n\n\nCall \ngetsockname\n.\n We call \ngetsockname\n and return the address family. The POSIX specification allows a call to \ngetsockname\n on an unbound socket.", 
            "title": "Chapter 4. Elementary TCP Sockets"
        }, 
        {
            "location": "/unp/ch5/", 
            "text": "Chapter 5. TCP Client/Server Example\n\n\nIntroduction\n\n\nWe will now use the elementary functions from the previous chapter to write a complete TCP client/server example. Our simple example is an echo server that performs the following steps:\n\n\n\n\nThe client reads a line of text from its standard input and writes the line to the server.\n\n\nThe server reads the line from its network input and echoes the line back to the client.\n\n\nThe client reads the echoed line and prints it on its standard output.\n\n\n\n\nThe figure below depcits this simple client/server:\n\n\n\n\nDespite two arrows between the client and server in the above figure, it is really a \nfull-duplex\n TCP connection. \nfgets\n and \nfputs\n functions are from the standard I/O library. \nwriten\n and \nreadline\n functions were shown in \nSection 3.9\n.\n\n\nThe echo client/server is a valid, simple example of a network application. To expand this example into your own application, all you need to do is change what the server does with the input it receives from its clients.\n\n\nBesides running the client/server in normal mode (type in a line and watch it echo), we examine lots of boundary conditions:\n\n\n\n\nWhat happens when the client and server are started?\n\n\nWhat happens when the client terminates normally?\n\n\nWhat happens to the client if the server process terminates before the client is done?\n\n\nWhat happens to the client if the server host crashes?\n\n\n\n\nIn all these examples, we have \"hard-coded\" protocol-specific constants such as addresses and ports. There are two reasons for this:\n\n\n\n\nWe must understand exactly what needs to be stored in the protocol-specific address structures\n\n\nWe have not yet covered the library functions that can make this more portable\n\n\n\n\nTCP Echo Server: \nmain\n Function\n\n\nOur TCP client and server follow the flow of functions that we diagrammed in \nFigure 4.1\n. The below code is the concurrent server program:\n\n\ntcpcliserv/tcpserv01.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nlistenfd\n,\n \nconnfd\n;\n\n    \npid_t\n               \nchildpid\n;\n\n    \nsocklen_t\n           \nclilen\n;\n\n    \nstruct\n \nsockaddr_in\n  \ncliaddr\n,\n \nservaddr\n;\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\nSERV_PORT\n);\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nclilen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n        \nconnfd\n \n=\n \nAccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n);\n\n\n        \nif\n \n(\n \n(\nchildpid\n \n=\n \nFork\n())\n \n==\n \n0\n)\n \n{\n    \n/* child process */\n\n            \nClose\n(\nlistenfd\n);\n    \n/* close listening socket */\n\n            \nstr_echo\n(\nconnfd\n);\n   \n/* process the request */\n\n            \nexit\n(\n0\n);\n\n        \n}\n\n        \nClose\n(\nconnfd\n);\n          \n/* parent closes connected socket */\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nCreate socket, bind server's well-known port\n\n\nA TCP socket is created.\n\n\nAn Internet socket address structure is filled in with the wildcard address (\nINADDR_ANY\n) and the server's well-known port (\nSERV_PORT\n, which is defined as 9877 in our \nunp.h\n header). Binding the wildcard address tells the system that we will accept a connection destined for any local interface, in case the system is multihomed. Our choice of the TCP port number is based on \nFigure 2.10\n in \nSection 2.9\n. It should be greater than 1023 (we do not need a reserved port), greater than 5000 (to avoid conflict with the ephemeral ports allocated by many Berkeley-derived implementations), less than 49152 (to avoid conflict with the \"correct\" range of ephemeral ports), and it should not conflict with any registered port.  [p122]\n\n\nThe socket is converted into a listening socket by \nlisten\n.\n\n\n\n\n\n\nWait for client connection to complete\n\n\nThe server blocks in the call to \naccept\n, waiting for a client connection to complete.\n\n\n\n\n\n\nConcurrent server\n\n\nFor each client, \nfork\n spawns a child, and the child handles the new client. The child closes the listening socket and the parent closes the connected socket. (\nSection 4.8\n)\n\n\n\n\n\n\n\n\nTCP Echo Server: \nstr_echo\n Function\n\n\nThe function \nstr_echo\n performs the server processing for each client: It reads data from the client and echoes it back to the client.\n\n\nlib/str_echo.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_echo\n(\nint\n \nsockfd\n)\n\n\n{\n\n    \nssize_t\n     \nn\n;\n\n    \nchar\n        \nbuf\n[\nMAXLINE\n];\n\n\n\nagain\n:\n\n    \nwhile\n \n(\n \n(\nn\n \n=\n \nread\n(\nsockfd\n,\n \nbuf\n,\n \nMAXLINE\n))\n \n \n0\n)\n\n        \nWriten\n(\nsockfd\n,\n \nbuf\n,\n \nn\n);\n\n\n    \nif\n \n(\nn\n \n \n0\n \n \nerrno\n \n==\n \nEINTR\n)\n\n        \ngoto\n \nagain\n;\n\n    \nelse\n \nif\n \n(\nn\n \n \n0\n)\n\n        \nerr_sys\n(\nstr_echo: read error\n);\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nRead a buffer and echo the buffer\n\n\nread\n reads data from the socket and the line is echoed back to the client by \nwriten\n. If the client closes the connection (the normal scenario), \nthe receipt of the client's FIN causes the child's read to return 0.\n This causes the \nstr_echo\n function to return, which terminates the child.\n\n\n\n\n\n\n\n\nTCP Echo Client: \nmain\n Function\n\n\ntcpcliserv/tcpcli01.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nsockfd\n;\n\n    \nstruct\n \nsockaddr_in\n  \nservaddr\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: tcpcli \nIPaddress\n);\n\n\n    \nsockfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_port\n \n=\n \nhtons\n(\nSERV_PORT\n);\n\n    \nInet_pton\n(\nAF_INET\n,\n \nargv\n[\n1\n],\n \nservaddr\n.\nsin_addr\n);\n\n\n    \nConnect\n(\nsockfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nstr_cli\n(\nstdin\n,\n \nsockfd\n);\n     \n/* do it all */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nCreate socket, fill in Internet socket address structure\n\n\nA TCP socket is created and an Internet socket address structure is filled in with the server's IP address and port number. The server's IP address is taken from the command-line argument and the server's well-known port (\nSERV_PORT\n) is from our \nunp.h\n header.\n\n\n\n\n\n\nConnect to server\n\n\nconnect\n establishes the connection with the server. The function \nstr_cli\n handles the rest of the client processing.\n\n\n\n\n\n\n\n\nTCP Echo Client: \nstr_cli\n Function\n\n\nThe \nstr_cli\n function handles the client processing loop: It reads a line of text from standard input, writes it to the server, reads back the server's echo of the line, and outputs the echoed line to standard output.\n\n\nlib/str_cli.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nchar\n    \nsendline\n[\nMAXLINE\n],\n \nrecvline\n[\nMAXLINE\n];\n\n\n    \nwhile\n \n(\nFgets\n(\nsendline\n,\n \nMAXLINE\n,\n \nfp\n)\n \n!=\n \nNULL\n)\n \n{\n\n\n        \nWriten\n(\nsockfd\n,\n \nsendline\n,\n \nstrlen\n(\nsendline\n));\n\n\n        \nif\n \n(\nReadline\n(\nsockfd\n,\n \nrecvline\n,\n \nMAXLINE\n)\n \n==\n \n0\n)\n\n            \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n\n        \nFputs\n(\nrecvline\n,\n \nstdout\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nRead a line, write to server\n\n\nfgets\n reads a line of text and \nwriten\n sends the line to the server.\n\n\n\n\n\n\nRead echoed line from server, write to standard output\n\n\nreadline\n reads the line echoed back from the server and \nfputs\n writes it to standard output.\n\n\n\n\n\n\nReturn to main\n\n\nThe loop terminates when \nfgets\n returns a null pointer, which occurs when it encounters either an end-of-file (EOF) or an error. Our \nFgets\n wrapper function checks for an error and aborts if one occurs, so \nFgets\n returns a null pointer only when an end-of-file is encountered.\n\n\n\n\n\n\n\n\nNormal Startup\n\n\nAlthough the TCP example is small, it is essential that we understand:\n\n\n\n\nHow the client and server start and end,\n\n\nWhat happens when something goes wrong:\n\n\nthe client host crashes,\n\n\nthe client process crashes,\n\n\nnetwork connectivity is lost\n\n\n\n\n\n\n\n\nOnly by understanding these boundary conditions, and their interaction with the TCP/IP protocols, can we write robust clients and servers that can handle these conditions.\n\n\nStart the server in the background\n\n\nFirst, we start the server in the background:\n\n\nlinux % tcpserv01 \n\n[1] 17870\n\n\n\n\n\nWhen the server starts, it calls \nsocket\n, \nbind\n, \nlisten\n, and \naccept\n, blocking in the call to accept.\n\n\nRun \nnetstat\n\n\nBefore starting the client, we run the \nnetstat\n program to verify the state of the server's listening socket.\n\n\nlinux % netstat -a\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address       Foreign Address      State\ntcp        0      0 *:9877              *:*                  LISTEN\n\n\n\n\n\nThis command shows the status of all sockets on the system. We must specify the \n-a\n flag to see listening sockets.\n\n\nIn the output, a socket is in the LISTEN state with a wildcard for the local IP address and a local port of 9877. \nnetstat\n prints an asterisk for an IP address of 0 (\nINADDR_ANY\n, the wildcard) or for a port of 0.\n\n\nStart the client on the same host\n\n\nWe then start the client on the same host, specifying the server's IP address of 127.0.0.1 (the loopback address). We could have also specified the server's normal (nonloopback) IP address.\n\n\nlinux % tcpcli01 127.0.0.1\n\n\n\n\n\nThe client calls \nsocket\n, and \nconnect\n which causes TCP's three-way handshake. When the three-way handshake completes, \nconnect\n returns in the client and \naccept\n returns in the server. The connection is established. The following steps then take place:\n\n\n\n\nThe client calls \nstr_cli\n, which will block in the call to \nfgets\n.\n\n\nWhen \naccept\n returns in the server, it calls \nfork\n and the child calls \nstr_echo\n. This function calls \nreadline\n, which calls \nread\n, which blocks while waiting for a line to be sent from the client.\n\n\nThe server parent, on the other hand, calls \naccept\n again, and blocks while waiting for the next client connection.\n\n\n\n\nNotes from the previous three steps:\n\n\n\n\nAll three processes are asleep (blocked): client, server parent, and server child.\n\n\nWe purposely list the client step first, and then the server steps when the three-way handshake completes. This is because \naccept\n returns one-half of the RTT after \nconnect\n returns (see \nFigure 2.5\n):\n\n\nOn the client side, \nconnect\n returns when the second segment of the handshake is received\n\n\nOn the server side, \naccept\n does not return until the third segment of the handshake is received\n\n\n\n\n\n\n\n\nRun \nnetstat\n after connection completes\n\n\nSince we are running the client and server on the same host, \nnetstat\n now shows two additional lines of output, corresponding to the TCP connection:\n\n\nlinux % netstat -a\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address          State\ntcp        0      0 local host:9877         localhost:42758          ESTABLISHED\ntcp        0      0 local host:42758        localhost:9877           ESTABLISHED\ntcp        0      0 *:9877                  *:*                      LISTEN\n\n\n\n\n\n\n\nThe first ESTABLISHED line corresponds to the server child's socket, since the local port is 9877.\n\n\nThe second ESTABLISHED lines is the client's socket, since the local port is 42758\n\n\n\n\nIf we were running the client and server on different hosts, the client host would display only the client's socket, and the server host would display only the two server sockets.\n\n\nRun \nps\n to check process status and relationship\n\n\nlinux % ps -t pts/6 -o pid,ppid,tty,stat,args,wchan\n  PID  PPID TT       STAT COMMAND          WCHAN\n22038 22036 pts/6    S    -bash            wait4\n17870 22038 pts/6    S    ./tcpserv01      wait_for_connect\n19315 17870 pts/6    S    ./tcpserv01      tcp_data_wait\n19314 22038 pts/6    S    ./tcpcli01 127.0 read_chan\n\n\n\n\n\nVery specific arguments to \nps\n are used:\n\n\n\n\nThe TT column (\npts/6\n): client and server are run from the same window, pseudo-terminal number 6.\n\n\nThe PID and PPID columns show the parent and child relationships.\n\n\nThe first \ntcpserv01\n line is the parent and the second tcpserv01 line is the child since the PPID of the child is the parent's PID.\n\n\nThe PPID of the parent is the shell (bash).\n\n\n\n\n\n\nThe STAT column for all three of our network processes is \"S\", meaning the process is sleeping (waiting for something).\n\n\nThe WCHAN column specifies the condition when a process is asleep.\n\n\nLinux prints \nwait_for_connect\n when a process is blocked in either \naccept\n or \nconnect\n, \ntcp_data_wait\n when a process is blocked on socket input or output, or \nread_chan\n when a process is blocked on terminal I/O.\n\n\nIn \nps(1)\n, WCHAN column indicates the name of the kernel function in which the process is sleeping, a \"-\" if the process is running, or a \"*\" if the process is multi-threaded and ps is not displaying threads.\n\n\n\n\n\n\n\n\nNormal Termination\n\n\nAt this point, the connection is established and whatever we type to the client is echoed back.\n\n\nlinux % tcpcli01 127.0.0.1   # we showed this line earlier\n\n\nhello, world                 # we now type this\n\n\nhello, world                 # and the line is echoed\n\n\ngood bye\n\n\ngood bye\n\n\n^D                           # Control-D is our terminal EOF character\n\n\n\n\n\n\nIf we immediately execute netstat, we have:\n\n\nlinux % netstat -a | grep 9877\n\n\ntcp        0      0 *:9877               *:*               LISTEN\n\n\ntcp        0      0 localhost:42758      localhost:9877    TIME_WAIT\n\n\n\n\n\n\nThis time we pipe the output of netstat into \ngrep\n, printing only the lines with our server's well-known port:\n\n\n\n\nThe client's side of the connection (since the local port is 42758) enters the TIME_WAIT state\n\n\nThe listening server is still waiting for another client connection.\n\n\n\n\nThe following steps are involved in the normal termination of client and server:\n\n\n\n\nWhen we type our EOF character, \nfgets\n returns a null pointer and the function \nstr_cli\n (\nSection 5.5\n) returns.\n\n\nstr_cli\n returns to the client \nmain\n function (\nSection 5.5\n), which terminates by calling \nexit\n.\n\n\nPart of process termination is the closing of all open descriptors, so the client socket is closed by the kernel. This sends a FIN to the server, to which the server TCP responds with an ACK. This is the first half of the TCP connection termination sequence. At this point, the server socket is in the CLOSE_WAIT state and the client socket is in the FIN_WAIT_2 state (\nFigure 2.4\n and \nFigure 2.5\n)\n\n\nWhen the server TCP receives the FIN, the server child is blocked in a call to \nread\n (\nSection 3.8\n), and \nread\n then returns 0. This causes the \nstr_echo\n function to return to the server child main. [Errata] [p128]\n\n\nThe server child terminates by calling exit. (\nSection 5.2\n)\n\n\nAll open descriptors in the server child are closed.\n\n\nThe closing of the connected socket by the child causes the final two segments of the TCP connection termination to take place: a FIN from the server to the client, and an ACK from the client.\n\n\n\n\n\n\nFinally, the \nSIGCHLD\n signal is sent to the parent when the server child terminates.\n\n\nThis occurs in this example, but we do not catch the signal in our code, and the default action of the signal is to be ignored. Thus, the child enters the zombie state. We can verify this with the \nps\n command.\n\n\n\n\n\n\n\n\nlinux % ps -t pts/6 -o pid,ppid,tty,stat,args,wchan\n\n\n  PID  PPID TT       STAT COMMAND          WCHAN\n\n\n22038 22036 pts/6    S    -bash            read_chan\n\n\n17870 22038 pts/6    S    ./tcpserv01      wait_for_connect\n\n\n19315 17870 pts/6    Z    [tcpserv01 \ndefu do_exit\n\n\n\n\n\n\nThe STAT of the child is now \nZ\n (for zombie).\n\n\nWe need to clean up our zombie processes and doing this requires dealing with Unix signals. The next section will give an overview of signal handling.\n\n\nPOSIX Signal Handling\n\n\nA \nsignal\n is a notification to a process that an event has occurred. Signals are sometimes called \nsoftware interrupts\n. Signals usually occur asynchronously, which means that a process doesn't know ahead of time exactly when a signal will occur.\n\n\nSignals can be sent:\n\n\n\n\nBy one process to another process (or to itself)\n\n\nBy the kernel to a process.\n\n\nFor example, whenever a process terminates, the kernel send a \nSIGCHLD\n signal to the parent of the terminating process.\n\n\n\n\n\n\n\n\nEvery signal has a \ndisposition\n, which is also called the \naction\n associated with the signal. We set the disposition of a signal by calling the \nsigaction\n function and we have three choices for the disposition:\n\n\n\n\n\n\nCatching a signal\n. We can provide a function called a \nsignal handler\n that is called whenever a specific signal occurs. The two signals \nSIGKILL\n and \nSIGSTOP\n cannot be caught. Our function is called with a single integer argument that is the signal number and the function returns nothing. Its function prototype is therefore:\n\n\nvoid handler (int signo);\n\n\n\n\n\nFor most signals, we can call \nsigaction\n and specify the signal handler to catch it. A few signals, \nSIGIO\n, \nSIGPOLL\n, and \nSIGURG\n, all require additional actions on the part of the process to catch the signal.\n\n\n\n\n\n\nIgnoring a signal\n. We can ignore a signal by setting its disposition to \nSIG_IGN\n. The two signals SIGKILL and SIGSTOP cannot be ignored.\n\n\n\n\nSetting the default disposition for a signal\n. This can be done by setting its disposition to \nSIG_DFL\n. The default is normally to terminate a process on receipt of a signal, with certain signals also generating a core image of the process in its current working directory. There are a few signals whose default disposition is to be ignored: \nSIGCHLD\n and \nSIGURG\n (sent on the arrival of out-of-band data) are two that we will encounter in this text.\n\n\n\n\nsignal\n Function\n\n\nThe POSIX way to establish the disposition of a signal is to call the \nsigaction\n function, which is complicated in that one argument to the function is a structure (\nstruct sigaction\n) that we must allocate and fill in.\n\n\nAn easier way to set the disposition of a signal is to call the \nsignal\n function. The first argument is the signal name and the second argument is either a pointer to a function or one of the constants \nSIG_IGN\n or \nSIG_DFL\n.\n\n\nHowever, \nsignal\n is an historical function that predates POSIX. Different implementations provide different signal semantics when it is called, providing backward compatibility, whereas POSIX explicitly spells out the semantics when \nsigaction\n is called.\n\n\nThe solution is to define our own function named \nsignal\n that just calls the POSIX \nsigaction\n function. This provides a simple interface with the desired POSIX semantics. We include this function in our own library, along with our \nerr\n_XXX functions and our wrapper functions. [p130]\n\n\nlib/signal.c\n\n\n#include    \nunp.h\n\n\n\nSigfunc\n \n*\n\n\nsignal\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nact\n,\n \noact\n;\n\n\n    \nact\n.\nsa_handler\n \n=\n \nfunc\n;\n\n    \nsigemptyset\n(\nact\n.\nsa_mask\n);\n\n    \nact\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGALRM\n)\n \n{\n\n\n#ifdef  SA_INTERRUPT\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_INTERRUPT\n;\n   \n/* SunOS 4.x */\n\n\n#endif\n\n    \n}\n \nelse\n \n{\n\n\n#ifdef  SA_RESTART\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_RESTART\n;\n     \n/* SVR4, 44BSD */\n\n\n#endif\n\n    \n}\n\n    \nif\n \n(\nsigaction\n(\nsigno\n,\n \nact\n,\n \noact\n)\n \n \n0\n)\n\n        \nreturn\n(\nSIG_ERR\n);\n\n    \nreturn\n(\noact\n.\nsa_handler\n);\n\n\n}\n\n\n/* end signal */\n\n\n\nSigfunc\n \n*\n\n\nSignal\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n    \n/* for our signal() function */\n\n\n{\n\n    \nSigfunc\n \n*\nsigfunc\n;\n\n\n    \nif\n \n(\n \n(\nsigfunc\n \n=\n \nsignal\n(\nsigno\n,\n \nfunc\n))\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal error\n);\n\n    \nreturn\n(\nsigfunc\n);\n\n\n}\n\n\n\n\n\n\nSimplify function prototype using \ntypedef\n\n\nThe normal function prototype for \nsignal\n is complicated by the level of nested parentheses.\n\n\nvoid\n \n(\n*\nsignal\n \n(\nint\n \nsigno\n,\n \nvoid\n \n(\n*\nfunc\n)\n \n(\nint\n)))\n \n(\nint\n);\n\n\n\n\n\n\nTo simplify this, we define the \nSigfunc\n type in our \nunp.h\n header as\n\n\ntypedef\n    \nvoid\n    \nSigfunc\n(\nint\n);\n\n\n\n\n\n\nstating that signal handlers are functions with an integer argument and the function returns nothing (\nvoid\n). The function prototype then becomes\n\n\nSigfunc\n \n*\nsignal\n \n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n);\n\n\n\n\n\n\nA pointer to a signal handling function is the second argument to the function, as well as the return value from the function.\n\n\nSet handler\n\n\nThe \nsa_handler\n member of the \nsigaction\n structure is set to the \nfunc\n argument.\n\n\nSet signal mask for handler\n\n\nPOSIX allows us to specify a set of signals that will be blocked when our signal handler is called. Any signal that is blocked cannot be delivered to a process. We set the \nsa_mask\n member to the empty set, which means that no additional signals will be blocked while our signal handler is running. \nPOSIX guarantees that the signal being caught is always blocked while its handler is executing.\n\n\nSet \nSA_RESTART\n flag\n\n\nSA_RESTART\n is an optional flag. When the flag is set, a system call interrupted by this signal will be automatically restarted by the kernel.\n\n\nIf the signal being caught is not \nSIGALRM\n, we specify the \nSA_RESTART\n flag, if defined. This is because the purpose of generating the \nSIGALRM\n signal is normally to place a timeout on an I/O operation, in which case, we want the blocked system call to be interrupted by the signal. [p131]\n\n\nCall \nsigaction\n\n\nWe call \nsigaction\n and then \nreturn the old action for the signal as the return value of the signal function.\n\n\nThroughout this text, we will use the \nsignal\n function from the above definition.\n\n\nHandling \nSIGCHLD\n Signals\n\n\nThe zombie state is to maintain information about the child for the parent to fetch later, which includes:\n\n\n\n\nprocess ID of the child,\n\n\ntermination status,\n\n\ninformation on the resource utilization of the child.\n\n\n\n\nIf a parent process of zombie children terminates, the parent process ID of all the zombie children is set to 1 (the \ninit\n process), which will inherit the children and clean them up (\ninit\n will \nwait\n for them, which removes the zombie). [p132]\n\n\nHandling Zombies\n\n\nZombies take up space in the kernel and eventually we can run out of processes. Whenever we \nfork\n children, we must \nwait\n for them to prevent them from becoming zombies. We can establish a signal handler to catch \nSIGCHLD\n and call \nwait\n within the handler. We establish the signal handler by adding the following function call after the call to \nlisten\n (in \nserver's \nmain\n function\n; it must be done before \nfork\ning the first child and needs to be done only once.):\n\n\nSignal\n \n(\nSIGCHLD\n,\n \nsig_chld\n);\n\n\n\n\n\n\nThe signal handler, the function \nsig_chld\n, is defined below:\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nsig_chld\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstat\n;\n\n\n    \npid\n \n=\n \nwait\n(\nstat\n);\n\n    \nprintf\n(\nchild %d terminated\n\\n\n,\n \npid\n);\n\n    \nreturn\n;\n\n\n}\n\n\n\n\n\n\nNote that calling standard I/O functions such as \nprintf\n in a signal handler is not recommended. We call \nprintf\n here as a diagnostic tool to see when the child terminates.\n\n\nCompiling and running the program on Solaris\n *\n\n\nThis program (\ntcpcliserv/tcpserv02.c\n) is compiled on Solaris 9 and uses the \nsignal\n function from the system library (not \nour version\n).\n\n\nsolaris % tcpserv02 \n                 # start server in background\n\n\n[2] 16939\n\n\nsolaris % tcpcli01 127.0.0.1          # then start client in foreground\n\n\nhi there                              # we type this\n\n\nhi there                              # and this is echoed\n\n\n^D                                    # we type our EOF character\n\n\nchild 16942 terminated                # output by printf in signal handler\n\n\naccept error: Interrupted system call # main function aborts\n\n\n\n\n\n\nThe sequence of steps is as follows:\n\n\n\n\nWe terminate the client by typing our EOF character. The client TCP sends a FIN to the server and the server responds with an ACK.\n\n\nThe receipt of the FIN delivers an EOF to the child's pending \nreadline\n. The child terminates.\n\n\nThe parent is blocked in its call to accept when the \nSIGCHLD\n signal is delivered. The \nsig_chld\n function executes (our signal handler), \nwait\n fetches the child's PID and termination status, and \nprintf\n is called from the signal handler. The signal handler returns.\n\n\nSince the signal was caught by the parent while the parent was blocked in a slow system call (\naccept\n), the kernel causes the \naccept\n to return an error of \nEINTR\n (interrupted system call). The parent does not handle this error (see \nserver's \nmain\n function\n), so it aborts.\n\n\n\n\nFrom this example, we know that when writing network programs that catch signals, we must be cognizant of interrupted system calls, and we must handle them. In this example, the \nsignal\n function provided in the standard C library does not cause an interrupted system call to be automatically restarted by the kernel. Some other systems automatically restart the interrupted system call. If we run the same example under 4.4BSD, using its library version of the \nsignal\n function, the kernel restarts the interrupted system call and accept does not return an error. To handle this potential problem between different operating systems is one reason we define our own version of the \nsignal\n function. [p134]\n\n\nAs part of the coding conventions used in this text, we always code an explicit return in our signal handlers, even though this is unnecessary for a function returning \nvoid\n. This reads as a reminder that the return may interrupt a system call.\n\n\nHandling Interrupted System Calls\n\n\nThe term \"slow system call\" is used to describe any system call that can block forever, such as \naccept\n. That is, the system call need never return. Most networking functions fall into this category. Examples are:\n\n\n\n\naccept\n: there is no guarantee that a server's call to \naccept\n will ever return, if there are no clients that will connect to the server.\n\n\nread\n: the server's call to \nread\n in \nserver's \nstr_echo\n function\n will never return if the client never sends a line for the server to echo.\n\n\n\n\nOther examples of slow system calls are reads and writes of pipes and terminal devices. A notable exception is disk I/O, which usually returns to the caller (assuming no catastrophic hardware failure).\n\n\nWhen a process is blocked in a slow system call and the process catches a signal and the signal handler returns, the system call can return an error of \nEINT\n. Some kernels automatically restart some interrupted system calls. For portability, when we write a program that catches signals (most concurrent servers catch \nSIGCHLD\n), we must be prepared for slow system calls to return \nEINTR\n. [p134]\n\n\nTo handle an interrupted \naccept\n, we change the call to \naccept\n in \nserver's \nmain\n function\n, the beginning of the for loop, to the following:\n\n\n     \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n         \nclilen\n \n=\n \nsizeof\n \n(\ncliaddr\n);\n\n         \nif\n \n(\n \n(\nconnfd\n \n=\n \naccept\n \n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n))\n \n \n0\n)\n \n{\n\n             \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n                 \ncontinue\n;\n         \n/* back to for () */\n\n             \nelse\n\n                 \nerr_sys\n \n(\naccept error\n);\n\n        \n}\n\n\n\n\n\n\nNote that this \naccept\n is not our wrapper function \nAccept\n, since we must handle the failure of the function ourselves.\n\n\nThe modified version of the server source code is \ntcpcliserv/tcpserv03.c\n.\n\n\nRestarting the interrupted system call is fine for:\n\n\n\n\naccept\n\n\nread\n\n\nwrite\n\n\nselect\n\n\nopen\n\n\n\n\nHowever, there is one function that we cannot restart: \nconnect\n. If this function returns \nEINTR\n, we cannot call it again, as doing so will return an immediate error. When \nconnect\n is interrupted by a caught signal and is not automatically restarted, we must call \nselect\n to wait for the connection to complete.\n\n\nwait\n and \nwaitpid\n Functions\n\n\nWe can call \nwait\n function to handle the terminated child.\n\n\n#include \nsys/wait.h\n\n\n\npid_t\n \nwait\n \n(\nint\n \n*\nstatloc\n);\n\n\npid_t\n \nwaitpid\n \n(\npid_t\n \npid\n,\n \nint\n \n*\nstatloc\n,\n \nint\n \noptions\n);\n\n\n\n/* Both return: process ID if OK, 0 or\u20131 on error */\n\n\n\n\n\n\nwait\n and \nwaitpid\n both return two values: the return value of the function is the process ID of the terminated child, and the termination status of the child (an integer) is returned through the statloc pointer.\n\n\nThere are three macros that we can call that examine the termination status (see \nAPUE\n):\n\n\n\n\nWIFEXITED\n: tells if the child terminated normally\n\n\nWIFSIGNALED\n: tells if the child was killed by a signal\n\n\nWIFSTOPPED\n: tells if the child was just stopped by job control\n\n\n\n\nAdditional macros let us then fetch the exit status of the child, or the value of the signal that killed the child, or the value of the job-control signal that stopped the child. We will use the \nWIFEXITED\n and \nWEXITSTATUS\n macros  for this purpose.\n\n\nIf there are no terminated children for the process calling \nwait\n, but the process has one or more children that are still executing, then \nwait\n blocks until the first of the existing children terminates.\n\n\nwaitpid\n has more control over which process to wait for and whether or not to block:\n\n\n\n\nThe \npid\n argument specifies the process ID that we want to wait for. A value of -1 says to wait for the first of our children to terminate.\n\n\nThe \noptions\n argument specifies additional options. The most common option is \nWNOHANG\n, which tells the kernel not to block if there are no terminated children.\n\n\n\n\nDifference between \nwait\n and \nwaitpid\n\n\nThe following example illustrates the difference between the \nwait\n and \nwaitpid\n functions when used to clean up terminated children.\n\n\nWe modify our TCP client as below, which establishes five connections with the server and then uses only the first one (\nsockfd[0]\n) in the call to \nstr_cli\n. The purpose of establishing multiple connections is to spawn multiple children from the concurrent server.\n\n\ntcpcliserv/tcpcli04.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \ni\n,\n \nsockfd\n[\n5\n];\n\n    \nstruct\n \nsockaddr_in\n  \nservaddr\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: tcpcli \nIPaddress\n);\n\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \n5\n;\n \ni\n++\n)\n \n{\n\n        \nsockfd\n[\ni\n]\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n        \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n        \nservaddr\n.\nsin_family\n \n=\n \nAF_INET\n;\n\n        \nservaddr\n.\nsin_port\n \n=\n \nhtons\n(\nSERV_PORT\n);\n\n        \nInet_pton\n(\nAF_INET\n,\n \nargv\n[\n1\n],\n \nservaddr\n.\nsin_addr\n);\n\n\n        \nConnect\n(\nsockfd\n[\ni\n],\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \n}\n\n\n    \nstr_cli\n(\nstdin\n,\n \nsockfd\n[\n0\n]);\n      \n/* do it all */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWhen the client terminates, all open descriptors are closed automatically by the kernel (we do not call \nclose\n, only \nexit\n), and all five connections are terminated at about the same time. This causes five FINs to be sent, one on each connection, which in turn causes all five server children to terminate at about the same time. This causes five \nSIGCHLD\n signals to be delivered to the parent at about the same time. This causes the problem under discussion.\n\n\nWe first run the server (\ntcpcliserv/tcpserv03.c\n) in the background and then our new client:\n\n\nlinux % tcpserv03 \n\n\n[1] 20419\n\n\nlinux % tcpcli04 127.0.0.1\n\n\nhello                       # we type this\n\n\nhello                       # and it is echoed\n\n\n^D                          # we then type our EOF character\n\n\nchild 20426 terminated      # output by server\n\n\n\n\n\n\nOnly one \nprintf\n is output, when we expect all five children to have terminated. If we execute \nps\n, we see that the other four children still exist as zombies.\n\n\nPID TTY          TIME CMD\n20419 pts/6     00:00:00 tcpserv03\n20421 pts/6     00:00:00 tcpserv03 \ndefunct\n\n20422 pts/6     00:00:00 tcpserv03 \ndefunct\n\n20423 pts/6     00:00:00 tcpserv03 \ndefunct\n\n\n\n\n\n\nEstablishing a signal handler and calling wait from that handler are insufficient for preventing zombies. \nThe problem is that all five signals are generated before the signal handler is executed, and the signal handler is executed only one time because Unix signals are normally not queued.\nThis problem is nondeterministic. Dependent on the timing of the FINs arriving at the server host, the signal handler is executed two, three or even four times.\n\n\nThe correct solution is to call \nwaitpid\n instead of \nwait\n. The code below shows the version of our \nsig_chld\n function that handles \nSIGCHLD\n correctly. This version works because we call \nwaitpid\n within a loop, fetching the status of any of our children that have terminated, with the \nWNOHANG\n option, which tells \nwaitpid\n not to block if there are running children that have not yet terminated. We cannot call \nwait\n in a loop, because there is no way to prevent wait from blocking if there are running children that have not yet terminated.\n\n\ntcpcliserv/sigchldwaitpid.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nsig_chld\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstat\n;\n\n\n    \nwhile\n \n(\n \n(\npid\n \n=\n \nwaitpid\n(\n-\n1\n,\n \nstat\n,\n \nWNOHANG\n))\n \n \n0\n)\n\n        \nprintf\n(\nchild %d terminated\n\\n\n,\n \npid\n);\n\n    \nreturn\n;\n\n\n}\n\n\n\n\n\n\nThe code below shows the final version of our server. It correctly handles a return of \nEINTR\n from \naccept\n and it establishes a signal handler (code above) that calls \nwaitpid\n for all terminated children.\n\n\ntcpcliserv/tcpserv04.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nlistenfd\n,\n \nconnfd\n;\n\n    \npid_t\n               \nchildpid\n;\n\n    \nsocklen_t\n           \nclilen\n;\n\n    \nstruct\n \nsockaddr_in\n  \ncliaddr\n,\n \nservaddr\n;\n\n    \nvoid\n                \nsig_chld\n(\nint\n);\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\nSERV_PORT\n);\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nSignal\n(\nSIGCHLD\n,\n \nsig_chld\n);\n  \n/* must call waitpid() */\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nclilen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n        \nif\n \n(\n \n(\nconnfd\n \n=\n \naccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n))\n \n \n0\n)\n \n{\n\n            \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n                \ncontinue\n;\n       \n/* back to for() */\n\n            \nelse\n\n                \nerr_sys\n(\naccept error\n);\n\n        \n}\n\n\n        \nif\n \n(\n \n(\nchildpid\n \n=\n \nFork\n())\n \n==\n \n0\n)\n \n{\n    \n/* child process */\n\n            \nClose\n(\nlistenfd\n);\n    \n/* close listening socket */\n\n            \nstr_echo\n(\nconnfd\n);\n   \n/* process the request */\n\n            \nexit\n(\n0\n);\n\n        \n}\n\n        \nClose\n(\nconnfd\n);\n          \n/* parent closes connected socket */\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe purpose of this section has been to demonstrate three scenarios that we can encounter with network programming:\n\n\n\n\nWe must catch the \nSIGCHLD\n signal when forking child processes.\n\n\nWe must handle interrupted system calls when we catch signals.\n\n\nA \nSIGCHLD\n handler must be coded correctly using \nwaitpid\n to prevent any zombies from being left around.\n\n\n\n\nConnection Abort before \naccept\n Returns\n\n\nThere is another condition similar to the interrupted system call that can cause \naccept\n to return a nonfatal error, in which case we should just call \naccept\n again. The sequence of packets shown below has been seen on busy servers (typically busy Web servers), where the server receives an RST for an \nESTABLISHED\n connection before accept is called.\n\n\n\n\nThe three-way handshake completes, the connection is established, and then the client TCP sends an RST (reset). On the server side, the connection is queued by its TCP, waiting for the server process to call accept when the RST arrives. Sometime later, the server process calls accept.\n\n\nAn easy way to simulate this scenario is to start the server, have it call \nsocket\n, \nbind\n, and \nlisten\n, and then go to sleep for a short period of time before calling \naccept\n. While the server process is asleep, start the client and have it call \nsocket\n and \nconnect\n. As soon as \nconnect\n returns, set the \nSO_LINGER\n socket option to generate the RST and terminate.\n\n\nTermination of Server Process\n\n\nWe will now start our client/server and then kill the server child process, which simulates the crashing of the server process. We must be careful to distinguish between the crashing of the server \nprocess\n and the crashing of the server \nhost\n.\n\n\nThe following steps take place:\n\n\n\n\nWe start the server and client and type one line to the client to verify that all is okay. That line is echoed normally by the server child.\n\n\nWe find the process ID of the server child and \nkill\n it. As part of process termination, all open descriptors in the child are closed. This causes a FIN to be sent to the client, and the client TCP responds with an ACK. This is the first half of the TCP connection termination.\n\n\nThe \nSIGCHLD\n signal is sent to the server parent and handled correctly.\n\n\nNothing happens at the client. The client TCP receives the FIN from the server TCP and responds with an ACK, but the problem is that the client process is blocked in the call to \nfgets\n waiting for a line from the terminal.\n\n\n\n\nRunning \nnetstat\n at this point shows the state of the sockets.\n\n\nlinux % netstat -a | grep 9877\ntcp        0      0 *:9877               *:*                 LISTEN\ntcp        0      0 localhost:9877       localhost:43604     FIN_WAIT2\ntcp        1      0 localhost:43604      localhost:9877      CLOSE_WAIT\n\n\n\n\n\n\n\n\n\nWe can still type a line of input to the client. Here is what happens at the client starting from Step 1:\n\n\nlinux % tcpcli01 127.0.0.1  # start client\nhello               # the first line that we type\nhello               # is echoed correctly  we kill the server child on the server host\nanother line        # we then type a second line to the client\nstr_cli : server terminated prematurely\n\n\n\n\n\nWhen we type \"another line,\" \nstr_cli\n calls \nwriten\n and the client TCP sends the data to the server. This is allowed by TCP because the receipt of the FIN by the client TCP only indicates that the server process has closed its end of the connection and will not be sending any more data. The receipt of the FIN does not tell the client TCP that the server process has terminated (which in this case, it has).\n\n\nWhen the server TCP receives the data from the client, it responds with an RST since the process that had that socket open has terminated. We can verify that the RST was sent by watching the packets with \ntcpdump\n.\n\n\n\n\n\n\nThe client process will not see the RST because it calls \nreadline\n immediately after the call to writen and readline returns 0 (EOF) immediately because of the FIN that was received in Step 2. Our client is not expecting to receive an EOF at this point (\nstr_cli\n) so it quits with the error message \"server terminated prematurely.\"\n\n\n\n\nWhen the client terminates (by calling \nerr_quit\n in \nstr_cli\n), all its open descriptors are closed.\n\n\nIf the \nreadline\n happens before the RST is received (as shown in this example), the result is an unexpected EOF in the client.\n\n\nIf the RST arrives first, the result is an \nECONNRESET\n (\"Connection reset by peer\") error return from \nreadline\n.\n\n\n\n\n\n\n\n\nThe problem in this example is that the client is blocked in the call to \nfgets\n when the FIN arrives on the socket. The client is really working with two descriptors,the socket and the user input. Instead of blocking on input from only one of the two sources, it should block on input from either source. Indeed, this is one purpose of the \nselect\n and \npoll\n functions described in \nChapter 6\n.\n\n\nSIGPIPE\n Signal\n\n\nThe rules are:\n\n\n\n\nWhen a process writes to a socket that has received an RST, the \nSIGPIPE\n signal is sent to the process. The default action of this signal is to terminate the process, so the process must catch the signal to avoid being involuntarily terminated.\n\n\nIf the process either catches the signal and returns from the signal handler, or ignores the signal, the write operation returns \nEPIPE\n.\n\n\n\n\nWe can simulate this from the client by performing two writes to the server (which has sent FIN to the client) before reading anything back, with the first write eliciting the RST (causing the server to send an RST to the client). We must use two writes to obtain the signal, because the first write elicits the RST and the second write elicits the signal. It is okay to write to a socket that has received a FIN, but it is an error to write to a socket that has received an RST.\n\n\nWe modify our client as below:\n\n\ntcpcliserv/str_cli11.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nchar\n    \nsendline\n[\nMAXLINE\n],\n \nrecvline\n[\nMAXLINE\n];\n\n\n    \nwhile\n \n(\nFgets\n(\nsendline\n,\n \nMAXLINE\n,\n \nfp\n)\n \n!=\n \nNULL\n)\n \n{\n\n\n        \nWriten\n(\nsockfd\n,\n \nsendline\n,\n \n1\n);\n\n        \nsleep\n(\n1\n);\n\n        \nWriten\n(\nsockfd\n,\n \nsendline\n+\n1\n,\n \nstrlen\n(\nsendline\n)\n-\n1\n);\n\n\n        \nif\n \n(\nReadline\n(\nsockfd\n,\n \nrecvline\n,\n \nMAXLINE\n)\n \n==\n \n0\n)\n\n            \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n\n        \nFputs\n(\nrecvline\n,\n \nstdout\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe \nwriten\n is called two times. The intent is for the first \nwriten\n to elicit the RST and then for the second \nwriten\n to generate \nSIGPIPE\n.\n\n\nRun the program on the Linux host:\n\n\nlinux % tcpclill 127.0.0.1\n\n\nhi there       # we type this line\n\n\nhi there       # this is echoed by the server\n\n\n               # here we kill the server child\n\n\nbye            # then we type this line\n\n\nBroken pipe    # this is printed by the shell\n\n\n\n\n\n\nWe start the client, type in one line, see that line echoed correctly, and then terminate the server child on the server host. We then type another line (\"bye\") and the shell tells us the process died with a \nSIGPIPE\n signal.\n\n\nThe recommended way to handle \nSIGPIPE\n depends on what the application wants to do when this occurs:\n\n\n\n\nIf there is nothing special to do, then setting the signal disposition to \nSIG_IGN\n is easy, assuming that subsequent output operations will catch the error of \nEPIPE\n and terminate.\n\n\nIf special actions are needed when the signal occurs (writing to a log file perhaps), then the signal should be caught and any desired actions can be performed in the signal handler.\n\n\nIf multiple sockets are in use, the delivery of the signal will not tell us which socket encountered the error. If we need to know which \nwrite\n caused the error, then we must either ignore the signal or return from the signal handler and handle \nEPIPE\n from the \nwrite\n.\n\n\n\n\nCrashing of Server Host\n\n\nTo simulate what happens when the server host crashes, we must run the client and server on different hosts. We then start the server, start the client, type in a line to the client to verify that the connection is up, disconnect the server host from the network, and type in another line at the client. This also covers the scenario of the server host being unreachable when the client sends data (i.e., some intermediate router goes down \nafter the connection has been established\n).\n\n\nThe following steps take place:\n\n\n\n\nWhen the server host crashes (which means it is not shut down by an operator), nothing is sent out on the existing network connections.\n\n\nWe type a line of input to the client, it is written by \nwriten\n (\nstr_cli\n), and is sent by the client TCP as a data segment. The client then blocks in the call to \nreadline\n, waiting for the echoed reply.\n\n\nWith \ntcpdump\n, we will see the client TCP continually retransmitting the data segment, trying to receive an ACK from the server. Berkeley-derived implementations retransmit the data segment 12 times, waiting for around 9 minutes before giving up. When the client TCP finally gives up (assuming the server host has not been rebooted during this time, or the server host is still unreachable), an error is returned to the client process's \nreadline\n. The error can be one of the following:\n\n\nIf the server host crashed and there were no responses at all to the client's data segments, the error is \nETIMEDOUT\n.\n\n\nIf some intermediate router determined that the server host was unreachable and responded with an ICMP \"destination unreachable\" message, the error is either \nEHOSTUNREACH\n or \nENETUNREACH\n.\n\n\n\n\n\n\n\n\nTo detect that the peer is down or unreachable quicker than 9 minutes, we can place a timeout on the call to \nreadline\n, which is discussed in \nChapter 14\n.\n\n\nThis example detects that the server host has crashed only when we send data to that host. If we want to detect the crashing of the server host even if we are not actively sending it data, another technique is required: SO_KEEPALIVE socket option (\nChapter 7\n).\n\n\nCrashing and Rebooting of Server Host\n\n\nIn the following example, we will establish a connection between the client and server and then assume the server host crashes and reboots. The easiest way to simulate this is to establish the connection, disconnect the server from the network, shut down the server host and then reboot it, and then reconnect the server host to the network. We do not want the client to see the server host shut down.\n\n\nAs stated in the previous section, if the client is not actively sending data to the server when the server host crashes, the client is not aware that the server host has crashed. The following steps take place:\n\n\n\n\nWe start the server and then the client. We type a line to verify that the connection is established.\n\n\nThe server host crashes and reboots.\n\n\nWe type a line of input to the client, which is sent as a TCP data segment to the server host.\n\n\nWhen the server host reboots after crashing, its TCP loses all information about connections that existed before the crash. Therefore, the server TCP responds to the received data segment from the client with an RST.\n\n\nOur client is blocked in the call to \nreadline\n when the RST is received, causing \nreadline\n to return the error \nECONNRESET\n.\n\n\n\n\nIf it is important for our client to detect the crashing of the server host, even if the client is not actively sending data, then some other technique, such as the \nSO_KEEPALIVE\n socket option or some client/server heartbeat function, is required.\n\n\nShutdown of Server Host\n\n\nThis section discusses what happens if the server host is shut down by an operator while our server process is running on that host.\n\n\nWhen a Unix system is shut down, the following steps happen:\n\n\n\n\nThe \ninit\n process normally sends the \nSIGTERM\n signal to all processes (we can catch this signal).\n\n\nThe \ninit\n waits some fixed amount of time (often between 5 and 20 seconds).\n\n\nThe \ninit\n sends the \nSIGKILL\n signal (which we cannot catch) to any processes still running.\n\n\n\n\nThis gives all running processes a short amount of time to clean up and terminate. When the process terminates, all open descriptors are closed (the sequence of steps are same to \nTermination of Server Process\n). We must use the \nselect\n or \npoll\n function in our client to have the client detect the termination of the server process as soon as it occurs.\n\n\nSummary of TCP Example\n\n\nBefore any TCP client and server can communicate with each other, each end must specify the socket pair for the connection: the local IP address, local port, foreign IP address, and foreign port. These four values are shown as bullets in the two figures below.\n\n\nClient's perspective\n\n\n\n\n\n\nconnect\n. The foreign IP address and foreign port must be specified by the client in the call to \nconnect\n. The two local values are normally chosen by the kernel as part of the \nconnect\n function.\n\n\nbind\n. The client has the option of specifying either or both of the local values, by \ncalling\n bind before \nconnect\n, but this is not common.\n\n\ngetsockname\n. The client can obtain the two local values chosen by the kernel by calling \ngetsockname\n after the connection is established.\n\n\n\n\nServer's perspective\n\n\n\n\n\n\nbind\n. The local port (the server's well-known port) is specified by \nbind\n. Normally, the server also specifies the wildcard IP address in this call.\n\n\ngetsockname\n. If the server binds the wildcard IP address on a multihomed host, it can determine the local IP address by calling \ngetsockname\n after the connection is established.\n\n\naccept.\n The two foreign values are returned to the server by \naccept\n.\n\n\ngetpeername\n. If another program is \nexec\ned by the server that calls \naccept\n, that program can call \ngetpeername\n to determine the client's IP address and port, if necessary.\n\n\n\n\nData Format\n\n\nNormally we must worry about the format of the data exchanged between the client and server.\n\n\nExample: Passing Text Strings between Client and Server\n\n\nWe modify our server so that it still reads a line of text from the client, but the server now expects that line to contain two integers separated by white space, and the server returns the sum of those two integers. All that changes is our \nstr_echo\n function:\n\n\ntcpcliserv/str_echo08.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_echo\n(\nint\n \nsockfd\n)\n\n\n{\n\n    \nlong\n        \narg1\n,\n \narg2\n;\n\n    \nssize_t\n     \nn\n;\n\n    \nchar\n        \nline\n[\nMAXLINE\n];\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n(\n \n(\nn\n \n=\n \nReadline\n(\nsockfd\n,\n \nline\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n\n            \nreturn\n;\n     \n/* connection closed by other end */\n\n\n        \nif\n \n(\nsscanf\n(\nline\n,\n \n%ld%ld\n,\n \narg1\n,\n \narg2\n)\n \n==\n \n2\n)\n\n            \nsnprintf\n(\nline\n,\n \nsizeof\n(\nline\n),\n \n%ld\n\\n\n,\n \narg1\n \n+\n \narg2\n);\n\n        \nelse\n\n            \nsnprintf\n(\nline\n,\n \nsizeof\n(\nline\n),\n \ninput error\n\\n\n);\n\n\n        \nn\n \n=\n \nstrlen\n(\nline\n);\n\n        \nWriten\n(\nsockfd\n,\n \nline\n,\n \nn\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWe call \nsscanf\n to convert the two arguments from text strings to long integers, and then snprintf is called to convert the result into a text string.\n\n\nThis modified client and server work fine, regardless of the byte ordering of the client and server hosts.\n\n\nExample: Passing Binary Structures between Client and Server\n\n\nWe now modify our client and server to pass binary values across the socket, instead of text strings. We will see that this does not work when the client and server are run on hosts with different byte orders, or on hosts that do not agree on the size of a long integer\n\n\nWe define one structure for the two arguments, another structure for the result, and place both definitions in our \nsum.h\n header. Below show the modified \nstr_cli\n function and \nstr_echo\n function.\n\n\ntcpcliserv/tcpcli09.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nsockfd\n;\n\n    \nstruct\n \nsockaddr_in\n  \nservaddr\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: tcpcli \nIPaddress\n);\n\n\n    \nsockfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_port\n \n=\n \nhtons\n(\nSERV_PORT\n);\n\n    \nInet_pton\n(\nAF_INET\n,\n \nargv\n[\n1\n],\n \nservaddr\n.\nsin_addr\n);\n\n\n    \nConnect\n(\nsockfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nstr_cli\n(\nstdin\n,\n \nsockfd\n);\n     \n/* do it all */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nsscanf\n converts the two arguments from text strings to binary, and we call \nwriten\n to send the structure to the server. We call \nreadn\n to read the reply, and print the result using \nprintf\n.\n\n\ntcpcliserv/str_echo09.c\n\n\n#include    \nunp.h\n\n\n#include    \nsum.h\n\n\n\nvoid\n\n\nstr_echo\n(\nint\n \nsockfd\n)\n\n\n{\n\n    \nssize_t\n         \nn\n;\n\n    \nstruct\n \nargs\n     \nargs\n;\n\n    \nstruct\n \nresult\n   \nresult\n;\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n(\n \n(\nn\n \n=\n \nReadn\n(\nsockfd\n,\n \nargs\n,\n \nsizeof\n(\nargs\n)))\n \n==\n \n0\n)\n\n            \nreturn\n;\n     \n/* connection closed by other end */\n\n\n        \nresult\n.\nsum\n \n=\n \nargs\n.\narg1\n \n+\n \nargs\n.\narg2\n;\n\n        \nWriten\n(\nsockfd\n,\n \nresult\n,\n \nsizeof\n(\nresult\n));\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWe read the arguments by calling \nreadn\n, calculate and store the sum, and call \nwriten\n to send back the result structure.\n\n\nIf we run the client and server on two machines of the same architecture, say two SPARC machines, everything works fine. But when the client and server are on two machines of different architectures (say the server is on the big-endian SPARC system freebsd and the client is on the little endian Intel system linux), it does not work.\n\n\nlinux % tcpcli09 206.168.112.96\n\n\n1 2        # we type this\n\n\n3          # and it works\n\n\n-22 -77    # then we type this\n\n\n-16777314  # and it does not work\n\n\n\n\n\n\nThe problem is that the two binary integers are sent across the socket in little-endian format by the client, but interpreted as big-endian integers by the server. It appears to work for positive integers but fails for negative integers. There are really three potential problems:\n\n\n\n\nDifferent implementations store binary numbers in different formats. The most common formats are big-endian and little-endian, as we described in Section 3.4.\n\n\nDifferent implementations can store the same C datatype differently. For example, most 32-bit Unix systems use 32 bits for a long but 64-bit systems typically use 64 bits for the same datatype. There is no guarantee that a \nshort\n, \nint\n, or \nlong\n is of any certain size.\n\n\nDifferent implementations pack structures differently, depending on the number of bits used for the various datatypes and the alignment restrictions of the machine. Therefore, it is never wise to send binary structures across a socket.\n\n\n\n\nThere are two common solutions to this data format problem:\n\n\n\n\nPass all numeric data as text strings.\n\n\nExplicitly define the binary formats of the supported datatypes (number of bits, big- or little-endian) and pass all data between the client and server in this format. RPC packages normally use this technique. RFC 1832 describes the External Data Representation (XDR) standard that is used with the Sun RPC package.\n\n\n\n\nSummary\n\n\n\n\nThe first problem was zombie children and we caught the \nSIGCHLD\n signal to handle this. Our signal handler then called \nwaitpid\n and  we must call this function instead of the older \nwait\n function, since Unix signals are not queued.\n\n\nThe next problem we encountered was the client not being notified when the server process terminated. We saw that our client's TCP was notified, but we did not receive that notification since we were blocked, waiting for user input. We will use the \nselect\n or \npoll\n function in \nChapter 6\n to handle this scenario, by waiting for any one of multiple descriptors to be ready, instead of blocking on a single descriptor.\n\n\nIf the server host crashes, we do not detect this until the client sends data to the server. Some applications must be made aware of this fact sooner; we will look at the \nSO_KEEPALIVE\n socket option in \nChapter 7\n.", 
            "title": "Chapter 5. TCP Client/Server Example"
        }, 
        {
            "location": "/unp/ch6/", 
            "text": "Chapter 6. I/O Multiplexing: The \nselect\n and \npoll\n Functions\n\n\nIntroduction\n\n\nWhen the TCP client is handling two inputs at the same time: standard input and a TCP socket, we encountered a problem when the client was blocked in a call to \nfgets\n (on standard input) and the server process was killed. The server TCP correctly sent a FIN to the client TCP, but since the client process was blocked reading from standard input, it never saw the EOF until it read from the socket (possibly much later).\n\n\nWe want to be notified if one or more I/O conditions are ready (i.e., input is ready to be read, or the descriptor is capable of taking more output). This capability is called \nI/O multiplexing\n and is provided by the \nselect\n and \npoll\n functions, as well as a newer POSIX variation of the former, called \npselect\n.\n\n\nI/O multiplexing is typically used in networking applications in the following scenarios:\n\n\n\n\nWhen a client is handling multiple descriptors (normally interactive input and a network socket)\n\n\nWhen a client to handle multiple sockets at the same time (this is possible, but rare)\n\n\nIf a TCP server handles both a listening socket and its connected sockets\n\n\nIf a server handles both TCP and UDP\n\n\nIf a server handles multiple services and perhaps multiple protocols\n\n\n\n\nI/O multiplexing is not limited to network programming. Many nontrivial applications find a need for these techniques.\n\n\nI/O Models\n\n\nWe first examine the basic differences in the five I/O models that are available to us under Unix:\n\n\n\n\nblocking I/O\n\n\nnonblocking I/O\n\n\nI/O multiplexing (\nselect\n and \npoll\n)\n\n\nsignal driven I/O (\nSIGIO\n)\n\n\nasynchronous I/O (the POSIX \naio_\n functions)\n\n\n\n\nThere are normally two distinct phases for an input operation:\n\n\n\n\nWaiting for the data to be ready. This involves waiting for data to arrive on the network. When the packet arrives, it is copied into a buffer within the kernel.\n\n\nCopying the data from the kernel to the process. This means copying the (ready) data from the kernel's buffer into our application buffer\n\n\n\n\nBlocking I/O Model\n\n\nThe most prevalent model for I/O is the blocking I/O model (which we have used for all our examples in the previous sections). By default, all sockets are blocking. The scenario is shown in the figure below:\n\n\n\n\nWe use UDP for this example instead of TCP because with UDP, the concept of data being \"ready\" to read is simple: either an entire datagram has been received or it has not. With TCP it gets more complicated, as additional variables such as the socket's low-water mark come into play.\n\n\nWe also refer to \nrecvfrom\n as a system call to differentiate between our application and the kernel, regardless of how \nrecvfrom\n is implemented (system call on BSD and function that invokes \ngetmsg\n system call on System V). There is normally a switch from running in the application to running in the kernel, followed at some time later by a return to the application.\n\n\nIn the figure above, the process calls \nrecvfrom\n and the system call does not return until the datagram arrives and is copied into our application buffer, or an error occurs. The most common error is the system call being interrupted by a signal, as we described in \nSection 5.9\n. We say that the process is blocked the entire time from when it calls \nrecvfrom\n until it returns. When \nrecvfrom\n returns successfully, our application processes the datagram.\n\n\nNonblocking I/O Model\n\n\nWhen a socket is set to be nonblocking, we are telling the kernel \"when an I/O operation that I request cannot be completed without putting the process to sleep, do not put the process to sleep, but return an error instead\". The figure is below:\n\n\n\n\n\n\nFor the first three \nrecvfrom\n, there is no data to return and the kernel immediately returns an error of \nEWOULDBLOCK\n.\n\n\nFor the fourth time we call recvfrom, a datagram is ready, it is copied into our application buffer, and \nrecvfrom\n returns successfully. We then process the data.\n\n\n\n\nWhen an application sits in a loop calling \nrecvfrom\n on a nonblocking descriptor like this, it is called \npolling\n. The application is continually polling the kernel to see if some operation is ready. This is often a waste of CPU time, but this model is occasionally encountered, normally on systems dedicated to one function.\n\n\nI/O Multiplexing Model\n\n\nWith \nI/O multiplexing\n, we call \nselect\n or \npoll\n and block in one of these two system calls, instead of blocking in the actual I/O system call. The figure is a summary of the I/O multiplexing model:\n\n\n\n\nWe block in a call to \nselect\n, waiting for the datagram socket to be readable. When \nselect\n returns that the socket is readable, we then call \nrecvfrom\n to copy the datagram into our application buffer.\n\n\nComparing to the blocking I/O model\n *\n\n\nComparing \nFigure 6.3\n to \nFigure 6.1\n:\n\n\n\n\nDisadvantage: using \nselect\n requires two system calls (\nselect\n and \nrecvfrom\n) instead of one\n\n\nAdvantage: we can wait for more than one descriptor to be ready (see \nthe \nselect\n function\n later in this chapter)\n\n\n\n\nMultithreading with blocking I/O\n *\n\n\nAnother closely related I/O model is to use multithreading with blocking I/O. That model very closely resembles the model described above, except that instead of using \nselect\n to block on multiple file descriptors, the program uses multiple threads (one per file descriptor), and each thread is then free to call blocking system calls like \nrecvfrom\n.\n\n\nSignal-Driven I/O Model\n\n\nThe \nsignal-driven I/O model\n uses signals, telling the kernel to notify us with the \nSIGIO\n signal when the descriptor is ready. The figure is below:\n\n\n\n\n\n\nWe first enable the socket for signal-driven I/O (\nSection 25.2\n) and install a signal handler using the \nsigaction\n system call. The return from this system call is immediate and our process continues; it is not blocked.\n\n\nWhen the datagram is ready to be read, the \nSIGIO\n signal is generated for our process. We can either:\n\n\nread the datagram from the signal handler by calling \nrecvfrom\n and then notify the main loop that the data is ready to be processed (\nSection 25.3\n)\n\n\nnotify the main loop and let it read the datagram.\n\n\n\n\n\n\n\n\nThe advantage to this model is that we are not blocked while waiting for the datagram to arrive. The main loop can continue executing and just wait to be notified by the signal handler that either the data is ready to process or the datagram is ready to be read.\n\n\nAsynchronous I/O Model\n\n\nAsynchronous I/O\n is defined by the POSIX specification, and various differences in the \nreal-time\n functions that appeared in the various standards which came together to form the current POSIX specification have been reconciled.\n\n\nThese functions work by telling the kernel to start the operation and to notify us when the entire operation (including the copy of the data from the kernel to our buffer) is complete. \nThe main difference between this model and the signal-driven I/O model is that with signal-driven I/O, the kernel tells us when an I/O operation can be initiated, but with asynchronous I/O, the kernel tells us when an I/O operation is complete.\n See the figure below for example:\n\n\n\n\n\n\n\n\nWe call \naio_read\n (the POSIX asynchronous I/O functions begin with \naio_\n or \nlio_\n) and pass the kernel the following:\n\n\n\n\ndescriptor, buffer pointer, buffer size (the same three arguments for \nread\n),\n\n\nfile offset (similar to \nlseek\n),\n\n\nand how to notify us when the entire operation is complete.\n\n\n\n\nThis system call returns immediately and our process is not blocked while waiting for the I/O to complete.\n\n\n\n\n\n\nWe assume in this example that we ask the kernel to generate some signal when the operation is complete. This signal is not generated until the data has been copied into our application buffer, which is different from the signal-driven I/O model.\n\n\n\n\n\n\nComparison of the I/O Models\n\n\nThe figure below is a comparison of the five different I/O models.\n\n\n\n\nThe main difference between the first four models is the first phase, as the second phase in the first four models is the same: the process is blocked in a call to \nrecvfrom\n while the data is copied from the kernel to the caller's buffer. Asynchronous I/O, however, handles both phases and is different from the first four.\n\n\nSynchronous I/O versus Asynchronous I/O\n\n\nPOSIX defines these two terms as follows:\n\n\n\n\nA synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes.\n\n\nAn asynchronous I/O operation does not cause the requesting process to be blocked.\n\n\n\n\nUsing these definitions, the first four I/O models (blocking, nonblocking, I/O multiplexing, and signal-driven I/O) are all synchronous because the actual I/O operation (\nrecvfrom\n) blocks the process. Only the asynchronous I/O model matches the asynchronous I/O definition.\n\n\nselect\n Function\n\n\nThe \nselect\n function allows the process to instruct the kernel to either:\n\n\n\n\nWait for any one of multiple events to occur and to wake up the process only when one or more of these events occurs, or\n\n\nWhen a specified amount of time has passed.\n\n\n\n\nThis means that we tell the kernel what descriptors we are interested in (for reading, writing, or an exception condition) and how long to wait. The descriptors in which we are interested are not restricted to sockets; any descriptor can be tested using \nselect\n.\n\n\n#include \nsys/select.h\n\n\n#include \nsys/time.h\n\n\n\nint\n \nselect\n(\nint\n \nmaxfdp1\n,\n \nfd_set\n \n*\nreadset\n,\n \nfd_set\n \n*\nwriteset\n,\n \nfd_set\n \n*\nexceptset\n,\n\n           \nconst\n \nstruct\n \ntimeval\n \n*\ntimeout\n);\n\n\n\n/* Returns: positive count of ready descriptors, 0 on timeout, \u20131 on error */\n\n\n\n\n\n\nThe \ntimeout\n argument\n *\n\n\nThe \ntimeout\n argument tells the kernel how long to wait for one of the specified descriptors to become ready. A \ntimeval\n structure specifies the number of seconds and microseconds.\n\n\nstruct\n \ntimeval\n  \n{\n\n  \nlong\n   \ntv_sec\n;\n          \n/* seconds */\n\n  \nlong\n   \ntv_usec\n;\n         \n/* microseconds */\n\n\n};\n\n\n\n\n\n\nThere are three possibilities for the \ntimeout\n:\n\n\n\n\nWait forever\n (\ntimeout\n is specified as a null pointer). Return only when one of the specified descriptors is ready for I/O.\n\n\nWait up to a fixed amount of time\n (\ntimeout\n points to a \ntimeval\n structure). Return when one of the specified descriptors is ready for I/O, but do not wait beyond the number of seconds and microseconds specified in the \ntimeval\n structure.\n\n\nDo not wait at all\n (\ntimeout\n points to a \ntimeval\n structure and the timer value is 0, i.e. the number of seconds and microseconds specified by the structure are 0). Return immediately after checking the descriptors. This is called \npolling\n.\n\n\n\n\nNote:\n\n\n\n\nThe wait in the first two scenarios is normally interrupted if the process catches a signal and returns from the signal handler. For portability, we must be prepared for \nselect\n to return an error of \nEINTR\n if we are catching signals. Berkeley-derived kernels never automatically restart \nselect\n.\n\n\nAlthough the \ntimeval\n structure has a microsecond field \ntv_usec\n, the actual resolution supported by the kernel is often more coarse. Many Unix kernels round the timeout value up to a multiple of 10 ms. There is also a scheduling latency involved, meaning it takes some time after the timer expires before the kernel schedules this process to run.\n\n\nOn some systems, the \ntimeval\n structure can represent values that are not supported by \nselect\n; it will fail with \nEINVAL\n if the \ntv_sec\n field in the timeout is over 100 million seconds.\n\n\nThe \nconst\n qualifier on the \ntimeout\n argument means it is not modified by \nselect\n on return.\n\n\n\n\nThe descriptor sets arguments\n *\n\n\nThe three middle arguments, \nreadset\n, \nwriteset\n, and \nexceptset\n, specify the descriptors that we want the kernel to test for reading, writing, and exception conditions. There are only two exception conditions currently supported:\n\n\n\n\nThe arrival of \nout-of-band data\n for a socket.\n\n\nThe presence of control status information to be read from the master side of a pseudo-terminal that has been put into packet mode. (Not covered in UNP)\n\n\n\n\nselect\n uses \ndescriptor sets\n, typically an array of integers, with each bit in each integer corresponding to a descriptor. For example, using 32-bit integers, the first element of the array corresponds to descriptors 0 through 31, the second element of the array corresponds to descriptors 32 through 63, and so on. All the implementation details are irrelevant to the application and are hidden in the \nfd_set\n datatype and the following four macros:\n\n\nvoid\n \nFD_ZERO\n(\nfd_set\n \n*\nfdset\n);\n         \n/* clear all bits in fdset */\n\n\nvoid\n \nFD_SET\n(\nint\n \nfd\n,\n \nfd_set\n \n*\nfdset\n);\n  \n/* turn on the bit for fd in fdset */\n\n\nvoid\n \nFD_CLR\n(\nint\n \nfd\n,\n \nfd_set\n \n*\nfdset\n);\n  \n/* turn off the bit for fd in fdset */\n\n\nint\n \nFD_ISSET\n(\nint\n \nfd\n,\n \nfd_set\n \n*\nfdset\n);\n \n/* is the bit for fd on in fdset ? */\n\n\n\n\n\n\nWe allocate a descriptor set of the \nfd_set\n datatype, we set and test the bits in the set using these macros, and we can also assign it to another descriptor set across an equals sign (=) in C.\n\n\nAn array of integers using one bit per descriptor, is just one possible way to implement \nselect\n. Nevertheless, it is common to refer to the individual descriptors within a descriptor set as bits, as in \"turn on the bit for the listening descriptor in the read set.\"\n\n\nThe following example defines a variable of type \nfd_set\n and then turn on the bits for descriptors 1, 4, and 5:\n\n\nfd_set\n \nrset\n;\n\n\n\nFD_ZERO\n(\nrset\n);\n          \n/* initialize the set: all bits off */\n\n\nFD_SET\n(\n1\n,\n \nrset\n);\n        \n/* turn on bit for fd 1 */\n\n\nFD_SET\n(\n4\n,\n \nrset\n);\n        \n/* turn on bit for fd 4 */\n\n\nFD_SET\n(\n5\n,\n \nrset\n);\n        \n/* turn on bit for fd 5 */\n\n\n\n\n\n\nIt is important to initialize the set, since unpredictable results can occur if the set is allocated as an automatic variable and not initialized.\n\n\nAny of the middle three arguments to \nselect\n, \nreadset\n, \nwriteset\n, or \nexceptset\n, can be specified as a null pointer if we are not interested in that condition. Indeed, if all three pointers are null, then we have a higher precision timer than the normal Unix \nsleep\n function. The \npoll\n function provides similar functionality.\n\n\nThe \nmaxfdp1\n argument\n *\n\n\nThe \nmaxfdp1\n argument specifies the number of descriptors to be tested. Its value is the maximum descriptor to be tested plus one. The descriptors 0, 1, 2, up through and including \nmaxfdp1\n\u20131 are tested.\n\n\nThe constant \nFD_SETSIZE\n, defined by including \nsys/select.h\n, is the number of descriptors in the \nfd_set\n datatype. Its value is often 1024, but few programs use that many descriptors.\n\n\nThe reason the \nmaxfdp1\n argument exists, along with the burden of calculating its value, is for efficiency. Although each \nfd_set\n has room for many descriptors, typically 1,024, this is much more than the number used by a typical process. The kernel gains efficiency by not copying unneeded portions of the descriptor set between the process and the kernel, and by not testing bits that are always 0.\n\n\nreadset\n, \nwriteset\n, and \nexceptset\n as value-result arguments\n *\n\n\nselect\n modifies the descriptor sets pointed to by the \nreadset\n, \nwriteset\n, and \nexceptset\n pointers. These three arguments are value-result arguments. When we call the function, we specify the values of the descriptors that we are interested in, and on return, the result indicates which descriptors are ready. We use the \nFD_ISSET\n macro on return to test a specific descriptor in an \nfd_set\n structure. Any descriptor that is not ready on return will have its corresponding bit cleared in the descriptor set. To handle this, we turn on all the bits in which we are interested in all the descriptor sets each time we call select.\n\n\nReturn value of \nselect\n *\n\n\nThe return value from this function indicates the total number of bits that are ready across all the descriptor sets. If the timer value expires before any of the descriptors are ready, a value of 0 is returned. A return value of \u20131 indicates an error (which can happen, for example, if the function is interrupted by a caught signal).\n\n\nConditions for a Ready Descriptor\n\n\nPrevious sections discusses waiting for a descriptor to become ready for I/O (reading or writing) or to have an exception condition pending on it (out-of-band data). The following discussion are specific about the conditions that cause select to return \"ready\" for sockets\n\n\n\n\nA socket is ready for reading\n if any of the following four conditions is true:\n\n\nThe number of bytes of data in the socket receive buffer is greater than or equal to the current size of the low-water mark for the socket receive buffer. A read operation on the socket will not block and will return a value greater than 0 (i.e., the data that is ready to be read). We can set this low-water mark using the \nSO_RCVLOWAT\n socket option. It defaults to 1 for TCP and UDP sockets.\n\n\nThe read half of the connection is closed (i.e., a TCP connection that has received a FIN). A read operation on the socket will not block and will return 0 (i.e., EOF).\n\n\nThe socket is a listening socket and the number of completed connections is nonzero.\n\n\nA socket error is pending. A read operation on the socket will not block and will return an error (\u20131) with \nerrno\n set to the specific error condition. These pending errors can also be fetched and cleared by calling \ngetsockopt\n and specifying the \nSO_ERROR\n socket option.\n\n\n\n\n\n\nA socket is ready for writing\n if any of the following four conditions is true:\n\n\nThe number of bytes of available space in the socket send buffer is greater than or equal to the current size of the low-water mark for the socket send buffer and either: (i) the socket is connected, or (ii) the socket does not require a connection (e.g., UDP). This means that if we set the socket to nonblocking (\nChapter 16\n), a write operation will not block and will return a positive value (e.g., the number of bytes accepted by the transport layer). We can set this low-water mark using the \nSO_SNDLOWAT\n socket option. This low-water mark normally defaults to 2048 for TCP and UDP sockets.\n\n\nThe write half of the connection is closed. A write operation on the socket will generate \nSIGPIPE\n (\nSection 5.12\n).\n\n\nA socket using a non-blocking connect has completed the connection, or the connect has failed.\n\n\nA socket error is pending. A write operation on the socket will not block and will return an error (\u20131) with \nerrno\n set to the specific error condition. These pending errors can also be fetched and cleared by calling getsockopt with the \nSO_ERROR\n socket option.\n\n\n\n\n\n\nA socket has an exception condition pending if there is out-of-band data for the socket or the socket is still at the out-of-band mark\n (\nChapter 24\n).\n\n\n\n\nWhen an error occurs on a socket, it is marked as both readable and writable by select.\n\n\nThe purpose of the receive and send low-water marks is to give the application control over how much data must be available for reading or how much space must be available for writing before select returns a readable or writable status. For example, if we know that our application has nothing productive to do unless at least 64 bytes of data are present, we can set the receive low-water mark to 64 to prevent select from waking us up if less than 64 bytes are ready for reading.\n\n\nAs long as the send low-water mark for a UDP socket is less than the send buffer size (which should always be the default relationship), the UDP socket is always writable, since a connection is not required.\n\n\nThe following table is the summary of conditions that cause a socket to be ready for select.\n\n\n\n\n\n\n\n\nCondition\n\n\nReadable?\n\n\nWritable?\n\n\nException\n\n\n\n\n\n\n\n\n\n\nData to read\n\n\nx\n\n\n\n\n\n\n\n\n\n\nRead half of the connection closed\n\n\nx\n\n\n\n\n\n\n\n\n\n\nNew connection ready for listening socket\n\n\nx\n\n\n\n\n\n\n\n\n\n\nSpace available for writing\n\n\n\n\nx\n\n\n\n\n\n\n\n\nWrite half of the connection closed\n\n\n\n\nx\n\n\n\n\n\n\n\n\nPending error\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nTCP out-of-band data\n\n\n\n\n\n\nx\n\n\n\n\n\n\n\n\nMaximum Number of Descriptors for \nselect\n\n\nMost applications do not use lots of descriptors. It is rare to find an application that uses hundreds of descriptors, but such applications do exist, and they often use \nselect\n to multiplex the descriptors.\n\n\nWhen \nselect\n was originally designed, the OS normally had an upper limit on the maximum number of descriptors per process (the 4.2BSD limit was 31), and select just used this same limit. But, current versions of Unix allow for a virtually unlimited number of descriptors per process (often limited only by the amount of memory and any administrative limits), which affects \nselect\n.\n\n\nMany implementations have declarations similar to the following, which are taken from the 4.4BSD \nsys/types.h\n header:\n\n\n/*\n\n\n * Select uses bitmasks of file descriptors in longs. These macros\n\n\n * manipulate such bit fields (the filesystem macros use chars).\n\n\n * FD_SETSIZE may be defined by the user, but the default here should\n\n\n * be enough for most uses.\n\n\n */\n\n\n#ifndef FD_SETSIZE\n\n\n#define FD_SETSIZE      256\n\n\n#endif\n\n\n\n\n\n\nThis makes us think that we can just \n#define FD_SETSIZE\n to some larger value before including this header to increase the size of the descriptor sets used by \nselect\n. Unfortunately, this normally does not work. The three descriptor sets are declared within the kernel and also uses the kernel's definition of \nFD_SETSIZE\n as the upper limit. The only way to increase the size of the descriptor sets is to increase the value of \nFD_SETSIZE\n and then recompile the kernel. Changing the value without recompiling the kernel is inadequate.\n\n\nSome vendors are changing their implementation of select to allow the process to define \nFD_SETSIZE\n to a larger value than the default. BSD/OS has changed the kernel implementation to allow larger descriptor sets, and it also provides four new \nFD_\nxxx\n macros to dynamically allocate and manipulate these larger sets. From a portability standpoint, however, beware of using large descriptor sets.\n\n\nstr_cli\n Function (Revisited)\n\n\nThe problem with earlier version of the \nstr_cli\n (\nSection 5.5\n) was that we could be blocked in the call to \nfgets\n when something happened on the socket. We can now rewrite our \nstr_cli\n function using \nselect\n so that:\n\n\n\n\nThe client process is notified as soon as the server process terminates.\n\n\nThe client process blocks in a call to \nselect\n waiting for either standard input or the socket to be readable.\n\n\n\n\nThe figure below shows the various conditions that are handled by our call to \nselect\n:\n\n\n\n\nThree conditions are handled with the socket:\n\n\n\n\nIf the peer TCP sends data, the socket becomes readable and \nread\n returns greater than 0 (the number of bytes of data).\n\n\nIf the peer TCP sends a FIN (the peer process terminates), the socket becomes readable and read returns 0 (EOF).\n\n\nIf the peer TCP sends an RST (the peer host has crashed and rebooted), the socket becomes readable, read returns \u20131, and \nerrno\n contains the specific error code.\n\n\n\n\nBelow is the source code for this new version.\n\n\nselect/strcliselect01.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nint\n         \nmaxfdp1\n;\n\n    \nfd_set\n      \nrset\n;\n\n    \nchar\n        \nsendline\n[\nMAXLINE\n],\n \nrecvline\n[\nMAXLINE\n];\n\n\n    \nFD_ZERO\n(\nrset\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nFD_SET\n(\nfileno\n(\nfp\n),\n \nrset\n);\n\n        \nFD_SET\n(\nsockfd\n,\n \nrset\n);\n\n        \nmaxfdp1\n \n=\n \nmax\n(\nfileno\n(\nfp\n),\n \nsockfd\n)\n \n+\n \n1\n;\n\n        \nSelect\n(\nmaxfdp1\n,\n \nrset\n,\n \nNULL\n,\n \nNULL\n,\n \nNULL\n);\n\n\n        \nif\n \n(\nFD_ISSET\n(\nsockfd\n,\n \nrset\n))\n \n{\n  \n/* socket is readable */\n\n            \nif\n \n(\nReadline\n(\nsockfd\n,\n \nrecvline\n,\n \nMAXLINE\n)\n \n==\n \n0\n)\n\n                \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n            \nFputs\n(\nrecvline\n,\n \nstdout\n);\n\n        \n}\n\n\n        \nif\n \n(\nFD_ISSET\n(\nfileno\n(\nfp\n),\n \nrset\n))\n \n{\n  \n/* input is readable */\n\n            \nif\n \n(\nFgets\n(\nsendline\n,\n \nMAXLINE\n,\n \nfp\n)\n \n==\n \nNULL\n)\n\n                \nreturn\n;\n     \n/* all done */\n\n            \nWriten\n(\nsockfd\n,\n \nsendline\n,\n \nstrlen\n(\nsendline\n));\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThis code does the following:\n\n\n\n\nCall \nselect\n.\n\n\nWe only need one descriptor set (\nrset\n) to check for readability. This set is initialized by \nFD_ZERO\n and then two bits are turned on using \nFD_SET\n: the bit corresponding to the standard I/O file pointer, \nfp\n, and the bit corresponding to the socket, \nsockfd\n. The function \nfileno\n converts a standard I/O file pointer into its corresponding descriptor, since \nselect\n (and \npoll\n) work only with descriptors.\n\n\nselect\n is called after calculating the maximum of the two descriptors. In the call, the write-set pointer and the exception-set pointer are both null pointers. The final argument (the time limit) is also a null pointer since we want the call to block until something is ready.\n\n\n\n\n\n\nHandle readable socket\n. On return from select, if the socket is readable, the echoed line is read with \nreadline\n and output by \nfputs\n.\n\n\nHandle readable input\n. If the standard input is readable, a line is read by \nfgets\n and written to the socket using \nwriten\n.\n\n\n\n\nInstead of the function flow being driven by the call to \nfgets\n, it is now driven by the call to \nselect\n.\n\n\nBatch Input and Buffering\n\n\nUnfortunately, our \nstr_cli\n function is still not correct. Our original version in \nSection 5.5\n operates in a stop-and-wait mode, which is fine for interactive use: It sends a line to the server and then waits for the reply. This amount of time is one RTT plus the server's processing time (which is close to 0 for a simple echo server). We can therefore estimate how long it will take for a given number of lines to be echoed if we know the RTT between the client and server. We can use \nping\n to measure RTTs.\n\n\nStop-and-wait mode *\n\n\nIf we consider the network between the client and server as a full-duplex pipe, with requests going from the client to the server and replies in the reverse direction, then the following figure shows our stop-and-wait mode:\n\n\n\n\nNote that this figure:\n\n\n\n\nAssumes that there is no server processing time and that the size of the request is the same as the reply\n\n\nShows show only the data packets, ignoring the TCP acknowledgments that are also going across the network\n\n\n\n\nA request is sent by the client at time 0 and we assume an RTT of 8 units of time. The reply sent at time 4 is received at time 7.\n\n\nThis stop-and-wait mode is fine for interactive input. The problem is: if we run our client in a batch mode, when we redirect the input and output, however, the resulting output file is always smaller than the input file (and they should be identical for an echo server).\n\n\nBatch mode *\n\n\nTo see what's happening, realize that in a batch mode, we can keep sending requests as fast as the network can accept them. The server processes them and sends back the replies at the same rate. This leads to the full pipe at time 7, as shown below:\n\n\n\n\nWe assume:\n\n\n\n\nAfter sending the first request, we immediately send another, and then another\n\n\nWe can keep sending requests as fast as the network can accept them, along with processing replies as fast as the network supplies them.\n\n\n\n\nAssume that the input file contains only nine lines. The last line is sent at time 8, as shown in the above figure. But we cannot close the connection after writing this request because there are still other requests and replies in the pipe. The cause of the problem is our handling of an EOF on input: The function returns to the \nmain\n function, which then terminates. But \nin a batch mode, an EOF on input does not imply that we have finished reading from the socket; there might still be requests on the way to the server, or replies on the way back from the server.\n\n\nThe solution is to close one-half of the TCP connection by sending a FIN to the server, telling it we have finished sending data, but leave the socket descriptor open for reading. This is done with the \nshutdown\n function, described in the next section.\n\n\nBuffering concerns *\n\n\nBuffering for performance as in \nstr_cli\n (\nSection 6.7\n) adds complexity to a network application.\n\n\nWhen several lines of input are available from the standard input. \nselect\n will cause the code (\nselect/strcliselect01.c#L24\n) to read the input using \nfgets\n, which will read the available lines into a buffer used by stdio. But, \nfgets\n only returns a single line and leaves any remaining data sitting in the stdio buffer. The following code (\nselect/strcliselect01.c#L26\n) writes that single line to the server and then \nselect\n is called again to wait for more work, even if there are additional lines to consume in the stdio buffer. The reason is that \nselect\n knows nothing of the buffers used by stdio;it will only show readability from the viewpoint of the \nread\n system call, not calls like \nfgets\n. Thus, mixing stdio and \nselect\n is considered very error-prone and should only be done with great care.\n\n\nThe same problem exists with \nreadline\n in this example (\nstr_cli\n function). Instead of data being hidden from \nselect\n in a stdio buffer, it is hidden in \nreadline\n's buffer. In \nSection 3.9\n we provided a function (\nlib/readline.c#L52\n) that gives visibility into \nreadline\n's buffer, so one possible solution is to modify our code to use that function before calling \nselect\n to see if data has already been read but not consumed. But again, the complexity grows out of hand quickly when we have to handle the case where the readline buffer contains a partial line (meaning we still need to read more) as well as when it contains one or more complete lines (which we can consume).\n\n\nWe will address these buffering concerns in the improved version of \nstr_cli\n shown in \nSection 6.7\n.\n\n\nshutdown\n Function\n\n\nThe normal way to terminate a network connection is to call the \nclose\n function. But, there are two limitations with \nclose\n that can be avoided with \nshutdown\n:\n\n\n\n\nclose\n decrements the descriptor's reference count and closes the socket only if the count reaches 0 (\nSection 4.8\n). With \nshutdown\n, we can initiate TCP's normal connection termination sequence (the four segments beginning with a FIN in \nFigure 2.5\n), regardless of the reference count.\n\n\nclose\n terminates both directions of data transfer, reading and writing. Since a TCP connection is full-duplex, there are times when we want to tell the other end that we have finished sending, even though that end might have more data to send us. This is the scenario we encountered in the previous section with batch input to our \nstr_cli\n function. The figure below shows the typical function calls in this scenario.\n\n\n\n\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nshutdown\n(\nint\n \nsockfd\n,\n \nint\n \nhowto\n);\n\n\n\n/* Returns: 0 if OK, \u20131 on error */\n\n\n\n\n\n\nThe action of the function depends on the value of the \nhowto\n argument:\n\n\n\n\nSHUT_RD\n: \nThe read half of the connection is closed.\n No more data can be received on the socket and any data currently in the socket receive buffer is discarded. The process can no longer issue any of the read functions on the socket. Any data received after this call for a TCP socket is acknowledged and then silently discarded.\n\n\nSHUT_WR\n: \nThe write half of the connection is closed.\n In the case of TCP, this is called a \nhalf-close\n. Any data currently in the socket send buffer will be sent, followed by TCP's normal connection termination sequence. As we mentioned earlier, this closing of the write half is done regardless of whether or not the socket descriptor's reference count is currently greater than 0. The process can no longer issue any of the write functions on the socket.\n\n\nSHUT_RDWR\n: \nThe read half and the write half of the connection are both closed.\n This is equivalent to calling \nshutdown\n twice: first with \nSHUT_RD\n and then with \nSHUT_WR\n.\n\n\n\n\nThe three \nSHUT_\nxxx\n names are defined by the POSIX specification. Typical values for the howto argument that you will encounter will be 0 (close the read half), 1 (close the write half), and 2 (close the read half and the write half).\n\n\nstr_cli\n Function (Revisited Again)\n\n\nThe following code is our revised and correct version of the \nstr_cli\n function that uses \nselect\n and \nshutdown\n. In the function, \nselect\n notifies us as soon as the server closes its end of the connection and \nshutdown\n lets us handle batch input correctly.\n\n\nselect/strcliselect02.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nint\n         \nmaxfdp1\n,\n \nstdineof\n;\n\n    \nfd_set\n      \nrset\n;\n\n    \nchar\n        \nbuf\n[\nMAXLINE\n];\n\n    \nint\n     \nn\n;\n\n\n    \nstdineof\n \n=\n \n0\n;\n\n    \nFD_ZERO\n(\nrset\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n(\nstdineof\n \n==\n \n0\n)\n\n            \nFD_SET\n(\nfileno\n(\nfp\n),\n \nrset\n);\n\n        \nFD_SET\n(\nsockfd\n,\n \nrset\n);\n\n        \nmaxfdp1\n \n=\n \nmax\n(\nfileno\n(\nfp\n),\n \nsockfd\n)\n \n+\n \n1\n;\n\n        \nSelect\n(\nmaxfdp1\n,\n \nrset\n,\n \nNULL\n,\n \nNULL\n,\n \nNULL\n);\n\n\n        \nif\n \n(\nFD_ISSET\n(\nsockfd\n,\n \nrset\n))\n \n{\n  \n/* socket is readable */\n\n            \nif\n \n(\n \n(\nn\n \n=\n \nRead\n(\nsockfd\n,\n \nbuf\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n \n{\n\n                \nif\n \n(\nstdineof\n \n==\n \n1\n)\n\n                    \nreturn\n;\n     \n/* normal termination */\n\n                \nelse\n\n                    \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n            \n}\n\n\n            \nWrite\n(\nfileno\n(\nstdout\n),\n \nbuf\n,\n \nn\n);\n\n        \n}\n\n\n        \nif\n \n(\nFD_ISSET\n(\nfileno\n(\nfp\n),\n \nrset\n))\n \n{\n  \n/* input is readable */\n\n            \nif\n \n(\n \n(\nn\n \n=\n \nRead\n(\nfileno\n(\nfp\n),\n \nbuf\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n \n{\n\n                \nstdineof\n \n=\n \n1\n;\n\n                \nShutdown\n(\nsockfd\n,\n \nSHUT_WR\n);\n  \n/* send FIN */\n\n                \nFD_CLR\n(\nfileno\n(\nfp\n),\n \nrset\n);\n\n                \ncontinue\n;\n\n            \n}\n\n\n            \nWriten\n(\nsockfd\n,\n \nbuf\n,\n \nn\n);\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nstdineof\n is a new flag that is initialized to 0. As long as this flag is 0, each time around the main loop, we \nselect\n on standard input for readability.\n\n\nNormal and premature termination.\n When we read the EOF on the socket, and:\n\n\nIf we have already encountered an EOF on standard input, this is normal termination and the function returns.\n\n\nIf we have not yet encountered an EOF on standard input, the server process has prematurely terminated. We now call \nread\n and \nwrite\n to operate on buffers instead of lines and allow select to work for us as expected.\n\n\n\n\n\n\nshutdown\n. When we encounter the EOF on standard input, our new flag, \nstdineof\n, is set and we call \nshutdown\n with a second argument of \nSHUT_WR\n to send the FIN. Here we also use buffers instead of lines, using \nread\n and \nwriten\n.\n\n\n\n\nTCP Echo Server (Revisited)\n\n\nWe now rewrite the TCP echo server (\nSection 5.2\n and \n5.3\n as a single process that uses \nselect\n to handle any number of clients, instead of \nfork\ning one child per client.\n\n\nBefore first client has established a connection *\n\n\nBefore the first client has established a connection, the server has a single listening descriptor.\n\n\n\n\nThe server maintains only a read descriptor set (\nrset\n), shown in the following figure. Assuming the server is started in the foreground, descriptors 0, 1, and 2 are set to standard input, output, and error, so the first available descriptor for the listening socket is 3.\n\n\nWe also show an array of integers named \nclient\n that contains the connected socket descriptor for each client. All elements in this array are initialized to \u20131.\n\n\n\n\n\n\nThe only nonzero entry in the descriptor set is the entry for the listening sockets and the first argument to \nselect\n will be 4.\n\n\nAfter first client establishes connection *\n\n\nWhen the first client establishes a connection with our server, the listening descriptor becomes readable and our server calls \naccept\n. The new connected descriptor returned by accept will be 4. The following figure shows this connection:\n\n\n\n\nThe server must remember the new connected socket in its \nclient\n array, and the connected socket must be added to the descriptor set. The updated data structures are shown in the figure below:\n\n\n\n\nAfter second client connection is established *\n\n\nSometime later a second client establishes a connection and we have the scenario shown below:\n\n\n\n\nThe new connected socket (which we assume is 5) must be remembered, giving the data structures shown below:\n\n\n\n\nAfter first client terminates its connection *\n\n\nNext, we assume the first client terminates its connection. The client TCP sends a FIN, which makes descriptor 4 in the server readable. When our server reads this connected socket, \nread\n returns 0. We then close this socket and update our data structures accordingly. The value of \nclient[0]\n is set to \u20131 and descriptor 4 in the descriptor set is set to 0. This is shown in the figure below. Notice that the value of \nmaxfd\n does not change.\n\n\n\n\nSummary of TCP echo server (revisited) *\n\n\n\n\nAs clients arrive, we record their connected socket descriptor in the first available entry in the client array (the first entry with a value of \u20131) and also add the connected socket to the read descriptor set.\n\n\nThe variable \nmaxi\n is the highest index in the client array that is currently in use and the variable \nmaxfd\n (plus one) is the current value of the first argument to select.\n\n\nThe only limit on the number of clients that this server can handle is the minimum of the two values \nFD_SETSIZE\n and the maximum number of descriptors allowed for this process by the kernel (\nSection 6.3\n).\n\n\n\n\ntcpcliserv/tcpservselect01.c\n\n\n/* include fig01 */\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \ni\n,\n \nmaxi\n,\n \nmaxfd\n,\n \nlistenfd\n,\n \nconnfd\n,\n \nsockfd\n;\n\n    \nint\n                 \nnready\n,\n \nclient\n[\nFD_SETSIZE\n];\n\n    \nssize_t\n             \nn\n;\n\n    \nfd_set\n              \nrset\n,\n \nallset\n;\n\n    \nchar\n                \nbuf\n[\nMAXLINE\n];\n\n    \nsocklen_t\n           \nclilen\n;\n\n    \nstruct\n \nsockaddr_in\n  \ncliaddr\n,\n \nservaddr\n;\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\nSERV_PORT\n);\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nmaxfd\n \n=\n \nlistenfd\n;\n           \n/* initialize */\n\n    \nmaxi\n \n=\n \n-\n1\n;\n                  \n/* index into client[] array */\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nFD_SETSIZE\n;\n \ni\n++\n)\n\n        \nclient\n[\ni\n]\n \n=\n \n-\n1\n;\n         \n/* -1 indicates available entry */\n\n    \nFD_ZERO\n(\nallset\n);\n\n    \nFD_SET\n(\nlistenfd\n,\n \nallset\n);\n\n\n/* end fig01 */\n\n\n\n/* include fig02 */\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nrset\n \n=\n \nallset\n;\n      \n/* structure assignment */\n\n        \nnready\n \n=\n \nSelect\n(\nmaxfd\n+\n1\n,\n \nrset\n,\n \nNULL\n,\n \nNULL\n,\n \nNULL\n);\n\n\n        \nif\n \n(\nFD_ISSET\n(\nlistenfd\n,\n \nrset\n))\n \n{\n    \n/* new client connection */\n\n            \nclilen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n            \nconnfd\n \n=\n \nAccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n);\n\n\n#ifdef  NOTDEF\n\n            \nprintf\n(\nnew client: %s, port %d\n\\n\n,\n\n                    \nInet_ntop\n(\nAF_INET\n,\n \ncliaddr\n.\nsin_addr\n,\n \n4\n,\n \nNULL\n),\n\n                    \nntohs\n(\ncliaddr\n.\nsin_port\n));\n\n\n#endif\n\n\n            \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nFD_SETSIZE\n;\n \ni\n++\n)\n\n                \nif\n \n(\nclient\n[\ni\n]\n \n \n0\n)\n \n{\n\n                    \nclient\n[\ni\n]\n \n=\n \nconnfd\n;\n \n/* save descriptor */\n\n                    \nbreak\n;\n\n                \n}\n\n            \nif\n \n(\ni\n \n==\n \nFD_SETSIZE\n)\n\n                \nerr_quit\n(\ntoo many clients\n);\n\n\n            \nFD_SET\n(\nconnfd\n,\n \nallset\n);\n    \n/* add new descriptor to set */\n\n            \nif\n \n(\nconnfd\n \n \nmaxfd\n)\n\n                \nmaxfd\n \n=\n \nconnfd\n;\n         \n/* for select */\n\n            \nif\n \n(\ni\n \n \nmaxi\n)\n\n                \nmaxi\n \n=\n \ni\n;\n               \n/* max index in client[] array */\n\n\n            \nif\n \n(\n--\nnready\n \n=\n \n0\n)\n\n                \ncontinue\n;\n               \n/* no more readable descriptors */\n\n        \n}\n\n\n        \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n=\n \nmaxi\n;\n \ni\n++\n)\n \n{\n   \n/* check all clients for data */\n\n            \nif\n \n(\n \n(\nsockfd\n \n=\n \nclient\n[\ni\n])\n \n \n0\n)\n\n                \ncontinue\n;\n\n            \nif\n \n(\nFD_ISSET\n(\nsockfd\n,\n \nrset\n))\n \n{\n\n                \nif\n \n(\n \n(\nn\n \n=\n \nRead\n(\nsockfd\n,\n \nbuf\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n \n{\n\n                        \n/* connection closed by client */\n\n                    \nClose\n(\nsockfd\n);\n\n                    \nFD_CLR\n(\nsockfd\n,\n \nallset\n);\n\n                    \nclient\n[\ni\n]\n \n=\n \n-\n1\n;\n\n                \n}\n \nelse\n\n                    \nWriten\n(\nsockfd\n,\n \nbuf\n,\n \nn\n);\n\n\n                \nif\n \n(\n--\nnready\n \n=\n \n0\n)\n\n                    \nbreak\n;\n              \n/* no more readable descriptors */\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n/* end fig02 */\n\n\n\n\n\n\nThe code does the following:\n\n\n\n\nCreate listening socket and initialize for \nselect\n.\n We create the listening socket using \nsocket\n, \nbind\n, and \nlisten\n and initialize our data structures assuming that the only descriptor that we will \nselect\n on initially is the listening socket.\n\n\nBlock in \nselect\n. \nselect\n waits for something to happen, which is one of the following:\n\n\nThe establishment of a new client connection.\n\n\nThe arrival of data on the existing connection.\n\n\nA FIN on the existing connection.\n\n\nA RST on the existing connection.\n\n\n\n\n\n\naccept\n new connections\n.\n\n\nIf the listening socket is readable, a new connection has been established.\n\n\nWe call \naccept\n and update our data structures accordingly. We use the first unused entry in the \nclient\n array to record the connected socket.\n\n\nThe number of ready descriptors is decremented, and if it is 0 (\ntcpcliserv/tcpservselect01.c#L62\n), we can avoid the next \nfor\n loop. This lets us use the return value from \nselect\n to avoid checking descriptors that are not ready.\n\n\n\n\n\n\nCheck existing connections\n.\n\n\nIn the second nested \nfor\n loop, a test is made for each existing client connection as to whether or not its descriptor is in the descriptor set returned by \nselect\n, and a line is read from the client and echoed back to the client. Otherwsie, if the client closes the connection, read returns 0 and we update our data structures accordingly.\n\n\nWe never decrement the value of \nmaxi\n, but we could check for this possibility each time a client closes its connection.\n\n\n\n\n\n\n\n\nThis server is more complicated than the earlier version (\nSection 5.2\n and \n5.3\n, but it avoids all the overhead of creating a new process for each client and it is a nice example of \nselect\n. Nevertheless, in \nSection 16.6\n, we will describe a problem with this server that is easily fixed by making the listening socket nonblocking and then checking for, and ignoring, a few errors from \naccept\n.\n\n\nDenial-of-Service Attacks\n\n\nThere is a problem with the server in the above example. If a malicious client connects to the server, sends one byte of data (other than a newline), and then goes to sleep. The server will call \nread\n, which will read the single byte of data from the client and then block in the next call to \nread\n, waiting for more data from this client. The server is then blocked (\"hung\") by this one client and will not service any other clients, until the malicious client either sends a newline or terminates.\n\n\nThe basic concept here is that when a server is handling multiple clients, the server can never block in a function call related to a single client. Doing so can hang the server and deny service to all other clients. This is called a \ndenial-of-service\n attack, which prevents the server from servicing other legitimate clients.\n\n\nPossible solutions are:\n\n\n\n\nUse nonblocking I/O (\nChapter 16\n)\n\n\nHave each client serviced by a separate thread of control (either spawn a process or a thread to service each client)\n\n\nPlace a timeout on the I/O operations\n\n\n\n\npselect\n Function\n\n\nThe \npselect\n function was invented by POSIX and is now supported by many of the Unix variants.\n\n\n#include \nsys/select.h\n\n\n#include \nsignal.h\n\n\n#include \ntime.h\n\n\n\nint\n \npselect\n \n(\nint\n \nmaxfdp1\n,\n \nfd_set\n \n*\nreadset\n,\n \nfd_set\n \n*\nwriteset\n,\n \nfd_set\n \n*\nexceptset\n,\n\n             \nconst\n \nstruct\n \ntimespec\n \n*\ntimeout\n,\n \nconst\n \nsigset_t\n \n*\nsigmask\n);\n\n\n\n/* Returns: count of ready descriptors, 0 on timeout, \u20131 on error */\n\n\n\n\n\n\npselect\n contains two changes from the normal \nselect\n function:\n\n\n\n\n\n\npselect\n uses the \ntimespec\n structure (another POSIX invention) instead of the \ntimeval\n structure. The \ntv_nsec\n member of the newer structure specifies nanoseconds, whereas the \ntv_usec\n member of the older structure specifies microseconds.\n\n\nstruct timespec {\n  time_t tv_sec;       /* seconds */\n  long   tv_nsec;      /* nanoseconds */\n};\n\n\n\n\n\n\n\n\n\npselect\n adds a sixth argument: a pointer to a signal mask. This allows the program to disable the delivery of certain signals, test some global variables that are set by the handlers for these now-disabled signals, and then call \npselect\n, telling it to reset the signal mask.\n\n\n\n\n\n\nWith regard to the second point, consider the following example (discussed on \nAPUE\n). Our program's signal handler for \nSIGINT\n just sets the global \nintr_flag\n and returns. If our process is blocked in a call to \nselect\n, the return from the signal handler causes the function to return with \nerrno\n set to \nEINTR\n. But when \nselect\n is called, the code looks like the following:\n\n\nif\n \n(\nintr_flag\n)\n\n    \nhandle_intr\n();\n       \n/* handle the signal */\n\n\n\n/* signals occurring in here are lost */\n\n\n\nif\n \n(\n \n(\nnready\n \n=\n \nselect\n(\n \n...\n \n))\n \n \n0\n)\n \n{\n\n    \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n \n{\n\n        \nif\n \n(\nintr_flag\n)\n\n            \nhandle_intr\n();\n\n    \n}\n\n    \n...\n\n\n}\n\n\n\n\n\n\nThe problem is that between the test of \nintr_flag\n and the call to \nselect\n, if the signal occurs, it will be lost if \nselect\n blocks forever.\n\n\nWith \npselect\n, we can now code this example reliably as:\n\n\nsigset_t\n \nnewmask\n,\n \noldmask\n,\n \nzeromask\n;\n\n\n\nsigemptyset\n(\nzeromask\n);\n\n\nsigemptyset\n(\nnewmask\n);\n\n\nsigaddset\n(\nnewmask\n,\n \nSIGINT\n);\n\n\n\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n);\n \n/* block SIGINT */\n\n\nif\n \n(\nintr_flag\n)\n\n    \nhandle_intr\n();\n     \n/* handle the signal */\n\n\nif\n \n(\n \n(\nnready\n \n=\n \npselect\n \n(\n \n...\n \n,\n \nzeromask\n))\n \n \n0\n)\n \n{\n\n    \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n  \n{\n\n        \nif\n \n(\nintr_flag\n)\n\n            \nhandle_intr\n \n();\n\n    \n}\n\n    \n...\n\n\n}\n\n\n\n\n\n\nBefore testing the \nintr_flag\n variable, we block \nSIGINT\n. When \npselect\n is called, it replaces the signal mask of the process with an empty set (i.e., \nzeromask\n) and then checks the descriptors, possibly going to \nsleep\n. But when \npselect\n returns, the signal mask of the process is reset to its value before \npselect\n was called (i.e., \nSIGINT\n is blocked).\n\n\npoll\n Function\n\n\npoll\n provides functionality that is similar to \nselect\n, but \npoll\n provides additional information when dealing with STREAMS devices.\n\n\n#include \npoll.h\n\n\n\nint\n \npoll\n \n(\nstruct\n \npollfd\n \n*\nfdarray\n,\n \nunsigned\n \nlong\n \nnfds\n,\n \nint\n \ntimeout\n);\n\n\n\n/* Returns: count of ready descriptors, 0 on timeout, \u20131 on error */\n\n\n\n\n\n\nArguments:\n\n\nThe first argument (\nfdarray\n) is a pointer to the first element of an array of structures. Each element is a \npollfd\n structure that specifies the conditions to be tested for a given descriptor, \nfd\n.\n\n\nstruct\n \npollfd\n \n{\n\n  \nint\n     \nfd\n;\n       \n/* descriptor to check */\n\n  \nshort\n   \nevents\n;\n   \n/* events of interest on fd */\n\n  \nshort\n   \nrevents\n;\n  \n/* events that occurred on fd */\n\n\n};\n\n\n\n\n\n\nThe conditions to be tested are specified by the \nevents\n member, and the function returns the status for that descriptor in the corresponding \nrevents\n member. This data structure (having two variables per descriptor, one a value and one a result) avoids value-result arguments (the middle three arguments for \nselect\n are value-result). Each of these two members is composed of one or more bits that specify a certain condition. The following figure shows the constants used to specify the \nevents\n flag and to test the \nrevents\n flag against.\n\n\n\n\nThe first four constants deal with input, the next three deal with output, and the final three deal with errors. The final three cannot be set in \nevents\n, but are always returned in \nrevents\n when the corresponding condition exists.\n\n\nWith regard to TCP and UDP sockets, the following conditions cause \npoll\n to return the specified \nrevent\n. Unfortunately, POSIX leaves many holes (optional ways to return the same condition) in its definition of \npoll\n.\n\n\n\n\nAll regular TCP data and all UDP data is considered normal.\n\n\nTCP's out-of-band data is considered priority band.\n\n\nWhen the read half of a TCP connection is closed (e.g., a FIN is received), this is also considered normal data and a subsequent read operation will return 0.\n\n\nThe presence of an error for a TCP connection can be considered either normal data or an error (\nPOLLERR\n). In either case, a subsequent \nread\n will return \u20131 with \nerrno\n set to the appropriate value. This handles conditions such as the receipt of an RST or a timeout.\n\n\nThe availability of a new connection on a listening socket can be considered either normal data or priority data. Most implementations consider this normal data.\n\n\nThe completion of a nonblocking \nconnect\n is considered to make a socket writable.\n\n\n\n\nThe number of elements in the array of structures is specified by the \nnfds\n argument.\n\n\nThe \ntimeout\n argument specifies how long the function is to wait before returning. A positive value specifies the number of milliseconds to wait. The constant \nINFTIM\n (wait forever) is defined to be a negative value.\n\n\nReturn values from \npoll\n:\n\n\n\n\n\u20131 if an error occurred\n\n\n0 if no descriptors are ready before the timer expires\n\n\nOtherwise, it is the number of descriptors that have a nonzero \nrevents\n member.\n\n\n\n\nIf we are no longer interested in a particular descriptor, we just set the \nfd\n member of the \npollfd\n structure to a negative value. Then the events member is ignored and the \nrevents\n member is set to 0 on return.\n\n\nTCP Echo Server (Revisited Again)\n\n\nThis section is discusses the TCP echo server from \nSection 6.8\n using \npoll\n instead of \nselect\n.\n\n\nIn the \nselect\n version we allocate a \nclient\n array along with a descriptor set named \nrset\n (\ntcpcliserv/tcpservselect01.c\n). With \npoll\n, we must allocate an array of \npollfd\n structures to maintain the client information instead of allocating another array. We handle the \nfd\n member of this array the same way we handled the \nclient\n array in the \nselection\n version: a value of \u20131 means the entry is not in use; otherwise, it is the descriptor value. Any entry in the array of \npollfd\n structures passed to \npoll\n with a negative value for the \nfd\n member is just ignored.\n\n\ntcpcliserv/tcpservpoll01.c\n\n\n/* include fig01 */\n\n\n#include    \nunp.h\n\n\n#include    \nlimits.h\n      \n/* for OPEN_MAX */\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \ni\n,\n \nmaxi\n,\n \nlistenfd\n,\n \nconnfd\n,\n \nsockfd\n;\n\n    \nint\n                 \nnready\n;\n\n    \nssize_t\n             \nn\n;\n\n    \nchar\n                \nbuf\n[\nMAXLINE\n];\n\n    \nsocklen_t\n           \nclilen\n;\n\n    \nstruct\n \npollfd\n       \nclient\n[\nOPEN_MAX\n];\n\n    \nstruct\n \nsockaddr_in\n  \ncliaddr\n,\n \nservaddr\n;\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\nSERV_PORT\n);\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nclient\n[\n0\n].\nfd\n \n=\n \nlistenfd\n;\n\n    \nclient\n[\n0\n].\nevents\n \n=\n \nPOLLRDNORM\n;\n\n    \nfor\n \n(\ni\n \n=\n \n1\n;\n \ni\n \n \nOPEN_MAX\n;\n \ni\n++\n)\n\n        \nclient\n[\ni\n].\nfd\n \n=\n \n-\n1\n;\n      \n/* -1 indicates available entry */\n\n    \nmaxi\n \n=\n \n0\n;\n                   \n/* max index into client[] array */\n\n\n/* end fig01 */\n\n\n\n/* include fig02 */\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nnready\n \n=\n \nPoll\n(\nclient\n,\n \nmaxi\n+\n1\n,\n \nINFTIM\n);\n\n\n        \nif\n \n(\nclient\n[\n0\n].\nrevents\n \n \nPOLLRDNORM\n)\n \n{\n   \n/* new client connection */\n\n            \nclilen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n            \nconnfd\n \n=\n \nAccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n);\n\n\n#ifdef  NOTDEF\n\n            \nprintf\n(\nnew client: %s\n\\n\n,\n \nSock_ntop\n((\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n));\n\n\n#endif\n\n\n            \nfor\n \n(\ni\n \n=\n \n1\n;\n \ni\n \n \nOPEN_MAX\n;\n \ni\n++\n)\n\n                \nif\n \n(\nclient\n[\ni\n].\nfd\n \n \n0\n)\n \n{\n\n                    \nclient\n[\ni\n].\nfd\n \n=\n \nconnfd\n;\n  \n/* save descriptor */\n\n                    \nbreak\n;\n\n                \n}\n\n            \nif\n \n(\ni\n \n==\n \nOPEN_MAX\n)\n\n                \nerr_quit\n(\ntoo many clients\n);\n\n\n            \nclient\n[\ni\n].\nevents\n \n=\n \nPOLLRDNORM\n;\n\n            \nif\n \n(\ni\n \n \nmaxi\n)\n\n                \nmaxi\n \n=\n \ni\n;\n               \n/* max index in client[] array */\n\n\n            \nif\n \n(\n--\nnready\n \n=\n \n0\n)\n\n                \ncontinue\n;\n               \n/* no more readable descriptors */\n\n        \n}\n\n\n        \nfor\n \n(\ni\n \n=\n \n1\n;\n \ni\n \n=\n \nmaxi\n;\n \ni\n++\n)\n \n{\n   \n/* check all clients for data */\n\n            \nif\n \n(\n \n(\nsockfd\n \n=\n \nclient\n[\ni\n].\nfd\n)\n \n \n0\n)\n\n                \ncontinue\n;\n\n            \nif\n \n(\nclient\n[\ni\n].\nrevents\n \n \n(\nPOLLRDNORM\n \n|\n \nPOLLERR\n))\n \n{\n\n                \nif\n \n(\n \n(\nn\n \n=\n \nread\n(\nsockfd\n,\n \nbuf\n,\n \nMAXLINE\n))\n \n \n0\n)\n \n{\n\n                    \nif\n \n(\nerrno\n \n==\n \nECONNRESET\n)\n \n{\n\n                            \n/* connection reset by client */\n\n\n#ifdef  NOTDEF\n\n                        \nprintf\n(\nclient[%d] aborted connection\n\\n\n,\n \ni\n);\n\n\n#endif\n\n                        \nClose\n(\nsockfd\n);\n\n                        \nclient\n[\ni\n].\nfd\n \n=\n \n-\n1\n;\n\n                    \n}\n \nelse\n\n                        \nerr_sys\n(\nread error\n);\n\n                \n}\n \nelse\n \nif\n \n(\nn\n \n==\n \n0\n)\n \n{\n\n                        \n/* connection closed by client */\n\n\n#ifdef  NOTDEF\n\n                    \nprintf\n(\nclient[%d] closed connection\n\\n\n,\n \ni\n);\n\n\n#endif\n\n                    \nClose\n(\nsockfd\n);\n\n                    \nclient\n[\ni\n].\nfd\n \n=\n \n-\n1\n;\n\n                \n}\n \nelse\n\n                    \nWriten\n(\nsockfd\n,\n \nbuf\n,\n \nn\n);\n\n\n                \nif\n \n(\n--\nnready\n \n=\n \n0\n)\n\n                    \nbreak\n;\n              \n/* no more readable descriptors */\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n/* end fig02 */\n\n\n\n\n\n\nThis code does the following:\n\n\n\n\nAllocate array of \npollfd\n structures.\n We declare \nOPEN_MAX\n elements in our array of \npollfd\n structures. Determining the maximum number of descriptors that a process can have open at any one time is difficult. One way is to call the POSIX sysconf function with an argument of \n_SC_OPEN_MAX\n (as described in APUE) and then dynamically allocate an array of the appropriate size.\n\n\nInitialize.\n We use the first entry in the \nclient\n array for the listening socket and set the descriptor for the remaining entries to \u20131. We also set the \nPOLLRDNORM\n event for this descriptor, to be notified by \npoll\n when a new connection is ready to be accepted. The variable \nmaxi\n contains the largest index of the \nclient\n array currently in use.\n\n\nCall \npoll\n, check for new connection.\n We call \npoll\n to wait for either a new connection or data on existing connection.\n\n\nWhen a new connection is accepted, we find the first available entry in the client array by looking for the first one with a negative descriptor.\n\n\nWe start the search with the index of 1, since \nclient[0]\n is used for the listening socket.\n\n\nWhen an available entry is found, we save the descriptor and set the \nPOLLRDNORM\n event.\n\n\n\n\n\n\nCheck for data on an existing connection.\n The two return events that we check for are \nPOLLRDNORM\n and \nPOLLERR\n. We did not set \nPOLLERR\n in the events member because it is always returned when the condition is true. The reason we check for \nPOLLERR\n is because some implementations return this event when an RST is received for a connection, while others just return \nPOLLRDNORM\n. In either case, we call \nread\n and if an error has occurred, it will return an error. When an existing connection is terminated by the client, we just set the \nfd\n member to \u20131.", 
            "title": "Chapter 6. I/O Multiplexing: The select and poll Functions"
        }, 
        {
            "location": "/unp/ch7/", 
            "text": "Chapter 7. Socket Options\n\n\nIntroduction\n\n\nThere are various ways to get and set the options that affect a socket:\n\n\n\n\nThe \ngetsockopt\n and \nsetsockopt\n functions.\n\n\nThe \nfcntl\n function, which is the POSIX way to set a socket for nonblocking I/O, signal-driven I/O, and to set the owner of a socket.\n\n\nThe \nioctl\n function.\n\n\n\n\ngetsockopt\n and \nsetsockopt\n Functions\n\n\nThese two functions apply only to sockets:\n\n\n#include \nsys/socket.h\n\n\n\nint\n \ngetsockopt\n(\nint\n \nsockfd\n,\n \nint\n \nlevel\n,\n \nint\n \noptname\n,\n \nvoid\n \n*\noptval\n,\n \nsocklen_t\n \n*\noptlen\n);\n\n\nint\n \nsetsockopt\n(\nint\n \nsockfd\n,\n \nint\n \nlevel\n,\n \nint\n \noptname\n,\n \nconst\n \nvoid\n \n*\noptval\n \nsocklen_t\n \noptlen\n);\n\n\n\n/* Both return: 0 if OK,\u20131 on error */\n\n\n\n\n\n\nArguments:\n\n\n\n\nsockfd\n must refer to an open socket descriptor.\n\n\nlevel\n specifies the code in the system that interprets the option: the general socket code or some protocol-specific code (e.g., IPv4, IPv6, TCP, or SCTP).\n\n\noptval\n is a pointer to a variable from which the new value of the option is fetched by \nsetsockopt\n, or into which the current value of the option is stored by \ngetsockopt\n. The size of this variable is specified by the final argument \noptlen\n, as a value for \nsetsockopt\n and as a value-result for \ngetsockopt\n.\n\n\n\n\nThe following table lists socket and IP-layer socket options for \ngetsockopt\n and \nsetsockopt\n.\n\n\n\n\nThe following table lists transport-layer socket options.\n\n\n\n\nThere are two basic types of options:\n\n\n\n\nFlags\n: binary options that enable or disable a certain feature (flags)\n\n\nValues\n: options that fetch and return specific values that we can either set or examine.\n\n\n\n\nThe column labeled \"Flag\" specifies a flag option:\n\n\n\n\ngetsockopt\n: \n*optval\n is an integer. The value returned in \n*optval\n is zero if the option is disabled, or nonzero if the option is enabled.\n\n\nsetsockopt\n: it requires a nonzero \n*optval\n to turn the option on, and a zero value to turn the option off.\n\n\n\n\nIf the \"Flag\" column does not contain a block dot, then the option is used to pass a value of the specified datatype between the user process and the system.\n\n\nChecking if an Option Is Supported and Obtaining the Default\n\n\nsockopt/checkopts.c\n\n\nSocket States\n\n\nThe following socket options are inherited by a connected TCP socket from the listening socket:\n\n\n\n\nSO_DEBUG\n\n\nSO_DONTROUTE\n\n\nSO_KEEPALIVE\n\n\nSO_LINGER\n\n\nSO_OOBINLINE\n\n\nSO_RCVBUF\n\n\nSO_RCVLOWAT\n\n\nSO_SNDBUF\n\n\nSO_SNDLOWAT\n\n\nTCP_MAXSEG\n\n\nTCP_NODELAY\n\n\n\n\nThis is important with TCP because the connected socket is not returned to a server by \naccept\n until the three-way handshake is completed by the TCP layer. \nTo ensure that one of these socket options is set for the connected socket when the three-way handshake completes, we must set that option for the listening socket.\n\n\nGeneric Socket Options\n\n\nGeneric socket options are protocol-independent (they are handled by the protocol-independent code within the kernel, not by one particular protocol module such as IPv4), but some of the options apply to only certain types of sockets. For example, even though the \nSO_BROADCAST\n socket option is called \"generic,\" it applies only to datagram sockets.\n\n\nIPv4 Socket Options\n\n\nSO_BROADCAST\n Socket Option\n\n\nThis option enables or disables the ability of the process to send broadcast messages. Broadcasting is supported for only datagram sockets and only on networks that support the concept of a broadcast message (e.g., Ethernet, token ring, etc.). You cannot broadcast on a point-to-point link or any connection-based transport protocol such as SCTP or TCP.\n\n\nSince an application must set this socket option before sending a broadcast datagram, it prevents a process from sending a broadcast when the application was never designed to broadcast. For example, a UDP application might take the destination IP address as a command-line argument, but the application never intended for a user to type in a broadcast address. Rather than forcing the application to try to determine if a given address is a broadcast address or not, the test is in the kernel: If the destination address is a broadcast address and this socket option is not set, \nEACCES\n is returned.\n\n\nSO_DEBUG\n Socket Option\n\n\nThis option is supported only by TCP. When enabled for a TCP socket, the kernel keeps track of detailed information about all the packets sent or received by TCP for the socket. These are kept in a \ncircular buffer\n within the kernel that can be examined with the \ntrpt\n program.\n\n\nSO_DONTROUTE\n Socket Option\n\n\nThis option specifies that outgoing packets are to bypass the normal routing mechanisms of the underlying protocol. The destination must be on a directly-connected network, and messages are directed to the appropriate network interface according to the destination address [\nUse of Options\n]. For example, with IPv4, the packet is directed to the appropriate local interface, as specified by the network and subnet portions of the destination address. If the local interface cannot be determined from the destination address (e.g., the destination is not on the other end of a point-to-point link, or is not on a shared network), \nENETUNREACH\n is returned.\n\n\nThe equivalent of this option can also be applied to individual datagrams using the \nMSG_DONTROUTE\n flag with the \nsend\n, \nsendto\n, or \nsendmsg\n functions.\n\n\nThis option is often used by routing daemons (e.g., \nrouted\n and \ngated\n) to bypass the routing table and force a packet to be sent out a particular interface.\n\n\nSO_ERROR\n Socket Option\n\n\nThis option is one that can be fetched but cannot be set.\n\n\nWhen an error occurs on a socket, the protocol module in a Berkeley-derived kernel sets a variable named \nso_error\n for that socket to one of the standard Unix \nE\nxxx values. This is called the \npending error\n for the socket. The process can be immediately notified of the error in one of two ways:\n\n\n\n\nIf the process is blocked in a call to \nselect\n on the socket (\nSection 6.3\n), for either readability or writability, \nselect\n returns with either or both conditions set.\n\n\nIf the process is using signal-driven I/O, the \nSIGIO\n signal is generated for either the process or the process group.\n\n\n\n\nThe process can then obtain the value of \nso_error\n by fetching the \nSO_ERROR\n socket option. The integer value returned by \ngetsockopt\n is the pending error for the socket. The value of \nso_error\n is then reset to 0 by the kernel.\n\n\n\n\nIf \nso_error\n is nonzero when the process calls \nread\n and there is no data to return, \nread\n returns \u20131 with \nerrno\n set to the value of \nso_error\n. The value of \nso_error\n is then reset to 0. If there is data queued for the socket, that data is returned by \nread\n instead of the error condition.\n\n\nIf \nso_error\n is nonzero when the process calls \nwrite\n, \u20131 is returned with \nerrno\n set to the value of \nso_error\n and \nso_error\n is reset to 0.\n\n\n\n\nSO_KEEPALIVE\n Socket Option\n\n\nWhen the keep-alive option is set for a TCP socket and no data has been exchanged across the socket in either direction for two hours, TCP automatically sends a \nkeep-alive probe\n to the peer. This probe is a TCP segment to which the peer must respond. One of three scenarios results:\n\n\n\n\nThe peer responds with the expected ACK. The application is not notified (since everything is okay). TCP will send another probe following another two hours of inactivity.\n\n\nThe peer responds with an RST, which tells the local TCP that the peer host has crashed and rebooted. The socket's pending error is set to \nECONNRESET\n and the socket is closed.\n\n\nThere is no response from the peer to the keep-alive probe. Berkeley-derived TCPs send 8 additional probes, 75 seconds apart, trying to elicit a response. TCP will give up if there is no response within 11 minutes and 15 seconds after sending the first probe.\n\n\n\n\nSO_LINGER\n Socket Option\n\n\nICMPv6 Socket Option\n\n\nIPv6 Socket Options\n\n\nTCP Socket Options", 
            "title": "Chapter 7. Socket Options"
        }, 
        {
            "location": "/tcpv1/", 
            "text": "TCPv1\n\n\n\n\nChapter 1. Introduction\n\n\nChapter 2. The Internet Address Architecture\n\n\nChapter 3. Link Layer\n\n\nChapter 4. ARP: Address Resolution Protocol\n\n\nChapter 5. The Internet Protocol (IP)\n\n\nChapter 6. System Configuration: DHCP and Autoconfiguration\n\n\nChapter 7. Firewalls and Network Address Translation (NAT)\n\n\nChapter 8. ICMPv4 and ICMPv6: Internet Control Message Protocol\n\n\nChapter 9. Broadcasting and Local Multicasting (IGMP and MLD)\n\n\nChapter 10. User Datagram Protocol (UDP) and IP Fragmentation\n\n\nChapter 11. Name Resolution and the Domain Name System (DNS)\n\n\nChapter 12. TCP: The Transmission Control Protocol (Preliminaries)\n\n\nChapter 13. TCP Connection Management\n\n\nChapter 14. TCP Timeout and Retransmission\n\n\nChapter 15. TCP Data Flow and Window Management\n\n\nChapter 16. TCP Congestion Control\n\n\nChapter 17. TCP Keepalive\n\n\nChapter 18. Security: EAP, IPsec, TLS, DNSSEC, and DKIM\n\n\nHeaders", 
            "title": "Contents"
        }, 
        {
            "location": "/tcpv1/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nSome terms [p1]:\n\n\n\n\nGateways\n: later called routers\n\n\nCatenet\n (\"concatenated\" network): obsolete term, later called internetwork\n\n\n\n\nThis chapter provides an overview of the Internet architecture and TCP/IP protocol suite.\n\n\nArchitectural Principles\n\n\nThe TCP/IP protocol suite is an open system which forms the basis for the Internet. We refer to World Wide Web (WWW) as an application that uses the Internet for communication (which is perhaps the most important Internet application) [p2-3]\n\n\nPackets, Connections, and Datagrams\n\n\nIn 1960s one of the most important concepts was \npacket switching\n, where \"chunks\" (packets) of digital information comprising some number of bytes are carried through the network somewhat independently. Chunks coming from different sources or senders can be mixed together and pulled apart later, which is called \nmultiplexing\n. The chunks can be moved around from one switch to another on their way to a destination, and the path might be subject to change. This has two potential advantages:\n\n\n\n\nThe network can be more resilient (against being physically attacked).\n\n\nThere can be better utilization of the network links and switches because of statistical multiplexing.\n\n\n\n\n[p4]\n\n\nConnection-oriented networks\n\n\nVirtual circuits\n (VCs) that behave like circuits but do not depend on physical circuit switches can be implemented atop connection-oriented packets. This is the basis for a protocol known as \nX.25\n that was popular until about the early 1990s when it was largely replaced with \nFrame Relay\n and ultimately \ndigital subscriber line\n (DSL) technology.\n\n\nThe VC abstraction and connection-oriented packet networks such as X.25 required \nstate\n to be stored in each switch for each connection. The reason is that each packet carries only a small bit of overhead information that provides an index into a state table. [p5] Such networks are consequently called \nconnection-oriented\n.\n\n\nConnectionless networks\n\n\nIn the late 1960s, another option was developed known as the datagram. A datagram is a special type of packet in which all the identifying information of the source and final destination resides inside the packet itself. Thus, a \nconnectionless network\n could be built.\n\n\nMessage boundaries\n\n\nMessage boundaries\n (or \nrecord markers\n) are related concepts. As shown in the figure below, when an application sends more than one chunk into the network, the fact that more than one chunk was written may or may not be preserved by the communication protocol. Most datagram protocols preserve message boundaries. This is natural because the datagram itself has a beginning and an end.  However, in a circuit or VC network, it is possible that an application may write several chunks of data, all of which are read together as one or more different-size chunks by a receiving application. These types of protocols do not preserve message boundaries. In cases where an underlying protocol fails to preserve message boundaries but they are needed by an application, the application must provide its own.\n\n\n\n\nIn this figure, applications write messages that are carried in protocols. A message boundary is the position or byte offset between one write and another.\n\n\n\n\nProtocols that preserve message boundaries\n (e.g., UDP) indicate the position of the sender\u2019s message boundaries at the receiver.\n\n\nProtocols that do not preserve message boundaries\n (e.g., streaming protocols like TCP) ignore this information and do not make it available to a receiver. As a result, applications may need to implement their own methods to indicate a sender\u2019s message boundaries if this capability is required.\n\n\n\n\nDesign and Implementation\n\n\nThe Architecture and Protocols of the TCP/IP Suite\n\n\nThe ARPANET Reference Model\n\n\nMultiplexing, Demultiplexing, and Encapsulation in TCP/IP\n\n\nPort Numbers\n\n\nPort numbers are 16-bit nonnegative integers (0\u201365535).\n\n\nNames, Addresses, and the DNS\n\n\nInternets, Intranets, and Extranets\n\n\nDesigning Applications\n\n\nClient/Server\n\n\nPeer-to-Peer\n\n\nApplication Programming Interfaces (APIs)\n\n\nStandardization Process\n\n\nThe group with which we will most often be concerned is the \nInternet Engineering Task Force\n (IETF). [p22]\n\n\nRequest for Comments (RFC)\n\n\nEvery official standard in the Internet community is published as a \nRequest for Comments\n (RFC).\n\n\nImplementations and Software Distributions\n\n\nThe historical de facto standard TCP/IP implementations were from the Computer Systems Research Group (CSRG) at the University of California, Berkeley. They were distributed with the 4.x BSD (Berkeley Software Distribution) system and with the BSD Networking Releases until the mid-1990s. This source code has been the starting point for many other implementations. [p24]\n\n\nIn this text, we tend to draw examples from the TCP/IP implementations in Linux, Windows, and sometimes FreeBSD and Mac OS (both of which are derived from historical BSD releases).\n\n\n\n\nAttacks Involving the Internet Architecture\n\n\nSpoofing *\n\n\nThe Internet architecture delivers IP datagrams based on destination IP addresses. As a result, malicious users are able to insert whatever IP address they choose into the source IP address field of each IP datagram they send, an activity called \nspoofing\n. The resulting datagrams are delivered to their destinations, but it is difficult to perform \nattribution\n. That is, it may be difficult or impossible to determine the origin of a datagram received from the Internet. [p25-26]\n\n\nDenial-of-service (DoS) *\n\n\n\n\nDenial-of-service (DoS)\n\n\nDistributed DoS (DDS)\n\n\n\n\nUnauthorized access\n\n\n\n\nBlack hats\n are programmers who intentionally develop malware and exploit systems for (illegal) profit or other malicious purposes are generally called .\n\n\nWhite Hats\n do the same sorts of technical things but notify vulnerable parties instead of exploit them.\n\n\n\n\nEncryption concerns\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np5-6 on message boundaries:\n\n\n\n\nProtocols that preserve message boundaries (e.g., UDP) indicate the position of the sender\u2019s message boundaries at the receiver. Protocols that do not preserve message boundaries (e.g., streaming protocols like TCP) ignore this information and do not make it available to a receiver.\n\n\n\n\nSome explanations:\n\n\n\n\nThe TCP Service Model\n in Chapter 12.\n\n\nTCP stream vs UDP message\n\n\nWhat is a message boundary?", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/tcpv1/ch2/", 
            "text": "Chapter 2. The Internet Address Architecture\n\n\nIntroduction\n\n\nThis chapter deals with the structure of network-layer addresses used in the Internet, the IP addresses. [p31-32]\n\n\n\n\nEvery device connected to the Internet has at least one IP address.\n\n\nWhen devices are attached to the global Internet, they are assigned addresses that must be coordinated so as to not duplicate other addresses in use on the network.\n\n\n\n\nExpressing IP Addresses\n\n\nIn IPv4, the dotted-quad notation for IPv4 addresses consists of four decimal numbers separated by periods. For example, 165.195.130.107. Each such number is a nonnegative integer in the range [0, 255] and represents one-quarter of the entire IP address. It is simply a way of writing the whole IPv4 address ( a 32-bit nonnegative integer used throughout the Internet system) using convenient decimal numbers. [p32]\n\n\nIn IPv6, addresses are 128 bits in length, four times larger than IPv4 addresses. The conventional notation for IPv6 addresses is a series of four hexadecimal (\"hex\" or base-16) numbers called \nblocks\n or \nfields\n separated by colons. For example, an IPv6 address containing eight blocks would be written as 5f05:2000:80ad:5800:0058:0800:2023:1d71. In addition, a number of agreed-upon simplifications have been standardized for expressing IPv6 addresses:\n\n\n\n\nLeading zeros of a block need not be written. In the preceding example, the address could have been written as 5f05:2000:80ad:5800:58:800:2023:1d71.\n\n\nBlocks of all zeros can be omitted and replaced by the notation ::.\n\n\nFor example, the IPv6 address 0:0:0:0:0:0:0:1 can be written more compactly as ::1.\n\n\nSimilarly, the address 2001:0db8:0:0:0:0:0:2 can be written more compactly as 2001:db8::2.\n\n\nTo avoid ambiguities, the :: notation may be used only once in an IPv6 address\n\n\n\n\n\n\nIPv4-mapped IPv6 address\n. The block immediately preceding the IPv4 portion of the address has the value ffff and the remaining part of the address is formatted using dotted-quad. For example, the IPv6 address ::ffff:10.0.0.1 represents the IPv4 address 10.0.0.1. This is called an \nIPv4-mapped IPv6 address\n.\n\n\nIPv4-compatible IPv6 address\n. The low-order 32 bits of the IPv6 address can be written using dotted-quad notation. The IPv6 address ::0102:f001 is therefore equivalent to the address ::1.2.240.1.\n\n\n\n\nThe colon delimiter in an IPv6 address may be confused with another separator such as the colon used between an IP address and a port number. In such circumstances, bracket characters, [ and ], are used to surround the IPv6 address. The following URL is an example:\n\n\nhttp://[2001:0db8:85a3:08d3:1319:8a2e:0370:7344]:443/\n\n\n\n\n\nThe flexibility provided by [RFC4291] resulted in unnecessary confusion due to the ability to represent the same IPv6 address in multiple ways. To remedy this situation, [RFC5952] imposes some rules to narrow the range of options while remaining compatible with [RFC4291]. They are as follows:\n\n\n\n\nLeading zeros must be suppressed (e.g., 2001:0db8::0022 becomes 2001:db8::22).\n\n\nThe :: construct must be used to its maximum possible effect (most zeros suppressed) but not for only 16-bit blocks. If multiple blocks contain equallength runs of zeros, the first is replaced with ::.\n\n\nThe hexadecimal digits a through f should be represented in lowercase.\n\n\n\n\nBasic IP Address Structure\n\n\nIPv4 has 2\n32\n possible addresses and IPv6 has 2\n128\n.\n\n\n\n\nMost of the IPv4 address space is \nunicast\n address space, which is IPv4 addresses chunks subdivided down to a single address and used to identify a single network interface of a computer attached to the Internet or to some private intranet.\n\n\nMost of the IPv6 address space is not currently being used.\n\n\n\n\nClassful Addressing\n\n\nSubnet Addressing\n\n\nSubnet Masks\n\n\nVariable-Length Subnet Masks (VLSM)\n\n\nBroadcast Addresses\n\n\nIPv6 Addresses and Interface Identifiers\n\n\nCIDR and Aggregation\n\n\nPrefixes\n\n\nAggregation\n\n\nSpecial-Use Addresses\n\n\nAddressing IPv4/IPv6 Translators\n\n\nMulticast Addresses\n\n\nIPv4 Multicast Addresses\n\n\nIPv6 Multicast Addresses\n\n\nAnycast Addresses\n\n\nAn \nanycast\n address is a unicast IPv4 or IPv6 address that identifies a different host depending on where in the network it is used. This is accomplished by configuring Internet routers to advertise the same unicast routes from multiple locations in the Internet. Thus, \nan anycast address refers not to a single host in the Internet, but to the \"most appropriate\" or \"closest\" single host that is responding to the anycast address.\n\n\nAnycast addressing is used most frequently for finding a computer that provides a common service. For example, a datagram sent to an anycast address could be used to find a DNS server (\nChapter 11\n), a 6to4 gateway that encapsulates IPv6 traffic in IPv4 tunnels, or RPs for multicast routing.\n\n\nAllocation\n\n\nUnicast\n\n\nMulticast\n\n\nUnicast Address Assignment\n\n\nSingle Provider/No Network/Single Address\n\n\nSingle Provider/Single Network/Single Address\n\n\nSingle Provider/Multiple Networks/Multiple Addresses\n\n\nMultiple Providers/Multiple Networks/Multiple Addresses (Multihoming)\n\n\nAttacks Involving IP Addresses", 
            "title": "Chapter 2. The Internet Address Architecture"
        }, 
        {
            "location": "/tcpv1/ch3/", 
            "text": "Chapter 3. Link Layer\n\n\nIntroduction\n\n\nThis chapter discusses the details involved in using the Ethernet and Wi-Fi link layers, how the Point-to-Point Protocol (PPP) is used, and how link-layer protocols can be carried inside other (link- or higher-layer) protocols, a technique known as tunneling.\n\n\nWhen referring to link-layer protocol data units (PDUs), we usually use the term \nframe\n, so as to distinguish the PDU format from those at higher layers such as packets or segments, terms used to describe network- and transport-layer PDUs, respectively.\n\n\nFrame formats usually support a variable-length frame size, the upper bound of which is called the \nmaximum transmission unit\n (MTU). Some network technologies, such as modems and serial lines, do not impose their own maximum frame size, so they can be configured by the user.\n\n\nEthernet and the IEEE 802 LAN/MAN Standards\n\n\n[p80]\n\n\nThe IEEE 802 LAN/MAN Standards\n\n\n[p82]\n\n\nThe Ethernet Frame Format\n\n\nThe figure below shows the current layout of an Ethernet frame and how it relates to a relatively new term introduced by IEEE, the \nIEEE packet\n.\n\n\n\n\n\n\nThe Ethernet frame begins with a \nPreamble\n area used by the receiving interface\u2019s circuitry to determine when a frame is arriving and to determine the amount of time between encoded bits (called \nclock recovery\n). Because Ethernet is an asynchronous LAN, the space between encoded bits may differ from one interface card from another.\n\n\n\n\nThis basic frame format includes 48-bit (6-byte) \nDestination\n (DST) and \nSource\n (SRC) Address fields. These addresses are sometimes known by other names such as:\n\n\n\n\nMAC address\n\n\nLink-layer address\n\n\n802 address\n\n\nHardware address\n\n\nPhysical address\n\n\n\n\nThe destination address in an Ethernet frame is also allowed to address more than one station (\"broadcast\" or \"multicast\"; see \nChapter 9\n). The broadcast capability is used by the ARP protocol (\nChapter 4\n) and multicast capability is used by the ICMPv6 protocol (\nChapter 8\n) to convert between network-layer and link-layer addresses.\n\n\n\n\n\n\nType\n field that doubles as a \nLength\n field. It identifies the type of data that follows the header. Popular values used with TCP/IP networks include:\n\n\n\n\nIPv4 (0x0800)\n\n\nIPv6 (0x86DD)\n\n\nARP (0x0806).\n\n\n\n\nThe value 0x8100 indicates a Q-tagged frame (i.e., one that can carry a \"virtual LAN\" or VLAN ID according to the 802.1q standard).\n\n\nThe size of a basic Ethernet frame is 1518 bytes\n, but the more recent standard extended this size to 2000 bytes.\n\n\n\n\n\n\nFull Duplex, Power Save, Autonegotiation, and 802.1X Flow Control\n\n\nBridges and Switches\n\n\nWireless LANs\u2014IEEE 802.11(Wi-Fi)\n\n\nPoint-to-Point Protocol (PPP)\n\n\nLoopback\n\n\nIn many cases clients want to communicate with servers on the same computer using Internet protocols such as TCP/IP. To enable this, most implementations support a network-layer \nloopback\n capability that typically takes the form of a \nvirtual loopback network interface\n. \nIt acts like a real network interface but is really a special piece of software provided by the operating system to enable TCP/IP and other communications on the same host computer.\n\n\nIPv4 addresses starting with 127 are reserved for this, as is the IPv6 address ::1 (\nChapter 2\n). Traditionally, UNIX-like systems including Linux assign the IPv4 address of 127.0.0.1 (::1 for IPv6) to the loopback interface and assign it the name localhost.\n\n\nAn IP datagram sent to the loopback interface must not appear on any network.\n Although we could imagine the transport layer detecting that the other end is a loopback address and shortcircuiting some of the transport-layer logic and all of the network-layer logic, most implementations perform complete processing of the data in the transport layer and network layer and loop the IP datagram back up in the network stack only when the datagram leaves the bottom of the network layer. This can be useful for performance measurement, for example, because the amount of time required to execute the stack software can be measured without any hardware overheads. In Linux, the loopback interface is called \nlo\n.\n\n\nLinux% ifconfig lo\nlo Link encap:Local Loopback\n inet addr:127.0.0.1 Mask:255.0.0.0\n inet6 addr: ::1/128 Scope:Host\n UP LOOPBACK RUNNING MTU:16436 Metric:1\n RX packets:458511 errors:0 dropped:0 overruns:0 frame:0\n TX packets:458511 errors:0 dropped:0 overruns:0 carrier:0\n collisions:0 txqueuelen:0\n RX bytes:266049199 (253.7 MiB)\n TX bytes:266049199 (253.7 MiB)\n\n\n\n\n\nThis local loopback interface:\n\n\n\n\nThe IPv4 address is 127.0.0.1 and has a subnet mask of 255.0.0.0 (corresponding to class A network number 127 in classful addressing).\n\n\nThe IPv6 address ::1 has a 128-bit-long prefix, so it represents only a single address. The interface has an MTU of 16KB (this can be configured to a much larger size, up to 2GB).\n\n\n\n\nWe would not expect to see errors on the local loopback device, given that it never really sends packets on any network\n\n\nMTU and Path MTU\n\n\nFrom \nFigure 3-3\n, there is a limit on the frame's size available for carrying the PDUs of higher-layer protocols in link-layer networks. This usually limits the number of payload bytes to about 1500 for Ethernet and often the same amount for PPP in order to maintain compatibility with Ethernet.\n\n\nThis characteristic (the limit of frame's size to carry higher-layer PDUs) of the link layer is called the \nmaximum transmission unit\n (MTU). Most packet networks (like Ethernet) have a fixed upper limit:\n\n\n\n\nMost stream-type networks (serial links) have a configurable limit that is then used by framing protocols such as PPP.\n\n\nIf IP has a datagram to send, and the datagram is larger than the link layer\u2019s MTU, IP performs \nfragmentation\n, breaking the datagram up into smaller pieces (fragments), so that each fragment is smaller than the MTU.\n\n\n\n\nMTU on networks:\n\n\n\n\nWhen two hosts on the same network are communicating with each other, it is the MTU of the local link interconnecting them that has a direct effect on the size of datagrams.\n\n\nWhen two hosts communicate across multiple networks, each link can have a different MTU. The minimum MTU across the network path comprising all of the links is called the \npath MTU\n.\n\n\n\n\nThe path MTU between any two hosts need not be constant over time:\n\n\n\n\nIt depends on the path being used at any time, which can change if the routers or links in the network fail;\n\n\nPaths are often not \nsymmetric\n (the path from host A to B may not be the reverse of the path from B to A); hence the path MTU need not be the same in the two directions.\n\n\n\n\nPath MTU discovery\n (PMTUD) is used to determine the path MTU at a point in time (and is required of IPv6 implementations).\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np146 on loopback\n\n\n\n\nAn IP datagram sent to the loopback interface must not appear on any network. Although we could imagine the transport layer detecting that the other end is a loopback address and shortcircuiting some of the transport-layer logic and all of the network-layer logic, most implementations perform complete processing of the data in the transport layer and network layer and loop the IP datagram back up in the network stack only when the datagram leaves the bottom of the network layer.", 
            "title": "Chapter 3. Link Layer"
        }, 
        {
            "location": "/tcpv1/ch4/", 
            "text": "Chapter 4. ARP: Address Resolution Protocol", 
            "title": "Chapter 4. ARP: Address Resolution Protocol"
        }, 
        {
            "location": "/tcpv1/ch5/", 
            "text": "Chapter 5. The Internet Protocol (IP)\n\n\n\n\nIP is the workhorse protocol of the TCP/IP protocol suite.\n\nTCPv1\n\n\n\n\nIntroduction\n\n\nIP provides a best-effort, connectionless datagram delivery service. When something goes wrong, such as a router temporarily running out of buffers, IP simly throws away some data. Any required reliability must be provided by the upper layers (e.g. TCP). IPv4 and IPv6 both use this basic best-effort delivery model.\n\n\nThe term \nconnectionless\n means that IP does not maintain any connection state information about related datagrams within the network elements (within the routers):\n\n\n\n\nEach IP datagram is handled independently from all other others.\n\n\nDatagrams can be delivered out of order.\n\n\n\n\nThis chapter is on IPv4 and IPv6 header fields, and describes how IP forwarding works.\n\n\nIPv4 and IPv6 Headers\n\n\nIPv4 Header\n *\n\n\n\n\nIPv6 Header\n *\n\n\n\n\nSize and network byte order\n *\n\n\n\n\nThe normal size of the IPv4 header is 20 bytes, unless options are present (which is rare).\n\n\nThe IPv6 header is twice as large as the IPv4 Header but never has any options.\n It may have \nextension headers\n.\n\n\n\n\nIn our pictures of headers and datagrams, for a 32-bit value, \nthe most significant bit is numbered 0 at the left, and the least significant bit of a 32-bit value is numbered 31 on the right.\n The 4 bytes in a 32-bit value are transmitted in the following order: bits 0\u20137 first, then bits 8\u201315, then 16\u201323, and bits 24\u201331 last. This is called \nbig endian\n byte ordering, which is the byte ordering required for all binary integers in the TCP/IP headers as they traverse a network. It is also called \nnetwork byte order\n. Computer CPUs that store binary integers in little endian format must convert the header values into network byte order for transmission and back again for reception.\n\n\nIP Header Fields\n\n\n\n\nThe \nVersion\n field is the first field (only 4 bits or one nibble wide). It contains the version number of the IP datagram: 4 for IPv4 and 6 for IPv6.\n\n\nThis is the only field that IPv4 and IPv6 of which share the location. The two protocols are not directly interoperable, which means a host or router must handle either IPv4 or IPv6 (or both, called \ndual stack\n) separately.\n\n\n\n\n\n\nThe \nInternet Header Length (IHL)\n field is the number of 32-bit words in the IPv4 header, including any options.\n\n\nBecause this is also a 4-bit field, the IPv4 header is limited to a maximum of fifteen 32-bit words or 60 bytes.\n\n\nThe normal value of this field (when no options are present) is 5. There is no such field in IPv6 because the header length is fixed at 40 bytes.\n\n\n\n\n\n\nThe 8 bits following the header length (IPv4) are two fields used for special processing of the datagram when it is forwarded, in both IPv4 and IPv6:\n\n\nThe first 6 bits are the \nDifferentiated Services (DS)\n field.\n\n\nThe last 2 bits are the \nExplicit Congestion Notification (ECN)\n field or indicator bits.\n\n\n\n\n\n\n\n\nThe \nTotal Length\n field is the total length of the IPv4 datagram in bytes.\n\n\n\n\nUsing this field and the IHL field can indicate where the data portion of the datagram starts, and its length.\n\n\nBecause this is a 16-bit field, the maximum size of an IPv4 datagram (including header) is 65,535 bytes.\n\n\nThis field is required in the header because some lower-layer protocols that carry IPv4 datagrams do not (accurately) convey the size of encapsulated datagrams on their own. For example, Ethernet pads small frames to be a minimum length (64 bytes) and an IPv4 datagram (minimum 20 bytes) can be smaller than the minimum Ethernet payload size (46 bytes). Without the Total Length field, the IPv4 implementation would not know how much of a 46-byte Ethernet frame was really an IP datagram, as opposed to padding.\n\n\n\n\nAlthough it is possible to send a 65,535-byte IP datagram, most link layers (such as Ethernet) are not able to carry one this large without fragmenting it into smaller pieces.\n\n\n\n\nIn IPv4, a host is not required to be able to receive an IPv4 datagram larger than 576 bytes.\n\n\nIn IPv6 a host must be able to process a datagram at least as large as the MTU of the link to which it is attached, and the minimum link MTU is 1280 bytes.\n\n\n\n\nMany applications that use the UDP protocol (\nChapter 10\n) for data transport (e.g., DNS, DHCP, etc.) use a limited data size of 512 bytes to avoid the 576-byte IPv4 limit. TCP chooses its own datagram size based on additional information (\nChapter 15\n).\n\n\n\n\n\n\nWhen an IPv4 datagram is fragmented into multiple smaller fragments, each of which itself is an independent IP datagram, the Total Length field reflects the length of the particular fragment.\n\n\n\n\n\n\n\n\n\n\nThe \nPayload Length\n field is the length of the IPv6 datagram not including the length of the header; extension headers, however, are included in the Payload Length field. In IPv6, fragmentation is not supported by the header.\n\n\n\n\nThe 16-bit size of this field limits its maximum value to 65,535 (64KB), which applies to the payload length, not the entire datagram.\n\n\nIn addition, IPv6 supports a \njumbogram\n option that provides for the possibility (at least theoretically) of single packets with payloads as large as 4GB (4,294,967,295 bytes).\n\n\n\n\n\n\nThe \nIdentification\n field (IPv4) indentifies each datagram sent by an IPv4 host. To prevent confusion among fragments of a datagrams, the sending host normally increments an internal counter by 1 each time a datagram is sent (from one of its IP addresses) and copies the value of the counter into the IPv4 Identification field.\n\n\nThis field is most important for implementing fragmentation, along with the Flags and Fragment Offset fields.\n\n\nIn IPv6, this field shows up in the Fragmentation extension header,\n\n\n\n\n\n\nThe \nTime-to-Live\n field, or \nTTL\n, sets an upper limit on the number of routers through which a datagram can pass.\n\n\nThis field initialized by the sender to some value (64 is recommended, although 128 or 255 is not uncommon) and decremented by 1 by every router that forwards the datagram. \nWhen this field reaches 0, the datagram is thrown away, and the sender is notified with an ICMP message\n (\nChapter 8\n). This prevents packets from getting caught in the network forever should an unwanted routing loop occur.\n\n\nIn IPv6, the field has been renamed to its de facto use: \nHop Limit\n.\n\n\n\n\n\n\nThe \nProtocol\n field in the IPv4 header contains a number indicating the type of data found in the payload portion of the datagram. The most common values are 17 (for UDP) and 6 (for TCP).\n\n\nThis field provides a demultiplexing feature so that the IP protocol can be used to carry payloads of more than one protocol type. Although this field originally specified the transport-layer protocol the datagram is encapsulating, it now can identify the encapsulated protocol, which may or not be a transport protocol. Other encapsulations are possible, such as IPv4-in-IPv4 (value 4). The official list of the possible values of the Protocol field\nis given in the \nassigned numbers page\n.\n\n\n\n\n\n\nThe \nNext Header\n field in the IPv6 header generalizes the Protocol field from IPv4. It is used to indicate the type of header following the IPv6 header. This field may contain any values defined for the IPv4 Protocol field, or any of the values associated with the IPv6 extension headers.\n\n\nThe \nHeader Checksum\n field is calculated \nover the IPv4 header only\n, which means that \nthe payload of the IPv4 datagram (e.g., TCP or UDP data) is not checked for correctness by the IP protocol.\n To ensure the payload has been correctly delivered, other protocols must cover any important data that follows the header with their own data-integrity-checking mechanisms.\n\n\nAlmost all protocols encapsulated in IP (ICMP, IGMP, UDP, and TCP) have a checksum in their own headers to cover their header and data and also to cover certain parts of the IP header they deem important (a form of \"layering violation\").\n\n\nThe IPv6 header does not have any checksum field.\n\n\nThe algorithm used in computing a checksum (also used by most of the other Internet-related protocols) is sometimes known as the \nInternet checksum\n.\n\n\nWhen an IPv4 datagram passes through a router, its header checksum must change as a result of decrementing the TTL field.\n\n\n\n\n\n\nThe \nSource IP Address\n is the IP address of the datagram's sender and the \nDestination IP Address\n of where the datagram is destined. These are 32-bit values for IPv4 and 128-bit values for IPv6, and they usually identify a single interface on a computer, although multicast and broadcast addresses (\nChapter 2\n) violate this rule.\n\n\n\n\nThe Internet Checksum\n\n\nThe \nInternet checksum\n is a 16-bit mathematical sum used to determine, with reasonably high probability, whether a received message or portion of a message matches the one sent. the Internet checksum algorithm is not the same as the common \ncyclic redundancy check\n (CRC), which offers stronger protection.\n\n\nTo compute the IPv4 header checksum for an outgoing datagram, the value of the datagram\u2019s Checksum field is first set to 0. Then, the 16-bit one\u2019s complement sum of the header is calculated (the entire header is considered a sequence of 16-bit words). The 16-bit one\u2019s complement of this sum is then stored in the Checksum field to make the datagram ready for transmission.\n\n\nWhen an IPv4 datagram is received, a checksum is computed across the whole header, including the value of the Checksum field itself. Assuming there are no errors, the computed checksum value is always 0 (a one\u2019s complement of the value FFFF). \nThe value of the Checksum field in the packet can never be FFFF.\n If it were, the sum (prior to the final one\u2019s complement operation at the sender) would have to have been 0. No sum can ever be 0 using one\u2019s complement addition unless all the bytes are 0. (\nend-round carry\n)\n\n\nWhen the header is found to be bad (the computed checksum is nonzero), the IPv4 implementation discards the received datagram. No error message is generated. It is up to the higher layers to somehow detect the missing datagram and retransmit if necessary.\n\n\nMathematics of the Internet Checksum\n\n\nFor the mathematically inclined, the set of 16-bit hexadecimal values V = {0001, . . . , FFFF} and the one\u2019s complement sum operation + together form an \nAbelian group\n. The following properties are obeyed:\n\n\n\n\nFor any X,Y in V, (X + Y) is in V [closure]\n\n\nFor any X,Y,Z in V, X + (Y + Z) = (X + Y) + Z [associativity]\n\n\nFor any X in V, e + X = X + e = X where e = FFFF [identity]\n\n\nFor any X in V, there is an X\u2032 in V such that X + X\u2032 = e [inverse]\n\n\nFor any X,Y in V, (X + Y) = (Y + X) [commutativity]\n\n\n\n\nNote that in the set V and the group \nV,+\n, number 0000 deleted the from consideration. If we put the number 0000 in the set V, then \nV,+\n is not a group any longer. [p187-188]\n\n\nDS Field and ECN\n\n\nThe third and fourth fields of the IPv4 header (second and third fields of the IPv6 header) are the \nDifferentiated Services\n (called DS Field) and \nECN\n fields, formerly called the \nToS Byte\n or IPv6 \nTraffic Class\n.\n\n\nDifferentiated Services (called \nDiffServ\n) is a framework and set of standards aimed at supporting differentiated classes of service (beyond just best-effort) on the Internet. IP datagrams that are marked in certain ways may be forwarded differently (e.g., with higher priority) and can lead to increased or decreased queuing delay in the network and other special effects (possibly with associated special fees imposed by an ISP). [p188]\n\n\nThe Differentiated Services Code Point (DSCP) is a number (in the DS Field) that refers to a particular predefined arrangement of bits with agreed-upon meaning. Datagrams have a DSCP assigned to them when they are given to the network infrastructure that remains unmodified during delivery ,but policies (such as how many high-priority packets are allowed to be sent in a period of time) may cause a change in DSCP during delivery. [p188]\n\n\nThe pair of ECN bits marks a datagram with a \ncongestion indicator\n when passing through a router that has a significant amount of internally queued traffic. Both bits are set by persistently congested ECN-aware routers when forwarding packets. When a marked packet is received at the destination, some protocol (such as TCP) will notice that the packet is marked and indicate this fact back to the sender, which would then slow down, thereby easing congestion before a router is forced to drop traffic because of overload. This mechanism is one of several aimed at avoiding or dealing with network congestion.\n\n\n(Original uses for the ToS and Traffic Class skipped) [p188-189]\n\n\nThe 6-bit DS Field holds the DSCP, providing support for 64 distinct code points. The particular value of the DSCP, expressed as \nper-hop behavior\n (PHB), tells a router the forwarding treatment or special handling the datagram should receive. The default value for the DSCP is generally 0, which corresponds to routine, best-effort Internet traffic.\n\n\n\n\nAs indicated in the table below, the DSCP values are divided into three pools: standardized, experimental/local use (EXP/LU), and experimental/local use.\n\n\n\n\n\n\n\n\nPool\n\n\nCode Point Prefix\n\n\nPolicy\n\n\n\n\n\n\n\n\n\n\n1\n\n\nxxxxx0\n\n\nStandards\n\n\n\n\n\n\n2\n\n\nxxxx11\n\n\nEXP/LU\n\n\n\n\n\n\n3\n\n\nxxxx01\n\n\nEXP/LU(*)\n\n\n\n\n\n\n\n\nA router is to first segregate traffic into different classes. Traffic within a common class may have different drop probabilities, allowing the router to decide what traffic to drop first if it is forced to discard traffic.\n\n\n\n\nThe 3-bit class selector provides for eight defined code points (called the \nclass selector code points\n) that correspond to PHBs with a specified minimum set of features providing similar functionality to the earlier IP precedence capability. These are called \nclass selector compliant PHBs\n. Code points of the form xxx000 always map to such PHBs.\n\n\nThe \nAssured Forwarding\n (AF) group provides forwarding of IP packets in a fixed number of independent AF classes. Traffic from one class is forwarded separately from other classes. Within a traffic class, a datagram is assigned a \ndrop precedence\n. Datagrams of higher drop precedence in a class areare discarded with higher priority over those with lower drop precedence in the same class. Combining the traffic class and drop precedence, the name \nAFij\n corresponds to assured forwarding class \ni\n with drop precedence \nj\n.\n\n\nThe \nExpedited Forwarding\n (EF) service provides the appearance of an uncongested network (EF traffic should receive relatively low delay, jitter, and loss). This requires the rate of EF traffic going out of a router to be at least as large as the rate coming in. Consequently, EF traffic will only ever have to wait in a router queue behind other EF traffic.\n\n\n\n\nThe following table indicates the class selector DSCP values:\n\n\n\n\n\n\n\n\n\n\nName\n\n\nValue\n\n\nReference\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCS0\n\n\n000000\n\n\n[RFC2474]\n\n\nClass selector (best-effort/routine)\n\n\n\n\n\n\nCS1\n\n\n001000\n\n\n[RFC2474]\n\n\nClass selector (priority)\n\n\n\n\n\n\nCS2\n\n\n010000\n\n\n[RFC2474]\n\n\nClass selector (immediate)\n\n\n\n\n\n\nCS3\n\n\n011000\n\n\n[RFC2474]\n\n\nClass selector (flash)\n\n\n\n\n\n\nCS4\n\n\n100000\n\n\n[RFC2474]\n\n\nClass selector (flash override)\n\n\n\n\n\n\nCS5\n\n\n101000\n\n\n[RFC2474]\n\n\nClass selector (CRITIC/ECP)\n\n\n\n\n\n\nCS6\n\n\n110000\n\n\n[RFC2474]\n\n\nClass selector (internetwork control)\n\n\n\n\n\n\nCS7\n\n\n111000\n\n\n[RFC2474]\n\n\nClass selector (control)\n\n\n\n\n\n\nAF11\n\n\n001010\n\n\n[RFC2597]\n\n\nAssured Forwarding (class 1,dp 1)\n\n\n\n\n\n\nAF12\n\n\n001100\n\n\n[RFC2597]\n\n\nAssured Forwarding (1,2)\n\n\n\n\n\n\nAF13\n\n\n001110\n\n\n[RFC2597]\n\n\nAssured Forwarding (1,3)\n\n\n\n\n\n\nAF21\n\n\n010010\n\n\n[RFC2597]\n\n\nAssured Forwarding (2,1)\n\n\n\n\n\n\nAF22\n\n\n010100\n\n\n[RFC2597]\n\n\nAssured Forwarding (2,2)\n\n\n\n\n\n\nAF23\n\n\n010110\n\n\n[RFC2597]\n\n\nAssured Forwarding (2,3)\n\n\n\n\n\n\nAF31\n\n\n011010\n\n\n[RFC2597]\n\n\nAssured Forwarding (3,1)\n\n\n\n\n\n\nAF32\n\n\n011100\n\n\n[RFC2597]\n\n\nAssured Forwarding (3,2)\n\n\n\n\n\n\nAF33\n\n\n011110\n\n\n[RFC2597]\n\n\nAssured Forwarding (3,3)\n\n\n\n\n\n\nAF41\n\n\n100010\n\n\n[RFC2597]\n\n\nAssured Forwarding (4,1)\n\n\n\n\n\n\nAF42\n\n\n100100\n\n\n[RFC2597]\n\n\nAssured Forwarding (4,2)\n\n\n\n\n\n\nAF43\n\n\n100110\n\n\n[RFC2597]\n\n\nAssured Forwarding (4,3)\n\n\n\n\n\n\nEF PHB\n\n\n101110\n\n\n[RFC3246]\n\n\nExpedited Forwarding\n\n\n\n\n\n\nVOICE-ADMIT\n\n\n101100\n\n\n[RFC5865]\n\n\nCapacity-Admitted Traffic\n\n\n\n\n\n\n\n\n\n\nIP Options\n\n\nIP options may be selected on a per-datagram basis. Many of the options are no longer practical or desirable because of the limited size of the IPv4 header or concerns regarding security. With IPv6, most of the options have been removed or altered and are in the basic IPv6 header but are placed after the IPv6 header in one or more extension headers.\n\n\nAn IP router that receives a datagram containing options should perform special processing. In some cases IPv6 routers process extension headers, but many headers are designed to be processed only by end hosts. In some routers, datagrams with options or extensions are not forwarded as fast as ordinary datagrams.\n\n\nThe table shows most of the IPv4 options that have been standardized over the years.\n\n\n\n\nThe options area always ends on a 32-bit boundary. Pad bytes with a value of 0 are added if necessary. This ensures that the IPv4 header is always a multiple of 32 bits (as required by the IHL field). [p192]\n\n\nOptions are identified by an 8-bit option \nType\n field. This field is subdivided into three subfields: \nCopy\n (1 bit), \nClass\n (2 bits), and \nNumber\n (5 bits). Options 0 and 1 are a single byte long, and most others are variable in length. Variable options consist of 1 byte of type identifier, 1 byte of length, and the option itself.\n\n\nMost of the standardized options are rarely or never used in the Internet today. In addition, the options are primarily for diagnostic purposes and make the construction of firewalls more cumbersome and risky. Thus, IPv4 options are typically disallowed or stripped at the perimeter of enterprise networks by firewalls. (\nChapter 7\n)\n\n\nWithin enterprise networks, where the average path length is smaller and protection from malicious users may be less of a concern, options can still be useful. In addition, since the \nRouter Alert\n option is designed primarily as a performance optimization and does not change fundamental router behavior, it is permitted more often than the other options. Some router implementations have a highly optimized internal pathway for forwarding IP traffic containing no options. The Router Alert option informs routers that a packet requires processing beyond the conventional forwarding algorithms. The experimental \nQuick-Start\n option at the end of the table is applicable to both IPv4 and IPv6.\n\n\nIPv6 Extension Headers\n\n\nIn IPv6, special functions such as those provided by options in IPv4 can be enabled by adding extension headers that follow the IPv6 header. IPv6 header is fixed at 40 bytes, and extension headers are added only when needed. [p194]\n\n\nIn choosing the IPv6 header to be of a fixed size, and requiring that extension headers be processed only by end hosts (with one exception), design and construction of high-performance routers are easier because the demands on packet processing at routers can be simpler than with IPv4.\n\n\nExtension headers, along with headers of higher-layer protocols such as TCP or UDP, are chained together with the IPv6 header to form a cascade of headers (see the figure below). The \nNext Header\n field in each header indicates the type of the subsequent header, which could be an IPv6 extension header or some other type.  The value of 59 indicates the end of the header chain. The most possible values for the Next Header field are provided in the following table.\n\n\n\n\nThis figure shows IPv6 headers form a chain using the Next Header field. Headers in the chain may be IPv6 extension headers or transport headers. The IPv6 header appears at the beginning of the datagram and is always 40 bytes long.\n\n\n\n\nThis table show values for the IPv6 Next Header field may indicate extensions or headers for other protocols. The same values are used with the IPv4 Protocol field, where appropriate. The IPv6 extension header mechanism distinguishes some functions (e.g., routing and fragmentation) from options.\n\n\n\n\nThe order of the extension headers is given as a recommendation, except for the location of the \nHop-by-Hop Options\n (HOPOPT)), which is mandatory, so an IPv6 implementation must be prepared to process extension headers in the order in which they are received.\n\n\nOnly the \nDestination Options\n header can be used twice: the first time for options pertaining to the destination IPv6 address contained in the IPv6 header and the second time (position 8) for options pertaining to the final destination of the datagram.\n\n\nIn some cases (e.g., when the \nRouting header\n is used), the \nDestination IP Address\n field in the IPv6 header changes as the datagram is forwarded to its ultimate destination.\n\n\n\n\nIPv6 Options\n\n\nIPv6 options, if present, are grouped into either of the following:\n\n\n\n\nHop-by-Hop Options\n: relevant to every router along a datagram\u2019s path\n\n\nDestination Options\n: relevant only to the recipient\n\n\n\n\nHopby-Hop Options (called HOPOPTs) are the only ones that need to be processed by every router a packet encounters.  The format for encoding options within the Hop-by-Hop and Destination Options extension headers is common.\n\n\nThe Hop-by-Hop and Destination Options headers are capable of holding more than one option. Each of these options is encoded as \ntype-length-value\n (TLV) sets, as shown below:\n\n\n\n\nIn the TLV sets, the first byte gives the option type, including subfields indicating how an IPv6 node should behave if the option is not recognized, and whether the option data might change as the datagram is forwarded. The \nOpt Data Len\n field gives the size of the option data in bytes.\n\n\nThe 2 high-order bits in an IPv6 TLV option type indicate whether an IPv6 node should forward or drop the datagram if the option is not recognized, and whether a message indicating the datagram\u2019s fate should be sent back to the sender, as shown in the table below:\n\n\n\n\nOptions in IPv6 are carried in either Hop-by-Hop (H) or Destination (D) Options extension headers. The option Type field contains the value from the \"Type\" column with the Action and Change subfields denoted in binary. The \"Length\" column contains the value of the Opt Data Len byte. See the table below:\n\n\n\n\n[p196-197]\n\n\nPad1 and PadN\n\n\nIPv6 options are aligned to 8-byte offsets, so options that are naturally smaller are padded with 0 bytes to round out their lengths to the nearest 8 bytes. [p197]\n\n\nIPv6 Jumbo Payload\n\n\nIn some TCP/IP networks, such as those used to interconnect supercomputers, the normal 64KB limit on the IP datagram size can lead to unwanted overhead when moving large amounts of data. The IPv6 \nJumbo Payload\n option specifies an IPv6 datagram with payload size larger than 65,535 bytes, called a \njumbogram\n. This option need not be implemented by nodes attached to links with MTU sizes below 64KB. The Jumbo Payload option provides a 32-bit field for holding the payload size for datagrams with payloads of sizes between 65,535 and 4,294,967,295 bytes (4 GB).\n\n\nWhen a jumbogram is formed for transmission, its normal Payload Length field is set to 0. The TCP protocol makes use of the Payload Length field in order to compute its checksum using the Internet checksum algorithm described previously. When the Jumbo Payload option is used, TCP must be careful to use the length value from the option instead of the regular Length field in the base header. [p198]\n\n\nTunnel Encapsulation Limit\n\n\nTunneling\n refers to the encapsulation of one protocol in another that does not conform to traditional layering. For example, IP datagrams may be encapsulated inside the payload portion of another IP datagram.\n\n\n\n\nTunneling can be used to form virtual \noverlay networks\n, in which one network (e.g., the Internet) acts as a well-connected link layer for another layer of IP.\n\n\nTunnels can be nested in the sense that datagrams that are in a tunnel may themselves be placed in a tunnel, in a recursive fashion.\n\n\n\n\nUsing Tunnel Encapsulation Limit option, a sender can specify a limit to have control over how many tunnel levels are ultimately used for encapsulation. Using this option.\n\n\nRouter Alert\n\n\nThe Router Alert option indicates that the datagram contains information that needs to be processed by a router. It is used for the same purpose as the IPv4 Router Alert option.\n\n\nQuick-Start\n\n\nThe Quick-Start (QS) option is used in conjunction with the experimental QuickStart procedure for TCP/IP specified in [RFC4782]. It is applicable to both IPv4 and IPv6 but at present is suggested only for private networks and not the global Internet. [p199]\n\n\nCALIPSO\n\n\nThis option is used for supporting the \nCommon Architecture Label IPv6 Security Option\n (CALIPSO) [RFC5570] in certain private networks.\n\n\nHome Address\n\n\nThis option holds the \"home\" address of the IPv6 node sending the datagram when IPv6 mobility options are in use. Mobile IP (\nSection 5.5\n) specifies a set of procedures for handling IP nodes that may change their point of network attachment without losing their higher-layer network connections. [p199]\n\n\nRouting Header\n\n\nThe IPv6 Routing header provides a mechanism for the sender of an IPv6 datagram to control the path the datagram takes through the network. Two different versions of the routing extension header have been specified: type 0 (RH0) and type 2 (RH2):\n\n\n\n\nRH0 has been deprecated because of security concerns [RFC5095]\n\n\nRH2 is defined in conjunction with Mobile IP.\n\n\n\n\nTo best understand the Routing header, we begin by discussing RH0 and then investigate why it has been deprecated and how it differs from RH2. RH0 specifies one or more IPv6 nodes to be \"visited\" as the datagram is forwarded.\n\n\n\n\nThe IPv6 Routing header shown below generalizes the loose Source and Record Route options from IPv4. RH0 allows the sender to specify a vector of IPv6 addresses for nodes to be visited. [p200-201]\n\n\n\n\nThe header contains an 8-bit \nRouting Type\n identifier and an 8-bit \nSegments Left\n field.\n\n\nThe Routing Type identifier for IPv6 addresses is 0 for RH0 and 2 for RH2.\n\n\nThe Segments Left field indicates how many route segments remain to be processed. (The number of explicitly listed intermediate nodes still to be visited before reaching the final destination.) [p201]\n\n\n\n\n\n\n\n\nA Routing header is not processed until it reaches the node whose address is contained in the \nDestination IP Address\n field of the IPv6 header. At this time, the Segments Left field is used to determine the next hop address from the address vector, and this address is swapped with the Destination IP Address field in the IPv6 header. Thus, as the datagram is forwarded, the Segments Left field grows smaller, and the list of addresses in the header reflects the node addresses that forwarded the datagram.\n\n\nThe forwarding procedure is shown in the below figure:\n\n\n\n\n\n\nThe sender (S) constructs the datagram with destination address R1 and a Routing header (type 0) containing the addresses R2, R3, and D. The final destination of the datagram is the last address in the list (D). The Segments Left field (labeled \"Left\") starts at 3.\n\n\nThe datagram is forwarded toward R1 automatically by S and R0 . Because R0's address is not present in the datagram, no modifications of the Routing header or addresses are performed by R0 .\n\n\nUpon reaching R1, the destination address from the base header is swapped with the first address listed in the Routing header and the Segments Left field is decremented.\n\n\nAs the datagram is forwarded, the process of swapping the destination address with the next address from the address list in the Routing header repeats until the last destination listed in the Routing header is reached.\n\n\n\n\nRH0 has been deprecated by [RFC5095] because of a security concern that allows RH0 to be used to increase the effectiveness of DoS attacks. \nThe problem is that RH0 allows the same address to be specified in multiple locations within the Routing header. This can lead to traffic being forwarded many times between two or more hosts or routers along a particular path.\n The potentially high traffic loads that can be created along particular paths in the network can cause disruption to other traffic flows competing for bandwidth across the same path. Consequently, RH0 has been deprecated and only RH2 remains as the sole Routing header supported by IPv6. RH2 is equivalent to RH0 except it has room for only a single address and uses a different value in the \nRouting Type\n field.\n\n\nFragment Header\n\n\nThe Fragment header is used by an IPv6 source when sending a datagram larger than the path MTU of the datagram\u2019s intended destination. (Path MTU and how it is determined are detailed in \nChapter 13\n). 1280 bytes is a network-wide link-layer minimum MTU for IPv6 [RFC2460].\n\n\n\n\nIn IPv4, any host or router can fragment a datagram if it is too large for the MTU on the next hop, and fields within the second 32-bit word of the IPv4 header indicate the fragmentation information.\n\n\nIn IPv6, only the sender of the datagram is permitted to perform fragmentation, and in such cases a Fragment header is added.\n\n\n\n\nThe Fragment header includes the same information as is found in the IPv4 header, but the Identification field is 32 bits instead of the 16 that are used for IPv4. The larger field provides the ability for more fragmented packets to be outstanding in the network simultaneously. The Fragment header uses the format shown in the figure below:\n\n\n\n\n\n\nThe \nReserved\n field and 2-bit Res field are both zero and ignored by receivers.\n\n\nThe \nFragment Offset\n field indicates where the data that follows the Fragment header is located, as a positive offset in 8-byte units, relative to the \"fragmentable part\" of the original IPv6 datagram.\n\n\n\n\nThe datagram serving as input to the fragmentation process is called the \"original packet\" and consists of two parts: the \"unfragmentable part\" and the \"fragmentable part\":\n\n\n\n\nThe \nunfragmentable part\n includes the IPv6 header and any included extension headers required to be processed by intermediate nodes to the destination, which includes:\n\n\nAll headers up to and including the Routing header, or,\n\n\nthe Hop-by-Hop Options extension header if only it is present.\n\n\n\n\n\n\nThe \nfragmentable part\n constitutes the remainder of the datagram, which includes:\n\n\nDestination Options header\n\n\nUpper-layer headers\n\n\nPayload data)\n\n\n\n\n\n\n\n\nWhen the original packet is fragmented, multiple fragment packets are produced, each of which contains a copy of the unfragmentable part of the original packet followed by the Fragment header. In each fragmented IPv6 packet:\n\n\n\n\nThe IPv6 header has the \nPayload Length\n field altered to reflect the size of the fragment packet it describes.\n\n\nFollowing the unfragmentable part, each new fragment packet contains a Fragment header with the following fields:\n\n\nAn appropriately assigned \nFragment Offset\n field (the first fragment contains offset 0)\n\n\nA copy of the original packet\u2019s \nIdentification\n field.\n\n\nThe last fragment has its \nM\n (\nMore Fragments\n) bit field set to 0.\n\n\n\n\n\n\n\n\nThe following example illustrates the way an IPv6 source might fragment a datagram:\n\n\n\n\nIn the figure above, a payload of 3960 bytes is fragmented such that no fragment\u2019s total packet size exceeds 1500 bytes (a typical MTU for Ethernet), yet the \nfragment data sizes still are arranged to be multiples of 8 bytes.\n [p204-205]\n\n\n\n\nA 3960-byte payload is split into three fragment packets of size 1448 bytes or less.\n\n\nThe Fragment header in each fragment contains a common Identification field\n\n\nAll but the last fragment have the More Fragments field (M) set to 1. The offset is given in 8-byte units\u2014the last fragment, for example, contains data beginning at offset (362 * 8) = 2896 bytes from the beginning of the original packet\u2019s data. The scheme is similar to fragmentation in IPv4.\n\n\nThe IPv6 header\u2019s Payload Length field is modified to reflect the size of the data and newly formed Fragment header.\n\n\n\n\nThe receiver must ensure that all fragments of an original datagram have been received before performing reassembly. As with fragmentation in IPv4 (\nChapter 10\n), fragments may arrive out of order at the receiver but are reassembled in order to form a datagram that is given to other protocols for processing.\n\n\n[p205-208]\n\n\n(Wireshark example skipped)\n\n\nIP Forwarding\n\n\nIP forwarding is simple, especially for a host:\n\n\n\n\nIf the destination is directly connected to the host (e.g., a point-to-point link) or on a shared network (e.g., Ethernet), the IP datagram is sent directly to the destination; a router is not required or used.\n\n\nOtherwise, the host sends the datagram to a single router (called the \ndefault\n router) and lets the router deliver the datagram to its destination.\n\n\n\n\nA host differs from a router in how IP datagrams are handled: a host never forwards datagrams it does not originate, whereas routers do.\n\n\nThe IP protocol can receive a datagram from either of the following:\n\n\n\n\nAnother protocol on the same machine (TCP, UDP, etc.),\n\n\nA network interface.\n\n\n\n\nThe IP layer has some information in memory, called a \nrouting table\n or \nforwarding table\n, which it searches each time it receives a datagram to send.\n\n\nWhen a datagram is received from a network interface, IP first checks if the destination IP address is one of its own IP addresses (one of the IP addresses associated with one of its network interfaces) or some other address for which it should receive traffic such as an IP broadcast or multicast address:\n\n\n\n\nIf so, the datagram is delivered to the protocol module specified by the \nProtocol\n field in the IPv4 header or \nNext Header\n field in the IPv6 header.\n\n\nIf the datagram is not destined for one of the IP addresses being used locally by the IP module, then:\n\n\nIf the IP layer was configured to act as a router, the datagram is forwarded (that is, handled as an outgoing datagram as described in \nSection 5.4.2\n); or,\n\n\nThe datagram is silently discarded. Under some circumstances (e.g., no route is known in case 1), an ICMP message may be sent back to the source indicating an error condition.\n\n\n\n\n\n\n\n\nForwarding Table\n\n\nThe data in a forwarding table is up to the implementation, though several key pieces of information are generally required to implement the forwarding table for IP. Each entry in the routing or forwarding table contains (at least conceptually) the following information fields:\n\n\n\n\nDestination\n: This contains a 32-bit field (or 128-bit field for IPv6) used for matching the result of a masking operation. The destination can be:\n\n\nZero, for a \"default route\" covering all destinations, or,\n\n\nFull length of an IP address, for a \"host route\" that describes only a single destination.\n\n\n\n\n\n\nMask\n: This contains a 32-bit field (or 128-bit field for IPv6) applied as a bitwise AND mask to the destination IP address of a datagram being looked up in the forwarding table. The masked result is compared with the set of destinations in the forwarding table entries.\n\n\nNext-hop\n: This contains the 32-bit IPv4 address or 128-bit IPv6 address of the next IP entity (router or host) to which the datagram should be sent. The next-hop entity is typically on a network shared with the system performing the forwarding lookup, meaning the two share the same network prefix.\n\n\nInterface\n: This contains an identifier used by the IP layer to reference the network interface that should be used to send the datagram to its next hop. For example, it could refer to a host\u2019s 802.11 wireless interface, a wired Ethernet interface, or a PPP interface associated with a serial port. If the forwarding system is also the sender of the IP datagram, this field is used in selecting which source IP address to use on the outgoing datagram (see \nSection 5.6.2.1\n).\n\n\n\n\nIP forwarding is performed on a \nhop-by-hop\n basis. The routers and hosts do not contain the complete forwarding path to any destination, except those destinations that are directly connected to the host or router. IP forwarding provides the IP address of only the next-hop entity to which the datagram is sent. The following assumption are made:\n\n\n\n\nThe next hop is really \"closer\" to the destination than the forwarding system is, and that the next-hop router is directly connected to (shares a common network prefix with) the forwarding system.\n\n\nNo \"loops\" are constructed between the next hops so that a datagram does not circulate around the network until its TTL or hop limit expires.\n\n\n\n\nThe job of ensuring correctness of the routing table is given to one or more routing protocols. Many different routing protocols are available to do this job, including \nRIP\n, \nOSPF\n, \nBGP\n, and \nIS-IS\n.\n\n\nIP Forwarding Actions\n\n\nWhen the IP layer in a host or router needs to send an IP datagram to a next-hop router or host, it first examines the destination IP address (\nD\n) in the datagram  Using the value \nD\n, the following \nlongest prefix match\n algorithm is executed on the forwarding table:\n\n\n\n\n\n\nSearch the table for all entries (masking and comparing) for which the following property holds:\n\n\n(\nD\n \n \nm\nj\n) = \nd\nj\n\n\nWhere:\n\n\n\n\nm\nj\n is the value of the mask field associated with the forwarding entry \ne\nj\n having index j\n\n\nd\nj\n is the value of the destination field associated with \ne\nj\n.\n\n\n\n\nThis means that the destination IP address \nD\n is bitwise ANDed with the mask in each forwarding table entry (\nm\nj\n), and the result is compared against the destination in the same forwarding table entry (\nd\nj\n). If the property holds, the entry (\ne\nj\n here) is a \"match\" for the destination IP address. When a match happens, the algorithm notes the entry index (\nj\n here) and how many bits in the mask \nm\nj\n were 1. The more bits are 1, the \"better\" the match.\n\n\n\n\n\n\nThe best matching entry \ne\nk\n (the one with the largest number of 1 bits in its mask \nm\nj\n) is selected, and its next-hop field \nnm\nk\n is used as the next-hop IP address in forwarding the datagram.\n\n\n\n\n\n\nIf no matches in the forwarding table are found, the datagram is undeliverable:\n\n\n\n\nIf on a host (the undeliverable datagram was generated locally), a \"host unreachable\" error is normally returned to the application that generated the datagram.\n\n\nIf on a router, an ICMP message is normally sent back to the host that sent the datagram.\n\n\n\n\nIn some circumstances, more than one entry may match an equal number of 1 bits: for example, when more than one default route is available (e.g., when attached to more than one ISP, called \nmultihoming\n). A common behavior is for the system to simply choose the first match. More sophisticated systems may attempt to load-balance or split traffic across the multiple routes. Studies suggest that multihoming can be beneficial not only for large enterprises, but also for residential users. [p210]\n\n\nExamples of IP Forwarding\n\n\nThere are two cases of IP forwarding:\n\n\n\n\nDirect delivery\n: all systems are using the same network prefix.\n\n\nIndirect delivery\n (\nFigure 5-16\n).\n\n\n\n\nDirect Delivery\n\n\nHost S (with IPv4 address S and MAC address \nS\n) has an IP datagram to send to Host D (IPv4 address D, MAC address \nD\n). Both hosts are on the same Ethernet (\nfront cover\n) and are interconnected using a switch. [p210]\n\n\nThe top part of the following figure shows the delivery of the datagram and the forwarding table on S to contain the information as shown in the following table:\n\n\n\n\n\n\n\n\n\n\nDestination\n\n\nMask\n\n\nGateway (Next Hop)\n\n\nInterface\n\n\n\n\n\n\n\n\n\n\n0.0.0.0\n\n\n0.0.0.0\n\n\n10.0.0.1\n\n\n10.0.0.100\n\n\n\n\n\n\n10.0.0.0\n\n\n255.255.255.128\n\n\n10.0.0.100\n\n\n10.0.0.100\n\n\n\n\n\n\n\n\n\nThe (unicast) IPv4 forwarding table at host S contains only two entries. Host S is configured with IPv4 address and subnet mask 10.0.0.100/25. Datagrams destined for addresses in the range 10.0.0.1 through 10.0.0.126 use the second forwarding table entry and are sent using direct delivery. All other datagrams use the first entry and are given to router R with IPv4 address 10.0.0.1.\n\n\n\nDirect delivery does not require the presence of a router: IP datagrams are encapsulated in a link-layer frame that directly identifies the source and destination. In the above forwarding table, the destination IPv4 address D (10.0.0.9) matches both the first and second forwarding table entries. Because it matches the second entry better (25 bits instead of none), the \"gateway\" or next-hop address is 10.0.0.100, the address S. Thus, \nthe gateway portion of the entry contains the address of the sending host\u2019s own network interface (no router is referenced), indicating that direct delivery is to be used to send the datagram.\n\n\nThe datagram is encapsulated in a lower-layer frame destined for the target host D. If the lower-layer address of the target host is unknown, the ARP protocol (for IPv4; \nChapter 4\n) or Neighbor Solicitation (for IPv6; \nChapter 8\n) operation may be invoked at this point to determine the correct lower-layer address, \nD\n. Once known, the destination address in the datagram is D\u2019s IPv4 address (10.0.0.9), and \nD\n is placed in the \nDestination IP Address\n field in the lower-layer header. The switch delivers the frame to D based solely on the link-layer address \nD\n; it pays no attention to the IP addresses.\n\n\nIndirect Delivery\n\n\nHost S has an IP datagram to send to the Host D (\nftp.uu.net\n), whose IPv4 address is 192.48.96.9. The bottom part of the \nFigure 5-16\n shows the conceptual path of the datagram through four routers. Host S searches its forwarding table but does not find a matching prefix on the local network. It uses its default route entry (which matches every destination, but with no 1 bits at all).\n\n\nThe IP addresses correspond to the source and destination hosts, but the lower-layer addresses do not. The lower-layer addresses determine which machines receive the frame containing the datagram on a per-hop basis.\n\n\nIn this example:\n\n\n\n\nThe lower-layer address needs the Ethernet address of the next-hop router R1\u2019s a-side interface (the lower-layer address corresponding to IPv4 address 10.0.0.1). This is accomplished by ARP (or a Neighbor Solicitation request for IPv6) on the network interconnecting S and R1.\n\n\nOnce R1 responds with its a-side lower-layer address, S sends the datagram to R1. Delivery from S to R1 takes place based on processing only the lower-layer headers (the lower-layer destination address).\n\n\nUpon receipt of the datagram, R1 checks its forwarding table.\n\n\n\n\nThe following table is the forwarding table of R1:\n\n\n\n\n\n\n\n\nDestination\n\n\nMask\n\n\nGateway (Next Hop)\n\n\nInterface\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n0.0.0.0\n\n\n0.0.0.0\n\n\n70.231.159.254\n\n\n70.231.132.85\n\n\nNAT\n\n\n\n\n\n\n10.0.0.0\n\n\n255.255.255.128\n\n\n10.0.0.100\n\n\n10.0.0.1\n\n\nNAT\n\n\n\n\n\n\n\n\n\nThe forwarding table at R1 indicates that address translation should be performed for traffic. The router has a private address on one side (10.0.0.1) and a public address on the other (70.231.132.85). Address translation is used to make datagrams originating on the 10.0.0.0/25 network appear to the Internet as though they had been sent from 70.231.132.85.\n\n\n\n\n\nWhen R1 receives the datagram, it realizes that the datagram\u2019s destination IP address is not one of its own, so it forwards the datagram. Its forwarding table is searched and the default entry is used. The default entry in this case has a next hop within the ISP servicing the network, 70.231.159.254 (this is R2\u2019s a-side interface).\n\n\nBecause this router is in the global Internet and the source address of Host S is the private address 10.0.0.100, R1 performs \nNetwork Address Translation\n (NAT) on the datagram to make it routable on the Internet. The NAT operation results in the datagram having the new source address 70.231.132.85, which corresponds to R1\u2019s b-side interface.\n\n\nWhen router R2 (inside the ISP) receives the datagram, it goes through the same steps that the local router R1 did (except for the NAT operation). If the datagram is not destined for one of its own IP addresses, the datagram is forwarded.\n\n\n\n\nIPv6 uses a slightly different mechanism (Neighbor Solicitation messages) from IPv4 (which uses ARP) to ascertain the lower-layer address of its next hop (\nChapter 8\n). In addition, IPv6 has both link-local addresses and global addresses (\nChapter 2\n). While global addresses behave like regular IP addresses, link-local addresses can be used only on the same link. In addition, because all the link-local addresses share the same IPv6 prefix (fe80::/10), a multihomed host may require user to determine which interface to use when sending a datagram destined for a link-local destination.\n\n\n[p213-214]\n\n\nTo see the path taken to an IP destination, we can use the \ntraceroute\n program:\n\n\nLinux% traceroute -n ftp.uu.net\ntraceroute to ftp.uu.net (192.48.96.9), 30 hops max, 38 byte packets\n 1 70.231.159.254 9.285 ms 8.404 ms 8.887 ms\n 2 206.171.134.131 8.412 ms 8.764 ms 8.661 ms\n 3 216.102.176.226 8.502 ms 8.995 ms 8.644 ms\n 4 151.164.190.185 8.705 ms 8.673 ms 9.014 ms\n 5 151.164.92.181 9.149 ms 9.057 ms 9.537 ms\n 6 151.164.240.134 9.680 ms 10.389 ms 11.003 ms\n 7 151.164.41.10 11.605 ms 37.699 ms 11.374 ms\n 8 12.122.79.97 13.449 ms 12.804 ms 13.126 ms\n 9 12.122.85.134 15.114 ms 15.020 ms 13.654 ms\n MPLS Label=32307 CoS=5 TTL=1 S=0\n10 12.123.12.18 16.011 ms 13.555 ms 13.167 ms\n11 192.205.33.198 15.594 ms 15.497 ms 16.093 ms\n12 152.63.57.102 15.103 ms 14.769 ms 15.128 ms\n13 152.63.34.133 77.501 ms 77.593 ms 76.974 ms\n14 152.63.38.1 77.906 ms 78.101 ms 78.398 ms\n15 207.18.173.162 81.146 ms 81.281 ms 80.918 ms\n16 198.5.240.36 77.988 ms 78.007 ms 77.947 ms\n17 198.5.241.101 81.912 ms 82.231 ms 83.115 ms\n\n\n\n\n\nThis program lists each of the IP hops traversed while sending a series of datagrams to the destination \nftp.uu.net\n (192.48.96.9). The \ntraceroute\n program uses a combination of UDP datagrams (with increasing TTL over time) and ICMP messages (used to detect each hop when the UDP datagrams expire) to accomplish its task. Three UDP packets are sent at each TTL value, providing three roundtrip-time measurements to each hop. The following line indicates that \nMultiprotocol Label Switching\n (MPLS) [RFC3031] is being used.\n\n\nMPLS Label=32307 CoS=5 TTL=1 S=0\n\n\n\n\n\nMPLS is a form of link-layer network capable of carrying multiple network-layer protocols. Many network operators use it for traffic engineering purposes (controlling where network traffic flows through their networks). [p215]\n\n\nDiscussion (IP Forwarding)\n\n\nKey points regarding the operation of IP unicast forwarding:\n\n\n\n\nMost of the hosts and routers in this example used a default route consisting of a single forwarding table entry of this form: mask 0, destination 0, next hop \nsome IP address\n. Indeed, most hosts and most routers at the edge of the Internet can use a default route for everything other than destinations on local networks because there is only one interface available that provides connectivity to the rest of the Internet.\n\n\nThe source and destination IP addresses in the datagram never change once in the regular Internet. This is always the case unless either source routing is used, or when other functions (such as NAT, as in the example) are encountered along the data path. Forwarding decisions at the IP layer are based on the destination address.\n\n\nA different lower-layer header is used on each link that uses addressing, and the lower-layer destination address (if present) always contains the lower-layer address of the next hop. Therefore, lower-layer headers routinely change as the datagram is moved along each hop toward its destination.  In our example, both Ethernet LANs encapsulated a link-layer header containing the next hop\u2019s Ethernet address, but the DSL link did not. Lower-layer addresses are normally obtained using ARP (see Chap\n\n\n\n\nMobile IP\n\n\n(skipped)\n\n\n[p215-220]\n\n\nHost Processing of IP Datagrams\n\n\nHost Models", 
            "title": "Chapter 5. The Internet Protocol (IP)"
        }, 
        {
            "location": "/tcpv1/ch6/", 
            "text": "Chapter 6. System Configuration: DHCP and Autoconfiguration", 
            "title": "Chapter 6. System Configuration: DHCP and Autoconfiguration"
        }, 
        {
            "location": "/tcpv1/ch7/", 
            "text": "Chapter 7. Firewalls and Network Address Translation (NAT)\n\n\n\n\nPerhaps ironically, the development and eventual widespread use of NAT has contributed to significantly slow the adoption of IPv6.\n\nTCPv1\n\n\n\n\nMany security problems (attacks) were caused by bugs or unplanned protocol operations in the software implementations of Internet hosts. Fixing the problem would have required a way to control the Internet traffic to which the end hosts were exposed. Today, this is provided by a \nfirewall\n, a type of router that restricts the types of traffic it forwards. [p299]\n\n\nAs firewalls are being deployed, another problem was becoming important: the number of available IPv4 addresses was diminishing,\nwith a threat of exhaustion. One of the most important mechanisms developed to deal with this, aside from IPv6, is called \nNetwork Address Translation\n (NAT). With NAT, Internet addresses need not be globally unique, but can be reused in different parts of the Internet, called \naddress realms\n. This greatly eased the problem of address exhaustion.\n\n\nFirewalls\n\n\nGiven the enormous management problems associated with trying to keep end system software up-to-date and bug-free, the focus of resisting attacks expanded\n\n\n\n\nFrom: securing end systems,\n\n\nTo: restricting the Internet traffic allowed to flow to end systems by filtering out some traffic using firewalls.\n\n\n\n\nToday, several different types of firewalls have evolved.\n\n\nThe two major types of firewalls commonly used include \nproxy firewalls\n and \npacket-filtering firewalls\n. The main difference between them is the layer in the protocol stack at which they operate, and consequently the way IP addresses and port numbers are used. The packet-filtering firewall is an Internet router that drops datagrams that (fail to) meet specific criteria. The proxy firewall operates as a multihomed server host from the viewpoint of an Internet client. That is, it is the endpoint of TCP and UDP transport associations; it does not typically route IP datagrams at the IP protocol layer.\n\n\nPacket-Filtering Firewalls\n\n\nPacket-filtering firewalls act as Internet routers and filter (drop) some traffic. They can generally be configured to discard or forward packets whose headers meet (or fail to meet) certain criteria, called \nfilters\n.\n\n\nPopular filters involve:\n\n\n\n\nUndesired IP addresses or options,\n\n\nTypes of ICMP messages,\n\n\nVarious UDP or TCP services, based on the port numbers contained in each packet.\n\n\n\n\nStateless and stateful:\n\n\n\n\nStateless\n firewalls treat each datagram individually.\n\n\nStateful\n firewalls are able associate packets with either previous or future packets to make inferences about datagrams or streams.\n\n\n\n\n[p300]\n\n\nA typical packet-filtering firewall is shown below.\n\n\nIn this figure\n\n\n\n\nThe firewall is an Internet router with three network interfaces:\n\n\n\"inside\"\n\n\n\"outside\"\n\n\n\"DMZ\"\n\n\n\n\n\n\nThe DMZ subnet provides access to an extranet or DMZ where servers are deployed for Internet users to access.\n\n\nNetwork administrators install filters or \naccess control lists\n (ACLs, basically policy lists indicating what types of packets to discard or forward) in the firewall.\n\n\nTypically, these filters conservatively block traffic from the outside that may be harmful and liberally allow traffic to travel from inside to outside.\n\n\n\n\n\n\nProxy Firewalls\n\n\nProxy firewalls are not really Internet routers. They are essentially hosts running one or more \napplication-layer gateways\n (ALGs), hosts with more than one network interface that relay traffic of certain types between one connection/association and another at the application layer.\n\n\nThe figure below illustrates a proxy firewall:\n\n\n\n\nClients on the inside of the firewall are usually configured in a special way to associate (or connect) with the proxy instead of the actual end host providing the desired service.\n\n\nThe firewalls act as multihomed hosts with their IP forwarding capability typically disabled.\n\n\nAs with packet-filtering firewalls, a common configuration is to have an \"outside\" interface assigned a globally routable IP address and for its \"inner\" interface to be configured with a private IP address. Thus, proxy firewalls support the use of private address realms.\n\n\n\n\n\n\nThis type of firewall can be quite secure at the cost of brittleness and lack of flexibility:\n\n\n\n\nSince this style of firewall must contain a proxy for each transport-layer service, any new services to be used must have a corresponding proxy installed and operated for connectivity to take place through the proxy.\n\n\nEach client must be configured to find the proxy, for example using the \nWeb Proxy Auto-Discovery Protocol\n (WPAD), although there are some alternatives: capturing proxies that catch all traffic of a certain type regardless of destination address).\n\n\nSignificant intervention is required from network operators to support additional services.\n\n\n\n\nThe two most common forms of proxy firewalls are HTTP proxy firewalls and SOCKS firewalls.\n\n\n\n\nHTTP proxy firewalls\n, also called \nWeb proxies\n, work only for the HTTP and HTTPS (Web) protocols.\n\n\nThese proxies act as Web servers for internal clients and as Web clients when accessing external Web sites.\n\n\nSuch proxies often also operate as \nWeb caches\n. These caches save copies of Web pages so that subsequent accesses can be served directly from the cache instead of from the originating Internet Web server. Doing so can reduce latency to display Web pages and improve the experience of users accessing the Web.\n\n\nSome Web proxies are also used as \ncontent filters\n, which attempt to block access to certain Web sites based on a \u201cblacklist\u201d of prohibited sites. Conversely, \ntunneling proxy servers\n are available on the Internet. These servers (e.g., \npsiphon\n, \nCGIProxy\n) essentially perform the opposite function: to allow users to avoid being blocked by content filters.\n\n\n\n\n\n\nSOCKS firewalls\n uses the \nSOCKS protocol\n, which is more generic than HTTP for proxy access and is applicable to more services than just the Web. Two versions of SOCKS are currently in use: version 4 (SOCKS5) and version 5 (SOCKS5). Version 4 provides the basic support for proxy traversal, and version 5 adds strong authentication, UDP traversal, and IPv6 addressing.\n\n\nTo use a SOCKS proxy, an application must be written to use SOCKS (it must be \"socksified\") and configured to know the location and version of the SOCKS proxy. Then the client uses the SOCKS protocol to request the proxy to perform network connections and, optionally, DNS lookups.\n\n\n\n\n\n\n\n\nNetwork Address Translation (NAT)\n\n\nNAT is a mechanism that allows the same sets of IP addresses to be reused in different parts of the Internet. With NAT as a common use, all incoming and outgoing traffic passes through a single NAT device that partitions the inside (private) address realm from the global Internet address realm, all the internal systems can be provided Internet connectivity as clients using locally assigned, private IP addresses. [p303]\n\n\nNAT was introduced to solve two problems: address depletion and concerns regarding the scalability of routing. NAT was initially suggested as a stopgap, temporary measure to be used until the deployment of some protocol with a larger number of addresses (IPv6) became widespread. Routing scalability was being tackled with the development of Classless Inter-Domain Routing (CIDR, \nChapter 2\n)\n\n\nNAT is popular because:\n\n\n\n\nIt reduces the need for globally routable Internet addresses\n\n\nIt offers some degree of natural firewall capability and requires little configuration.\n\n\n\n\nPerhaps ironically, the development and eventual widespread use of NAT has contributed to significantly slow the adoption of IPv6. Among its other benefits, IPv6 was intended to make NAT unnecessary.\n\n\nNAT has several drawbacks:\n\n\n\n\nOffering Internet-accessible services from the private side requires special configuration because privately addressed systems are not directly reachable from the Internet.\n\n\nEvery packet in both directions of a connection or association must pass through the same NAT, because the NAT must actively rewrite the addressing information in each packet.\n\n\nNATs require connection state on a \nper-association\n (or \nper-connection\n) basis and must operate across multiple protocol layers, unlike conventional routers. Modifying an address at the IP layer also requires modifying checksums at the transport layer (see \nChapters 10\n and \nChatper 13\n regarding the pseudoheader checksum)\n\n\n\n\n\n\nSome applications protocols, especially those that send IP addressing information inside the application-layer payload, such as \nFile Transfer Protocol\n (FTP) and \nSession Initiation Protocol\n (SIP), require a special application-layer gateway function that rewrites the application content in order to work unmodified with NAT or other NAT traversal methods that allow the applications to determine how to work with the specific NAT they are using.\n\n\n\n\nDespite its shortcomings, NATs are very widely used, and most network routers support it; NAT supports the basic protocols (e.g., e-mail, Web browsing) that are needed by millions of client systems accessing the Internet every day.\n\n\nA NAT works by rewriting the identifying information in packets transiting through a router. Most commonly NAT involves rewriting the source IP address of packets as they are forwarded in one direction and the destination IP addresses of packets traveling in the reverse direction. This allows the source IP address in outgoing packets to become one of the NAT router\u2019s Internet-facing interfaces instead of the originating host\u2019s. Thus, \nto a host on the Internet, packets coming from any of the hosts on the privately addressed side of the NAT appear to be coming from a globally routable IP address of the NAT router.\n\n\nMost NATs perform both \ntranslation\n and \npacket filtering\n, and the packet-filtering criteria depend on the dynamics of the NAT state. The choice of packet-filtering policy may have a different granularity. For example, the treatment of unsolicited packets (those not associated with packets originating from behind the NAT) received by the NAT may depend on source and destination IP address and/or source and destination port number. [p305]\n\n\nTraditional NAT: Basic NAT and NAPT\n\n\nTraditional NAT\n includes both:\n\n\n\n\nBasic NAT\n. It performs rewriting of IP addresses only: a private address is rewritten to be a public address, often from a pool or range of public addresses supplied. This type of NAT is not the most popular because it does not help to dramatically reduce the need for (globally routable) IP addresses.\n\n\nNetwork Address Port Translation\n (NAPT), also known as \nIP masquerading\n. It uses transport-layer identifiers (i.e., ports for TCP and UDP, query identifiers for ICMP) to differentiate which host on the private side of the NAT is associated with a particular packet. This allows a large number of internal hosts to access the Internet simultaneously using a limited number of public addresses, often only a single one.\n\n\n\n\nSee the following figure for the distinction between basic NAT and NAPT:\n\n\n\n\nThe addresses used in a private addressing realm \"behind\" (or \"inside\") a NAT are not enforced by anyone other than the local network administrator. It is possible and acceptable for a private realm to make use of global address space. However, \nlocal systems in the private realm would most likely be unable to reach the public systems using the same addresses because the close proximity of the local systems would effectively \"mask\" the visibility of the farther-away systems using the same addresses.\n To avoid this, three IPv4 address ranges are reserved for use with private addressing realms: 10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16, which are often used as default values for address pools in embedded DHCP servers\n\n\nNAT provides some degree of security, similar to a firewall [p306]:\n\n\n\n\nBy default, systems on the private side (using private addresses) of the NAT cannot be reached from the Internet.\n\n\nA common policy allows almost all outgoing and returning traffic (associated with outgoing traffic) to pass through the NAT but blocks almost all incoming new connection requests. This behavior inhibits \"probing\" attacks that attempt to ascertain which IP addresses have active hosts available to exploit.\n\n\nA NAT (especially a NAPT) \"hides\" the number and configuration of internal addresses from the outside. NAT helps by providing \ntopology hiding\n.\n\n\n\n\nThe following subsections discusses how NAT behaves with each major transport protocol and how it may be used in mixed IPv4/IPv6 environments. [p306]\n\n\nNAT and TCP\n\n\nWhen a TCP connection starts, an \"active opener\" or client usually sends a synchronization (SYN) packet to a \"passive opener\" or server. The server responds with its own SYN packet, which also includes an acknowledgment (ACK) of the client\u2019s SYN.  The client then responds with an ACK to the server. This \u201cthree-way handshake\u201d establishes the connection. A similar exchange with finish (FIN) packets is used to gracefully close a connection. The connection can also be forcefully closed right away using a reset (RST) packet. The behavioral requirements for traditional NAT with TCP relate primarily to the TCP three-way handshake.\n\n\nReferring to the figure below, consider a TCP connection initiated by the wireless client at 10.0.0.126 destined for the Web server on the host \nwww.isoc.org\n (IPv4 address 212.110.167.157). With the format \"(source IP:source port; destination IP:destination port)\", the packet initiating the connection on the private segment might be addressed as (10.0.0.126:9200; 212.110.167.157:80).\n\n\n\n\n[p307]\n\n\n\n\nThe NAT receives the first incoming packet from the client and notices it is a new connection (SYN bit in the TCP header is turned on).\n\n\nIt modifies the source IP address to the routable IP address of the NAT router\u2019s external interface. Thus, when the NAT forwards this packet, the addressing is (63.204.134.177:9200; 212.110.167.157:80).\n\n\nIt creates a \nNAT session\n, which is internal state to remember that a new connection is being handled by the NAT. This state includes an entry, called a \nNAT mapping\n, containing the source port number and IP address of the client.\n\n\n\n\n\n\nThe server replies to the endpoint (63.204.134.177:9200), the external NAT address, using the port number chosen initially by the client. This behavior is called \nport preservation\n. By matching the destination port number on the received datagram against the NAT mapping, the NAT ascertains the internal IP address of the client that made the initial request. The NAT rewrites the response packet from (212.110.167.157:80; 63.204.134.177:9200) to (212.110.167.157:80; 10.0.0.126:9200) and forwards it.\n\n\nThe client then receives a response to its request and is now connected to the server.\n\n\n\n\nSession state is removed if FINs are exchanged. The NAT must also remove \"dead\" mappings (identified by lack of traffic or RST) that are left stale in the NAT's memory, such when a client host is simply turned off.\n\n\nMost NATs include a simplified TCP connection establishment procedures and can distinguish between connection success and failure:\n\n\n\n\nA \nconnection timer\n is activated when an outgoing SYN segment is observed, and if no ACK is seen before the timer expires, the session state is cleared.\n\n\nA \nsession timer\n is created, with a longer timeout (hours), after an ACK does arrives and the connection timer is canceled.\n\n\nThe NAT may send an additional packet to the internal endpoint to doublecheck if the session is indeed dead (called \nprobing\n). If it receives an ACK, the NAT realizes that the connection is still active, resets the session timer, and does not delete the session. If it receives either no response (after a \nclose timer\n has expired) or an RST segment, the connection has gone dead, and the state is cleared.\n\n\n\n\n\n\n\n\nA TCP connection can be configured to send \"keepalive\" packets (\nChapter 17\n), and the default rate is one packet every 2 hours, if enabled. Otherwise, a TCP connection can remain established indefinitely. While a connection is being set up or cleared, however, the maximum idle time is 4 minutes. Consequently, [RFC5382] requires (REQ-5) that a NAT wait at least 2 hours and 4 minutes before concluding that an established connection is dead and at least 4 minutes before concluding that a partially opened or closed connection is dead.\n\n\nThere are tricky problems for TCP NAT. [p308] See \nDoubts and Solutions\n\n\nNAT and UDP\n\n\nBesides issues when performing NAT on TCP, the NAT on UDP has other issues due to:\n\n\n\n\nUDP has no connection establishment and clearing procedures as in TCP.\n\n\nThere are no indicators such as the SYN, FIN, and RST bits to indicate that a session is being created or destroyed.\n\n\nAn association may not be completely clear: UDP does not use a 4-tuple to identify a connection like TCP; it can rely on only the two endpoint address/port number combinations.\n\n\n\n\nTo handle these issues, UDP NATs use a \nmapping timer\n to clear NAT state if a binding has not been used \"recently\". The \"recently\" may mean different values. [RFC4787] requires the timer to be at least 2 minutes and recommends that it be 5 minutes. Timers can be refreshed when packets travel from the inside to the outside of the NAT (NAT outbound refresh behavior). [p309]\n\n\nWith IP fragmentation, an IP fragment other than the first one does not contain the port number information needed by NAPT to operate properly. This also applies to TCP and ICMP. Thus, fragments cannot be handled properly by simple NATs or NAPTs. [p309]\n\n\nNAT and Other Transport Protocols (DCCP, SCTP)\n\n\n\n\nThe \nDatagram Congestion Control Protocol\n (DCCP) [RFC4340] provides a congestion-controlled datagram service.\n\n\nThe \nStream Control Transmission Protocol\n (SCTP) [RFC4960] provides a reliable messaging service that can accommodate hosts with multiple addresses.\n\n\n\n\nNAT and ICMP\n\n\nThe Internet Control Message Protocol (ICMP) provides status information about IP packets and can also be used for making certain measurements and gathering information about the state of the network.\n\n\nICMP has two categories of messages: informational and error: [p310]\n\n\n\n\nError messages contain a (partial or full) copy of the IP packet that induced the error condition. They are sent from the point where an error was detected, often in the middle of the network, to the original sender.\n\n\nWhen an ICMP error message passes through a NAT, the IP addresses in the included \"offending datagram\" need to be rewritten by the NAT in order for them to make sense to the end client (called \nICMP fix-up\n).\n\n\n\n\n\n\nInformational messages include a \nQuery ID\n field that is handled much like port numbers for TCP or UDP.\n\n\nNAT handling these types of messages can recognize outgoing informational requests and set a timer in anticipation of a returning response.\n\n\n\n\n\n\n\n\nNAT and Tunneled Packets\n\n\nWhen tunneled packets (\nChapter 3\n) are to be sent through a NATs, not only must a NAT rewrite the IP header, but it may also have to rewrite the headers or payloads of other packets that are encapsulated in them. One example of this is the \nGeneric Routing Encapsulation\n (GRE) header used with the \nPoint-to-Point Tunneling Protocol\n (PPTP). [p310]\n\n\nNAT and Multicast\n\n\nNATs can be configured to support multicast traffic (\nChapter 9\n), although this is rare. [p310]\n\n\nNAT and IPv6\n\n\nThere is staunch resistance to supporting the use of NAT with IPv6 based on the idea that saving address space is unnecessary with IPv6 and that other desirable NAT features (firewall-like functionality, topology hiding, and privacy) can be better achieved using Local Network Protection (LNP) [RFC4864]. LNP represents a collection of techniques with IPv6 that match or exceed the properties of NATs.\n\n\nAside from its packet-filtering properties, NAT supports the coexistence of multiple address realms and thereby helps to avoid the problem of a site having to change its IP addresses when it switches ISPs. [p310-311]\n\n\nAddress and Port Translation Behavior\n\n\nOne of the primary goals of the BEHAVE working group in IETF was to clarify the common behaviors and set guidelines. [p311]\n\n\nSee the following figure as a generic NAT mapping example:\n\n\n\n\nIn this figure:\n\n\n\n\nThe notation \nX:x\n indicates that a host in the private addressing realm (inside host) uses IP address \nX\n with port number \nx\n (for ICMP, the query ID is used instead of the port number). The IP address \nX\n is a private IPv4 address.\n\n\nTo reach the remote address/port combination \nY:y\n, the NAT establishes a mapping using an external (globally routable) address \nX1\u2032\n and port number \nx1\u2032\n. Assuming that the internal host contacts \nY1:y1\n followed by \nY2:y2\n, the NAT establishes mappings \nX1\u2032:x1\u2032\n and \nX2\u2032:x2\u2032\n, respectively.\n\n\nIn most cases, X1\u2032 equals X2\u2032 because most sites use only a single globally routable IP address.\n\n\nThe mapping is said to be \nreused\n if \nx1\u2032\n equals \nx2\u2032\n. If \nx1\u2032\n and \nx2\u2032\n equal \nx\n, the NAT implements port preservation, as \nmentioned earlier\n. In some cases, port preservation is not possible, so the NAT must deal with port collisions as suggested by \nFigure 7-4\n.\n\n\n\n\n\n\n\n\nA NAT\u2019s address and port behavior is characterized by what its mappings depend on.  The inside host uses IP address:port \nX:x\n to contact \nY1:y1\n and then \nY2:y2\n. The address and port used by the NAT for these associations are \nX1\u2032:x1\u2032\n and \nX2\u2032:x2\u2032\n, respectively.\n\n\n\n\nIf \nX1\u2032:x1\u2032\n equals \nX2\u2032:x2\u2032\n for any \nY1:y1\n or \nY2:y2\n, the NAT has \nendpoint-independent\n mappings.\n\n\nIf \nX1\u2032:x1\u2032\n equals \nX2\u2032:x2\u2032\n if and only if \nY1\n equals \nY2\n, the NAT has \naddress-dependent\n mappings.\n\n\nIf \nX1\u2032:x1\u2032\n equals \nX2\u2032:x2\u2032\n if and only if \nY1:y1\n equals \nY2:y2\n, the NAT has \naddress and port-dependent\n mappings.\n\n\n\n\nA NAT with multiple external addresses (i.e., where \nX1\u2032\n may not equal \nX2\u2032\n) has an address pooling behavior of arbitrary if the outside address is chosen without regard to inside or outside address. Alternatively, it may have a pooling behavior of paired, in which case the same \nX1\n is used for any association with \nY1\n.\n\n\nThe figure above and the table below summarize the various NAT port and address behaviors based on definitions from [RFC4787]. The table also gives filtering behaviors that use similar terminology.\n\n\nFor all common transports, including TCP and UDP, the required NAT address- and port-handling behavior is endpoint-independent.\n The purpose of this requirement is to help applications that attempt to determine the external addresses used for their traffic to work more reliably. This is detailed in \nNAT traversal\n.\n\n\n\n\n\n\n\n\nBehavior Name\n\n\nTranslation Behavior\n\n\nFiltering Behavior\n\n\n\n\n\n\n\n\n\n\nEndpoint-independent\n\n\nX1\u2032:x1\u2032 = X2\u2032:x2\u2032\n for all \nY2:y2\n (required)\n\n\nAllows any packets for \nX1:x1\n as long as any \nX1\u2032:x1\u2032\n exists (recommended for greatest transparency)\n\n\n\n\n\n\nAddress-dependent\n\n\nX1\u2032:x1\u2032 = X2\u2032:x2\u2032\n iff \nY1 = Y2\n\n\nAllows packets for \nX1:x1\n from \nY1:y1\n as long as \nX1\n has previously contacted \nY1\n (recommended for more stringent filtering)\n\n\n\n\n\n\nAddress-and port-dependent\n\n\nX1\u2032:x1\u2032 = X2\u2032:x2\u2032\n iff \nY1:y1 = Y2:y2\n\n\nAllows packets for \nX1:x1\n from \nY1:y1\n as long as \nX1\n has previously contacted \nY1:y1\n\n\n\n\n\n\n\n\nNAT address pool\n *\n\n\nA NAT may have several external addresses available to use. The set of addresses is typically called the \nNAT pool\n or \nNAT address pool\n. Note that NAT address pools are distinct from the DHCP address pools discussed in \nChapter 6\n, although a single device may need to handle both NAT and DHCP address pools.\n\n\nAddress pairing or not?\n *\n\n\nWhen a single host behind the NAT opens multiple simultaneous connections, is each assigned the same external IP address (called address \npairing\n) or not?\n\n\nA NAT\u2019s \nIP address pooling behavior\n is said to be \narbitrary\n if there is no restriction on which external address is used for any association. It is said to be paired if it implements address pairing. Pairing is the recommended NAT behavior for all transports. If pairing is not used, the communication peer of an internal host may erroneously conclude that it is communicating with different hosts. For NATs with only a single external address, this is obviously not a problem.\n\n\nPort overloading\n *\n\n\nPort overloading\n is a type of NAT that overloads not only addresses but also ports, where the traffic of multiple internal hosts may be rewritten to the same external IP address and port number. This is a dangerous because if multiple hosts associate with a service on the same external host, it cannot determine the appropriate destination for traffic returning from the external host. For TCP, this is a consequence of all four elements of the connection identifier (source and destination address and port numbers) being identical in the external network among the various connections. Such behavior\nis now disallowed.\n\n\nPort parity\n *\n\n\nSome NATs implement a special feature called \nport parity\n. Such NATs attempt to preserve the \"parity\" (evenness or oddness) of port numbers. Thus, if \nx1\n is even, \nx1\u2032\n is even and vice versa. Although not as strong as port preservation, such behavior is sometimes useful for specific application protocols that use special port numberings (e.g., the Real-Time Protocol, abbreviated RTP, has traditionally used multiple ports, but there are proposed methods for avoiding this issue).\n\n\nPort parity preservation is a recommended NAT feature but not a requirement. It is also expected to become less important over time as more sophisticated \nNAT traversal\n methods become widespread.\n\n\nFiltering Behavior\n\n\nWhen a NAT creates a binding for a TCP connection, UDP association, or ICMP traffic, not only does it establish the address and port mappings, but it must also determine its filtering behavior for the returning traffic if it acts as a firewall, which is the common case. The type of filtering a NAT performs, though logically distinct from its address- and port-handling behavior, is often related and the same terminology is used.\n\n\nA NAT\u2019s filtering behavior is usually related to whether it has established an address mapping. A NAT lacking any form of address mapping is unable to forward any traffic it receives from the outside to the inside because it would not know which internal destination to use. For the most common case of outgoing traffic, when a binding is established, filtering is disabled for relevant return traffic:\n\n\n\n\nFor endpoint-independent filtering behavior, as soon as any mapping is established for an internal host, any incoming traffic is permitted, regardless of source.\n\n\nFor address-dependent filtering behavior, traffic destined for \nX1:x1\n is permitted from \nY1:y1\n only if \nY1\n had been previously contacted by \nX1:x1\n.\n\n\nFor address- and port-dependent filtering behavior, traffic destined for \nX1:x1\n is permitted from \nY1:y1\n only if \nY1:y1\n had been previously contacted by \nX1:x1\n.\n\n\n\n\nThe difference between the last two is that the last form takes the port number \ny1\n into account.\n\n\nServers behind NATs\n\n\nA system that wishes to provide a service from behind a NAT is not directly reachable from the outside. In \nFigure 7-3\n, if the host with address 10.0.0.3 is to provide a service to the Internet, it cannot be reached without participation from the NAT, for at least two reasons:\n\n\n\n\nThe NAT is acting as the Internet router, so it must agree to forward the incoming traffic destined for 10.0.0.3.\n\n\nThe IP address 10.0.0.3 is not routable through the Internet and cannot be used to identify the server by hosts in the Internet. Instead, the external address of the NAT must be used to find the server, and the NAT must arrange to properly rewrite and forward the appropriate traffic to the server so that it can operate. This process is most often called \nport forwarding\n or \nport mapping\n.\n\n\n\n\nPort forwarding\n *\n\n\nWith port forwarding, incoming traffic to a NAT is forwarded to a specific configured destination behind the NAT. This allows servers to provide services to the Internet even though they may be assigned private, nonroutable addresses.\n\n\nPort forwarding typically requires static configuration of the NAT with the address of the server and the associated port number whose traffic should be forwarded. The port forwarding directive acts like an always-present static NAT mapping. If the server\u2019s IP address is changed, the NAT must be updated with the new addressing information.\n\n\nPort forwarding also has the limitation that it has only one set of port numbers for each of its (IP address, transport protocol) combinations. Thus, if the NAT has only a single external IP address, it can forward only a single port of the same transport protocol to at most one internal machine (e.g., it could not support two independent Web servers on the inside being remotely accessible using TCP port 80 from the outside).\n\n\nHairpinning and NAT Loopback\n\n\nAn interesting issue arises when a client wishes to reach a server and both reside on the same, private side of the same NAT. NATs that support this scenario implement so-called \nhairpinning\n or \nNAT loopback\n.\n\n\n\n\nReferring to the figure above, assume that host \nX1\n attempts to establish a connection to host \nX2\n. If \nX1\n knows the private addressing information, \nX2:x2\n, there is no problem because the connection can be made directly. However, in some cases \nX1\n knows only the public address information, \nX2\u2032:x2\u2032\n. In these cases, \nX1\n attempts to contact \nX2\n using the NAT with destination \nX2\u2032:x2\u2032\n. The hairpinning process takes place when the NAT notices the existence of the mapping between \nX2\u2032:x2\u2032\n and \nX2:x2\n and forwards the packet to \nX2:x2\n residing on the private side of the NAT. At this point a question arises as to which source address is contained in the packet heading to \nX2:x2\n: \nX1:x1\n or \nX1\u2032:x1\u2032\n?\n\n\nIf the NAT presents the hairpinned packet to \nX2\n with source addressing information \nX1\u2032:x1\u2032\n, the NAT is said to have \"external source IP address and port\" hairpinning behavior. This behavior is required for TCP NAT [RFC5382]. The justification for requiring this behavior is for applications that identify their peers using globally routable addresses. In our example, \nX2\n may be expecting an incoming connection from \nX1\u2032\n (e.g., because of coordination from a third-party system).\n\n\nNAT Editors\n\n\nService Provider NAT (SPNAT) and Service Provider IPv6 Transition\n\n\nNAT Traversal\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np308 on TCP NAT:\n\n\nOne of the tricky problems for a TCP NAT is handling peer-to-peer applications operating on hosts residing on the private sides of multiple NATs [RFC5128].  Some of these applications use a simultaneous open whereby each end of the connection acts as a client and sends SYN packets more or less simultaneously. TCP is able to handle this case by responding with SYN + ACK packets that complete the connection faster than with the three-way handshake, but many existing NATs do not handle it properly. [RFC5382] addresses this by requiring (REQ-2) that a NAT handle all valid TCP packet exchanges, and simultaneous opens in particular.  Some peer-to-peer applications (e.g., network games) use this behavior. In addition, [RFC5382] specifies that an inbound SYN for a connection about which the NAT knows nothing should be silently discarded. This can occur when a simultaneous open is attempted but the external host\u2019s SYN arrives at the NAT before the internal host\u2019s SYN. Although this may seem unlikely, it can happen as a result of clock skew, for example. If the incoming external SYN is dropped, the internal SYN has time to establish a NAT mapping for the same connection represented by the external SYN. If no internal SYN is forthcoming in 6s, the NAT may signal an error to the external host.\n\n\n\nSome other NAT drawbacks:\n\n\n\n\nThe ugly side of NAT", 
            "title": "Chapter 7. Firewalls and Network Address Translation (NAT)"
        }, 
        {
            "location": "/tcpv1/ch8/", 
            "text": "Chapter 8. ICMPv4 and ICMPv6: Internet Control Message Protocol\n\n\nIntroduction\n\n\nThe IP protocol alone provides no direct way to do the following:\n\n\n\n\nFor an end system to learn the fate of IP packets that fail to make it to their destinations.\n\n\nFor obtaining diagnostic information (e.g., which routers are used along a path or a method to estimate the round-trip time).\n\n\n\n\nTo address these deficiencies, a special protocol called the \nInternet Control Message Protocol\n (ICMP) is used in conjunction with IP to provide diagnostics and control information related to the configuration of the IP protocol layer and the disposition of IP packets.\n\n\nICMP provides for the delivery of error and control messages that may require attention. ICMP messages are usually acted on by:\n\n\n\n\nThe IP layer itself,\n\n\nHigher-layer transport protocols (TCP or UDP),\n\n\nUser applications.\n\n\n\n\nICMP does not provide reliability for IP; it indicates certain classes of failures and configuration information. The most common cause of packet drops (buffer overrun at a router) does not elicit any ICMP information. Other protocols, such as TCP, handle such situations.\n\n\nBecause of the ability of ICMP to affect the operation of important system functions and obtain configuration information, hackers have used ICMP messages in a large number of attacks. As a result of concerns about such attacks, network administrators often arrange to block ICMP messages with firewalls, especially at border routers. If ICMP is blocked, however, a number of common diagnostic utilities (e.g., ping, traceroute) do not work properly.\n\n\nThe term ICMP refers to ICMP in general, and the terms ICMPv4 and ICMPv6 to refer specifically to the versions of ICMP used with IPv4 and IPv6, respectively. ICMPv6 plays a far more important role in the operation of IPv6 than ICMPv4 does for IPv4.\n\n\nIn IPv6, ICMPv6 is used for several purposes beyond simple error reporting and signaling. It is used for:\n\n\n\n\nNeighbor Discovery\n (ND), which plays the same role as ARP does for IPv4 (\nChapter 4\n).\n\n\nRouter Discovery\n function used for configuring hosts (\nChapter 6\n) and multicast address management (\nChapter 9\n).\n\n\nManageing hand-offs in Mobile IPv6.\n\n\n\n\nEncapsulation in IPv4 and IPv6\n\n\n\n\n\n\nIn IPv4, a Protocol field value of 1 indicates that the datagram caries ICMPv4.\n\n\nIn IPv6, the ICMPv6 message may begin after zero or more extension headers. The last extension header before the ICMPv6 header includes a Next Header field with value 58.\n\n\n\n\nICMP messages may be fragmented like other IP datagrams (\nChapter 10\n), although this is not common.\n\n\nThe following figure shows the format of both ICMPv4 and ICMPv6 messages. The first 4 bytes have the same format for all messages, but the remainder differ from one message to the next.\n\n\n\n\nIn ICMPv4:\n\n\n\n\n42 different values are reserved for the \nType\n field [\nICMPTYPES\n], which identify the particular message. Only about 8 of these are in regular use.\n\n\nMany types of ICMP messages also use different values of the \nCode\n field to further specify the meaning of the message.\n\n\nThe \nChecksum\n field covers the entire ICMPv4 message; in ICMPv6 it also covers a pseudo-header derived from portions of the IPv6 header.  The algorithm used for computing the checksum is the same as that used for the IP header checksum defined in \nChapter 5\n.\n\n\nThis is our first example of an \nend-to-end\n checksum. It is carried all the way from the sender of the ICMP message to the final recipient. In contrast, the IPv4 header checksum discussed in \nChapter 5\n is changed at every router hop. If an ICMP implementation receives an ICMP message with a bad checksum, the message is discarded; there is no ICMP message to indicate a bad checksum in a received ICMP message. Recall that the IP layer has no protection on the payload portion of the datagram. If ICMP did not include a checksum, the contents of the ICMP message might not be correct, leading to incorrect system behavior.\n\n\n\n\n\n\n\n\nICMP Messages\n\n\nICMP messages are grouped into two major categories:\n\n\n\n\nError messages\n: related to problems with delivering IP datagrams.\n\n\nQuery or information messages\n: related to information gathering and configuration.\n\n\n\n\nICMPv4 Messages\n\n\nFor ICMPv4, the informational messages include:\n\n\n\n\nEcho Request (type 8)\n\n\nEcho Reply (type 0)\n\n\nRouter Advertisement (type 9)\n\n\nRouter Solicitation (type 10)\n\n\n\n\nRouter Advertisement and Router Solicitation are together called Router Discovery.\n\n\nThe most common error message types are:\n\n\n\n\nDestination Unreachable (type 3)\n\n\nRedirect (type 5)\n\n\nTime Exceeded (type 11)\n\n\nParameter Problem (type 12)\n\n\n\n\nThe table below lists the message types defined for standard ICMPv4 messages. Types marked with asterisks (*) are the most common. Those marked with a plus (+) may contain [RFC4884] extension objects. In the fourth column, E is for error messages and I indicates query/informational messages.\n\n\n\n\n\n\n\n\nType\n\n\nOfficial Name\n\n\nReference\n\n\nE/I\n\n\nUse/Comment\n\n\n\n\n\n\n\n\n\n\n0 (*)\n\n\nEcho Reply\n\n\n[RFC0792]\n\n\nI\n\n\nEcho (\nping\n) reply; returns data\n\n\n\n\n\n\n3 (*)(+)\n\n\nDestination Unreachable\n\n\n[RFC0792]\n\n\nE\n\n\nUnreachable host/protocol\n\n\n\n\n\n\n4\n\n\nSource Quench\n\n\n[RFC0792]\n\n\nE\n\n\nIndicates congestion (deprecated)\n\n\n\n\n\n\n5 (*)\n\n\nRedirect\n\n\n[RFC0792]\n\n\nE\n\n\nIndicates alternate router should be used\n\n\n\n\n\n\n8 (*)\n\n\nEcho\n\n\n[RFC0792]\n\n\nI\n\n\nEcho (\nping\n) request (data optional)\n\n\n\n\n\n\n9\n\n\nRouter Advertisement\n\n\n[RFC1256]\n\n\nI\n\n\nIndicates router addresses/preferences\n\n\n\n\n\n\n10\n\n\nRouter Solicitation\n\n\n[RFC1256]\n\n\nI\n\n\nRequests Router Advertisement\n\n\n\n\n\n\n11 (*)(+)\n\n\nTime Exceeded\n\n\n[RFC0792]\n\n\nE\n\n\nResource exhausted (e.g., IPv4 TTL)\n\n\n\n\n\n\n12 (*)(+)\n\n\nParameter Problem\n\n\n[RFC0792]\n\n\nE\n\n\nMalformed packet or header\n\n\n\n\n\n\n\n\nFor the commonly used messages, the code numbers shown in the table below are used. Some messages are capable of carrying extended information\n\n\n\n\n\n\n\n\nType\n\n\nCode\n\n\nOfficial Name\n\n\nUse/Comment\n\n\n\n\n\n\n\n\n\n\n3\n\n\n0\n\n\nNet Unreachable\n\n\nNo route (at all) to destination\n\n\n\n\n\n\n3 (*)\n\n\n1\n\n\nHost Unreachable\n\n\nKnown but unreachable host\n\n\n\n\n\n\n3\n\n\n2\n\n\nProtocol Unreachable\n\n\nUnknown (transport) protocol\n\n\n\n\n\n\n3 (*)\n\n\n3\n\n\nPort Unreachable\n\n\nUnknown/unused (transport) port\n\n\n\n\n\n\n3 (*)\n\n\n4\n\n\nFragmentation Needed and Don\u2019t Fragment Was Set (PTB message)\n\n\nNeeded fragmentation prohibited by DF bit; used by PMTUD [RFC1191]\n\n\n\n\n\n\n3\n\n\n5\n\n\nSource Route Failed\n\n\nIntermediary hop not reachable\n\n\n\n\n\n\n3\n\n\n6\n\n\nDestination Network Unknown\n\n\nDeprecated [RFC1812]\n\n\n\n\n\n\n3\n\n\n7\n\n\nDestination Host Unknown\n\n\nDestination does not exist\n\n\n\n\n\n\n3\n\n\n8\n\n\nSource Host Isolated\n\n\nDeprecated [RFC1812]\n\n\n\n\n\n\n3\n\n\n9\n\n\nCommunication with Destination Network Administratively\n\n\nProhibited Deprecated [RFC1812]\n\n\n\n\n\n\n3\n\n\n10\n\n\nCommunication with Destination Host Administratively\n\n\nProhibited Deprecated [RFC1812]\n\n\n\n\n\n\n3\n\n\n11\n\n\nDestination Network Unreachable for Type of Service\n\n\nType of service not available (net)\n\n\n\n\n\n\n3\n\n\n12\n\n\nDestination Host Unreachable for Type of Service\n\n\nType of service not available (host)\n\n\n\n\n\n\n3\n\n\n13\n\n\nCommunication Administratively Prohibited\n\n\nCommunication prohibited by filtering policy\n\n\n\n\n\n\n3\n\n\n14\n\n\nHost Precedence Violation\n\n\nPrecedence disallowed for src/dest/port\n\n\n\n\n\n\n3\n\n\n15\n\n\nPrecedence Cutoff in Effect\n\n\nBelow minimum ToS [RFC1812]\n\n\n\n\n\n\n5\n\n\n0\n\n\nRedirect Datagram for the Network (or Subnet)\n\n\nIndicates alternate router\n\n\n\n\n\n\n5 (*)\n\n\n1\n\n\nRedirect Datagram for the Host\n\n\nIndicates alternate router (host)\n\n\n\n\n\n\n5\n\n\n2\n\n\nRedirect Datagram for the Type of Service and Network\n\n\nIndicates alternate router (ToS/net)\n\n\n\n\n\n\n5\n\n\n3\n\n\nRedirect Datagram for the Type of Service and Host\n\n\nIndicates alternate router (ToS/host)\n\n\n\n\n\n\n9\n\n\n0\n\n\nNormal Router Advertisement\n\n\nRouter\u2019s address and configuration information\n\n\n\n\n\n\n9\n\n\n16\n\n\nDoes Not Route Common Traffic\n\n\nWith Mobile IP [RFC5944], router does not route ordinary packets\n\n\n\n\n\n\n11 (*)\n\n\n0\n\n\nTime to Live Exceeded in Transit\n\n\nHop limit/TTL exceeded\n\n\n\n\n\n\n11\n\n\n1\n\n\nFragment Reassembly Time Exceeded\n\n\nNot all fragments of datagram arrived before reassembly timer expired\n\n\n\n\n\n\n12 (*)\n\n\n0\n\n\nPointer Indicates the Error\n\n\nByte offset (pointer) indicates first problem field\n\n\n\n\n\n\n12\n\n\n1\n\n\nMissing a Required Option\n\n\nDeprecated/historic\n\n\n\n\n\n\n12\n\n\n2\n\n\nBad Length Packet had invalid\n\n\nTotal Length field\n\n\n\n\n\n\n\n\nICMPv6 Messages\n\n\nICMPv6 is responsible not only for error and informational messages but also for a great deal of IPv6 router and host configuration.\n\n\n[p358-359]\n\n\nIn ICMPv6, as in ICMPv4, messages are grouped into the informational and error classes. In ICMPv6, however, all the error messages have a 0 in the high-order bit of the \nType\n field. Thus, ICMPv6 types 0 through 127 are all errors, and types 128 through 255 are all informational. Many of the informational messages are request/reply pairs.\n\n\nIn comparing the common ICMPv4 messages with the ICMPv6 standard messages, we conclude that some of the effort in designing ICMPv6 was to eliminate the unused messages from the original specification while retaining the useful ones. Following this approach, ICMPv6 also makes use of the \nCode\n field, primarily to refine the meanings of certain error messages.\n\n\n[p360]\n\n\nIn addition to the Type and Code fields that define basic functions in ICMPv6, a large number of standard options are also supported, some of which are required.  This distinguishes ICMPv6 from ICMPv4 (ICMPv4 does not have options).\n\n\nProcessing of ICMP Messages\n\n\nIn ICMP, the processing of incoming messages varies from system to system. Generally:\n\n\n\n\nIncoming informational requests are handled automatically by the operating system.\n\n\nError messages are delivered to user processes or to a transport protocol such as TCP.\n\n\n\n\nThe processes may choose to act on them or ignore them. Exceptions to this general rule include:\n\n\n\n\nThe Redirect message. This results in an automatic update to the host\u2019s routing table.\n\n\nThe Destination Unreachable\u2014Fragmentation Required messages. This is used in the path MTU discovery (PMTUD) mechanism, which is generally implemented by the transport-layer protocols such as TCP.\n\n\n\n\nIn ICMPv6, the following rules are applied when processing incoming ICMPv6 messages:\n\n\n\n\nUnknown ICMPv6 error messages must be passed to the upper-layer process that produced the datagram causing the error (if possible).\n\n\nUnknown ICMPv6 informational messages are dropped.\n\n\nICMPv6 error messages include as much of the original (\"offending\") IPv6 datagram that caused the error as will fit without making the error message datagram exceed the minimum IPv6 MTU (1280 bytes).\n\n\nWhen processing ICMPv6 error messages, the upper-layer protocol type is extracted from the original or \"offending\" packet (contained in the body of the ICMPv6 error message) and used to select the appropriate upper-layer process. If this is not possible, the error message is silently dropped after any IPv6-layer processing.\n\n\nThere are special rules for handling errors (see Section 8.3).\n\n\nAn IPv6 node must limit the rate of ICMPv6 error messages it sends. There are a variety of ways of implementing the rate-limiting\n\n\n\n\nICMP Error Messages\n\n\nThe distinction between the error and informational classes of ICMP messages is important. An ICMP error message is not to be sent in response to any of the following messages:\n\n\n\n\nAnother ICMP error message,\n\n\nDatagrams with bad headers (e.g., bad checksum),\n\n\nIP-layer broadcast/multicast datagrams,\n\n\nDatagrams encapsulated in link-layer broadcast or multicast frames,\n\n\nDatagrams with an invalid or network zero source address,\n\n\nAny fragment other than the first.\n\n\n\n\nThe reason for imposing these restrictions on the generation of ICMP errors is to limit the creation of so-called \nbroadcast storms\n, a scenario in which the generation of a small number of messages creates an unwanted traffic cascade (e.g., by generating error responses in response to error responses, indefinitely). These rules can be summarized as follows:\n\n\nICMPv4 error messages *\n\n\nAn ICMPv4 error message is never generated in response to:\n\n\n\n\nAn ICMPv4 error message. (An ICMPv4 error message may, however, be generated in response to an ICMPv4 query message.)\n\n\nA datagram destined for an IPv4 broadcast address or an IPv4 multicast address (formerly known as a class D address).\n\n\nA datagram sent as a link-layer broadcast.\n\n\nA fragment other than the first.\n\n\nA datagram whose source address does not define a single host. This means that the source address cannot be any of the following:\n\n\nZero address,\n\n\nLoopback address,\n\n\nBroadcast address,\n\n\nMulticast address.\n\n\n\n\n\n\n\n\nICMPv4 error messages *\n\n\nAn ICMPv6 error message is never generated in response to\n\n\n\n\nAn ICMPv6 error message\n\n\nAn ICMPv6 Redirect message\n\n\nA packet destined for an IPv6 multicast address, with two exceptions:\n\n\nThe Packet Too Big (PTB) message\n\n\nThe Parameter Problem message (code 2)\n\n\n\n\n\n\nA packet sent as a link-layer multicast (with the exceptions noted previously)\n\n\nA packet sent as a link-layer broadcast (with the exceptions noted previously)\n\n\nA packet whose source address does not uniquely identify a single node. This means that the source address cannot be any of the following:\n\n\nUnspecified address,\n\n\nIPv6 multicast address,\n\n\nAny address known by the sender to be an anycast address.\n\n\n\n\n\n\n\n\nRate-limiting ICMP messages with token buckets *\n\n\nIn addition to the rules governing the conditions under which ICMP messages are generated, there is also a rule that limits the overall ICMP traffic level from a single sender. In [RFC4443], a recommendation for rate-limiting ICMP messages is to use a \ntoken bucket\n.\n\n\nWith a token bucket, a \"bucket\" holds a maximum number (\nB\n) of \"tokens\", each of which allows a certain number of messages to be sent. The bucket is periodically filled with new tokens (at rate \nN\n) and drained by 1 for each message sent. Thus, a token bucket (or \ntoken bucket filter\n, as it is often called) is characterized by the parameters (\nB\n, \nN\n). For small or midsize devices, [RFC4443] provides an example token bucket using the parameters (10, 10). Token buckets are a common mechanism used in protocol implementations to limit bandwidth utilization, and in many cases \nB\n and \nN\n are in byte units rather than message units.\n\n\nCopy of offending datagram headers in ICMP error message\n\n\nWhen an ICMP error message is sent, it contains a copy of the full IP header from the \"offending\" or \"original\" datagram (i.e., the IP header of the datagram that caused the error to be generated, including any IP options), plus any other data from the original datagram\u2019s IP payload area such that the generated IP/ ICMP datagram\u2019s size does not exceed a specific value. For IPv4 this value is 576 bytes, and for IPv6 it is the IPv6 minimum MTU, which is at least 1280 bytes.\n\n\nIncluding a portion of the payload from the original IP datagram lets the receiving ICMP module associate the message with one particular protocol (e.g., TCP or UDP) from the Protocol or Next Header field in the IP header and one particular user process (from the TCP or UDP port numbers that are in the TCP or UDP header contained in the first 8 bytes of the IP datagram payload area).\n\n\n[p362-363]\n\n\nExtended ICMP and Multipart Messages\n\n\n[p363-364]\n\n\nDestination Unreachable (ICMPv4 Type 3, ICMPv6 Type 1) and Packet Too Big (ICMPv6 Type 2)\n\n\nMessages of this type are used to indicate that \na datagram could not be delivered all the way to its destination because of either a problem in transit or the lack of a receiver interested in receiving it.\n Although 16 different codes are defined for this message in ICMPv4, only 4 are commonly used. These include:\n\n\n\n\nHost Unreachable (code 1)\n\n\nPort Unreachable (code 3)\n\n\nFragmentation Required/ Don\u2019t-Fragment Specified (code 4),\n\n\nCommunication Administratively Prohibited (code 13).\n\n\n\n\nIn ICMPv6, the Destination Unreachable message is type 1 with seven possible code values. In ICMPv6, as compared with IPv4, the Fragmentation Required message has been replaced by an entirely different type (type 2), but the usage is very similar to the corresponding ICMP Destination Unreachable message. In ICMPv6 this is called the Packet Too Big (PTB) message. We will use the simpler ICMPv6 PTB terminology from here onward to refer to either the ICMPv4 (type 3, code 4) message or the ICMPv6 (type 2, code 0) message.\n\n\nICMPv4 Host Unreachable (Code 1) and ICMPv6 Address Unreachable (Code 3)\n\n\nThis form of the Destination Unreachable message is \ngenerated by a router or host when it is required to send an IP datagram to a host using direct delivery (\nChapter 5\n) but for some reason cannot reach the destination\n. This situation may arise, for example, because \nthe last-hop router is attempting to send an ARP request to a host that is either missing or down.\n (This situation is explored in \nChapter 4\n, which describes ARP.) For ICMPv6, which uses a somewhat different mechanism for detecting unresponsive hosts, this message can be the result of a failure in the ND process (see Section 8.5).\n\n\nICMPv6 No Route to Destination (Code 0)\n\n\n[p365]\n\n\nICMPv4 Communication Administratively Prohibited (Code 13) and ICMPv6 Communication with Destination Administratively Prohibited (Code 1)\n\n\n[p365]\n\n\nICMPv4 Port Unreachable (Code 3) and ICMPv6 Port Unreachable (Code 4)\n\n\nThe Port Unreachable message is generated when an incoming datagram is destined for an application that is not ready to receive it. This occurs most commonly in conjunction with UDP, when a message is sent to a port number that is not in use by any server process. If UDP receives a datagram and the destination port does not correspond to a port that some process has in use, UDP responds with an ICMP Port Unreachable message.\n\n\n[p366-370]\n\n\nICMPv4 PTB (Code 4)\n\n\nICMPv6 PTB (Type 2, Code 0)\n\n\nICMPv6 Beyond Scope of Source Address (Code 2)\n\n\nICMPv6 Source Address Failed Ingress/Egress Policy (Code 5)\n\n\nICMPv6 Reject Route to Destination (Code 6)\n\n\nRedirect (ICMPv4 Type 5, ICMPv6 Type 137)\n\n\nICMP Time Exceeded (ICMPv4 Type 11, ICMPv6 Type 3)\n\n\nEvery IPv4 datagram has a \nTime-to-Live\n (TTL) field in its IPv4 header, and every IPv6 datagram has a \nHop Limit\n field in its header (\nChapter 5\n).\n\n\nAs originally conceived, the 8-bit TTL field was to hold the number of seconds a datagram was allowed to remain active in the network before being forcibly discarded (a good thing if forwarding loops are present). Because of an additional rule that said that any router must decrement the TTL field by at least 1, combined with the fact that datagram forwarding times grew to be small fractions of a second, the \nTTL field has been used in practice as a limitation on the number of hops an IPv4 datagram is allowed to take before it is discarded by a router.\n This usage was formalized and\nultimately adopted in IPv6.\n\n\nICMP Time Exceeded (code 0) messages are generated when a router discards a datagram because the TTL or Hop Limit field is too low (i.e., arrives with value 0 or 1 and must be forwarded). This message is important for the proper operation of the \ntraceroute\n tool (called \ntracert\n on Windows). Its format, for both ICMPv4 and ICMPv6, is given in the figure below.\n\n\n\n\nAnother less common variant of this message is when a fragmented IP datagram only partially arrives at its destination (all its fragments do not arrive after a period of time). In such cases, a variant of the ICMP Time Exceeded message (code 1) is used to inform the sender that its overall datagram has been discarded. Recall that if any fragment of a datagram is dropped, the entire datagram is lost.\n\n\nExample: The \ntraceroute\n Tool\n\n\nThe \ntraceroute\n tool is used to determine the routers used along a path from a sender to a destination. This section discusses the operation of the IPv4 version. The approach involves sending datagrams first with an IPv4 TTL field set to 1 and allowing the expiring datagrams to induce routers along the path to send ICMPv4 Time Exceeded (code 0) messages. Each round, the sending TTL value is increased by 1, causing the routers that are one hop farther to expire the datagrams and generate ICMP messages. These messages are sent from the router\u2019s primary IPv4 address \"facing\" the sender.\n\n\nIn this example, \ntraceroute\n is used to send UDP datagrams from the laptop to the host \nwww.eecs.berkeley.edu\n. (an Internet host with IPv4 address 128.32.244.172). This is accomplished using the following command:\n\n\nLinux% traceroute \u2013m 2 www.cs.berkeley.edu\ntraceroute to web2.eecs.berkeley.edu (128.32.244.172), 2 hops max,\n52 byte packets\n 1 gw (192.168.0.1) 3.213 ms 0.839 ms 0.920 ms\n 2 10.0.0.1 (10.0.0.1) 1.524 ms 1.221 ms 9.176 ms\n\n\n\n\n\nThe \n\u2013m\n option instructs \ntraceroute\n to perform only two rounds: one using TTL = 1 and one using TTL = 2. Each line gives the information found at the corresponding TTL. For example, line 1 indicates that one hop away a router with IPv4 address 192.168.0.1 was found and that three independent round-trip-time (RTT) measurements (3.213, 0.839, and 0.920ms) were taken. The difference between the first and subsequent times relates to additional work that is involved in the first measurement (i.e., an ARP transaction).\n\n\n[p377-379]\n\n\nParameter Problem (ICMPv4 Type 12, ICMPv6 Type 4)", 
            "title": "Chapter 8. ICMPv4 and ICMPv6: Internet Control Message Protocol"
        }, 
        {
            "location": "/tcpv1/ch9/", 
            "text": "Chapter 9. Broadcasting and Local Multicasting (IGMP and MLD)", 
            "title": "Chapter 9. Broadcasting and Local Multicasting (IGMP and MLD)"
        }, 
        {
            "location": "/tcpv1/ch10/", 
            "text": "Chapter 10. User Datagram Protocol (UDP) and IP Fragmentation\n\n\nIntroduction\n\n\nUDP is a simple, datagram-oriented, transport-layer protocol that preserves message boundaries:\n\n\n\n\nIt does not provide error correction, sequencing, duplicate elimination, flow control, or congestion control.\n\n\nIt can provide error detection, and it includes the true \nend-to-end\n checksum at the transport layer.\n\n\nThe \nChecksum\n field (\nfigure_10-2.png\n) is end-to-end and is computed over the UDP pseudo-header, which includes the Source and Destination IP Address fields from the IP header. Thus, any modification made to those fields (e.g., by NAT) requires a modification to the UDP checksum.\n\n\n\n\n\n\nIt provides minimal functionality itself, so applications using it have a great deal of control over how packets are sent and processed. Applications wishing to ensure that their data is reliably delivered or sequenced must implement these protections themselves.\n\n\nEach UDP output operation requested by an application produces exactly one UDP datagram, which causes one IP datagram to be sent.\n\n\nThis is in contrast to a stream-oriented protocol such as TCP (\nChapter 15\n), where the amount of data written by an application may have little relationship to what actually gets sent in a single IP datagram or what is consumed at the receiver.\n\n\n\n\n\n\n\n\n[\nRFC0768\n] is the official specification of UDP, and it has remained as a standard without significant revisions for more than 30 years.\n\n\n\n\nUDP provides no error correction as mentioned: it sends the datagrams that the application writes to the IP layer, but there is no guarantee that they ever reach their destination.\n\n\nThere is no protocol mechanism to prevent high-rate UDP traffic from negatively impacting other network users.\n\n\n\n\nAdvantages of UDP *\n\n\nGiven this lack of reliability and protection, we might be tempted to conclude that there are no benefits to using UDP at all. This is not true, however. UDP has the following advantages:\n\n\n\n\nBecause of its connectionless character, it has less overhead than other transport protocols.\n\n\nBroadcast and multicast operations (\nChapter 9\n) are much more straightforward using a connectionless transport such as UDP.\n\n\nThe ability of an application to choose its own unit of retransmission can be an important consideration.\n\n\n\n\nEncapsulation of a UDP datagram *\n\n\nThe following figure shows the encapsulation of a UDP datagram as a single IPv4 datagram.\n\n\n\n\nThe IPv6 encapsulation is similar, but other details differ slightly (\nSection 10.5\n).\n\n\nThe IPv4 \nProtocol\n field has the value 17 to indicate UDP.\n\n\nIPv6 uses the same value (17) in the \nNext Header\n field.\n\n\nLater in this chapter\n describes what happens when the size of the UDP datagram exceeds the MTU size and the datagram must be fragmented into more than one IP-layer packet.\n\n\n\n\n\n\nUDP Header\n\n\nTHe following figure shows UDP datagram, including the payload and UDP header (which is always 8 bytes in size):\n\n\n\n\n\n\nPort numbers act as mailboxes and help a protocol implementation identify the sending and receiving processes (\nChapter 1\n). They are purely \nabstract\n: they do not correspond to any physical entity on a host. In UDP port numbers are positive 16-bit numbers:\n\n\nThe source port number is optional; it may be set to 0 if the sender of the datagram never requires a reply.\n\n\n\n\n\n\n\n\nTransport protocols such as TCP and UDP, and SCTP [RFC4960] use the destination port number to help demultiplex incoming data from IP. \nBecause IP demultiplexes the incoming IP datagram to a particular transport protocol based on the value of the \nProtocol\n field in the IPv4 header or \nNext Header\n field in the IPv6 header, this means that the port numbers can be made independent among the transport protocols. That is, TCP port numbers are used only by TCP, and the UDP port numbers only by UDP, and so on.\n A straightforward consequence of this separation is that two completely distinct servers can use the same port number and IP address, as long as they use different transport protocols.\n\n\nDespite this independence, if a well-known service is provided (or can conceivably be provided) by both TCP and UDP, the port number is normally allocated to be the same for both transport protocols. This is purely for convenience and is not required by the protocols. See [\nIPORT\n] for details on how port numbers are formally assigned.\n\n\n\n\nThe UDP \nLength\n field is the length of the UDP header and the UDP data in bytes. The minimum value for this field is 8 except when UDP is used with IPv6 jumbograms (see Section 10.5). Sending a UDP datagram with 0 bytes of data is acceptable, although rare.\n\n\nThe UDP Length field is redundant; the IPv4 header contains the datagram\u2019s total length (\nChapter 5\n), and the IPv6 header contains the payload length. The length of a UDP/IPv4 datagram is then the total length of the IPv4 datagram minus the length of the IPv4 header. A UDP/IPv6 datagram\u2019s length is the value of the Payload Length field contained in the IPv6 header minus the lengths of any extension headers (unless jumbograms are being used). In either case, the UDP Length field should match the length computed from the IP-layer information.\n\n\n\n\n\n\n\n\nUDP Checksum\n\n\nExamples\n\n\nUDP and IPv6\n\n\nUDP-Lite\n\n\nIP Fragmentation\n\n\nIP employs \nfragmentation\n and \nreassembly\n. Fragmentation in IPv4 can take place at the original sending host and at any intermediate routers along the end-to-end path. Note that datagram fragments can themselves be fragmented. Fragmentation in IPv6 is somewhat different because \nonly the source is permitted to perform fragmentation\n.\n\n\nWhen an IP datagram is fragmented, it is not reassembled until it reaches its final destination, because:\n\n\n\n\nNot performing reassembly within the network alleviates the forwarding software (or hardware) in routers from implementing this feature\n\n\nDifferent fragments of the same datagram may follow different paths to their common destination\n\n\n\n\nExample: UDP/IPv4 Fragmentation\n\n\nAn UDP application may wish to avoid IP fragmentation, because when the size of the resulting datagram exceeds the link\u2019s MTU, the IP datagram is split across multiple IP packets, which can lead to performance issues because \nif any fragment is lost, the entire datagram is lost.\n\n\n\n\nA single UDP datagram with 2992 UDP payload bytes is fragmented into three UDP/ IPv4 packets (no options). The UDP header that contains the source and destination port numbers appears only in the first fragment (a complicating factor for firewalls and NATs). Fragmentation is controlled by the \nIdentification\n, \nFragment Offset\n, and \nMore Fragments\n (MF) fields in the IPv4 header.\n\n\nThe original UDP datagram included 2992 bytes of application (UDP payload) data and 8 bytes of UDP header, resulting in an IPv4 Total Length field value of 3020 bytes (IP header is 20-byte). When this datagram was fragmented into three packets, 40 extra bytes were created (20 bytes for each of the newly created IPv4 fragment headers). Thus, the total number of bytes sent is 3060. [p489]\n\n\nFields:\n\n\n\n\nIdentification\n: its value (set by the original sender) is copied to each fragment and is used to group them together when they arrive\n\n\nFragment Offset\n: the offset of the first byte of the fragment payload byte in the original IPv4 datagram (in 8-byte units)\n\n\nMF\n: indicates whether more fragments in the datagram should be expected and is 0 only in the final fragment\n\n\n\n\nIf one fragment is lost, the entire datagram is lost, since IP itself has no error correction mechanism of its own. Mechanisms such as timeout and retransmission are left as the responsibility of the higher layers. \nFor this reason, fragmentation is often avoided.\n\n\nWe can use our \nsock\n program and increase the size of the datagram until fragmentation occurs. On an Ethernet, the maximum amount of data in a frame is ordinarily 1500 bytes, which leaves at most 1472 bytes for application data to avoid fragmentation, assuming 20 bytes for the IPv4 header and 8 bytes for the UDP header.\n\n\nWe will run our sock program with data sizes of 1471, 1472, 1473, and 1474 bytes. We expect the last two to cause fragmentation:\n\n\n[p490-492]\n\n\nLinux% sock -u -i -n1 -w1471 10.0.0.3 discard\nLinux% sock -u -i -n1 -w1472 10.0.0.3 discard\nLinux% sock -u -i -n1 -w1473 10.0.0.3 discard\nLinux% sock -u -i -n1 -w1474 10.0.0.3 discard\n\n\n\n\n\n1 23:42:43.562452 10.0.0.5.46530 \n 10.0.0.3.9:\n        udp 1471 (DF) (ttl 64, id 61350, len 1499)\n2 23:42:50.267424 10.0.0.5.46531 \n 10.0.0.3.9:\n        udp 1472 (DF) (ttl 64, id 62020, len 1500)\n3 23:42:57.814555 10.0.0.5 \n 10.0.0.3:\n        udp (frag 37671:1@1480) (ttl 64, len 21)\n4 23:42:57.814715 10.0.0.5.46532 \n 10.0.0.3.9:\n        udp 1473 (frag 37671:1480@0+) (ttl 64, len 1500)\n5 23:43:04.368677 10.0.0.5 \n 10.0.0.3:\n        udp (frag 37672:2@1480) (ttl 64, len 22)\n6 23:43:04.368838 10.0.0.5.46535 \n 10.0.0.3.9:\n        udp 1474 (frag 37672:1480@0+) (ttl 64, len 1500)\n\n\n\n\n\nOne observation that may be surprising is that the fragments with larger offsets are delivered \nprior\n to the first fragments. In effect, \nthe sender has intentionally reordered the fragments.\n This behavior can be beneficial. If the last fragment is delivered first, the receiving host is able to ascertain the maximum amount of buffer space it will require in order to reassemble the entire datagram.", 
            "title": "Chapter 10. User Datagram Protocol (UDP) and IP Fragmentation"
        }, 
        {
            "location": "/tcpv1/ch11/", 
            "text": "Chapter 11. Name Resolution and the Domain Name System (DNS)\n\n\nTo identify hosts, IP addresses (especially IPv6 addresses) are cumbersome for humans to use and remember. The Internet supports the use of \nhost names\n to identify hosts, both clients and servers. In order to be used by protocols such as TCP and IP, host names are converted into IP addresses using a process known as name resolution. There are different forms of name resolution in the Internet, but the most prevalent and important one uses a distributed database system known as the \nDomain Name System\n (DNS). DNS runs as an application on the Internet, using IPv4 or IPv6 (or both). For scalability, DNS names are hierarchical, as are the servers that support name resolution.\n\n\nDNS is a distributed client/server networked database used by TCP/IP applications to map between host names and IP addresses (and vice versa), to provide capabilities like electronic mail routing information and service naming. The DNS provides the protocol that allows clients and servers to communicate\nwith each other and also a protocol for allowing servers to exchange information. [p511]\n\n\nFrom an application\u2019s point of view, access to the DNS is through an application library called a \nresolver\n. \nAn application must convert a host name to an IPv4 and/or IPv6 address before it can ask TCP to open a connection or send a unicast datagram using UDP.\n The TCP and IP protocol implementations know nothing about the DNS; they operate only with the addresses.\n\n\nThis chapter covers:\n\n\n\n\nHow the names in DNS are set up\n\n\nHow resolvers and servers communicate using the Internet protocols (mainly UDP)\n\n\nSome other resolution mechanisms used in Internet environments.\n\n\n\n\nThe DNS Name Space\n\n\nThe DNS \nname space\n is the set of all names used with DNS. This space is partitioned hierarchically and is case insensitive.\n\n\nThe current DNS name space is a tree of domains with an unnamed root at the top. The top echelons of the tree are the so-called\ntop-level domains (TLDs), which include:\n\n\n\n\nGeneric TLDs (gTLDs)\n\n\nCountry-code TLDs (ccTLDs)\n\n\nInternationalized country-code TLDs (IDN ccTLDs)\n\n\nA special infrastructure TLD called, for historical reasons, ARPA [RFC3172].\n\n\n\n\nThese form the top levels of a naming tree with the form shown below.\n\n\n\n\nThere are five commonly used groups of TLDs, and one group of specialized domains being used for \ninternationalized domain names\n (IDNs). [p512]\n\n\nThe gTLDs are grouped into categories:\n\n\n\n\nGeneric\n\n\nGeneric-restricted\n\n\nSponsored\n\n\n\n\nThe generic gTLDs (\ngeneric\n appears twice) are open for unrestricted use. The others (generic-restricted and sponsored) are limited to various sorts of uses or are constrained as to what entity may assign names from the domain.\n\n\nThere is a \"new gTLD\" program in the works that may significantly expand the current set, possibly to several hundred or even thousand. This program and policies relating to TLD management in general are maintained by the \nInternet Corporation for Assigned Names and Numbers\n (ICANN).\n\n\nBecause some of these two-letter country codes of ccTLDs are suggestive of other uses and meanings, various countries have been able to find commercial windfalls from selling names within their ccTLDs. For example, the domain name \ncnn.tv\n is really a registration in the Pacific island of Tuvalu, which has been selling domain names associated with the television entertainment industry. This is called a \ndomain hack\n.\n\n\nDNS Naming Syntax\n\n\nThe names below a TLD in the DNS name tree are further partitioned into \nsubdomains\n, which is very common practice, especially for the ccTLDs.\n\n\nFully qualified domain name (FQDN) *\n\n\nThe example names we have seen so far are known as \nfully qualified domain names\n (FQDNs). They are sometimes written more formally with a trailing period (e.g., \nmit.edu.\n). This trailing period indicates that the name is complete; no additional information should be added to the name when performing a name resolution.\n\n\nUnqualified domain name *\n\n\nAn \nunqualified domain name\n, which is used in combination with a default domain or domain search list set during system configuration, has one or more strings appended to the end. During configuration, system is typically assigned a default domain extension and search list using DHCP. For example, the default domain \ncs.berkeley.edu\n might be configured in systems at the computer science department at UC Berkeley. If a user on one of these machines types in the name \nvangogh\n, the local resolver software converts this name to the FQDN \nvangogh.cs.berkeley.edu\n. before invoking a resolver to determine \nvangogh\n\u2019s IP address.\n\n\nA domain name consists of a sequence of \nlabels\n separated by periods. The name represents a location in the name hierarchy, where the period is the hierarchy delimiter and descending down the tree takes place from right to left in the name.\n\n\nThe hierarchical structure of the DNS name space allows different administrative authorities to manage different parts of the name space.\n For example, creating a new DNS name \nelevator.cs.berkeley.edu\n wouldrequire dealing with the owner of the \ncs.berkeley.edu\n subdomain only. The \nberkeley.edu\n and \nedu\n portions of the name space would not require alteration, so the owners of those would not need to be bothered. \nThis feature of DNS is one key aspect of its \nscalability\n. No single entity is required to administer all the changes for the entire DNS name space.\n [p516]\n\n\nName Servers and Zones\n\n\nA person responsible for managing part of the active DNS name space is supposed to arrange for at least two \nname servers\n or \nDNS servers\n to hold information about the name space so that Internet users can perform queries on the names.\n\n\nThe DNS (formed by servers) is a distributed system whose primary job is to provide name-to-address mappings; however, it can also provide a wide array of additional information.\n\n\nA \nzone\n, as the unit of administrative delegation, is a subtree of the DNS name space that can be administered separately from other zones. Every domain name exists within some zone (even the TLDs that exist in the root zone). Whenever a new record is added to a zone, the DNS administrator for the zone allocates a name and additional information (usually an IP address) for the new entry into the name server\u2019s database. For example:\n\n\n\n\nAt a small campus, one person could do this each time a new server is added to the network;\n\n\nIn a large enterprise the responsibility would have to be delegated (probably by departments or other organizational units), as one person likely could not keep up with the work.\n\n\n\n\nA DNS server can contain information for more than one zone. At any hierarchical change point in a domain name (i.e., wherever a period appears), a different zone and containing server may be accessed to provide information for the name. This is called a \ndelegation\n. A common delegation approach uses a zone for implementing a second-level domain name, such as \nberkeley.edu\n. In this domain, there may be individual hosts (e.g., \nwww.berkeley.edu\n) or other domains (e.g., \ncs.berkeley.edu\n). \nEach zone has a designated owner or responsible party who is given authority to manage the names, addresses, and subordinate zones within the zone. Often this person manages not only the contents of the zone but also the name servers that contain the zone\u2019s database(s).\n\n\nFor redundancy, zone information is supposed to exist in at least two places: there should be at least two servers containing information for each zone. All of these servers contain identical information about a zone. Among the servers, a primary server contains the zone database in a disk file, and one or more secondary servers obtain copies from the primary using a process called a \nzone transfer\n. DNS has a special protocol for performing zone transfers, but copies of a zone\u2019s contents can also be obtained using other means (e.g., the \nrsync\n utility).\n\n\nCaching\n\n\nName servers contain information (e.g. name-to-IP-address mappings) that\nmay be obtained from three sources:\n\n\n\n\nDirectly from the zone database,\n\n\nAs the result of a zone transfer (e.g., for a slave server),\n\n\nFrom another server in the course of processing a resolution.\n\n\n\n\nIn the first case, the server is said to contain authoritative information about the zone and may be called an \nauthoritative server\n for the zone. Such servers are identified by name within the zone information.\n\n\nMost name servers (except some root and TLD servers) also \ncache\n zone information they learn, up to a time limit called the \ntime to live\n (TTL). They use this cached information to answer queries. This greatly decreases the amount of DNS message traffic on the Internet. When answering a query, a server indicates whether the information it is returning has been derived from its cache or from its authoritative copy of the zone. When cached information is returned, it is common for a server to also include the domain names of the name servers that can be contacted to retrieve authoritative information about the corresponding zone.\n\n\nEach DNS record has its own TTL, which are set and altered by the zone administrator when necessary. If a zone changes, there still may exist cached data within the network, leading to incorrect DNS resolution behavior until expiry of the TTL. For this reason, some zone administrators, anticipating a change to the zone contents, first reduce the TTL before implementing the change. This reduces the window for incorrect cached data to be present in the network.\n\n\nCaching is applied both for successful and unsuccessful resolutions (called \nnegative caching\n). \nIf a request for a particular domain name fails to return a record, this fact is also cached. This reduces Internet traffic when errant applications repeatedly make requests for names that do not exist.\n\n\nIn some network configurations, the cache is maintained in a nearby name server, not in the resolvers resident in the clients. Placing the cache in the server allows any hosts on the LAN that use the nearby server to benefit from the server\u2019s cache but implies a small delay in accessing the cache over the local network. In Windows and more recent systems, the client can maintain a cache, and it is made available to all applications running on the same system. In Windows, this happens by default, and in Linux, it is a service that can be enabled or disabled.\n\n\nnscd(8)\n and \nnsswitch.conf(5)\n *\n\n\nIn Linux , the \nName Service Caching Daemon\n (NSCD) provides a client-side caching capability. It is controlled by the \n/etc/nscd.conf\n file that can indicate which types of resolutions (for DNS and some other services) are cached, along with some cache parameters such as TTL settings. T\n\n\nThe file \n/etc/nsswitch.conf\n controls how name resolution for applications takes place. It also controls whether local files, the DNS protocol, and/or NSCD is employed for mappings.\n\n\nThe DNS Protocol\n\n\nThe DNS protocol consists of two main parts:\n\n\n\n\nQuery/response protocol used for performing queries against the DNS for particular names\n\n\nProtocol for name servers to exchange database records (zone transfers)\n\n\n\n\nIt has other functionalities:\n\n\n\n\nNotifying secondary servers that the zone database has evolved and a zone transfer is necessary (DNS Notify)\n\n\nDynamically updating the zone (dynamic updates).\n\n\n\n\nDNS name resolution is the process of mapping a domain name to an IPv4 address, although IPv6 addresses mappings work in essentially the same way. DNS query/response operations are supported over the distributed DNS infrastructure consisting of servers deployed locally at each site or ISP, and a special set of \nroot servers\n. There is also a special set of \ngeneric top-level domain servers\n used for scaling some of the larger gTLDs, including COM and NET.\n\n\nAs of mid-2011, there are:\n\n\n\n\n13 root servers named by the letters \nA\n through \nM\n; 9 of them have IPv6 addresses.\n\n\n13 gTLD servers named by \nA\n through \nM\n; 2 of them have IPv6 addresses.\n\n\n\n\nSome of them are not a single physical server but a group of servers (over 50 for the J root server) that use the same IP address (i.e., using IP anycast addressing; \nChapter 2\n).\n\n\nRecursive query *\n\n\nA full resolution that is unable to benefit from preexisting cached entries takes place among several entities, as shown in the figure below:\n\n\n\n\nHere's what happened:\n\n\n\n\nMessage 1\n. The resolver software (assuming it does not know the IP address for the server EXAMPLE.COM) on A.HOME first makes a request to its local name server, GW.HOME.\n\n\nMessage 2 through 6\n.\n\n\nIf GW.HOME does not already know the IP address for EXAMPLE.COM or the name servers for either the EXAMPLE.COM domain or the COM TLD, it forwards the request to another DNS server (called \nrecursion\n), in this case, an ISP-provided DNS server.\n\n\nAssuming that the ISP-provided DNS server also does not know the required address or other information, it contacts one of the root name servers (message 3).\n\n\nThe root servers are not recursive, so they do not process the request further but instead return the information required to contact a name server for the COM TLD. For example, it might return the name A.GTLD-SERVERS.NET and one or more of its IP addresses (message 4).\n\n\nWith this (the above) information, the ISP-provided server contacts the gTLD server (message 5) and discovers the name and IP addresses of the name servers for the domain EXAMPLE.COM (message 6). In this case, one of the servers is A.IANA-SERVERS.NET.\n\n\n\n\n\n\nMessage 7 through 10\n.\n\n\nGiven the correct server for the domain, the ISP-provided server contacts the appropriate server (message 7), which responds with the requested IP address (message 8). At this point, the ISP-provided server can respond to GW.HOME with the required information (message 9).\n\n\nGW.HOME is now able to complete the initial query and responds to the client with the desired IPv4 and/or IPv6 address(es) (message 10)\n\n\n\n\n\n\n\n\nFrom A.HOME's side it seems the local name server was able to perform the request. What really happened is a \nrecursive query\n, where the GW.HOME and ISP-provided servers in turn made additional DNS requests to satisfy A.HOME\u2019s query. In general, most name servers perform recursive queries such as this. The notable exceptions are the root servers and other TLD servers that do not perform recursive queries. These servers are a relatively precious resource, so encumbering them with recursive queries for every machine that performs a DNS query would lead to poor global Internet performance.\n\n\nDefault domain search list *\n\n\nIn the previous query example, if the A.HOME system is configured with a default domain search list, there may be additional queries. For example, if .HOME is a default search domain used by A.HOME, the first DNS query may be for the name EXAMPLE.COM.HOME, which will fail at the GW.HOME name server, which is authoritative for .HOME. A subsequent query will typically remove the default extension, resulting in a query for EXAMPLE.COM.\n\n\nDNS Message Format\n\n\nThere is one basic DNS message format used for all DNS operations (queries, responses, zone transfers, notifications, and dynamic updates), as illustrated in the figure below:\n\n\n\n\nThe basic DNS message begins with a fixed 12-byte header followed by four variable-length sections:\n\n\n\n\nQuestions (or queries)\n\n\nAnswers\n\n\nAuthority records\n\n\nAdditional records.\n\n\n\n\nAll but the first section (question section) contain one or more \nresource records\n (RRs), which is detailed in \nSection 11.5.6\n. The question section contains a data item that is very close in structure to an RR. RRs can be cached; questions are not.\n\n\n\n\nThe \nTransaction ID\n field is set by the client and returned by the server, which lets the client match responses to requests.\n\n\nQR\n is a 1-bit field:\n\n\n0 means the message is a query;\n\n\n1 means it is a response.\n\n\n\n\n\n\nOpCode\n is a 4-bit field.\n\n\nThe normal value is 0 (a standard query) for requests and responses.\n\n\nOther values are: 4 (notify), and 5 (update).\n\n\nOther values (1\u20133) are deprecated or never seen in operational use.\n\n\n\n\n\n\nThe \nAA\n bit field indicates an \"authoritative answer\" as opposed to a cached answer.\n\n\nTC\n is a 1-bit field that means \"truncated\". With UDP, this flag being set means that the total size of the reply exceeded 512 bytes, and only the first 512 bytes of the reply were returned.\n\n\nRD\n is a bit field that means \"recursion desired\". It tells the server to perform a \nrecursive query\n.\n\n\nIt can be set in a query and is then returned in the response.\n\n\nIf the bit is not set and the requested name server does not have an authoritative answer, the requested name server returns a list of other name servers to contact for the answer. At this point, the overall query may be continued by contacting the list of other name servers. This is called an \niterative query\n.\n\n\n\n\n\n\nRA\n is a bit field that means \"recursion available\". This bit is set in the response if the server supports recursion. Root servers generally do not support recursion, thereby forcing clients to perform iterative queries to complete name resolution.\n\n\nThe \nZ\n bit field must be 0 for now but is reserved for future use.\n\n\nThe \nAD\n bit field is set to true if the contained information is authenticated.\n\n\nThe \nCD\n bit is set to true if security checking is disabled.\n\n\nThe \nResponse Code\n (\nRCODE\n) field is a 4-bit field with the return code. The common values include 0 (no error) and 3 (name error or \"nonexistent domain\", written as NXDOMAIN). A name error is returned only from an authoritative name server and means that the domain name specified in the query does not exist. A list of the first 11 error codes for RCODE is in the following table.\n\n\n\n\n\n\n\n\n\n\nValue\n\n\nName\n\n\nReference\n\n\nDescription and Purpose\n\n\n\n\n\n\n\n\n\n\n0\n\n\nNoError\n\n\n[RFC1035]\n\n\nNo error\n\n\n\n\n\n\n1\n\n\nFormErr\n\n\n[RFC1035]\n\n\nFormat error; query cannot be interpreted\n\n\n\n\n\n\n2\n\n\nServFail\n\n\n[RFC1035]\n\n\nServer failure; error in processing at server\n\n\n\n\n\n\n3\n\n\nNXDomain\n\n\n[RFC1035]\n\n\nNonexistent domain; unknown domain referenced\n\n\n\n\n\n\n4\n\n\nNotImp\n\n\n[RFC1035]\n\n\nNot implemented; request not supported in server\n\n\n\n\n\n\n5\n\n\nRefused\n\n\n[RFC1035]\n\n\nRefused; server unwilling to provide answer\n\n\n\n\n\n\n6\n\n\nYXDomain\n\n\n[RFC2136]\n\n\nName exists but should not (used with updates)\n\n\n\n\n\n\n7\n\n\nYXRRSet\n\n\n[RFC2136]\n\n\nRRSet exists but should not (used with updates)\n\n\n\n\n\n\n8\n\n\nNXRRSet\n\n\n[RFC2136]\n\n\nRRSet does not exist but should (used with updates)\n\n\n\n\n\n\n9\n\n\nNotAuth\n\n\n[RFC2136]\n\n\nServer not authorized for zone (used with updates)\n\n\n\n\n\n\n10\n\n\nNotZone\n\n\n[RFC2136]\n\n\nName not contained in zone (used with updates)\n\n\n\n\n\n\n\n\nThe next four fields are 16 bits in size and specify the number of entries in the question, answer, authority, and additional information sections that complete the DNS message.\n\n\n\n\nFor a query, the number of questions is normally 1 and the other three counts are 0.\n\n\nFor a reply, the number of answers is at least 1.\n\n\n\n\nQuestions have a name, type, and class. All of the other sections contain zero or more RRs. RRs contain a name, type, and class information, but also the TTL value that controls how long the data can be cached. [p521]\n\n\nNames and Labels\n\n\nThe variable-length sections at the end of a DNS message contain a collection of:\n\n\n\n\nQuestions.\n\n\nAnswers.\n\n\nAuthority information: names of name servers that contain authoritative information for certain data.\n\n\nAdditional information: useful to reduce the number of necessary queries.\n\n\n\n\nEach question and each RR begins with a \nname\n (called the domain name or owning name) to which it refers. Each name consists of a sequence of \nlabels\n. There are two categories of label types:\n\n\n\n\nData labels\n contain characters that constitute a label.\n\n\nCompression labels\n act as pointers to other labels, which helps save space in a DNS message when multiple copies of the same string of characters are present across multiple labels.\n\n\n\n\nData Labels\n\n\nEach data label begins with a 1-byte count that specifies the number of bytes that immediately follow. The name is terminated with a byte containing the value 0, which is a label with a length of 0 (the label of the root).\n\n\n\n\n\n\nEach label Length byte must be in the range of 0 to 63, as labels are limited to 63 bytes.\n\n\nThe labels contain non-ASCII values, but this is uncommon and not recommended. It is suggested that labels start with a letter, end with a letter or digit, and have as interior characters only letters, digits and hyphen. [p523]\n\n\n\n\nCompression Labels\n\n\nA DNS response may carry information in the answer, authority, and additional information sections relating to the same domain name. For data labels the same characters would be repeated in the DNS message when referring to the same name. To avoid this redundancy and save space, a compression scheme is used.\n\n\nThe following figure illustrates how to encode the domain names \nusc.edu\n and \nucla.edu\n using compression labels.\n\n\n\n\nIn the above figure, common label \nedu\n can be shared by the two domain names:\n\n\n\n\nAssuming the names start at offset 0, data labels are used to encode \nusc.edu\n as described previously.\n\n\nThe next name is \nucla.edu\n, and the label \nucla\n is encoded using a data label.\n\n\nThe label \nedu\n of \nucla.edu\n may be reused from the encoding of \nusc.edu\n. This is accomplished by setting the 2 high-order bits of the label \nType\n byte to 1 and encoding the offset of \nedu\n in the remaining 14 bits. Because the first occurrence of \nedu\n is at offset 4, we only need to set the first byte to 192 (6 bits of 0) and the next byte to 4.\n\n\n\n\nThis example shows a savings of only 4 bytes, but it is clear how compression of larger common labels can result in more substantial savings.\n\n\nThe DNS Extension Format (EDNS0)\n\n\nAn extension mechanism called \nEDNS0\n (because there could be future extensions beyond the index 0) is specified in [RFC2671]. It is necessary for supporting DNS security (\nDNSSEC\n; see \nChapter 18\n).\n\n\nEDNS0 specifies a particular type of RR (called an \nOPT pseudo-RR\n or \nmeta-RR\n) that is added to the additional data section of a request or response to indicate the use of EDNS0; at most one such record may be present in any DNS message. If a UDP DNS message includes an OPT RR, it is permitted to exceed the 512-byte length limitation and may contain an expanded set of error codes.\n\n\nEDNS0 also defines an extended label type (extending beyond the data labels and compression labels mentioned earlier). Extended labels have their first 2 bits in the label Type/Length byte set to 01, corresponding to values between 64 and 127 (inclusive). [p525]\n\n\nUDP or TCP\n\n\nThe well-known port number for DNS is 53, for both UDP and TCP.  The most common format uses the UDP/IPv4 datagram structure is shown below:\n\n\n\n\n\n\nUDP and truncated response\n. When a resolver issues a query and the response comes back with the TC bit field set (\"truncated\"), the size of the true response exceeded 512 bytes, so only the first 512 bytes are returned by the server.\n\n\nTCP and full response\n. The resolver may issue the request again, using TCP (which now must be a supported configuration [RFC5966]). This allows more than 512 bytes to be returned because TCP breaks up large messages into multiple segments.\n\n\n\n\nWhen a secondary name server for a zone starts up, it normally performs a \nzone transfer\n from the primary name server for the zone. Zone transfers can also be initiated by a timer or as a result of a DNS NOTIFY message (\nSection 11.5.8.3\n).\n\n\n\n\nFull zone transfers use TCP as they can be large.\n\n\nIncremental zone transfers, where only the updated entries are transferred, may use UDP at first but switch to TCP if the response is too large, just like a conventional query.\n\n\n\n\nWhen UDP is used, both the resolver and the server application software must perform their own timeout and retransmission. RFC1536 suggests starting with a timeout of at least 4s, and that subsequent timeouts result in an exponential increase of the timeout (a bit like TCP\u2019s algorithms; see \nChapter 14\n). Linux and UNIX-like systems allow a change to be made to the retransmission timeout parameters by altering the contents of the \n/etc/resolv.conf\n file (by setting the timeout and attempts options).\n\n\nQuestion (Query) and Zone Section Format\n\n\nThe question or query section of a DNS message lists the question(s) being referenced. The format of each question in the question section is shown the figure below. There is normally just one, although the protocol can support more. The same structure is also used for the zone section in dynamic updates (\nSection 11.5.7\n), but with different names.\n\n\n\n\nThe \nQuery Name\n is the domain name being looked up (using the encoding for labels discussed earlier)\n\n\nThe \nQuery Class\n has the following values:\n\n\n1: the Internet class\n\n\n254: no class\n\n\n255: all classes\n\n\n\n\n\n\nThe \nQuery Type\n field holds a value indicating the type of query being performed.\n\n\nThe most common query type is A (or AAAA if IPv6 DNS resolution is enabled), which means that an IP address is desired for the query name.\n\n\nA query of type ANY returns all RRs of any type in the same class that match the query name.\n\n\n\n\n\n\n\n\nAnswer, Authority, and Additional Information Section Formats\n\n\nThe answer, authority, and additional information (final sections in the DNS message) sections contain sets of RRs. RRs in these sections can, for the most part, have wildcard domain names as owning names. These are domain names in which the asterisk label (a data label containing only the asterisk character) appears first.\n\n\n\n\n\n\nThe \nName\n field (sometimes called the \"owning name\", \"owner\", or \"record owner\u2019s name\") is the domain name to which the following resource data corresponds. It uses the same for format for names and labels described earlier.\n\n\nThe \nType\n field specifies one of the RR type codes, which are the same as the query type value described earlier.\n\n\nThe \nClass\n field is 1 for Internet data.\n\n\nThe \nTTL\n field is the number of seconds for which the RR can be cached.\n\n\nThe \nResource Data Length\n (\nRDLENGTH\n) field specifies the number of bytes contained in the \nResource Data\n (\nRDATA\n) field. The format of this data depends on the type. For example, A records (type 1) have a 32-bit IPv4 address in the RDATA area.\n\n\n\n\nThe \nResource Record Set\n (RRSet) is a set of resource records that share the same name, class, and type but not the same data. For example, \nRRSet occurs when a host has more than one address record for its name (e.g., because it has more than one IP address). TTLs for RRs in the same RRSet must be equal.\n\n\nResource Record Types\n\n\nThere are many types of resource records and a single name may have multiple matching RRs. The following table provides a listing of the most common RR types used with conventional DNS (i.e., DNS without the DNSSEC security extensions).\n\n\n\n\n\n\n\n\nValue\n\n\nRR Type\n\n\nReference\n\n\nDescription and Purpose\n\n\n\n\n\n\n\n\n\n\n1\n\n\nA\n\n\n[RFC1035]\n\n\nAddress record for IPv4 (32-bit IPv4 address)\n\n\n\n\n\n\n2\n\n\nNS\n\n\n[RFC1035]\n\n\nName server; provides name of authoritative name server for zone\n\n\n\n\n\n\n5\n\n\nCNAME\n\n\n[RFC1035]\n\n\nCanonical name; maps one name to another (to provide a form of name aliasing)\n\n\n\n\n\n\n6\n\n\nSOA\n\n\n[RFC1035]\n\n\nStart of authority; provides authoritative information for the zone (name servers, e-mail address of contact, serial number, zone transfer timers)\n\n\n\n\n\n\n12\n\n\nPTR\n\n\n[RFC1035]\n\n\nPointer; provides address to (canonical) name mapping; used with in-addr.arpa and ip6.arpa domains for IPv4 and IPv6 reverse queries\n\n\n\n\n\n\n15\n\n\nMX\n\n\n[RFC1035]\n\n\nMail exchanger; provides name of e-mail handling host for a domain\n\n\n\n\n\n\n16\n\n\nTXT\n\n\n[RFC1035] [RFC1464]\n\n\nText; provides a variety of information (e.g., used with SPF anti-spam scheme to identify authorized e-mail servers)\n\n\n\n\n\n\n28\n\n\nAAAA\n\n\n[RFC3596]\n\n\nAddress record for IPv6 (128-bit IPv6 address)\n\n\n\n\n\n\n33\n\n\nSRV\n\n\n[RFC2782]\n\n\nServer selection; transport endpoints of a generic service\n\n\n\n\n\n\n35\n\n\nNAPTR\n\n\n[RFC3403]\n\n\nName authority pointer; supports alternative name spaces\n\n\n\n\n\n\n41\n\n\nOPT\n\n\n[RFC2671]\n\n\nPseudo-RR; supports larger datagrams, labels, return codes in EDNS0\n\n\n\n\n\n\n251\n\n\nIXFR\n\n\n[RFC1995]\n\n\nIncremental zone transfer\n\n\n\n\n\n\n252\n\n\nAXFR\n\n\n[RFC1035] [RFC5936]\n\n\nFull zone transfer; carried over TCP\n\n\n\n\n\n\n255\n\n\n(ANY)\n\n\n[RFC1035]\n\n\nRequest for all (any) records\n\n\n\n\n\n\n\n\nDynamic Updates (DNS UPDATE)\n\n\nZone Transfers and DNS NOTIFY\n\n\nFull Zone Transfers (AXFR Messages)\n\n\nIncremental Zone Transfers (IXFR Messages)\n\n\nDNS NOTIFY\n\n\nSort Lists, Round-Robin, and Split DNS\n\n\nConsider what data is returned and in what order in response to a DNS query. A DNS server could return all matching data to any client in whatever order the server finds most convenient. However, special configuration options and behaviors are available in most DNS server software to achieve certain operational, privacy, or performance goals. Consider the the topology shown below:\n\n\n\n\nA host wishing to contact M performs a DNS lookup that returns two addresses: one associated with the internal network and one with the DMZ. \nIt would be more efficient if A, B, and R reached M via the DMZ and C reached M via the internal network, which happens if the DNS server orders its returned address records based on the source IP address of the request\n (It could also use the destination IP address, especially if M uses multiple IP addresses from different subnets on the same network interface.):\n\n\n\n\nIf the requesting system uses a source IP address with the same network prefix as the source of a returning address record, the DNS server places the set of such matching records early in the returned message. This behavior encourages the client to find the \"closest\" IP address for a particular server it is attempting to contact, because most simple applications attempt to contact the first address found among the returned address records.\n\n\nThe precise behavior can usually be controlled using a so-called \nsortlist\n or \nrrset-order\n directive (options used in configuration files for resolvers and servers). Such sorting behavior may also happen automatically if performed by the DNS server software by default.\n\n\n\n\nLoad-balancing *\n\n\nA related situation arises when one service is offered using more than one server such that the incoming connections are load-balanced (i.e., divided among the servers).\n\n\nIn the preceding example, imagine that a service is offered on both A and B and such a service may be identified by the URL \nhttp://www.example.com\n:\n\n\n\n\nRequesting clients (like R) perform a DNS query on the domain name \nwww.example.com\n, and the DNS server eventually returns a set of address records.\n\n\nTo achieve load balancing, the DNS server may be configured to use DNS round-robin, which means that the server permutes the order of the returned address records. This encourages each new client to access the service on a different server from the previous client.\n\n\n\n\nHowever, this load balancing mechanism is far from perfect:\n\n\n\n\nWhen records are cached, the desired effect may not occur because of reuse of existing cached address records.\n\n\nIn addition, this scheme may balance the number of connections well across servers, but not the load. Different connections can have radically different processing requirements, so the true processing load is likely to remain unbalanced unless the particular service always has the same processing requirements.\n\n\n\n\nSplit DNS\n\n\nA final consideration regarding the data returned by a DNS server is support for privacy. In the previous example, we may wish to arrange for hosts within the enterprise to be able to retrieve resource records for every computer in the network, while we limit the set of systems that remain visible to R.\n\n\nSplit DNS\n is a technique for implementing this goal. In split DNS, the set of resource records returned in response to a query is dependent on the identity of the client and possibly query destination address. Most often, the client is identified by IP address or address prefix. With split DNS, we could arrange for any host in the enterprise (i.e., those sharing a set of prefixes) to be provided with the entire DNS database, whereas those outside are given visibility only to A and B, where the main Web service is offered.", 
            "title": "Chapter 11. Name Resolution and the Domain Name System (DNS)"
        }, 
        {
            "location": "/tcpv1/ch12/", 
            "text": "Chapter 12. TCP: The Transmission Control Protocol (Preliminaries)\n\n\nIntroduction\n\n\n[p579]\n\n\nThe protocols discussed so far do not include mechanisms for delivering data reliably; they may detect that erroneous data has been received, using a checksum or CRC, but they do not try very hard to repair errors:\n\n\n\n\nWith IP and UDP, no error repair is done at all.\n\n\nWith Ethernet and other protocols based on it, the protocol provides some number of retries and then gives up if it cannot succeed.\n\n\n\n\nInformation theory and coding theory\n\n\n\n\nError-correcting codes\n (adding redundant bits so that the real information can be retrieved even if some bits are damaged) is one way to correct communications problems is one very important method for handling errors.\n\n\nAutomatic Repeat Request\n (ARQ): which means \"try sending again\" until the information is finally received. This approach forms the basis for many communications protocols, including TCP.\n\n\n\n\nARQ and Retransmission\n\n\nFor a multihop communications channel, there are other problems besides packet bit errors:\n\n\n\n\nProblems that arise at an intermediate router\n\n\nPacket reordering\n\n\nPacket duplication\n\n\nPacket erasures (drops)\n\n\n\n\nAn error-correcting protocol designed for use over a multihop communications channel (such as IP) must cope with all of these problems.\n\n\nPacket drops and bit errors\n\n\nA straightforward method dealing with packet drops (and bit errors) is to resend the packet until it is received properly. This requires a way to determine:\n\n\n\n\nWhether the receiver has received the packet.\n\n\nWhether the packet it received was the same one the sender sent.\n\n\n\n\nThis is solved by using acknowledgment (ACK): the sender sends a packet and awaits an ACK. When the receiver receives\nthe packet, it sends the ACK. When the sender receives the ACK, it sends another\npacket, and the process continues. Interesting questions to ask here are:\n\n\n\n\nHow long should the sender (expect to) wait for an ACK?\n\n\nThis is discussed in \nChapter 14\n.\n\n\n\n\n\n\nWhat if the ACK is lost?\n\n\nIf an ACK is dropped, the sender cannot distinguish this case from the case in which the original packet is dropped, so it simply sends the packet again. The receiver may receive two or more copies in that case, so it must be prepared to handle that situation\n\n\n\n\n\n\nWhat if the packet was received but had errors in it?\n\n\nDetecting errors is easiter than correcting errors. By using a form of checksum. When a receiver receives a packet containing an error, it refrains from sending an ACK. Eventually, the sender resends the packet, which ideally arrives undamaged.\n\n\n\n\n\n\n\n\nPacket duplication\n\n\nThe receiver might receive duplicate copies of the packet. This problem is addressed using a \nsequence number\n. Every unique packet gets a new sequence number when it is sent at the source, and this sequence number is carried along in the packet itself. The receiver can use this number to determine whether it has already seen the packet and if so, discard it.\n\n\nEfficiency\n\n\nThe protocol described so far is reliable but not very efficient. The sender injects a single packet into the communications path but then must stop until it hears the ACK. This protocol is therefore called \"\nstop and wait\n\". Its throughput performance (data sent on the network per unit time) is proportional to \nM/R\n where \nM\n is the packet size and \nR\n is the round-trip time (RTT), assuming no packets are lost or irreparably damaged in transit. For a fixed-size packet, as \nR\n goes up, the throughput goes down. If packets are lost or damaged, the situation is even worse: the \"\ngoodput\n\" (useful amount of data transferred per unit time) can be considerably less than the throughput.\n\n\nFor a network that doesn\u2019t damage or drop many packets, the cause for low throughput is usually that the network is not being kept busy. The situation is similar to using an assembly line where new work cannot enter the line until a complete product emerges. Most of the line goes idle. We could have more than one work unit in the line at a time. This is same for networks: if we could have more than one packet in the network, we would keep it \"more busy\", leading to higher throughput.\n\n\nAllowing more than one packet to be in the network at a time:\n\n\n\n\nThe sender must decide not only when to inject a packet into the network, but also how many. It also must figure out how to keep the timers when waiting for ACKs, and it must keep a copy of each packet not yet acknowledged in case retransmissions are necessary.\n\n\nThe receiver needs to have a more sophisticated ACK mechanism: one that can distinguish which packets have been received and which have not.\n\n\nThe receiver may need a more sophisticated buffering (packet storage) mechanism: one that allows it to hold \"out-of-sequence\" packets (those packets that have arrived earlier than those expected because of loss or reordering).\n\n\n\n\nThere are other issues:\n\n\n\n\nWhat if the receiver is slower than the sender? If the sender simply injects many packets at a very high rate, the receiver might just drop them because of processing or memory limitations. The same question can be asked about the routers in the middle.\n\n\nWhat if the network infrastructure cannot handle the rate of data the sender and receiver wish to use?\n\n\n\n\nWindows of Packets and Sliding Windows\n\n\nAssume each unique packet has a sequence number. We define a \nwindow\n of packets as the collection of packets (or their sequence numbers) that have been injected by the sender but not yet completely acknowledged (the sender has not received an ACK for them). We refer to the \nwindow size\n as the number of packets in the window.\n\n\n\n\nIn the figure:\n\n\n\n\nPacket number 3 has already been sent and acknowledged, so the copy of it that the sender was keeping can now be released.\n\n\nPacket 7 is ready at the sender but not yet able to be sent because it is not yet \"in\" the window.\n\n\nWhen the sender receives an ACK for packet 4, the window \"slides\" to the right by one packet, meaning that the copy of packet 4 can be released and packet 7 can be sent.\n\n\n\n\nThis movement of the window gives rise to another name for this type of protocol, a \nsliding window\n protocol.\n\n\nTypically, this window structure is kept at both the sender and the receiver.\n\n\n\n\nAt the sender, it keeps track of what packets can be released, awaiting ACKs, and cannot yet be sent.\n\n\nAt the receiver, it keeps track of:\n\n\nWhat packets have already been received and acknowledged,\n\n\nWhat packets are expected (and how much memory has been allocated to hold them),\n\n\nWhich packets (even if received) will not be kept because of limited memory.\n\n\n\n\n\n\n\n\nAlthough the window structure is convenient for keeping track of data as it flows between sender and receiver, it does not provide guidance as to how large the window should be, or what happens if the receiver or network cannot handle the sender\u2019s data rate.\n\n\nVariable Windows: Flow Control and Congestion Control\n\n\nFlow control\n can handle problem that arises when a receiver is too slow relative to a sender, by forcing the sender to slow down when the receiver cannot keep up. It is usually handled in one of two ways:\n\n\n\n\nRate-based flow control\n gives the sender a certain data rate allocation and ensures that data is never allowed to be sent at a rate that exceeds the allocation. This type of flow control is most appropriate for streaming applications and can be used with broadcast and multicast delivery (Chapter 9).\n\n\nWindow-based flow control\n is the most popular approach when sliding windows are being used. In this approach, the window size is not fixed but is instead allowed to vary over time.\n\n\nWindow advertisement\n, or simply a \nwindow update\n is a method for the receiver to signal the sender how large a window to use. This value is used by the sender (the receiver of the window advertisement) to adjust its window size.\n\n\nLogically, window update is separate from the ACKs we discussed previously, but in practice the window update and ACK are carried in a single packet, meaning that the sender tends to adjust the size of its window at the same time it slides it to the right.\n\n\n\n\n\n\n\n\nIf we consider the effect of changing the window size at the sender, it becomes clear how this achieves flow control. The sender is allowed to inject \nW\n packets into the network before it hears an ACK for any of them. If the sender and receiver are sufficiently fast, and the network loses no packets and has an infinite capacity, this means that the transfer rate is proportional to (\nSW/R\n) bits/s, where \nW\n is the window size, \nS\n is the packet size in bits, and \nR\n is the RTT. When the window advertisement from the receiver clamps the value of \nW\n at the sender, the sender\u2019s overall rate can be limited so as to not overwhelm the receiver.\n\n\nThis approach works fine for protecting the receiver, but what about the network in between? We may have routers with limited memory between the sender and the receiver that have to contend with slow network links. When this happens, it is possible for the sender\u2019s rate to exceed a router\u2019s ability to keep up, leading to packet loss. This is addressed with a special form of flow control called \ncongestion control\n.\n\n\nCongestion control involves the sender slowing down so as to not overwhelm the network between itself and the receiver.\n\n\n\n\nExplicit signaling\n uses a window advertisement to signal the sender to slow down for the receiver.\n\n\nImplicit signaling\n: the sender guesses that it needs to slow down. It would involve deciding to slow down based on some other evidence.\n\n\n\n\nThe problem of congestion control in datagram-style networks, and more generally \nqueuing theory\n to which it is closely related, has remained a major research topic for years, and it is unlikely to ever be solved completely for all circumstances. It is also not practical to discuss all the options and methods of performing flow control here. In Chapter 16 we will explore the particular congestion control technique used with TCP in more detail, along with a number of variants that have arisen over the years.\n\n\nSetting the Retransmission Timeout\n\n\nOne of the most important performance issues is how long to wait before concluding that a packet has been lost and should be resent. That is, \nWhat should the retransmission timeout be?\n Intuitively, the amount of time the sender should wait before\nresending a packet is about the sum of the following times:\n\n\n\n\nThe time to send the packet,\n\n\nThe time for the receiver to process it and send an ACK,\n\n\nThe time for the ACK to travel back to the sender,\n\n\nThe time for the sender to process the ACK.\n\n\n\n\nIn practice, none of these times are known with certainty and any or all of them vary over time as additional load is added to or removed from the end hosts or routers.\n\n\nBecause it is not practical for the user to estimate all the times, a better strategy is to have the protocol implementation try to estimate them. This is called \nround-trip-time estimation\n and is a statistical process. The true RTT is likely to be close to the sample mean of a collection of samples of RTTs. This average naturally changes over time (it is not stationary), as the paths taken through the network may change.\n\n\n[p584]\n\n\nIt would not be sensible to set the retransmission timer to be exactly equal to the mean estimator, as it is likely that many actual RTTs will be larger, thereby inducing unwanted retransmissions.\n\n\n\n\nThe timeout should be set to something larger than the mean, but exactly what this relationship is (or even if the mean should be directly used) is not yet clear.\n\n\nSetting the timeout too large is also undesirable, as this leads back to letting the network go idle, reducing throughput.\n\n\n\n\nThis is further explored in Chapter 14.\n\n\nIntroduction to TCP\n\n\nOur description of TCP starts in this chapter and continues in the next five chapters:\n\n\n\n\nChapter 13: how a TCP connection is established and terminated.\n\n\nChapter 14:\n\n\nHow TCP estimates the per-connection RTT.\n\n\nHow the retransmission timeout is set based on the above estimate.\n\n\n\n\n\n\nChapter 15:\n\n\nNormal transfer of data (starting with \"interactive\" applications, such as chat).\n\n\nWindow management and flow control, which apply to both interactive and \"bulk\" data flow applications (such as file transfer).\n\n\nUrgent mechanism\n of TCP, which allows a sender to mark certain data in the data stream as special.\n\n\n\n\n\n\nChapter 16:\n\n\nCongestion control algorithms in TCP that help to reduce packet loss when the network is very busy.\n\n\nModifications that have been proposed to increase throughput on fast networks or improve resiliency on lossy (e.g., wireless) networks.\n\n\n\n\n\n\nChapter 17: how TCP keeps connections active even when no data is flowing.\n\n\n\n\nThe TCP Service Model\n\n\nEven though TCP and UDP use the same network layer (IPv4 or IPv6), TCP provides a totally different service to the application layer from what UDP does. \nTCP provides a \nconnection-oriented\n, reliable, byte stream service.\n The term connection-oriented means that the two applications using TCP must establish a TCP connection by contacting each other before they can exchange data. There are exactly two endpoints communicating with each other on a TCP connection; concepts such as broadcasting and multicasting (Chapter 9) are not applicable to TCP.\n\n\nTCP provides a byte stream abstraction to applications that use it. Its consequence is that no record markers or message boundaries are automatically inserted by TCP (\nChapter 1\n). A record marker corresponds to an indication of an application\u2019s write extent. If the application on one end writes 10 bytes, followed by a write of 20 bytes, followed by a write of 50 bytes, the application at the other end of the connection cannot tell what size the individual writes were. For example, the other end may read the 80 bytes in four reads of 20 bytes at a time or in some other way. One end puts a stream of bytes into TCP, and the identical stream of bytes appears at the other end. Each endpoint individually chooses its read and write sizes.\n\n\nTCP does not interpret the contents of the bytes in the byte stream at all. It has no idea if the data bytes being exchanged are binary data, ASCII characters, \nEBCDIC\n characters, or something else. The interpretation of this byte stream is up to the applications on each end of the connection. TCP supports the urgent mechanism mentioned before, although it is no longer recommended for use.\n\n\nReliability in TCP\n\n\nTCP provides reliability using specific variations on the techniques just described.\n\n\n\n\nPacketization\n: TCP must convert a sending application\u2019s stream of bytes into a set of packets that IP can carry, since it provides a byte stream interface.\n\n\nRepacketization\n: these packets contain sequence numbers, which in TCP actually represent the byte offsets of the first byte in each packet in the overall data stream rather than packet numbers. This allows packets to be of variable size during a transfer and may also allow them to be combined.\n\n\n\n\nThe application data is broken into what TCP considers the best-size chunks to send, typically fitting each segment into a single IP-layer datagram that will not be fragmented.  This is different from UDP, where each write by the application usually generates a UDP datagram of that size (plus headers). The chunk passed by TCP to IP is called a \nsegment\n. Chapter 15 discusses how TCP decides what size a segment should be.\n\n\nTCP Header and Encapsulation\n\n\nTCP is encapsulated in IP datagrams as shown the figure below:\n\n\n\n\nThe TCP header (show in the figure below) is considerably more complicated than the UDP header (\nChapter 10\n). This is not very surprising, as TCP is a significantly more complicated protocol that must keep each end of the connection informed (synchronized) about the current state.\n\n\n\n\nEach TCP header contains the source and destination port number. \nThe source and destination port number, along with the source and destination IP addresses in the IP header, uniquely identify each connection.\n\n\nThe combination of an IP address and a port number is sometimes called an \nendpoint\n or \nsocket\n in the TCP literature. The term \"socket\" appeared in [RFC0793] and was ultimately adopted as the name of the Berkeley-derived programming interface for network communications (called \"Berkeley sockets\"). It is a \npair\n of sockets or endpoints (\nthe 4-tuple consisting of the client IP address, client port number, server IP address, and server port number) that uniquely identifies each TCP connection\n. This fact will become important when we look at how a TCP server can communicate with multiple clients (\nChapter 13\n).\n\n\nSequence Number and Acknowledgment Number fields *\n\n\n\n\nThe \nSequence Number\n field identifies the byte in the stream of data from the sending TCP to the receiving TCP that the first byte of data in the containing segment represents.\n\n\nIf we consider the stream of bytes flowing in one direction between two applications, TCP numbers each byte with a sequence number.\n\n\nThis sequence number is a 32-bit unsigned number that wraps back around to 0 after reaching (2\n32\n) \u2212 1.\n\n\n\n\n\n\nThe \nAcknowledgment Number\n field (also called the \nACK Number\n or ACK field for short) contains the next sequence number that the sender of the acknowledgment expects to receive. \nThis is therefore the sequence number of the last successfully received byte of data plus 1.\n\n\nThis field is valid only if the \nACK\n bit field is on\n, which it usually is for all but initial and closing segments.\n\n\nSending an ACK costs nothing more than sending any other TCP segment because the 32-bit ACK Number field is always part of the header, as is the ACK bit field.\n\n\n\n\n\n\n\n\nWhen a new connection is being established, the \nSYN\n bit field is turned on in the first segment sent from client to server. Such segments are called \nSYN segments\n, or simply \nSYNs\n. The Sequence Number field contains the first sequence number to be used on that direction of the connection for subsequent sequence numbers and in returning ACK numbers. This number is not 0 or 1 but instead is another number, often randomly chosen, called the \ninitial sequence number\n (ISN). The reason for the ISN not being 0 or 1 is a security measure and will be discussed in \nChapter 13\n. The sequence number of the first byte of data sent on this direction of the connection is the ISN plus 1 because the SYN bit field consumes one sequence number. Consuming a sequence number also implies reliable delivery using retransmission (discussed later). Thus, SYNs and application bytes (and FINs) are reliably delivered. ACKs, which do not consume sequence numbers, are not.\n\n\nTCP can be described as \"a sliding window protocol with cumulative positive acknowledgments\". The \nACK Number\n field is constructed to indicate \nthe largest byte received in order at the receiver (plus 1)\n. For example, if bytes 1\u20131024 are received OK, and the next segment contains bytes 2049\u20133072, the receiver cannot use the regular ACK Number field to signal the sender that it received this new segment. Modern TCPs, however, have a \nselective acknowledgment\n (SACK) option that allows the receiver to indicate to the sender out-of-order data it has received correctly. When paired with a TCP sender capable of \nselective repeat\n, a significant performance benefit may be realized [FF96]. \nChapter 14\n discusses how TCP uses \nduplicate acknowledgments\n (multiple segments with the same ACK field) to help with its congestion control and error control procedures\n\n\nOther fields in the TCP header *\n\n\n\n\nThe \nHeader Length\n field gives the length of the header in 32-bit words. This is required because the length of the \nOptions\n field is variable.\n\n\nWith a 4-bit field, TCP is limited to a 60-byte header.\n\n\nWithout options, the size is 20 bytes.\n\n\n\n\n\n\n\n\nCurrently eight bit fields are defined for the TCP header, although some older implementations understand only the last six of them ([RFC3540], an experimental RFC, also defines the least significant of the Resv bits as a nonce sum (NS)). One or more of them can be turned on at the same time. Their use are briefly mentioned here and detailed in later chapters:\n\n\n\n\nCWR\n. Congestion Window Reduced (the sender reduced its sending rate); see \nChapter 16\n.\n\n\nECE\n. ECN Echo (the sender received an earlier congestion notification); see Chapter 16.\n\n\nURG\n. Urgent (the \nUrgent Pointer\n field is valid; rarely used); see \nChapter 15\n.\n\n\nACK\n. Acknowledgment (the \nAcknowledgment Number\n field is valid; always on after a connection is established); see \nChapters 13\n and 15.\n\n\nPSH\n. Push (the receiver should pass this data to the application as soon as possible; not reliably implemented or used); see Chapter 15.\n\n\nRST\n. Reset the connection (connection abort, usually because of an error); see Chapter 13.\n\n\nSYN\n. Synchronize sequence numbers to initiate a connection; see Chapter 13.\n\n\nFIN\n. The sender of the segment is finished sending data to its peer; see Chapter 13.\n\n\n\n\nRemaining fields:\n\n\n\n\nWindow Size\n field. TCP\u2019s flow control is provided by each end advertising a window size using the Window Size field. This is the number of bytes, starting with the one specified by the ACK number, that the receiver is willing to accept. This is a 16-bit field, limiting the window to 65,535 bytes, and thereby limiting TCP\u2019s throughput performance. \nChapter 15\n discusses the Window Scale option that allows this value to be scaled, providing much larger windows and improved performance for high-speed and long-delay networks.\n\n\nThe \nTCP Checksum\n field covers the TCP header and data and some fields in the IP header, using a pseudo-header computation similar to the one used with ICMPv6 and UDP discussed in \nChapters 8\n and \nChapter 10\n. It is mandatory for this field to be calculated and stored by the sender, and then verified by the receiver.  The TCP checksum is calculated with the same algorithm as the IP, ICMP, and UDP (\"Internet\") checksums.\n\n\nThe \nUrgent Pointer\n field is valid only if the \nURG\n bit field is set. This \"pointer\" is a positive offset that must be added to the Sequence Number field of the segment to yield the sequence number of the last byte of urgent data. TCP\u2019s urgent mechanism is a way for the sender to provide specially marked data to the other end.\n\n\nThe most common \nOption\n field is the \nMaximum Segment Size\n option, called the MSS. Each end of a connection normally specifies this option on the first segment it sends (the ones with the SYN bit field set to establish the connection). \nThe MSS option specifies the maximum-size segment that the sender of the option is willing to receive in the reverse direction.\n The MSS option is detailed in \nChapter 13\n and some of the other TCP options in \nChapters 14\n and \nChapter 15\n.\n\n\nOther common options include SACK, Timestamp, and Window Scale.\n\n\n\n\n\n\n\n\nTCP segments without data *\n\n\nIn \nFigure 12-2\n, the data portion of the TCP segment is optional. The TCP segment without data may be one of the following cases:\n\n\n\n\nConnection establishment and termination\n. \nWhen a connection is established, and when a connection is terminated, segments are exchanged that contain only the TCP header (with or without options) but no data\n.\n\n\nAcknowledgment\n. A header without any data is also used to acknowledge received data, if there is no data to be transmitted in that direction (called a pure ACK)\n\n\nWindow update\n notifies the communication peer of a change in the window size.\n\n\nThere are also some cases resulting from timeouts when a segment can be sent without any data.\n\n\n\n\nSummary\n\n\nThe problem of providing reliable communications over lossy communication channels has been studied for years. The two primary methods for dealing with errors include error-correcting codes and data retransmission. The protocols using retransmissions must also handle data loss, usually by setting a timer, and must also arrange some way for the receiver to signal the sender what it has received.  Deciding how long to wait for an ACK can be tricky, as the appropriate time may change as network routing or load on the end systems varies. Modern protocols estimate the round-trip time and set the retransmission timer based on some function of these measurements.\n\n\nExcept for setting the retransmission timer, retransmission protocols are simple when only one packet may be in the network at one time, but they perform poorly for networks where the delay is high. To be more efficient, multiple packets must be injected into the network before an ACK is received. This approach is more efficient but also more complex. A typical approach to managing the complexity is to use sliding windows, whereby packets are marked with sequence numbers, and the window size bounds the number of such packets. When the window size varies based on either feedback from the receiver or other signals (such as dropped packets), both flow control and congestion control can be achieved.\n\n\nTCP provides a reliable, connection-oriented, byte stream, transport-layer service built using many of these techniques. We looked briefly at all of the fields in the TCP header, noting that most of them are directly related to these abstract concepts in reliable delivery. We will examine them in detail in the chapters that follow. TCP packetizes the application data into segments, sets a timeout anytime it sends data, acknowledges data received by the other end, reorders out-of-order data, discards duplicate data, provides end-to-end flow control, and calculates and verifies a mandatory end-to-end checksum. It is the most widely used protocol on the Internet. It is used by most of the popular applications, such as HTTP, SSH/TLS, \nNetBIOS\n (NBT\u2014NetBIOS over TCP), Telnet, FTP, and electronic mail (SMTP). Many distributed file-sharing applications (e.g., BitTorrent, Shareaza) also use TCP.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np589 on SYN segments:\n\n\n\n\nConsuming a sequence number also implies reliable delivery using retransmission (discussed later). Thus, SYNs and application bytes (and FINs) are reliably delivered. ACKs, which do not consume sequence numbers, are not.\n\n\n\n\nWhy?", 
            "title": "Chapter 12. TCP: The Transmission Control Protocol (Preliminaries)"
        }, 
        {
            "location": "/tcpv1/ch13/", 
            "text": "Chapter 13. TCP Connection Management\n\n\nIntroduction\n\n\nTCP is a unicast \nconnection-oriented\n protocol. Before either end can send data to the other, a connection must be established between them. TCP detects and repairs essentially all the data transfer problems that may be introduced by packet loss, duplication, or errors at the IP layer (or below).\n\n\nBecause of its management of \nconnection state\n (information about the connection kept by both endpoints), TCP is a considerably more complicated protocol than UDP (\nChapter 10\n). UDP is a connectionless protocol that involves no connection establishment or termination. One of the major differences between the two is the amount of detail required to handle the various TCP states properly: when connections are created, terminated normally, and reset without warning. Other chapters discuss what happens once the connection is established and data is transferred.\n\n\nDuring connection establishment, several options can be exchanged between the two endpoints regarding the parameters of the connection. Some options are allowed to be sent only when the connection is established, and others can be sent later. The TCP header has a limited space for holding options (40 bytes). (\nChapter 12\n)\n\n\nTCP Connection Establishment and Termination\n\n\nA TCP connection is defined to be a 4-tuple consisting of two IP addresses and two port numbers. It is a pair of \nendpoints\n or \nsockets\n where each endpoint is identified by an (IP address, port number) pair.\n\n\nA connection typically goes through three phases:\n\n\n\n\nSetup\n\n\nData transfer (called \nestablished\n)\n\n\nTeardown (\nclosing\n).\n\n\n\n\nSome of the difficulty in creating a robust TCP implementation is handling all of the transitions between and among these phases correctly.\n\n\nA typical TCP connection establishment and close (without any data transfer) is shown below:\n\n\n\n\nConnection Establishment *\n\n\nTo establish a TCP connection, the following events usually take place:\n\n\n\n\nThe \nactive opener\n (normally called the client) sends a SYN segment (a TCP/IP packet with the SYN bit field turned on in the TCP header) specifying the port number of the peer to which it wants to connect and the client\u2019s initial sequence number or ISN(c) (\nSection 13.2.3\n). It typically sends one or more options at this point (\nSection 13.3\n). This is segment 1.\n\n\nThe server responds with its own SYN segment containing its initial sequence number (ISN(s)). This is segment 2. The server also acknowledges the client\u2019s SYN by ACKing ISN(c) plus 1. A SYN consumes one sequence number and is retransmitted if lost.\n\n\nThe client must acknowledge this SYN from the server by ACKing ISN(s) plus 1. This is segment 3.\n\n\n\n\nThese three segments complete the connection establishment. \nThis is often called the \nthree-way handshake\n. Its main purposes are to let each end of the connection know that a connection is starting and the special details that are carried as options, and to exchange the ISNs.\n\n\nThe side that sends the first SYN is said to perform an \nactive open\n. This is typically a client. The other side, which receives this SYN and sends\nthe next SYN, performs a \npassive open\n. It is most commonly called the server. (\nSection 13.2.2\n describes a supported but unusual \nsimultaneous open\n when both sides can do an active open at the same time and become both clients and servers.\n\n\nTCP supports the capability of carrying application data on SYN segments. This is rarely used, however, because the Berkeley sockets API does not support it.\n\n\nConnection Termination *\n\n\nThe \nfigure above\n also shows how a TCP connection is closed (also called cleared or terminated). Either end can initiate a close operation, and simultaneous closes are also supported but are rare. Traditionally, it was most common for the client to initiate a close. However, other servers (e.g., Web servers) initiate a close after they have completed a request. Usually a close operation starts with an application indicating its desire to terminate its connection (e.g., using the \nclose()\n system call). The closing TCP initiates the close operation by sending a FIN segment (a TCP segment with the FIN bit field set). The complete close operation occurs after both sides have completed the close:\n\n\n\n\nThe \nactive closer\n sends a FIN segment specifying the current sequence number the receiver expects to see (\nK\n in \nFigure 13-1\n). The FIN also includes an ACK for the last data sent in the other direction (labeled \nL\n in \nFigure 13-1\n).\n\n\nThe \npassive closer\n responds by ACKing value \nK\n + 1 to indicate its successful receipt of the active closer\u2019s FIN. At this point, the application is notified that the other end of its connection has performed a close. Typically this results in the application initiating its own close operation. \nThe passive closer then effectively becomes another active closer and sends its own FIN.  The sequence number is equal to \nL\n.\n\n\nTo complete the close, the final segment contains an ACK for the last FIN. Note that if a FIN is lost, it is retransmitted until an ACK for it is received.\n\n\n\n\nWhile it takes three segments to establish a connection, it takes four to terminate one. It is also possible for the connection to be in a half-open state, although this is not common. This reason is that TCP\u2019s data communications model is bidirectional, meaning it is possible to have only one of the two directions operating. \nThe \nhalf-close\n operation in TCP closes only a single direction of the data flow. Two half-close operations together close the entire connection.\n The rule is that either end can send a FIN when it is done sending data. When a TCP receives a FIN, it must notify the application that the other end has terminated that direction of data flow. The sending of a FIN is normally the result of the application issuing a close operation, which typically causes both directions to close.\n\n\nThe seven segments discussed are baseline overheads for any TCP connection that is established and cleared \"gracefully\". (There are more abrupt ways to tear down a TCP connection using special reset segments, which are covered later.) When a small amount of data needs to be exchanged, it is now apparent why some applications prefer to use UDP because of its ability to send and receive data without establishing connections. However, such applications are then faced with handling their own error repair features, congestion management, and flow control.\n\n\nTCP Half-Close\n\n\nTCP supports a half-close operation. Few applications require this capability, so it is not common. To use this feature, the API must provide a way for the application to say, \"I am done sending data, so send a FIN to the other end, but I still want to receive data from the other end, until it sends me a FIN.\"\n\n\nThe Berkeley sockets API supports half-close, if the application calls the \nshutdown()\n function instead of calling the more typical \nclose()\n function.  Most applications, however, terminate both directions of the connection by calling close. The figure below shows an example of a half-close being used. It shows the client on the left side initiating the half-close, but either end can do this.\n\n\n\n\nThe first two segments are the same as for a regular close: a FIN by the initiator, followed by an ACK of the FIN by the recipient. The operation then differs from \nFigure 13-1\n, because the side that receives the half-close can still send data.  We show only one data segment, followed by an ACK, but any number of data segments can be sent. (The exchange of data segments and acknowledgments is detailed in \nChapter 15\n.) When the end that received the half-close is done sending data, it closes its end of the connection, causing a FIN to be sent, and this delivers an end-of-file indication to the application that initiated the half-close.  When this second FIN is acknowledged, the connection is completely closed.\n\n\nSimultaneous Open and Close\n\n\nInitial Sequence Number (ISN)\n\n\nExample\n\n\nTimeout of Connection Establishment\n\n\nConnections and Translators\n\n\nTCP Options\n\n\nMaximum Segment Size (MSS) Option\n\n\nSelective Acknowledgment (SACK) Options\n\n\nWindow Scale (WSCALE or WSOPT) Option\n\n\nTimestamps Option and Protection against Wrapped Sequence Numbers (PAWS)\n\n\nUser Timeout (UTO) Option\n\n\nAuthentication Option (TCP-AO)\n\n\nPath MTU Discovery with TCP\n\n\nTCP State Transitions\n\n\nReset Segments\n\n\nTCP Server Operation\n\n\nAttacks Involving TCP Connection Management", 
            "title": "Chapter 13. TCP Connection Management"
        }, 
        {
            "location": "/tcpv1/ch14/", 
            "text": "Chapter 14. TCP Timeout and Retransmission", 
            "title": "Chapter 14. TCP Timeout and Retransmission"
        }, 
        {
            "location": "/tcpv1/ch15/", 
            "text": "Chapter 15. TCP Data Flow and Window Management", 
            "title": "Chapter 15. TCP Data Flow and Window Management"
        }, 
        {
            "location": "/tcpv1/ch16/", 
            "text": "Chapter 16. TCP Congestion Control", 
            "title": "Chapter 16. TCP Congestion Control"
        }, 
        {
            "location": "/tcpv1/ch17/", 
            "text": "Chapter 17. TCP Keepalive", 
            "title": "Chapter 17. TCP Keepalive"
        }, 
        {
            "location": "/tcpv1/ch18/", 
            "text": "Chapter 18. Security: EAP, IPsec, TLS, DNSSEC, and DKIM\n\n\nIntroduction\n\n\nBasic Principles of Information Security\n\n\nThreats to Network Communication\n\n\nBasic Cryptography and Security Mechanisms\n\n\nCertificates, Certificate Authorities (CAs), and PKIs\n\n\nTCP/IP Security Protocols and Layering\n\n\nNetwork Access Control: 802.1X, 802.1AE, EAP, and PANA\n\n\nLayer 3 IP Security (IPsec)\n\n\nTransport Layer Security (TLS and DTLS)\n\n\nTLS 1.2\n\n\nTLS Record Protocol\n\n\nTLS Handshaking Protocols", 
            "title": "Chapter 18. Security: EAP, IPsec, TLS, DNSSEC, and DKIM"
        }, 
        {
            "location": "/tcpv1/headers/", 
            "text": "Headers\n\n\nIPv4 Header\n\n\n\n\nIPv6 Header\n\n\n\n\nUDP Header\n\n\n\n\nTCP Header", 
            "title": "Headers"
        }, 
        {
            "location": "/tcpv1/headers/#headers", 
            "text": "IPv4 Header   IPv6 Header   UDP Header   TCP Header", 
            "title": "Headers"
        }, 
        {
            "location": "/tcpip/", 
            "text": "TCPIP\n\n\n\n\nChapter 37. Overview of Key Routing Protocol Concepts", 
            "title": "Contents"
        }, 
        {
            "location": "/tcpip/ch37/", 
            "text": "Part II-7: TCP/IP Routing Protocols (Gateway Protocols)\n\n\nRouting is not just one of the most important activities at the network layer, but also the function that defines layer 3 of the \nOSI Reference Model\n. Routing is what enables small local networks to be linked together to form potentially huge internetworks that can span cities, countries, or even the entire globe. The job of routing is done by special devices called \nrouters\n, which forward datagrams from network to network, allowing any device to send to any other device, even if the source has no idea where the destination is.\n\n\nRouters decide how to forward a datagram based on its destination address, which is compared to information the router keeps in special routing tables. These tables contain entries for each of the networks the router knows about, telling the router which adjacent router the datagram should be sent to in order for it to reach its eventual destination.\n\n\nRouting tables are critically important to the routing process. It is possible for these tables to be manually maintained by network administrators, but this is tedious and time-consuming and doesn\u2019t allow routers to deal with changes or problems in the internetwork. Instead, most modern routers are designed with functionality that lets them share route information with other routers, so they can keep their routing tables up-to-date automatically. This information exchange is accomplished through the use of \nrouting protocols\n.\n\n\nThe title of this part refers to both \nrouting protocols\n and \ngateway protocols\n. These terms are interchangeable, and the word \"gateway\" appears in the name of several of the protocols, because historical use of the term \"gateway\" in early TCP/IP standards to refer to the devices we now call routers.  Today, the term \"gateway\" normally refers not to a router, but to a different type of network interconnection device, so this can be particularly confusing. The term \"routing protocol\" is now preferred.\n\n\nChapter 37. Overview of Key Routing Protocol Concepts\n\n\nThis chapter provide an overview of the routing protocol architectures, protocol types, algorithms, and metrics.\n\n\nRouting Protocol Architectures\n\n\nThe word \narchitecture\n refers to the way that an internetwork is structured. Once you have some networks and routers that you wish to connect together, there are any number of ways that you can do this. The architecture you choose is based on the way that routers are linked, and this has an impact on the way that routing is done and how routing protocols operate.\n\n\nCore Architecture\n\n\nEarly architecture of the Internet consisted of a small number of \ncore\n routers that contained comprehensive information about the internetwork. When the Internet was very small, adding more routers to this core expanded it. However, each time the core was expanded, the amount of routing information that needed to be maintained grew.\n\n\nEventually, the core became too large, so a two-level hierarchy was formed to allow further expansion. \nNoncore\n routers were located on the periphery of the core and contained only partial routing information; they relied on the core routers for transmissions that went across the internetwork. There are two special routing protocols:\n\n\n\n\nThe \nGateway-to-Gateway Protocol\n (GGP) was used within the core of the internetwork,\n\n\nThe \nExterior Gateway Protocol\n (EGP) was used between noncore and core routers.\n\n\n\n\nThe noncore routers were sometimes single, stand-alone routers that connected a single network to the core, or they could be sets of routers for an organization.\n\n\nThis architecture served for a while, but it did not scale very well as the Internet grew. The problem was mainly due to the fact that there was only a single level to the architecture:\n\n\n\n\nEvery router in the core had to communicate with every other router.\n\n\nEven with peripheral routers being kept outside the core, the amount of traffic in the core kept growing.\n\n\n\n\nAutonomous System (AS) Architecture\n\n\nTo resolve the scaling problem, a new architecture was created that moved away from the centralized concept of a core toward an architecture that was better suited to a larger and growing internetwork. This decentralized architecture treats the internetwork as a set of independent groups, with each group called an \nautonomous system\n (AS). \nAn AS consists of a set of routers and networks controlled by a particular organization or administrative entity, which uses a single consistent policy for internal routing.\n\n\nThe power of this system is that routing on the internetwork as a whole occurs between ASes and not individual routers:\n\n\n\n\nInformation is shared between one and maybe a couple of routers in each AS, not every router in each AS.\n\n\nThe details of routing within an AS are also hidden from the rest of the internetwork.\n\n\n\n\nThis provides both flexibility for each AS to do routing as it sees fit (thus the name \nautonomous\n) and efficiency for the overall internetwork. \nEach AS has its own number, and the numbers are globally managed to make sure that they are unique across an internetwork (such as the Internet).\n\n\n\n\nLarge, modern TCP/IP internetworks can contain thousands of routers. To better manage routing in such an environment, routers are grouped into constructs called autonomous systems (ASes), each of which consists of a group of routers managed independently by a particular organization or entity.\n\n\n\n\nModern Protocol Types: Interior and Exterior Routing Protocols\n\n\nThe different nature of routing within an AS and between ASes can be seen in the fact that the following distinct sets of TCP/IP routing protocols are used for each type:\n\n\n\n\nInterior Routing Protocols\n. These protocols are used to exchange routing information between routers within an AS. Interior routing protocols are not used between ASes.\n\n\nExterior Routing Protocols\n. These protocols are used to exchange routing information between ASes. They may in some cases be used between routers within an AS, but they primarily deal with exchanging information between ASes.\n\n\n\n\n\n\nInterior routing protocols are used to share routing information within an autonomous system; each AS may use a different interior routing protocol because the system is, as the name says, autonomous. Exterior routing protocols convey routing data between ASes; each AS must use the same exterior protocol to ensure that it can communicate.\n\n\n\n\nSince ASes are just sets of routers, you connect ASes by linking a router in one AS to a router in another AS. Architecturally, an AS consists of a set of routers with two different types of connectivity:\n\n\n\n\nInternal Routers\n. Some routers in an AS connect only to other routers in the same AS. These run interior routing protocols.\n\n\nBorder Routers\n. Some routers in an AS connect both to routers within the AS and to routers in one or more other ASes. These devices are responsible for passing traffic between the AS and the rest of the internetwork. \nThey run both interior and exterior routing protocols.\n\n\n\n\nDue to its advantages, the AS architecture, an example of which can be seen in the figure below, has become the standard for TCP/IP networks, most notably the Internet. The division of routing protocols into the interior and exterior classifications has thus also become standard, and all modern TCP/IP routing protocols are first subdivided by type in this manner.\n\n\n\n\nRouting Protocol Algorithms and Metrics\n\n\nAnother key differentiation of routing protocols is on the basis of the algorithms\nand metrics they use:\n\n\n\n\nAn algorithm refers to a method that the protocol uses for determining the best route between any pair of networks, and for sharing routing information between routers.\n\n\nA metric is a measure of \"cost\" that is used to assess the efficiency of a particular route.\n\n\n\n\nSince internetworks can be quite complex, the algorithms and metrics of a protocol are very important, and they can be the determining factor in deciding that one protocol is superior to another. There are two routing protocol algorithms that are most commonly encountered: distance vector and link state. There are also protocols that use a combination of these methods or other methods\n\n\nDistance-Vector (Bellman-Ford) Routing Protocol Algorithm\n\n\nA \ndistance-vector\n routing algorithm\n, also called a \nBellman-Ford\n algorithm after two of its inventors, is one where routes are selected based on the distance between networks:\n\n\n\n\nThe distance metric is the number of hops, or routers, between them.\n\n\nRouters using this type of protocol maintain information about the distance to all known networks in a table. They regularly send that table to each router they immediately connect with (their neighbors or peers). These routers then update their tables and send those tables to their neighbors. This causes distance information to propagate across the internetwork, so that eventually, each router obtains distance information about all networks on the internetwork.\n\n\n\n\nDistance-vector routing protocols are somewhat limited in their ability to choose the best route. They also are subject to certain problems in their operation that must be worked around through the addition of special heuristics and features. Their chief advantages are simplicity and history (they have been used for a long time).\n\n\nLink-State (Shortest-Path First) Routing Protocol Algorithm\n\n\nA \nlink-state\n algorithm\n selects routes based on a dynamic assessment of the shortest path between any two networks. For that reason, it\u2019s also called a \nshortest-path first\n method.\n\n\nUsing this method, each router maintains a map describing the current topology of the internetwork. This map is updated regularly by testing reachability of different parts of the Internet, and by exchanging link-state information with other routers. The determination of the best route (or shortest path) can be made based on a variety of metrics that indicate the true cost of sending a datagram over a particular route.\n\n\nLink-state algorithms are much more powerful than distance-vector algorithms.  They adapt dynamically to changing internetwork conditions, and they also allow routes to be selected based on more realistic metrics of cost than simply the number of hops between networks. However, they are more complicated to set up and use more computer processing resources than distance-vector algorithms, and they aren\u2019t as well established.\n\n\nHybrid Routing Protocol Algorithms\n\n\nThere are also hybrid protocols that combine features from both types of algorithms (and other protocols that use completely different algorithms). For example, the \nBorder Gateway Protocol\n (BGP) is a path-vector algorithm, which is somewhat similar to the distance-vector algorithm, but communicates much more detailed route information. It includes some of the attributes of distance-vector and linkstate protocols, but is more than just a combination of the two.\n\n\nStatic and Dynamic Routing Protocols\n\n\n\n\nStatic routing\n simply refers to a situation where the routing tables are manually set up so that they remain static.\n\n\nDynamic routing\n is the use of routing protocols to dynamically update routing tables.\n\n\n\n\nThus, all routing protocols are dynamic. There is no such thing as a static routing protocol (unless you consider a network administrator who is editing a routing table a protocol).", 
            "title": "Chapter 37. Overview of Key Routing Protocol Concepts"
        }, 
        {
            "location": "/utlk/", 
            "text": "UTLK\n\n\n\n\nChapter 1. Introduction\n\n\nChapter 2. Memory Addressing", 
            "title": "Contents"
        }, 
        {
            "location": "/utlk/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nThis chapter gives an overview of major features of Linux, as well as Unix kernels. This book is based on \nLinux 2.6.11\n source code.\n\n\nLinux Versus Other Unix-Like Kernels\n\n\nSeveral differences between Linux and Unix implementations:\n\n\n\n\nKernel threading\n\n\nPreemptive kernel: Linux 2.6 can arbitrarily interleave execution flows while they are in privileged mode\n\n\nMultiprocessor support: Linux 2.6 supports symmetric multiprocessing (SMP)\n\n\nSTREAMS\n is not included in Linux\n\n\n\n\nThe Process/Kernel Model\n\n\n\n\nUsers processes\n\n\nKernel threads:\n\n\nrun in Kernel Mode;\n\n\nare non-interactive;\n\n\ncreated during system startup\n\n\n\n\n\n\nKernel routines can be activated in: \n\n\nsystem call;\n\n\nexception signaled by a process; \n\n\ninterrupt by a peripheral device;\n\n\nkernel thread executed\n\n\n\n\n\n\n\n\nProcess Implementation\n\n\nProcess descriptor\n contains registers:\n\n\n\n\nProgram counter (PC) registers\n\n\nStack pointer (SP) registers\n\n\nGeneral purpose registers\n\n\nFloating point registers\n\n\nProcessor control registers\n\n\nMemory management registers\n\n\n\n\nReentrant Kernels\n\n\nA \nkernel control\n path denotes the sequence of instructions executed by the kernel to handle a system call, an exception, or an interrupt.\n\n\nProcess Address Space\n\n\nSynchronization and Critical Regions\n\n\nSignals and Interprocess Communication\n\n\n\n\nUnix signals\n\n\nSystem V IPC: semaphores, message queues, and shared memory\n\n\n\n\nProcess Management\n\n\n\n\nfork()\n, \n_exit()\n, and \nexec()\n-like system calls\n\n\nwait4()\n\n\nProcess groups and login sessions\n\n\n\n\nMemory Management\n\n\n\n\nVirtual memory acts as a logical layer between the application memory requests and the hardware Memory Management Unit (MMU).\n\n\nKernel Memory Allocator: Linux\u2019s KMA uses a Slab allocator on top of a buddy system.\n\n\nProcess virtual address space\n\n\n\n\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\nChatper 1 on Linux Versus Other Unix-Like Kernels [p3]:\n\n\n\n\nLinux uses kernel threads in a very limited way to execute a few kernel functions periodically; however, they do not represent the basic execution context abstraction. \n\n\n\n\nSummary\n\n\nKernel Architecture\n\n\n\n\nThe Linux kernel, as with most Unix kernels, is \nmonolithic\n: each kernel layer is integrated into the whole kernel program and runs in Kernel Mode on behalf of the current process. [p11]", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/utlk/ch2/", 
            "text": "Chapter 2. Memory Addressing\n\n\nThis chapter offers details in \nx86\n microprocessors address memory chips and how Linux uses the available addressing circuits.\n\n\nMemory Addresses\n\n\n\n\nLogical address\n\n\nLinear address\n (also known as \nvirtual address\n)\n\n\nPhysical address\n\n\n\n\nMemory Management Unit (MMU) transforms a logical address into a linear address, and the linear address into a physical address.\n\n\n\n\nMemory arbiter: read or write operations on a RAM chip must be performed serially.\n\n\nSegmentation in Hardware\n\n\nThe following sections focus on address translation when \nprotected mode\n is enabled, in Intel microprocessors starting with the 80286 model.\n\n\nSegment Selectors\n\n\nA logical address consists of:\n\n\n\n\nSegment Selector\n (segment identifier): 16-bit\n\n\nOffset: 32-bit\n\n\n\n\nSegmentation registers\n\n\nSegmentation Registers\n hold Segment Selectors.\n\n\n\n\ncs\n: code segment (program instructions); 2-bit field for CPU's Current Privilege Level (CPL), Linux uses only levels 0 and 3 for Kernel Mode and User Mode\n\n\nss\n: stack segment (current program stack)\n\n\nds\n: data segment (global and static data)\n\n\nes\n, \nfs\n, and \ngs\n: general purpose (arbitrary data)\n\n\n\n\nSegment Descriptors\n\n\nEach segment is represented by an 8-byte \nSegment Descriptor\n that describes the segment characteristics. Segment Descriptors are stored either in the \nGlobal Descriptor Table\n (GDT) or in the \nLocal Descriptor Table\n (LDT). The address and size of GDT and LDT are contained in \ngdtr\n and \nldtr\n control registers respectively.\n\n\n\n\nCode Segment Descriptor: included in GDT or LDT\n\n\nData Segment Descriptor: included in GDT or LDT\n\n\nTask State Segment Descriptor (TSSD): refers to a Task State Segment (TSS), a segment used to save the contents of the processor registers; included in GDT only\n\n\nLocal Descriptor Table Descriptor (LDTD): refers to a segment containing an LDT; included in GDT only\n\n\n\n\nFast Access to Segment Descriptors\n\n\nSegmentation registers store only the Segment Selector. The x86 process provides an additional nonprogrammable register for each of the six programmable segmentation registers to speed up the translation of logical addresses into linear addresses. Each nonprogrammable register contains the 8-byte Segment Descriptor.\n\n\nSegment Selector fields [p40]:\n\n\n\n\nindex\n: identifies the Segment Descriptor entry contained in GDT or LDT\n\n\nTI\n (Table Indicator): specifies whether the Segment Descriptor is included in the GDT (\nTI\n = 0) or in the LDT (\nTI\n = 1).\n\n\nRPL\n (Requestor Privilege Level):  specifies the \nCurrent Privilege Level\n (CPL) of the CPU when the corresponding Segment Selector is loaded into the \ncs\n register\n\n\n\n\nSegmentation Unit\n\n\nThe \nsegmentation unit\n performs the following operations to obtain the linear address:\n\n\n\n\n\n\nExamines the \nTI\n field of the Segment Selector to determine which Descriptor Table (GDT or LDT) stores the Segment Descriptor\n\n\nComputes the address of the Segment Descriptor from the \nindex\n field of the Segment Selector\n\n\nAdds the offset of the logical address to the \nBase\n field of the Segment Descriptor\n\n\n\n\nSegmentation in Linux\n\n\nAll Linux processes running in User Mode use the same pair of segments to address instructions and data. This is similar to processes running in Kernel Mode.\n\n\n\n\nuser code segment\n\n\nuser data segment\n\n\nkernel code segment\n\n\nkernel data segment\n\n\n\n\nSegment Selectors are defined by the macros:\n\n\n\n\n__USER_CS\n\n\n__USER_DS\n\n\n__KERNEL_CS\n\n\n__KERNEL_DS\n\n\n\n\nTo address the kernel code segment, for instance, the kernel just loads the value yielded by the \n__KERNEL_CS\n macro into the \ncs\n segmentation register.\n\n\nThe linear addresses associated with such segments all start at 0 and reach the addressing limit of 2\n32\n \u20131. This means that all processes, either in User Mode or in Kernel Mode, may use the same logical addresses.\n\n\nCPL\n, \nRPL\n and registers\n\n\nThe Current Privilege Level (CPL) of the CPU indicates whether the processor is in User or Kernel Mode and is specified by the \nRPL\n field of the Segment Selector stored in the \ncs\n register. [p42]\n\n\nWhenever the CPL is changed, some segmentation registers (e.g. \nds\n, \nss\n) must be correspondingly updated. [p42-43]\n\n\nImplicit Segment Selector\n\n\nOnly Offset component of its logical address is specified:\n\n\n\n\nss\n: kernel saves a pointer to an instruction or to a data structure\n\n\ncs\n: kernel invokes a function\n\n\nds\n: kernel data structure\n\n\nes\n: user data structure\n\n\n\n\nThe Linux GDT\n\n\nIn multiprocessor systems there is one GDT for every CPU [p43].\n\n\n\n\ncpu_gdt_table\n array: stores GDTs\n\n\ncpu_gdt_descr\n array: addresses and sizes of the GDTs\n\n\n\n\nEach GDT includes 18 segment descriptors and 14 null, unused, or reserved entries. Unused entries are inserted on purpose so that Segment Descriptors usually accessed together are kept in the same 32-byte line of the hardware cache.\n\n\n\n\nFour user and kernel code and data segments\n\n\nTask State Segment (TSS)\n\n\nDefault Local Descriptor Table(LDT), usually shared by all processes\n\n\nThree Thread-Local Storage (TLS) segments: allows multithreaded applications to make use of up to three segments containing data local to each thread. The \nset_thread_area()\n and \nget_thread_area()\n system calls, respectively, create and release a TLS segment for the executing process.\n\n\nThree segments related to Advanced Power Management (APM)\n\n\nFive segments related to Plug and Play (PnP) BIOS services\n\n\nA special TSS segment used by the kernel to handle \"Double fault\" exceptions\n\n\n\n\nThe Linux LDT\n\n\nMost Linux User Mode applications do not make use of a Local Descriptor Table. The kernel defines a default LDT to be shared by most processes. It has five entries but only two are used by the kernel: a \ncall gate\n for \niBCS\n executables, and a call gate for Solaris/x86 executables.\n\n\nIn some cases, processes may require to set up their own LDT, such as applications (such as Wine) that execute segment-oriented Microsoft Windows applications. The \nmodify_ldt()\n system call allows a process to do this.\n\n\nPaging in Hardware\n\n\nThe paging unit translates linear addresses into physical ones. Its key task is to check the requested access type against the access rights of the linear address, and generates a Page Fault exception if memory access is not valid.\n\n\n\n\nPages\n: grouped fixed-length intervals of linear addresses; contiguous linear addresses within a page are mapped into contiguous physical addresses. The term \"page\" to refer both to a set of linear addresses and to the data contained in this group of addresses.\n\n\nPage frames\n (or \nphysical pages\n): RAM partitions from the perspective of the paging unit. Each page frame (storage area) contains a page (block of data), thus the length of a page frame coincides with that of a page.\n\n\nPage table\n: data structures (in main memory) that map linear to physical addresses\n\n\n\n\nRegular Paging\n\n\nThe x86 processors support paging; it is enabled by setting the \nPG\n flag of a control register named \ncr0\n.\n\n\n\n\nDoubts and Solutions\n\n\nSegmentation in Linux [p41]\n\n\n\n\nHowever, Linux uses segmentation in a very limited way. In fact, segmentation and paging are somewhat redundant, because both can be used to separate the physical address spaces of processes: segmentation can assign a different linear address space to each process, while paging can map the same linear address space into different physical address spaces. Linux prefers paging to segmentation for the following reasons:", 
            "title": "Chapter 2. Memory Addressing"
        }, 
        {
            "location": "/lsp/", 
            "text": "LSP\n\n\n\n\nChapter 9. Memory Management", 
            "title": "Contents"
        }, 
        {
            "location": "/lsp/ch9/", 
            "text": "Chapter 9. Memory Management\n\n\nThis chapter covers the allocation, manipulation, and eventual release of memory.\n\n\nThe Process Address Space\n\n\nLinux virtualizes its physical resource of memory. Processes do not directly address physical memory. Instead, the kernel associates each process with a unique \nvirtual address space\n:\n\n\n\n\nThis address space is \nlinear\n, with addresses starting at zero, increasing contiguously to some maximum value.\n\n\nThe address space is also \nflat\n: it exists in one space, directly accessible, without the need for segmentation.\n\n\n\n\nPages and Paging\n\n\nFor the purposes of memory management, the page is the most important of these: it is the smallest addressable unit of memory that the memory management unit (MMU) can manage. Thus the virtual address space is carved up into pages. The machine architecture determines the page size. Typical sizes include 4 KB for 32-bit systems and 8 KB for 64-bit systems.\n\n\nA 32-bit address space contains roughly a million 4 KB pages; a 64-bit address space with 8 KB pages contains several magnitudes more. A process cannot necessarily access all of those pages (they may not correspond to anything). Thus, pages are either valid or invalid:\n\n\n\n\nA \nvalid page\n is associated with an actual page of data, either in physical memory (RAM) or on secondary storage (e.g a swap partition or file on disk).\n\n\nAn \ninvalid page\n is not associated with anything and represents an unused, unallocated piece of the address space. Accessing an invalid page results in a segmentation violation.\n\n\n\n\nPage fault, paging in and paging out \n*\n\n\nIf a valid page is associated with data on secondary storage, a process cannot access that page until the data is brought into physical memory. When a process attempts to access such a page, the memory management unit generates a \npage fault\n. The kernel then intervenes, transparently \npaging in\n the data from secondary storage to physical memory.\n\n\nBecause there is considerably more virtual memory than physical memory, the kernel may have to move data out of memory to make room for the data paging in. \nPaging out\n is the process of moving data from physical memory to secondary storage. To minimize subsequent page-ins, the kernel attempts to page out the data that is the least likely to be used in the near future.\n\n\nSharing and copy-on-write\n\n\nMultiple pages of virtual memory, even in different virtual address spaces owned by different processes, may map to a single physical page. This allows different virtual address spaces to share the data in physical memory. For example, many processes on the system are using the standard C library. With shared memory, each of these processes may map the library into their virtual address space, but only one copy need exist in physical memory. As a more explicit example, two processes may both map into memory a large database. While both of these processes will have the database in their virtual address spaces, it will exist in RAM only once.\n\n\nThe shared data may be read-only, writable, or both readable and writable. When a process writes to a shared writable page, one of two things can happen. The simplest is that the kernel allows the write to occur, in which case all processes sharing the page can see the results of the write operation. Usually, allowing multiple processes to read from or write to a shared page requires some level of coordination and synchronization among the processes, but at the kernel level the write \"just works\" and all processes sharing the data instantly see the modifications.\n\n\nAlternatively, the MMU can intercept the write operation and raise an exception; the kernel, in response, will transparently create a new copy of the page for the writing process, and allow the write to continue against the new page. We call this approach \ncopy-on-write\n (COW). Effectively, processes are allowed read access to shared data, which saves space. But when a process wants to write to a shared page, it receives a unique copy of that page on the fly, thereby allowing the kernel to act as if the process always had its own private copy. As copy-on-write occurs on a page-by-page basis, with this technique a huge file may be efficiently shared among many processes, and the individual processes will receive unique physical pages only for those pages to which they themselves write.\n\n\nMemory Regions\n\n\nThe kernel arranges pages into blocks that share certain properties (e.g. access permissions). These blocks are called \nmappings\n, \nmemory areas\n, or \nmemory regions\n. Certain types of memory regions can be found in every process:\n\n\n\n\nThe \ntext segment\n contains a process\u2019s program code, string literals, constant variables, and other read-only data. In Linux, this segment is marked read-only and is mapped in directly from the object file (the program executable or a library).\n\n\nThe \nstack\n contains the process\u2019s execution stack, which grows and shrinks dynamically as the stack depth increases and decreases. The execution stack contains local variables and function return data. In a multithreaded process, there is one stack per thread.\n\n\nThe \ndata segment\n, or \nheap\n, contains a process\u2019s dynamic memory. This segment is writable and can grow or shrink in size. \nmalloc()\n can satisfy memory requests from this segment.\n\n\nThe \nbss segment\n contains uninitialized global variables. These variables contain special values (all zeros), per the C standard.\n\n\n\n\nDoubts and Solution\n\n\nVerbatim\n\n\np295 on memory regions\n\n\n\n\nThe \ndata segment\n, or \nheap\n, contains a process\u2019s dynamic memory. This segment is writable and can grow or shrink in size. \nmalloc()\n can satisfy memory requests from this segment.\n\n\n\n\ndata segment = heap ?", 
            "title": "Chapter 9. Memory Management"
        }, 
        {
            "location": "/tlpi/", 
            "text": "TLPI\n\n\n\n\nChapter 6. Processes\n\n\nChapter 7. Memory Allocation", 
            "title": "Contents"
        }, 
        {
            "location": "/tlpi/ch6/", 
            "text": "Chapter 6. Processes\n\n\nProcesses and Programs\n\n\nProcess ID and Parent Process ID\n\n\nMemory Layout of a Process\n\n\nThe memory allocated to each process is composed of a number of parts, usually referred to as \nsegments\n. These segments are as follows:\n\n\n\n\nThe \ntext segment\n contains the machine-language instructions of the program run by the process.\n\n\nThe text segment is made read-only so that a process doesn\u2019t accidentally modify its own instructions via a bad pointer value.\n\n\nSince many processes may be running the same program, the text segment is made sharable so that a single copy of the program code can be mapped into the virtual address space of all of the processes.\n\n\n\n\n\n\nThe \ninitialized data segment\n contains global and static variables that are explicitly initialized. The values of these variables are read from the executable file when the program is loaded into memory.\n\n\nThe \nuninitialized data segment\n contains global and static variables that are not explicitly initialized. Before starting the program, the system initializes all memory in this segment to 0.\n\n\nFor historical reasons, this is often called the \nbss segment\n, a name derived from an old assembler mnemonic for \"block started by symbol\".\n\n\nThe main reason for placing global and static variables that are initialized into a separate segment from those that are uninitialized is that, when a program is stored on disk, it is not necessary to allocate space for the uninitialized data. Instead, the executable merely needs to record the location and size required for the uninitialized data segment, and this space is allocated by the program loader at run time.\n\n\n\n\n\n\nThe \nstack\n is a dynamically growing and shrinking segment containing stack frames. One stack frame is allocated for each currently called function. A frame stores the function\u2019s local variables (so-called automatic variables), arguments, and return value. Stack frames are detailed in \nSection 6.5\n.\n\n\nThe \nheap\n is an area from which memory (for variables) can be dynamically allocated at run time. The top end of the heap is called the \nprogram break\n.\n\n\n\n\nThe following code shows various types of C variables along with comments indicating in which segment each variable is located. These comments assume a nonoptimizing compiler and an application binary interface in which all arguments are passed on the stack. In practice, an optimizing compiler may allocate frequently used variables in registers, or optimize a variable out of existence altogether. Furthermore, some ABIs require function arguments and the function result to be passed via registers, rather than on the stack. Nevertheless, this example serves to demonstrate the mapping between C variables and the segments of a process.\n\n\nproc/mem_segments.c\n\n\n#define _BSD_SOURCE\n\n\n#include \nstdio.h\n\n\n#include \nstdlib.h\n\n\n\nchar\n \nglobBuf\n[\n65536\n];\n            \n/* Uninitialized data segment */\n\n\nint\n \nprimes\n[]\n \n=\n \n{\n \n2\n,\n \n3\n,\n \n5\n,\n \n7\n \n};\n  \n/* Initialized data segment */\n\n\n\nstatic\n \nint\n\n\nsquare\n(\nint\n \nx\n)\n                   \n/* Allocated in frame for square() */\n\n\n{\n\n    \nint\n \nresult\n;\n                 \n/* Allocated in frame for square() */\n\n\n    \nresult\n \n=\n \nx\n \n*\n \nx\n;\n\n    \nreturn\n \nresult\n;\n              \n/* Return value passed via register */\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\ndoCalc\n(\nint\n \nval\n)\n                 \n/* Allocated in frame for doCalc() */\n\n\n{\n\n    \nprintf\n(\nThe square of %d is %d\n\\n\n,\n \nval\n,\n \nsquare\n(\nval\n));\n\n\n    \nif\n \n(\nval\n \n \n1000\n)\n \n{\n\n        \nint\n \nt\n;\n                  \n/* Allocated in frame for doCalc() */\n\n\n        \nt\n \n=\n \nval\n \n*\n \nval\n \n*\n \nval\n;\n\n        \nprintf\n(\nThe cube of %d is %d\n\\n\n,\n \nval\n,\n \nt\n);\n\n    \n}\n\n\n}\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n    \n/* Allocated in frame for main() */\n\n\n{\n\n    \nstatic\n \nint\n \nkey\n \n=\n \n9973\n;\n      \n/* Initialized data segment */\n\n    \nstatic\n \nchar\n \nmbuf\n[\n10240000\n];\n \n/* Uninitialized data segment */\n\n    \nchar\n \n*\np\n;\n                    \n/* Allocated in frame for main() */\n\n\n    \np\n \n=\n \nmalloc\n(\n1024\n);\n           \n/* Points to memory in heap segment */\n\n\n    \ndoCalc\n(\nkey\n);\n\n\n    \nexit\n(\nEXIT_SUCCESS\n);\n\n\n}\n\n\n\n\n\n\nAn \napplication binary interface\n (ABI) is a set of rules specifying how a binary executable should exchange information with some service (e.g., the kernel or a library) at run time. Among other things, an ABI specifies which registers and stack locations are used to exchange this information, and what meaning is attached to the exchanged values. Once compiled for a particular ABI, a binary executable should be able to run on any system presenting the same ABI. This contrasts with a standardized API (such as SUSv3), which guarantees portability only for applications compiled from source code.\n\n\nAlthough not specified in SUSv3, the C program environment on most UNIX implementations (including Linux) provides three global symbols: \netext\n, \nedata\n, and \nend\n. These symbols can be used from within a program to obtain the addresses of the next byte past, respectively, the end of the program text, the end of the initialized data segment, and the end of the uninitialized data segment. To make use of these symbols, we must explicitly declare them, as follows:\n\n\nextern\n \nchar\n \netext\n,\n \nedata\n,\n \nend\n;\n\n \n/* For example, \netext gives the address of the end\n\n\n of the program text / start of initialized data */\n\n\n\n\n\n\nThe following figure (Figure 6-1) shows the arrangement of the various memory segments on the x86-32 architecture.\n\n\n\n\nThe space labeled \nargv\n, \nenviron\n at the top of this diagram holds the program command-line arguments (available in C via the \nargv\n argument of the \nmain()\n function) and the process environment list.\n\n\nThe hexadecimal addresses shown in the diagram may vary, depending on kernel configuration and program linking options.\n\n\nThe grayed-out areas represent invalid ranges in the process\u2019s virtual address space; that is, areas for which page tables have not been created (see the following discussion of virtual memory management).\n\n\n\n\n\n\nVirtual Memory Management\n\n\nThe Stack and Stack Frames", 
            "title": "Chapter 6. Processes"
        }, 
        {
            "location": "/tlpi/ch7/", 
            "text": "Chapter 7. Memory Allocation\n\n\nMany system programs need to be able to allocate extra memory for dynamic data structures (e.g., linked lists and binary trees), whose size depends on information that is available only at run time. This chapter describes the functions that are used to allocate memory on the heap or the stack.\n\n\nAllocating Memory on the Heap\n\n\nA process can allocate memory by increasing the size of the heap, a variable-size segment of contiguous virtual memory that begins just after the uninitialized data segment of a process and grows and shrinks as memory is allocated and freed (\nFigure 6-1\n). The current limit of the heap is referred to as the \nprogram break\n.\n\n\nAdjusting the Program Break: \nbrk()\n and \nsbrk()\n\n\nResizing the heap (allocating or deallocating memory) is actually as simple as telling the kernel to adjust its idea of where the process\u2019s program break is. Initially, the program break lies just past the end of the uninitialized data segment (the same location as \nend\n, shown in \nFigure 6-1\n).\n\n\nAfter the program break is increased, the program may access any address in the newly allocated area, but no physical memory pages are allocated yet. The kernel automatically allocates new physical pages on the first attempt by the process to access addresses in those pages.\n\n\nTraditionally, the UNIX system has provided two system calls for manipulating the program break, and these are both available on Linux: \nbrk()\n and \nsbrk()\n.  Although these system calls are seldom used directly in programs, understanding them helps clarify how memory allocation works.\n\n\n#include \nunistd.h\n\n\nint\n \nbrk\n(\nvoid\n \n*\nend_data_segment\n);\n\n\n/* Returns 0 on success, or \u20131 on error */\n\n\n\nvoid\n \n*\nsbrk\n(\nintptr_t\n \nincrement\n);\n\n\n/* Returns previous program break on success, or (void *) \u20131 on error */\n\n\n\n\n\n\n\n\nThe \nbrk()\n system call sets the program break to the location specified by \nend_data_segment\n. Since virtual memory is allocated in units of pages, \nend_data_segment\n is effectively rounded up to the next page boundary.\n\n\nAttempts to set the program break below its initial value (i.e., below \nend\n) are likely to result in unexpected behavior, such as a segmentation fault (the \nSIGSEGV\n signal) when trying to access data in now nonexistent parts of the initialized or uninitialized data segments.\n\n\nThe precise upper limit on where the program break can be set depends on a range of factors, including:\n\n\nThe process resource limit for the size of the data segment (\nRLIMIT_DATA\n)\n\n\nThe location of memory mappings, shared memory segments, and shared libraries.\n\n\n\n\n\n\n\n\n\n\nA call to \nsbrk()\n adjusts the program break by adding increment to it. On Linux, \nsbrk()\n is a library function implemented on top of \nbrk()\n.\n\n\nThe \nintptr_t\n type used to declare increment is an integer data type.\n\n\nOn success, \nsbrk()\n returns the previous address of the program break. In other words, if we have increased the program break, then the return value is a pointer to the start of the newly allocated block of memory.\n\n\nThe call \nsbrk(0)\n returns the current setting of the program break without changing it. This can be useful if we want to track the size of the heap, perhaps in order to monitor the behavior of a memory allocation package.\n\n\n\n\n\n\n\n\nAllocating Memory on the Heap: \nmalloc()\n and \nfree()\n\n\nIn general, C programs use the \nmalloc\n family of functions to allocate and deallocate memory on the heap. These functions offer several advantages over \nbrk()\n and \nsbrk()\n in that:\n\n\n\n\nThey are standardized as part of the C language;\n\n\nThey are easier to use in threaded programs;\n\n\nThey provide a simple interface that allows memory to be allocated in small units;\n\n\nThey allow us to arbitrarily deallocate blocks of memory, which are maintained on a free list and recycled in future calls to allocate memory.\n\n\n\n\nThe \nmalloc()\n function allocates \nsize\n bytes from the heap and returns a pointer to the start of the newly allocated block of memory. The allocated memory is not initialized.\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \n*\nmalloc\n(\nsize_t\n \nsize\n);\n\n\n/* Returns pointer to allocated memory on success, or NULL on error */\n\n\n\n\n\n\nBecause \nmalloc()\n returns \nvoid *\n, we can assign it to any type of C pointer. The block of memory returned by \nmalloc()\n is always aligned on a byte boundary suitable for any type of C data structure. In practice, this means that it is allocated on an 8-byte or 16-byte boundary on most architectures.\n\n\nSUSv3 specifies that the call \nmalloc(0)\n may return either \nNULL\n or a pointer to a small piece of memory that can (and should) be freed with \nfree()\n. On Linux, \nmalloc(0)\n follows the latter behavior.\n\n\nIf memory could not be allocated (perhaps because we reached the limit to which the program break could be raised), then \nmalloc()\n returns \nNULL\n and sets \nerrno\n to indicate the error. Although the possibility of failure in allocating memory is small, all calls to \nmalloc()\n, and the related functions that we describe later, should check for this error return.\n\n\nThe \nfree()\n function deallocates the block of memory pointed to by its \nptr\n argument, which should be an address previously returned by \nmalloc()\n or one of the other heap memory allocation functions described later this chapter.\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \nfree\n(\nvoid\n \n*\nptr\n);\n\n\n\n\n\n\nIn general, \nfree()\n doesn\u2019t lower the program break, but instead adds the block of memory to a list of free blocks that are recycled by future calls to \nmalloc()\n. This is done for several reasons:\n\n\n\n\nThe block of memory being freed is typically somewhere in the middle of the heap, rather than at the end, so that lowering the program break is not possible.\n\n\nIt minimizes the number of \nsbrk()\n calls that the program must perform. System calls have a small but significant overhead.\n\n\nIn many cases, lowering the break would not help programs that allocate large amounts of memory, since they typically tend to hold on to allocated memory or repeatedly release and reallocate memory, rather than release it all and then continue to run for an extended period of time.\n\n\n\n\nIf the argument given to \nfree()\n is a \nNULL\n pointer, then the call does nothing. In other words, it is not an error to give a \nNULL\n pointer to \nfree()\n.\n\n\nMaking any use of \nptr\n after the call to \nfree\n (e.g. passing it to \nfree()\n a second time) is an error that can lead to unpredictable results.", 
            "title": "Chapter 7. Memory Allocation"
        }, 
        {
            "location": "/gopl/", 
            "text": "GOPL\n\n\n\n\nChapter 1. Tutorial\n\n\nChapter 2. Program Structure\n\n\nChapter 3. Basic Data Types\n\n\nChapter 4. Composite Types\n\n\nChapter 5. Functions\n\n\nChapter 6. Methods\n\n\nChapter 7. Interfaces", 
            "title": "Contents"
        }, 
        {
            "location": "/gopl/ch1/", 
            "text": "Chapter 1. Tutorial\n\n\nThis chapter is a tour of the basic components of Go. We hope to provide enough information and examples to get you off the ground and doing useful things as quickly as possible.\n\n\nWhen you\u2019re learning a new language, there\u2019s a natural tendency to write code as you would have written it in a language you already know. Be aware of this bias as you learn Go and try to avoid it. We\u2019ve tried to illustrate and explain how to write good Go, so use the code here as a guide when you\u2019re writing your own.\n\n\nHello, World\n\n\nWe'll start with the now-traditional \"hello, world\" example, which appears at the beginning of \nThe C Programming Language\n, published in 1987.\n\n\ngopl.io/ch1/helloworld/main.go\n\n\npackage\n \nmain\n\n\n\nimport\n \nfmt\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nfmt\n.\nPrintln\n(\nHello, \u4e16\u754c\n)\n\n\n}\n\n\n\n\n\n\nGo is a compiled language:\n\n\n\n\nThe Go toolchain converts a source program and the things it depends on into instructions in the native machine language of a computer.\n\n\nThese tools are accessed through a single command called \ngo\n that has a number of subcommands. The simplest of these subcommands is \nrun\n, which compiles the source code from one or more source files whose names end in \n.go\n, links it with libraries, then runs the resulting executable file.\n\n\n\n\n$ go run helloworld.go\n\n\n\n\n\n\nGo natively handles Unicode, so it can process text in all the world\u2019s languages.\n\n\nIf the program is more than a one-shot experiment, you can compile it once and save the compiled result for later use, which is done with \ngo build\n:\n\n\n$ go build helloworld.go\n\n\n\n\n\n\nThis creates an executable binary file called \nhelloworld\n that can be run any time without further processing:\n\n\n$ ./helloworld\n\n\nHello, \u4e16\u754c\n\n\n\n\n\n\nIf you run \ngo get gopl.io/ch1/helloworld\n, it will fetch the source code and place it in the corresponding directory. There\u2019s more about this topic in \nSection 2.6\n and \nSection 10.7\n.\n\n\nGo code is organized into packages (similar to libraries or modules in other languages). A package consists of \n.go\n source files in a single directory that define what the package does. Each source file begins with the following things in order:\n\n\n\n\nA package declaration (e.g. \npackage main\n) that states which package the file belongs to,\n\n\nA list of other packages that it imports,\n\n\nThe declarations of the program that are stored in that file.\n\n\n\n\nPackage \nmain\n is special. It defines a standalone executable program, not a library. Within package \nmain\n the function \nmain\n is also special: it\u2019s where execution of the program begins. \nmain\n will normally call upon functions in other packages to do much of the work, such as the function \nfmt.Println\n.\n\n\nThe \nimport\n declaration tells the compiler what packages are needed by this source file. The \"hello, world\" program uses only one function from one other package, but most programs will import more packages.  You must import exactly the packages you need. \nA program will not compile if there are missing imports or if there are unnecessary ones.\n This strict requirement prevents references to unused packages from accumulating as programs evolve.\n\n\nThe \nimport\n declarations must follow the package declaration. After that, a program consists of the declarations of functions, variables, constants, and types (keywords \nfunc\n, \nvar\n, \nconst\n, and \ntype\n); for the most part, the order of declarations does not matter. This program is about as short as possible since it declares only one function, which in turn calls only one other function.\n\n\nA function declaration consists of the keyword \nfunc\n, the name of the function, a parameter\nlist (empty for \nmain\n), a result list (also empty here), and the body of the function enclosed in braces. This is detailed in \nChapter 5\n.\n\n\nGo does not require semicolons at the ends of statements or declarations, except where two or more appear on the same line. In effect, newlines following certain tokens are converted into semicolons, so where newlines are placed matters to proper parsing of Go code. For instance, the opening brace \n{\n of the function must be on the same line as the end of the \nfunc\n declaration, not on a line by itself, and in the expression \nx + y\n, a newline is permitted after but not before the \n+\n operator.\n\n\nGo takes a strong stance on code formatting. The \ngofmt\n tool rewrites code into the standard format, and the go tool\u2019s \nfmt\n subcommand applies \ngofmt\n to all the files in the specified package, or the ones in the current directory by default. All Go source files in the book have been run through \ngofmt\n. \nDeclaring a standard format by fiat eliminates a lot of pointless debate about trivia and, more importantly, enables a variety of automated source code transformations that would be infeasible if arbitrary formatting were allowed.\n\n\nMany text editors can be configured to run \ngofmt\n each time you save a file, so that your source code is always properly formatted. A related tool, \ngoimports\n, additionally manages the insertion and removal of import declarations as needed. It is not part of the standard distribution but you can obtain it with this command:\n\n\n$ go get golang.org/x/tools/cmd/goimports\n\n\n\n\n\n\nFor most users, the usual way to download and build packages, run their tests, show their documentation, and so on, is with the go tool.\n\n\nCommand-Line Arguments\n\n\nThe \nos\n package provides functions and other values for dealing with the operating system in a platform-independent fashion. Command-line arguments are available to a program as the variable \nos.Args\n.\n\n\nSlice \nos.Args\n *\n\n\nThe variable \nos.Args\n is a slice of strings. Slices are a fundamental notion in Go. For now, think of a slice as a dynamically sized sequence \ns\n of array elements where:\n\n\n\n\nIndividual elements can be accessed as \ns[i]\n;\n\n\nA contiguous subsequence can be accessed as \ns[m:n]\n.\n\n\nThe number of elements is given by \nlen(s)\n.\n\n\nAs in most other programming languages, all indexing in Go uses half-open intervals that include the first index but exclude the last, because it simplifies logic. For example, the slice \ns[m:n]\n, where \n0\n \u2264 \nm\n \u2264 \nn\n \u2264 \nlen(s)\n, contains \nn-m\n elements.\n\n\n\n\nThe first element of \nos.Args\n, \nos.Args[0]\n, is the name of the command itself; the other elements are the arguments that were presented to the program when it started execution. A slice expression of the form \ns[m:n]\n yields a slice that refers to elements \nm\n through \nn-1\n, so the elements we need for our next example are those in the slice \nos.Args[1:len(os.Args)]\n. If \nm\n or \nn\n is omitted, it defaults to 0 or \nlen(s)\n respectively, so we can abbreviate the desired slice as \nos.Args[1:]\n.\n\n\nExample implementation of Unix \necho\n command *\n\n\nThe following is an implementation of the Unix \necho\n command, which prints its command-line arguments on a single line. \nIt imports two packages, which are given as a parenthesized list rather than as individual import declarations. Either form is legal, but conventionally the list form is used. The order of imports doesn\u2019t matter; the \ngofmt\n tool sorts the package names into alphabetical order.\n\n\ngopl.io/ch1/echo1/main.go\n\n\n// Echo1 prints its command-line arguments.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nos\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nvar\n \ns\n,\n \nsep\n \nstring\n\n    \nfor\n \ni\n \n:=\n \n1\n;\n \ni\n \n \nlen\n(\nos\n.\nArgs\n);\n \ni\n++\n \n{\n\n        \ns\n \n+=\n \nsep\n \n+\n \nos\n.\nArgs\n[\ni\n]\n\n        \nsep\n \n=\n \n \n\n    \n}\n\n    \nfmt\n.\nPrintln\n(\ns\n)\n\n\n}\n\n\n\n\n\n\nComments that describe the program *\n\n\nComments begin with \n//\n. By convention, we describe each package in a comment immediately preceding its package declaration; for a \nmain\n package, this comment is one or more complete sentences that describe the program as a whole.\n\n\nVariables, declarations and assignment *\n\n\nThe \nvar\n declaration declares two variables \ns\n and \nsep\n, of type \nstring\n. A variable can be initialized as part of its declaration. If it is not explicitly initialized, it is implicitly initialized to the \nzero value\n for its type, which is 0 for numeric types and the empty string \"\" for strings. In this example, the declaration implicitly initializes \ns\n and \nsep\n to empty strings. Variables and declarations are detailed in \nChapter 2\n.\n\n\nThe statement:\n\n\ns\n \n+=\n \nsep\n \n+\n \nos\n.\nArgs\n[\ni\n]\n\n\n\n\n\n\nis an \nassignment statement\n that concatenates the old value of \ns\n with \nsep\n and \nos.Args[i]\n and assigns it back to \ns\n; it is equivalent to:\n\n\ns\n \n=\n \ns\n \n+\n \nsep\n \n+\n \nos\n.\nArgs\n[\ni\n]\n\n\n\n\n\n\nThe operator \n+=\n is an \nassignment operator\n. Each arithmetic and logical operator like + or * has a corresponding assignment operator.\n\n\nA number of improved versions of \necho\n will be shown in this chapter and the next that will deal with any real inefficiency.\n\n\nfor\n loop *\n\n\nThe loop index variable \ni\n is declared in the first part of the \nfor\n loop. The \n:=\n symbol is part of a \nshort variable declaration\n, a statement that declares one or more variables and gives them appropriate types based on the initializer values (detailed in the next chapter). The increment statement \ni++\n adds 1 to \ni\n; it\u2019s equivalent to \ni += 1\n which is in turn equivalent to \ni = i + 1\n. There\u2019s a corresponding decrement statement \ni--\n that subtracts 1. These are statements, not expressions as they are in most languages in the C family, so \nj = i++\n is illegal, and they are postfix only, so \n--i\n is not legal either.\n\n\nThe \nfor\n loop is the only loop statement in Go. It has a number of forms, one of which is illustrated here:\n\n\nfor initialization; condition; post {\n    // zero or more statements\n}\n\n\n\n\n\nIn the above form, parentheses are never used around the three components of a \nfor\n loop. The braces are mandatory, and the opening brace must be on the same line as the \npost\n statement. The three statements are:\n\n\n\n\nThe optional \ninitialization\n statement is executed before the loop starts. If it is present, it must be a \nsimple statement\n, which is one of the following:\n\n\nA short variable declaration,\n\n\nAn increment or assignment statement,\n\n\nA function call.\n\n\n\n\n\n\nThe \ncondition\n is a boolean expression evaluated at the beginning of each iteration of the loop; if it evaluates to true, the statements controlled by the loop are executed.\n\n\nThe \npost\n statement is executed after the body of the loop, then the condition is evaluated again. The loop ends when the condition becomes false.  Any of these parts may be omitted. If there is no initialization and no post, the semicolons may also be omitted:\n\n\n\n\nIf there is no \ninitialization\n and no \npost\n, the semicolons may also be omitted:\n\n\nfor\n as a \"while\" loop\n *\n\n\n// a traditional \nwhile\n loop\n\n\nfor\n \ncondition\n \n{\n\n    \n// ...\n\n\n}\n\n\n\n\n\n\nIf the \ncondition\n is omitted entirely in any of these forms, for example in\n\n\n// a traditional infinite loop\n\n\nfor\n \n{\n\n\n// ...\n\n\n}\n\n\n\n\n\n\nThis loop is infinite, though it may be terminated in some other way, like a \nbreak\n or \nreturn\n statement.\n\n\nfor\n as iteration\n *\n\n\nAnother form of the for loop iterates over a range of values from a data type like a string or a slice:\n\n\ngopl.io/ch1/echo2/main.go\n\n\n// Echo2 prints its command-line arguments.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nos\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \ns\n,\n \nsep\n \n:=\n \n,\n \n\n    \nfor\n \n_\n,\n \narg\n \n:=\n \nrange\n \nos\n.\nArgs\n[\n1\n:]\n \n{\n\n        \ns\n \n+=\n \nsep\n \n+\n \narg\n\n        \nsep\n \n=\n \n \n\n    \n}\n\n    \nfmt\n.\nPrintln\n(\ns\n)\n\n\n}\n\n\n\n\n\n\nIn each iteration, \nrange\n produces a pair of values: the index and the value of the element at that index. Here, we don\u2019t need the index, but the \nrange\n loop requires that we deal with both the element and the index. Since Go does not permit unused local variables (which would result in a compilation error), the solution is to use the \nblank identifier\n, whose name is \n_\n (an underscore). The blank identifier may be used whenever syntax requires a variable name but program logic does not, for instance to discard an unwanted loop index when we require only the element value.\n\n\nEquivalent ways of declaring string variables\n *\n\n\nThere are several ways to declare a string variable; these are all equivalent:\n\n\ns\n \n:=\n \n\n\nvar\n \ns\n \nstring\n\n\nvar\n \ns\n \n=\n \n\n\nvar\n \ns\n \nstring\n \n=\n \n\n\n\n\n\n\n\n\nThe first form is a short variable declaration and is the most compact, but it may be used only within a function, not for package-level variables.\n\n\nThe second form relies on default initialization to the zero value for strings, which is \"\".\n\n\nThe third form is rarely used except when declaring multiple variables.\n\n\nThe fourth form is explicit about the variable\u2019s type, which is redundant when it is the same as that of the initial value but necessary in other cases where they are not of the same type.\n\n\n\n\nIn practice, you should generally use one of the first two forms, with explicit initialization to say that the initial value is important and implicit initialization to say that the initial value doesn\u2019t matter.\n\n\nEach time around the loop, the string s gets completely new contents. The \n+=\n statement makes a new string by concatenating the old string, a space character, and the next argument, then assigns the new string to \ns\n. \nThe old contents of \ns\n are no longer in use, so they will be garbage-collected in due course.\n\n\nstrings.Join\n function\n\n\nIf the amount of data involved is large, this could be costly. A simpler and more efficient solution would be to use the \nJoin\n function from the \nstrings\n package:\n\n\ngopl.io/ch1/echo3/main.go\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nfmt\n.\nPrintln\n(\nstrings\n.\nJoin\n(\nos\n.\nArgs\n[\n1\n:],\n \n \n))\n\n\n}\n\n\n\n\n\n\nIf we don\u2019t care about format but just want to see the values, perhaps for debugging, we can let \nPrintln\n format the results for us:\n\n\nfmt\n.\nPrintln\n(\nos\n.\nArgs\n[\n1\n:])\n\n\n\n\n\n\nFinding Duplicate Lines\n\n\nThis section shows three variants of a program called \ndup\n; it is partly inspired by the Unix \nuniq\n command, which looks for adjacent duplicate lines.\n\n\nThe first version of \ndup\n prints each line that appears more than once in the standard input, preceded by its count. This program introduces the following:\n\n\n\n\nif\n statement\n\n\nmap\n data type\n\n\nbufio\n package\n\n\n\n\ngopl.io/ch1/dup1/main.go\n\n\n// Dup1 prints the text of each line that appears more than\n\n\n// once in the standard input, preceded by its count.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nbufio\n\n    \nfmt\n\n    \nos\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \ncounts\n \n:=\n \nmake\n(\nmap\n[\nstring\n]\nint\n)\n\n    \ninput\n \n:=\n \nbufio\n.\nNewScanner\n(\nos\n.\nStdin\n)\n\n    \nfor\n \ninput\n.\nScan\n()\n \n{\n\n        \ncounts\n[\ninput\n.\nText\n()]\n++\n\n    \n}\n\n    \n// NOTE: ignoring potential errors from input.Err()\n\n    \nfor\n \nline\n,\n \nn\n \n:=\n \nrange\n \ncounts\n \n{\n\n        \nif\n \nn\n \n \n1\n \n{\n\n            \nfmt\n.\nPrintf\n(\n%d\\t%s\\n\n,\n \nn\n,\n \nline\n)\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nif\n statement *\n\n\nAs with \nfor\n, parentheses are never used around the condition in an \nif\n statement, but braces are required for the body. There can be an optional \nelse\n part that is executed if the condition is false.\n\n\nmap\n that holds \ncounts\n *\n\n\nA \nmap\n holds a set of key/value pairs and provides constant-time operations to store, retrieve, or test for an item in the set.\n\n\n\n\nThe key may be of any type whose values can compared with \n==\n, strings being the most common example;\n\n\nThe value may be of any type at all.\n\n\n\n\nIn this example, the keys are \nstring\ns and the values are \nint\ns. The built-in function \nmake\n creates a new empty map. Maps are detailed in \nSection 4.3\n.\n\n\nThe statement \ncounts[input.Text()]++\n is equivalent to these two statements:\n\n\nline\n \n:=\n \ninput\n.\nText\n()\n\n\ncounts\n[\nline\n]\n \n=\n \ncounts\n[\nline\n]\n \n+\n \n1\n\n\n\n\n\n\nIt\u2019s not a problem if the map doesn\u2019t yet contain that key. The first time a new line is seen, the expression \ncounts[line]\n on the right-hand side evaluates to the zero value for its type, which is 0 for \nint\n.\n\n\nTo print the results, we use another \nrange\n-based \nfor\n loop, this time over the \ncounts\n map. Each iteration produces two results, a key and the value of the map element for that key. \nThe order of map iteration is not specified, but in practice it is random, varying from one run to another. This design is intentional, since it prevents programs from relying on any particular ordering where none is guaranteed.\n\n\nbufio.Scanner\n function\n\n\nThe \nbufio\n package helps make input and output efficient and convenient. One of its most useful features is a type called \nScanner\n that reads input and breaks it into lines or words; it\u2019s often the easiest way to process input that comes naturally in lines.\n\n\nThe program uses a short variable declaration to create a new variable \ninput\n that refers to a \nbufio.Scanner\n:\n\n\ninput\n \n:=\n \nbufio\n.\nNewScanner\n(\nos\n.\nStdin\n)\n\n\n\n\n\n\nThe scanner reads from the program\u2019s standard input. Each call to \ninput.Scan()\n reads the next line and removes the newline character from the end; the result can be retrieved by calling \ninput.Text()\n. The \nScan\n function returns \ntrue\n if there is a line and \nfalse\n when there is no more input.\n\n\nfmt.Printf\n function\n\n\nThe function \nfmt.Printf\n produces formatted output from a list of expressions. Its first argument is a format string that specifies how subsequent arguments should be formatted. The format of each argument is determined by a conversion character, a letter following a percent sign.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n%d\n\n\ndecimal integer\n\n\n\n\n\n\n%x\n, \n%o\n, \n%b\n\n\ninteger in hexadecimal, octal, binary\n\n\n\n\n\n\n%f\n, \n%g\n, \n%e\n\n\nfloating-point number: \n3.141593\n \n3.141592653589793\n \n3.141593e+00\n\n\n\n\n\n\n%t\n\n\nboolean: \ntrue\n or \nfalse\n\n\n\n\n\n\n%c\n\n\nrune (Unicode code point)\n\n\n\n\n\n\n%s\n\n\nstring\n\n\n\n\n\n\n%q\n\n\nquoted string \n\"abc\"\n or rune \n'c'\n\n\n\n\n\n\n%v\n\n\nany value in a natural format\n\n\n\n\n\n\n%T\n\n\ntype of any value\n\n\n\n\n\n\n%%\n\n\nliteral percent sign (no operand)\n\n\n\n\n\n\n\n\n\\t\n (tab) and \n\\n\n (newline) are \nescape sequences\n for representing otherwise invisible characters. \nPrintf\n does not write a newline by default. By convention:\n\n\n\n\nFormatting functions whose names end in \nf\n, such as \nlog.Printf\n and \nfmt.Errorf\n, use the formatting rules of \nfmt.Printf\n;\n\n\nFormatting functions whose names end in \nln\n use the formatting rules of \nfmt.Println\n, formatting their arguments as if by \n%v\n, followed by a newline.\n\n\n\n\nos.Open\n function\n\n\nThe next version of \ndup\n can read from the standard input or handle a list of file names, using \nos.Open\n to open each one:\n\n\ngopl.io/ch1/dup2/main.go\n\n\n// Dup2 prints the count and text of lines that appear more than once\n\n\n// in the input.  It reads from stdin or from a list of named files.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nbufio\n\n    \nfmt\n\n    \nos\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \ncounts\n \n:=\n \nmake\n(\nmap\n[\nstring\n]\nint\n)\n\n    \nfiles\n \n:=\n \nos\n.\nArgs\n[\n1\n:]\n\n    \nif\n \nlen\n(\nfiles\n)\n \n==\n \n0\n \n{\n\n        \ncountLines\n(\nos\n.\nStdin\n,\n \ncounts\n)\n\n    \n}\n \nelse\n \n{\n\n        \nfor\n \n_\n,\n \narg\n \n:=\n \nrange\n \nfiles\n \n{\n\n            \nf\n,\n \nerr\n \n:=\n \nos\n.\nOpen\n(\narg\n)\n\n            \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n                \nfmt\n.\nFprintf\n(\nos\n.\nStderr\n,\n \ndup2: %v\\n\n,\n \nerr\n)\n\n                \ncontinue\n\n            \n}\n\n            \ncountLines\n(\nf\n,\n \ncounts\n)\n\n            \nf\n.\nClose\n()\n\n        \n}\n\n    \n}\n\n    \nfor\n \nline\n,\n \nn\n \n:=\n \nrange\n \ncounts\n \n{\n\n        \nif\n \nn\n \n \n1\n \n{\n\n            \nfmt\n.\nPrintf\n(\n%d\\t%s\\n\n,\n \nn\n,\n \nline\n)\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\nfunc\n \ncountLines\n(\nf\n \n*\nos\n.\nFile\n,\n \ncounts\n \nmap\n[\nstring\n]\nint\n)\n \n{\n\n    \ninput\n \n:=\n \nbufio\n.\nNewScanner\n(\nf\n)\n\n    \nfor\n \ninput\n.\nScan\n()\n \n{\n\n        \ncounts\n[\ninput\n.\nText\n()]\n++\n\n    \n}\n\n    \n// NOTE: ignoring potential errors from input.Err()\n\n\n}\n\n\n\n\n\n\nThe function \nos.Open\n returns two values:\n\n\n\n\nThe first is an open file (\n*os.File\n) used in subsequent reads by the \nScanner\n.\n\n\nThe second result of \nos.Open\n is a value of the built-in error type:\n\n\nIf \nerr\n equals the special built-in value \nnil\n, the file was opened successfully. The file is read, and when the end of the input is reached, \nClose\n closes the file and releases any resources.\n\n\nIf \nerr\n is not \nnil\n, something went wrong; the error value describes the problem.\n\n\n\n\n\n\n\n\nIn this program, the error handling prints a message on the standard error stream using \nFprintf\n and\nthe verb \n%v\n, which displays a value of any type in a default format. The details of error handling are in \nSection 5.4\n.\n\n\nNotice that the call to \ncountLines\n precedes its declaration. Functions and other package-level entities may be declared in any order.\n\n\nAnimated GIFs\n\n\nThe next program demonstrates usage of Go\u2019s standard image packages to create a sequence of bit-mapped images and then encode the sequence as a GIF animation, called \nLissajous figures\n.\n\n\nThere are several new constructs in this code, including \nconst\n declarations, struct types, and composite literals, and also involves floating-point computations.\n\n\ngopl.io/ch1/lissajous/main.go\n\n\n// Lissajous generates GIF animations of random Lissajous figures.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nimage\n\n    \nimage/color\n\n    \nimage/gif\n\n    \nio\n\n    \nmath\n\n    \nmath/rand\n\n    \nos\n\n\n)\n\n\n\n//!-main\n\n\n// Packages not needed by version in book.\n\n\nimport\n \n(\n\n    \nlog\n\n    \nnet/http\n\n    \ntime\n\n\n)\n\n\n\n//!+main\n\n\n\nvar\n \npalette\n \n=\n \n[]\ncolor\n.\nColor\n{\ncolor\n.\nWhite\n,\n \ncolor\n.\nBlack\n}\n\n\n\nconst\n \n(\n\n    \nwhiteIndex\n \n=\n \n0\n \n// first color in palette\n\n    \nblackIndex\n \n=\n \n1\n \n// next color in palette\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nlissajous\n(\nos\n.\nStdout\n)\n\n\n}\n\n\n\nfunc\n \nlissajous\n(\nout\n \nio\n.\nWriter\n)\n \n{\n\n    \nconst\n \n(\n\n        \ncycles\n  \n=\n \n5\n     \n// number of complete x oscillator revolutions\n\n        \nres\n     \n=\n \n0.001\n \n// angular resolution\n\n        \nsize\n    \n=\n \n100\n   \n// image canvas covers [-size..+size]\n\n        \nnframes\n \n=\n \n64\n    \n// number of animation frames\n\n        \ndelay\n   \n=\n \n8\n     \n// delay between frames in 10ms units\n\n    \n)\n\n    \nfreq\n \n:=\n \nrand\n.\nFloat64\n()\n \n*\n \n3.0\n \n// relative frequency of y oscillator\n\n    \nanim\n \n:=\n \ngif\n.\nGIF\n{\nLoopCount\n:\n \nnframes\n}\n\n    \nphase\n \n:=\n \n0.0\n \n// phase difference\n\n    \nfor\n \ni\n \n:=\n \n0\n;\n \ni\n \n \nnframes\n;\n \ni\n++\n \n{\n\n        \nrect\n \n:=\n \nimage\n.\nRect\n(\n0\n,\n \n0\n,\n \n2\n*\nsize\n+\n1\n,\n \n2\n*\nsize\n+\n1\n)\n\n        \nimg\n \n:=\n \nimage\n.\nNewPaletted\n(\nrect\n,\n \npalette\n)\n\n        \nfor\n \nt\n \n:=\n \n0.0\n;\n \nt\n \n \ncycles\n*\n2\n*\nmath\n.\nPi\n;\n \nt\n \n+=\n \nres\n \n{\n\n            \nx\n \n:=\n \nmath\n.\nSin\n(\nt\n)\n\n            \ny\n \n:=\n \nmath\n.\nSin\n(\nt\n*\nfreq\n \n+\n \nphase\n)\n\n            \nimg\n.\nSetColorIndex\n(\nsize\n+\nint\n(\nx\n*\nsize\n+\n0.5\n),\n \nsize\n+\nint\n(\ny\n*\nsize\n+\n0.5\n),\n\n                \nblackIndex\n)\n\n        \n}\n\n        \nphase\n \n+=\n \n0.1\n\n        \nanim\n.\nDelay\n \n=\n \nappend\n(\nanim\n.\nDelay\n,\n \ndelay\n)\n\n        \nanim\n.\nImage\n \n=\n \nappend\n(\nanim\n.\nImage\n,\n \nimg\n)\n\n    \n}\n\n    \ngif\n.\nEncodeAll\n(\nout\n,\n \nanim\n)\n \n// NOTE: ignoring encoding errors\n\n\n}\n\n\n\n\n\n\nPackage names with multiple components *\n\n\nAfter importing a package whose path has multiple components, we refer to the package with a name that comes from the last component. Therefore:\n\n\n\n\nThe variable \ncolor.White\n belongs to the \nimage/color\n package\n\n\nThe \ngif.GIF\n belongs to the \nimage/gif\n package\n\n\n\n\nconstant\n declarations *\n\n\nA \nconst\n declaration (\nSection 3.6\n) gives names to constants (values that are fixed at compile time) such as the numerical parameters for cycles, frames, and delay. Like \nvar\n declarations, const declarations may appear at package level (so the names are visible throughout the package) or within a function (so the names are visible only within that function). \nThe value of a constant must be a number, string, or boolean.\n\n\nComposite literals *\n\n\nThe expressions \n[]color.Color{...}\n (a slice) and \ngif.GIF{...}\n (a struct) are \ncomposite literals\n (\nSection 4.2\n, \nSection 4.4.1\n), a compact notation for instantiating any of Go\u2019s composite types from a sequence of element values.\n\n\nStructs *\n\n\nThe type \ngif.GIF\n is a struct type (\nSection 4.4\n). A struct is a group of values called \nfields\n, often of different types, that are collected together in a single object that can be treated as a unit. The variable \nanim\n is a struct of type \ngif.GIF\n. The struct literal creates a struct value whose \nLoopCount\n field is set to \nnframes\n; all other fields have the zero value for their type. The individual fields of a struct can be accessed using dot notation, as in the final two assignments which explicitly update the \nDelay\n and \nImage\n fields of \nanim\n.\n\n\nThe \nlissajous\n function *\n\n\n[p15]\n\n\n(skipped)\n\n\nUsed concepts:\n\n\n\n\nBuilt-in \nappend\n function\n\n\nio.Writer\n\n\n\n\nThe \nmain\n function calls the \nlissajous\n function, directing it to write to the standard output, so this command produces an animated GIF:\n\n\n$ go build gopl.io/ch1/lissajous\n\n\n$ ./lissajous \nout.gif\n\n\n\n\n\n\nFetching a URL\n\n\nGo provides a collection of packages, grouped under \nnet\n, that make it easy to send and receive information through the Internet, make low-level network connections, and set up servers, for which Go\u2019s concurrency features (\nChapter 8\n) are particularly useful.\n\n\nThe following program fetches the content of each specified URL and prints it as uninterpreted text, which is inspired the \ncurl\n utility:\n\n\ngopl.io/ch1/fetch/main.go\n\n\n// Fetch prints the content found at a URL.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nio/ioutil\n\n    \nnet/http\n\n    \nos\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nfor\n \n_\n,\n \nurl\n \n:=\n \nrange\n \nos\n.\nArgs\n[\n1\n:]\n \n{\n\n        \nresp\n,\n \nerr\n \n:=\n \nhttp\n.\nGet\n(\nurl\n)\n\n        \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n            \nfmt\n.\nFprintf\n(\nos\n.\nStderr\n,\n \nfetch: %v\\n\n,\n \nerr\n)\n\n            \nos\n.\nExit\n(\n1\n)\n\n        \n}\n\n        \nb\n,\n \nerr\n \n:=\n \nioutil\n.\nReadAll\n(\nresp\n.\nBody\n)\n\n        \nresp\n.\nBody\n.\nClose\n()\n\n        \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n            \nfmt\n.\nFprintf\n(\nos\n.\nStderr\n,\n \nfetch: reading %s: %v\\n\n,\n \nurl\n,\n \nerr\n)\n\n            \nos\n.\nExit\n(\n1\n)\n\n        \n}\n\n        \nfmt\n.\nPrintf\n(\n%s\n,\n \nb\n)\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThis program introduces functions from two packages, \nnet/http\n and \nio/ioutil\n.\n\n\n\n\nThe \nhttp.Get\n function makes an HTTP request and, if there is no error, returns the result in the response struct \nresp\n.\n\n\nThe \nBody\n field of \nresp\n contains the server response as a readable stream.\n\n\nioutil.ReadAll\n reads the entire response; the result is stored in \nb\n.\n\n\nThe \nBody\n stream is closed to avoid leaking resources, and \nPrintf\n writes the response to the standard output.\n\n\n\n\n$ go build gopl.io/ch1/fetch\n\n\n$ ./fetch http://gopl.io\n\n\nhtml\n\n\nhead\n\n\ntitle\nThe Go Programming Language\n/title\n\n\n...\n\n\n\n\n\n\nIf the HTTP request fails, \nfetch\n reports the failure instead:\n\n\n$ ./fetch http://bad.gopl.io\n\n\nfetch: Get http://bad.gopl.io: dial tcp: lookup bad.gopl.io: no such host\n\n\n\n\n\n\nFetching URLs Concurrently\n\n\nSupport for concurrent programming is one of the most interesting and novel aspects of Go. This is a large topic (concurrency mechanisms, goroutines and channels) to which Chapter 8 and Chapter 9 are devoted.\n\n\nThe following program, \nfetchall\n, does the same fetch of a URL\u2019s contents as the previous example, but it fetches many URLs concurrently, so that the process will take no longer than the longest fetch rather than the sum of all the fetch times. This version of \nfetchall\n discards the responses but reports the size and elapsed time for each one:\n\n\ngopl.io/ch1/fetchall/main.go\n\n\n// Fetchall fetches URLs in parallel and reports their times and sizes.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nio\n\n    \nio/ioutil\n\n    \nnet/http\n\n    \nos\n\n    \ntime\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstart\n \n:=\n \ntime\n.\nNow\n()\n\n    \nch\n \n:=\n \nmake\n(\nchan\n \nstring\n)\n\n    \nfor\n \n_\n,\n \nurl\n \n:=\n \nrange\n \nos\n.\nArgs\n[\n1\n:]\n \n{\n\n        \ngo\n \nfetch\n(\nurl\n,\n \nch\n)\n \n// start a goroutine\n\n    \n}\n\n    \nfor\n \nrange\n \nos\n.\nArgs\n[\n1\n:]\n \n{\n\n        \nfmt\n.\nPrintln\n(\n-\nch\n)\n \n// receive from channel ch\n\n    \n}\n\n    \nfmt\n.\nPrintf\n(\n%.2fs elapsed\\n\n,\n \ntime\n.\nSince\n(\nstart\n).\nSeconds\n())\n\n\n}\n\n\n\nfunc\n \nfetch\n(\nurl\n \nstring\n,\n \nch\n \nchan\n-\n \nstring\n)\n \n{\n\n    \nstart\n \n:=\n \ntime\n.\nNow\n()\n\n    \nresp\n,\n \nerr\n \n:=\n \nhttp\n.\nGet\n(\nurl\n)\n\n    \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n        \nch\n \n-\n \nfmt\n.\nSprint\n(\nerr\n)\n \n// send to channel ch\n\n        \nreturn\n\n    \n}\n\n\n    \nnbytes\n,\n \nerr\n \n:=\n \nio\n.\nCopy\n(\nioutil\n.\nDiscard\n,\n \nresp\n.\nBody\n)\n\n    \nresp\n.\nBody\n.\nClose\n()\n \n// don\nt leak resources\n\n    \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n        \nch\n \n-\n \nfmt\n.\nSprintf\n(\nwhile reading %s: %v\n,\n \nurl\n,\n \nerr\n)\n\n        \nreturn\n\n    \n}\n\n    \nsecs\n \n:=\n \ntime\n.\nSince\n(\nstart\n).\nSeconds\n()\n\n    \nch\n \n-\n \nfmt\n.\nSprintf\n(\n%.2fs  %7d  %s\n,\n \nsecs\n,\n \nnbytes\n,\n \nurl\n)\n\n\n}\n\n\n\n\n\n\nResult:\n\n\n$ go build gopl.io/ch1/fetchall\n\n\n$ ./fetchall https://golang.org http://gopl.io https://godoc.org\n\n\n0.14s\n\n\n6852 https://godoc.org\n\n\n0.16s\n\n\n7261 https://golang.org\n\n\n0.48s\n\n\n2475 http://gopl.io\n\n\n0.48s elapsed\n\n\n\n\n\n\n\n\nA \ngoroutine\n is a concurrent function execution.\n\n\nA \nchannel\n is a communication mechanism that allows one goroutine to pass values of a specified type to another goroutine.\n\n\nThe function \nmain\n runs in a goroutine and the \ngo\n statement creates additional goroutines.\n\n\n\n\n\n\n\n\nThis program does the following:\n\n\n\n\nThe \nmain\n function creates a channel of strings using \nmake\n.\n\n\nFor each command-line argument, the \ngo\n statement in the first range loop starts a new goroutine that calls \nfetch\n asynchronously to fetch the URL using \nhttp.Get\n.\n\n\nThe \nio.Copy\n function reads the body of the response and discards it by writing to the \nioutil.Discard\n output stream.\n\n\nCopy\n returns the byte count, along with any error that occurred. As each result arrives, \nfetch\n sends a summary line on the channel \nch\n.\n\n\nThe second range loop in main receives and prints those lines.\n\n\n\n\nWhen one goroutine attempts a send or receive on a channel, it blocks until another goroutine attempts the corresponding receive or send operation, at which point the value is transferred and both goroutines proceed. In this example, each \nfetch\n sends a value (\nch \n-\n \nexpression\n) on the channel \nch\n, and \nmain\n receives all of them (\n-ch\n). \nHaving \nmain\n do all the printing ensures that output from each goroutine is processed as a unit, with no danger of interleaving if two goroutines finish at the same time.\n\n\nA Web Server\n\n\nGo\u2019s libraries makes it easy to write a web server.\n\n\nEchoing URL path *\n\n\nThe following example shows a minimal server that returns the path component of the URL used to access the server. That is, if the request is for \nhttp://localhost:8000/hello\n, the response will be \nURL.Path = \"/hello\"\n.\n\n\ngopl.io/ch1/server1/main.go\n\n\n// Server1 is a minimal \necho\n server.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nlog\n\n    \nnet/http\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nhttp\n.\nHandleFunc\n(\n/\n,\n \nhandler\n)\n \n// each request calls handler\n\n    \nlog\n.\nFatal\n(\nhttp\n.\nListenAndServe\n(\nlocalhost:8000\n,\n \nnil\n))\n\n\n}\n\n\n\n// handler echoes the Path component of the request URL r.\n\n\nfunc\n \nhandler\n(\nw\n \nhttp\n.\nResponseWriter\n,\n \nr\n \n*\nhttp\n.\nRequest\n)\n \n{\n\n    \nfmt\n.\nFprintf\n(\nw\n,\n \nURL.Path = %q\\n\n,\n \nr\n.\nURL\n.\nPath\n)\n\n\n}\n\n\n\n\n\n\nThis program does the following:\n\n\n\n\nThe \nmain\n function connects a handler function to incoming URLs that begin with \n/\n (which is all URLs) using \nhttp.HandleFunc\n, and starts a server listening for incoming requests on port 8000 using \nhttp.ListenAndServe\n.\n\n\nA request is represented as a struct of type \nhttp.Request\n, which contains a number of related fields, one of which is the URL of the incoming request.\n\n\nWhen a request arrives, it is given to the \nhandler\n function, which extracts the path component (\n/hello\n) from the request URL and sends it back as the response, using \nfmt.Fprintf\n. Web servers will be explained in detail in \nSection 7.7\n.\n\n\n\n\nRequest counter *\n\n\nThis version does the same echo but also counts the number of requests; a request to the URL \n/count\n returns the count so far, excluding \n/count\n requests themselves:\n\n\ngopl.io/ch1/server2/main.go\n\n\n// Server2 is a minimal \necho\n and counter server.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nlog\n\n    \nnet/http\n\n    \nsync\n\n\n)\n\n\n\nvar\n \nmu\n \nsync\n.\nMutex\n\n\nvar\n \ncount\n \nint\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nhttp\n.\nHandleFunc\n(\n/\n,\n \nhandler\n)\n\n    \nhttp\n.\nHandleFunc\n(\n/count\n,\n \ncounter\n)\n\n    \nlog\n.\nFatal\n(\nhttp\n.\nListenAndServe\n(\nlocalhost:8000\n,\n \nnil\n))\n\n\n}\n\n\n\n// handler echoes the Path component of the requested URL.\n\n\nfunc\n \nhandler\n(\nw\n \nhttp\n.\nResponseWriter\n,\n \nr\n \n*\nhttp\n.\nRequest\n)\n \n{\n\n    \nmu\n.\nLock\n()\n\n    \ncount\n++\n\n    \nmu\n.\nUnlock\n()\n\n    \nfmt\n.\nFprintf\n(\nw\n,\n \nURL.Path = %q\\n\n,\n \nr\n.\nURL\n.\nPath\n)\n\n\n}\n\n\n\n// counter echoes the number of calls so far.\n\n\nfunc\n \ncounter\n(\nw\n \nhttp\n.\nResponseWriter\n,\n \nr\n \n*\nhttp\n.\nRequest\n)\n \n{\n\n    \nmu\n.\nLock\n()\n\n    \nfmt\n.\nFprintf\n(\nw\n,\n \nCount %d\\n\n,\n \ncount\n)\n\n    \nmu\n.\nUnlock\n()\n\n\n}\n\n\n\n\n\n\nThe server has two handlers, and the request URL determines which one is called: a request for \n/count\n invokes \ncounter\n and all others invoke \nhandler\n. A handler pattern that ends with a slash matches any URL that has the pattern as a prefix.\n\n\nBehind the scenes, the server runs the handler for each incoming request in a separate goroutine so that it can serve multiple requests simultaneously. We must ensure that at most one goroutine accesses the \ncount\n variable at a time, which is the purpose of the \nmu.Lock()\n and \nmu.Unlock()\n calls that bracket each access of \ncount\n. Otherwise, if two concurrent requests try to update count at the same time, it might not be incremented consistently; the program would have a serious bug called a race condition. Concurrency and shared variables are detailed in \nChapter 9\n.\n\n\nInspecting requests *\n\n\nIn the following example, the \nhandler\n function can report on the headers and form data that it receives, making the server useful for inspecting and debugging requests:\n\n\ngopl.io/ch1/server3/main.go\n\n\n// handler echoes the HTTP request.\n\n\nfunc\n \nhandler\n(\nw\n \nhttp\n.\nResponseWriter\n,\n \nr\n \n*\nhttp\n.\nRequest\n)\n \n{\n\n    \nfmt\n.\nFprintf\n(\nw\n,\n \n%s %s %s\\n\n,\n \nr\n.\nMethod\n,\n \nr\n.\nURL\n,\n \nr\n.\nProto\n)\n\n    \nfor\n \nk\n,\n \nv\n \n:=\n \nrange\n \nr\n.\nHeader\n \n{\n\n        \nfmt\n.\nFprintf\n(\nw\n,\n \nHeader[%q] = %q\\n\n,\n \nk\n,\n \nv\n)\n\n    \n}\n\n    \nfmt\n.\nFprintf\n(\nw\n,\n \nHost = %q\\n\n,\n \nr\n.\nHost\n)\n\n    \nfmt\n.\nFprintf\n(\nw\n,\n \nRemoteAddr = %q\\n\n,\n \nr\n.\nRemoteAddr\n)\n\n    \nif\n \nerr\n \n:=\n \nr\n.\nParseForm\n();\n \nerr\n \n!=\n \nnil\n \n{\n\n        \nlog\n.\nPrint\n(\nerr\n)\n\n    \n}\n\n    \nfor\n \nk\n,\n \nv\n \n:=\n \nrange\n \nr\n.\nForm\n \n{\n\n        \nfmt\n.\nFprintf\n(\nw\n,\n \nForm[%q] = %q\\n\n,\n \nk\n,\n \nv\n)\n\n    \n}\n\n\n}\n\n\n\n\n\n\n[p21]\n\n\nThe call to \nParseForm\n is nested within an \nif\n statement. Go allows a simple statement such as a local variable declaration to precede the \nif\n condition, which is particularly useful for error handling as in this example. It could have been written it as:\n\n\nerr\n \n:=\n \nr\n.\nParseForm\n()\n\n\nif\n \nerr\n \n!=\n \nnil\n \n{\n\n    \nlog\n.\nPrint\n(\nerr\n)\n\n\n}\n\n\n\n\n\n\nbut combining the statements is shorter and reduces the scope of the variable \nerr\n, which is good practice. Scope is defined in \nSection 2.7\n.\n\n\nIn these programs, three very different types are used as output streams:\n\n\n\n\nThe \nfetch\n program copied HTTP response data to \nos.Stdout\n,\n\n\nThe \nfetchall\n program threw the response away by copying it to the trivial sink \nioutil.Discard\n.\n\n\nThe web server above used \nfmt.Fprintf\nto write to an \nhttp.ResponseWriter\n representing the web browser.\n\n\n\n\nAlthough these three types differ in the details of what they do, they all satisfy a common\ninterface, allowing any of them to be used wherever an output stream is needed. That interface, called \nio.Writer\n, is discussed in \nSection 7.1\n.\n\n\nGo\u2019s interface mechanism is the topic of \nChapter 7\n. It's easy to combine the web server with the \nlissajous\n function so that animated GIFs are written not to the standard output, but to the HTTP client. Add the following code:\n\n\nhandler\n \n:=\n \nfunc\n(\nw\n \nhttp\n.\nResponseWriter\n,\n \nr\n \n*\nhttp\n.\nRequest\n)\n \n{\n\n    \nlissajous\n(\nw\n)\n\n\n}\n\n\nhttp\n.\nHandleFunc\n(\n/\n,\n \nhandler\n)\n\n\n\n\n\n\nor equivalently:\n\n\nhttp\n.\nHandleFunc\n(\n/\n,\n \nfunc\n(\nw\n \nhttp\n.\nResponseWriter\n,\n \nr\n \n*\nhttp\n.\nRequest\n)\n \n{\n\n    \nlissajous\n(\nw\n)\n\n\n})\n\n\n\n\n\n\nThe second argument to the \nHandleFunc\n function call immediately above is a \nfunction literal\n, which is an anonymous function defined at its point of use. This is detailed in \nSection 5.6\n.\n\n\nLoose Ends\n\n\nThe following are some topics that have been barely touched upon or omitted entirely.\n\n\nControl flow\n\n\nThe \nswitch\n statement\n *\n\n\nBesides \nif\n and \nfor\n, there is the \nswitch\n statement, which is a multi-way branch. For example:\n\n\nswitch\n \ncoinflip\n()\n \n{\n\n\ncase\n \nheads\n:\n\n    \nheads\n++\n\n\ncase\n \ntails\n:\n\n    \ntails\n++\n\n\ndefault\n:\n\n    \nfmt\n.\nPrintln\n(\nlanded on edge!\n)\n\n\n}\n\n\n\n\n\n\nThe result of calling \ncoinflip\n is compared to the value of each case. Cases are evaluated from\ntop to bottom, so the first matching one is executed. \nThe optional default case matches if none\nof the other cases does; it may be placed anywhere. Cases do not fall through from one to the\nnext as in C-like languages,\n though there is a rarely used \nfallthrough\n statement that overrides this behavior.\n\n\nA \nswitch\n does not need an operand; it can just list the cases, each of which is a boolean expression:\n\n\nfunc\n \nSignum\n(\nx\n \nint\n)\n \nint\n \n{\n\n    \nswitch\n \n{\n\n    \ncase\n \nx\n \n \n0\n:\n\n        \nreturn\n \n+\n1\n\n    \ndefault\n:\n\n        \nreturn\n \n0\n\n    \ncase\n \nx\n \n \n0\n:\n\n        \nreturn\n \n-\n1\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThis form is called a \ntagless switch\n; it\u2019s equivalent to \nswitch true\n.\n\n\nLike the \nfor\n and \nif\n statements, a \nswitch\n may include an optional simple statement: a short variable declaration, an increment or assignment statement, or a function call, that can be used to set a value before it is tested.\n\n\nbreak\n and \ncontinue\n *\n\n\nThe \nbreak\n and continue \nstatements\n modify the flow of control.\n\n\n\n\nA \nbreak\n causes control to resume at the next statement after the innermost \nfor\n, \nswitch\n, or \nselect\n statement\n\n\nA \ncontinue\n causes the innermost for loop to start its next iteration.\n\n\n\n\nStatements \nmay be labeled\n so that \nbreak\n and \ncontinue\n can refer to them, for instance to break out of several nested loops at once or to start the next iteration of the outermost loop.\n\n\nThere is even a \ngoto\n statement, though it\u2019s intended for machine-generated code, not regular use by programmers.", 
            "title": "Chapter 1. Tutorial"
        }, 
        {
            "location": "/gopl/ch2/", 
            "text": "Chapter 2. Program Structure\n\n\nThis chapter provides details about the basic structural elements of a Go program.\n\n\nNames\n\n\nIn Go, the names of functions, variables, constants, types, statement labels, and packages follow a simple rule: a name begins with a letter (anything that Unicode deems a letter) or an underscore and may have any number of additional letters, digits, and underscores. The names are case-sensitive: \nheapSort\n and \nHeapsort\n are different names.\n\n\nGo has 25 keywords like \nif\n and \nswitch\n that may be used only where the syntax permits; they can\u2019t be used as names.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbreak\n\n\ndefault\n\n\nfunc\n\n\ninterface\n\n\n\n\n\n\ncase\n\n\ndefer\n\n\ngo\n\n\nmap\n\n\n\n\n\n\nchan\n\n\nelse\n\n\ngoto\n\n\npackage\n\n\n\n\n\n\nconst\n\n\nfallthrough\n\n\nif\n\n\nrange\n\n\n\n\n\n\ncontinue\n\n\nfor\n\n\nimport\n\n\nreturn\n\n\n\n\n\n\n\n\nIn addition, there are about three dozen \npredeclared\n names like \nint\n and \ntrue\n for built-in constants, types, and functions:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstants:\n\n\ntrue\n \nfalse\n \niota\n \nnil\n\n\n\n\n\n\nTypes:\n\n\nint\n \nint8\n \nint16\n \nint32\n \nint64\n \nuint\n \nuint8\n \nuint16\n \nuint32\n \nuint64\n \nuintptr\n \nfloat32\n \nfloat64\n \ncomplex128\n \ncomplex64\n \nbool\n \nbyte\n \nrune\n \nstring\n \nerror\n\n\n\n\n\n\nFunctions:\n\n\nmake\n \nlen\n \ncap\n \nnew\n \nappend\n \ncopy\n \nclose\n \ndelete\n \ncomplex\n \nreal\n \nimag\n \npanic\n \nrecover\n\n\n\n\n\n\n\n\nThese names are not reserved, so you may use them in declarations. Beware of the potential for confusion.\n\n\nLocal and exported names *\n\n\nIf an entity is:\n\n\n\n\nDeclared within a function: it is \nlocal\n to that function.\n\n\nDeclared outside of a function: it is visible in all files of the package to which it belongs.\n\n\n\n\nThe case of the first letter of a name determines its visibility across package boundaries:\n\n\n\n\nIf the name begins with an upper-case letter, it is \nexported\n (visible and accessible outside of its own package and may be referred to by other parts of the program), as with \nPrintf\n in the \nfmt\n package.\n\n\nPackage names themselves are always in lower case.\n\n\n\n\nNaming convention and style *\n\n\n\n\nThere is no limit on name length;\n\n\nShort names are preferred, especially for local variables with small scopes (\ni\n is better than \ntheLoopIndex\n);\n\n\nThe larger the scope of a name, the longer and more meaningful it should be.\n\n\nCamel case\n are used when forming names by combining words, e.g. \nQuoteRuneToASCII\n and \nparseRequestLine\n (instead of \nquote_rune_to_ASCII\n or \nparse_request_line\n).\n\n\nThe letters of acronyms and initialisms like \nASCII\n and \nHTML\n are always rendered in the same case, so a function might be called \nhtmlEscape\n, \nHTMLEscape\n, or \nescapeHTML\n, but not \nescapeHtml\n.\n\n\n\n\nDeclarations\n\n\nA \ndeclaration\n names a program entity and specifies its properties. There are four major kinds of declarations:\n\n\n\n\nvar\n (variables)\n\n\nconst\n (constants)\n\n\ntype\n (types)\n\n\nfunc\n (functions)\n\n\n\n\nThis chapter discusses variables and types. Constants are disucssed in \nChapter 3\n, and functions in \nChapter 5\n.\n\n\nEach \n.go\n file has declarations in the following order:\n\n\n\n\nA \npackage\n declaration that says what package the file is part of.\n\n\nAny \nimport\n declarations\n\n\nA sequence of package-level declarations of types, variables, constants, and functions, in any order.\n\n\n\n\nFor example, the following program declares a constant, a function, and a couple of variables:\n\n\ngopl.io/ch2/boiling/main.go\n\n\n// Boiling prints the boiling point of water.\n\n\npackage\n \nmain\n\n\n\nimport\n \nfmt\n\n\n\nconst\n \nboilingF\n \n=\n \n212.0\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nvar\n \nf\n \n=\n \nboilingF\n\n    \nvar\n \nc\n \n=\n \n(\nf\n \n-\n \n32\n)\n \n*\n \n5\n \n/\n \n9\n\n    \nfmt\n.\nPrintf\n(\nboiling point = %g\u00b0F or %g\u00b0C\\n\n,\n \nf\n,\n \nc\n)\n\n    \n// Output:\n\n    \n// boiling point = 212\u00b0F or 100\u00b0C\n\n\n}\n\n\n\n\n\n\n\n\nEach package-level name is visible in all the files of the package.\n\n\nLocal declarations are visible only within the function in which they are declared.\n\n\n\n\nA function declaration has a name, a list of parameters an optional list of results (omitted if the function does not return anything), and the function body.\n\n\nVariables\n\n\nA \nvar\n declaration creates a variable of a particular type, attaches a name to it, and sets its initial value, with the general form:\n\n\nvar\n \nname\n \ntype\n \n=\n \nexpression\n\n\n\n\n\n\nEither the type or the \n= expression\n part may be omitted, but not both:\n\n\n\n\nIf the type is omitted, it is determined by the initializer expression.\n\n\nIf the expression is omitted, the initial value is the \nzero value\n for the type, which is:\n\n\n0 for numbers\n\n\nfalse\n for booleans\n\n\n\"\"\n for strings\n\n\nnil\n for interfaces and reference types (slice, pointer, map, channel, function).\n\n\n\n\n\n\n\n\nThe zero value of an aggregate type like an array or a struct has the zero value of all of its elements or fields.\n\n\nThe zero-value mechanism ensures that a variable always holds a well-defined value of its type; in Go there is no such thing as an uninitialized variable. This simplifies code and often ensures sensible behavior of boundary conditions without extra work. For example,\n\n\nvar\n \ns\n \nstring\n\n\nfmt\n.\nPrintln\n(\ns\n)\n \n// \n\n\n\n\n\n\nGo programmers often go to some effort to make the zero value of a more complicated type meaningful, so that variables begin life in a useful state.\n\n\nIt is possible to declare and optionally initialize a set of variables in a single declaration, with a matching list of expressions. Omitting the type allows declaration of multiple variables of different types:\n\n\nvar\n \ni\n,\n \nj\n,\n \nk\n \nint\n \n// int, int, int\n\n\nvar\n \nb\n,\n \nf\n,\n \ns\n \n=\n \ntrue\n,\n \n2.3\n,\n \nfour\n \n// bool, float64, string\n\n\n\n\n\n\n\n\nInitializers may be literal values or arbitrary expressions.\n\n\nPackage-level variables are initialized before \nmain\n begins (\nSection 2.6.2\n).\n\n\nLocal variables are initialized as their declarations are encountered during function execution.\n\n\n\n\nA set of variables can also be initialized by calling a function that returns multiple values:\n\n\nvar\n \nf\n,\n \nerr\n \n=\n \nos\n.\nOpen\n(\nname\n)\n \n// os.Open returns a file and an error\n\n\n\n\n\n\nShort Variable Declarations\n\n\nWithin a function, an alternate form called a short variable declaration may be used to declare and initialize local variables. It takes the form \nname := expression\n, and the type of name is determined by the type of expression. For exmaple (\nAnimated GIFs\n),\n\n\nWhen to use short variable declaration and \nvar\n declaration\n *\n\n\n\n\nShort variable declarations are used to declare and initialize the majority of local variables, for brevity and flexibility.\n\n\nA \nvar\n declaration tends to be reserved for:\n\n\nLocal variables that need an explicit type that differs from that of the initializer expression;\n\n\nLocal variables when they will be assigned a value later and its initial value is unimportant.\n\n\n\n\n\n\n\n\ni\n \n:=\n \n100\n \n// an int\n\n\nvar\n \nboiling\n \nfloat64\n \n=\n \n100\n \n// a float64\n\n\nvar\n \nnames\n \n[]\nstring\n\n\nvar\n \nerr\n \nerror\n\n\nvar\n \np\n \nPoint\n\n\n\n\n\n\nAs with \nvar\n declarations, multiple variables may be declared and initialized in the same short variable declaration:\n\n\ni\n,\n \nj\n \n:=\n \n0\n,\n \n1\n\n\n\n\n\n\nHowever, declarations with multiple initializer expressions should be used only when they help readability, such as for short and natural groupings like the initialization part of a for loop.\n\n\nKeep in mind that \n:=\n is a declaration, whereas \n=\n is an assignment. A multi-variable declaration should not be confused with a \ntuple assignment\n, in which each variable on the left-hand side is assigned the corresponding value from the right-hand side:\n\n\ni\n,\n \nj\n \n=\n \nj\n,\n \ni\n \n// swap values of i and j\n\n\n\n\n\n\nLike \nvar\n declarations, short variable declarations may be used for calls to functions like \nos.Open\n that return two or more values:\n\n\nf\n,\n \nerr\n \n:=\n \nos\n.\nOpen\n(\nname\n)\n\n    \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n        \nreturn\n \nerr\n\n\n}\n\n\n// ...use f...\n\n\nf\n.\nClose\n()\n\n\n\n\n\n\nOne subtle but important point\n *\n\n\nA short variable declaration does not necessarily declare all the variables on its left-hand side. If some of them were already declared in the same lexical block , then the short variable declaration acts like an assignment to those variables. For example,\n\n\nin\n,\n \nerr\n \n:=\n \nos\n.\nOpen\n(\ninfile\n)\n\n\n// ...\n\n\nout\n,\n \nerr\n \n:=\n \nos\n.\nCreate\n(\noutfile\n)\n\n\n\n\n\n\nIn the above code:\n\n\n\n\nThe first statement declares both \nin\n and \nerr\n.\n\n\nThe second declares \nout\n but only assigns a value to the existing \nerr\n variable.\n\n\n\n\nA short variable declaration must declare at least one new variable. Therefore, the following code will not compile:\n\n\nf\n,\n \nerr\n \n:=\n \nos\n.\nOpen\n(\ninfile\n)\n\n\n// ...\n\n\nf\n,\n \nerr\n \n:=\n \nos\n.\nCreate\n(\noutfile\n)\n \n// compile error: no new variables\n\n\n\n\n\n\nThe fix is to use an ordinary assignment for the second statement.\n\n\nA short variable declaration acts like an assignment only to variables that were already declared in the same lexical block; declarations in an outer block are ignored.\n\n\nPointers\n\n\nA \nvariable\n is a piece of storage containing a value.\n\n\n\n\nVariables created by declarations are identified by a name, such as \nx\n\n\nMany other variables are identified only by expressions like \nx[i]\n or \nx.f\n.\n\n\n\n\nAll these expressions read the value of a variable, except when they appear on the lefthand side of an assignment, in which case a new value is assigned to the variable.\n\n\nA \npointer\n value is the address of a variable. A pointer is thus the location at which a value is stored. Not every value has an address, but every variable does. With a pointer, we can read or update the value of a variable indirectly, without using or even knowing the name of the variable, if indeed it has a name.\n\n\nPointer type (\n*type\n) and address-of (\n) operators\n *\n\n\nIf a variable is declared \nvar x int\n, the expression \nx\n (\"address of \nx\n\") yields a pointer to an integer variable (a value of type \n*int\n, which is pronounced \"pointer to \nint\n\"). If this value is called \np\n, we say \"\np\n points to \nx\n\", or equivalently \"\np\n contains the address of \nx\n\". The variable to which \np\n points is written \n*p\n. The expression \n*p\n yields the value of that variable, an \nint\n, but since \n*p\n denotes a variable, it may also appear on the left-hand side of an assignment, in which case the assignment updates the variable.\n\n\nx\n \n:=\n \n1\n\n\np\n \n:=\n \nx\n          \n// p, of type *int, points to x\n\n\nfmt\n.\nPrintln\n(\n*\np\n)\n  \n// \n1\n\n\n*\np\n \n=\n \n2\n           \n// equivalent to x = 2\n\n\nfmt\n.\nPrintln\n(\nx\n)\n   \n// \n2\n\n\n\n\n\n\nEach component of a variable of aggregate type: a field of a struct or an element of an array, is also a variable and thus has an address too.\n\n\nVariables are sometimes described as \naddressable\n values. Expressions that denote variables are the only expressions to which the \naddress-of\n operator \n may be applied.\n\n\nComparing pointers\n *\n\n\nThe zero value for a pointer of any type is \nnil\n. The test \np != nil\n is true if \np\n points to a variable. Pointers are comparable; two pointers are equal if and only if they point to the same variable or both are \nnil\n.\n\n\nvar\n \nx\n,\n \ny\n \nint\n\n\nfmt\n.\nPrintln\n(\nx\n \n==\n \nx\n,\n \nx\n \n==\n \ny\n,\n \nx\n \n==\n \nnil\n)\n \n// \ntrue false false\n\n\n\n\n\n\nIt is perfectly safe for a function to return the address of a local variable.\n For example:\n\n\nvar\n \np\n \n=\n \nf\n()\n\n\n\nfunc\n \nf\n()\n \n*\nint\n \n{\n\n    \nv\n \n:=\n \n1\n\n    \nreturn\n \nv\n\n\n}\n\n\n\n\n\n\nThe local variable \nv\n created by this particular call to \nf\n will remain in existence even after the call has returned, and the pointer \np\n will still refer to it.\n Each call of \nf\n returns a distinct value:\n\n\nfmt\n.\nPrintln\n(\nf\n()\n \n==\n \nf\n())\n \n// \nfalse\n\n\n\n\n\n\nPassing a pointer argument to a function makes it possible for the function to update the variable that was indirectly passed. For example:\n\n\nfunc\n \nincr\n(\np\n \n*\nint\n)\n \nint\n \n{\n\n    \n*\np\n++\n \n// increments what p points to; does not change p\n\n    \nreturn\n \n*\np\n\n\n}\n\n\n\nv\n \n:=\n \n1\n\n\nincr\n(\nv\n)\n\n\n// side effect: v is now 2\n\n\nfmt\n.\nPrintln\n(\nincr\n(\nv\n))\n \n// \n3\n (and v is 3)\n\n\n\n\n\n\nPointer aliasing\n *\n\n\nEach time we take the address of a variable or copy a pointer, we create new aliases or ways to identify the same variable. For example, \n*p\n is an alias for \nv\n. Pointer aliasing is useful because it allows us to access a variable without using its name, but this is a double-edged sword: to find all the statements that access a variable, we have to know all its aliases. \nAliasing also occurs when we copy values of other reference types like slices, maps, and channels, and even structs, arrays, and interfaces that contain these types.\n\n\nPointer and the \nflag\n package\n\n\nPointers are key to the \nflag\n package, which uses a program\u2019s command-line arguments to set the values of certain variables for the entire program. To illustrate, this variation on the earlier \necho\n command takes two optional flags:\n\n\n\n\n-n\n causes \necho\n to omit the trailing newline that would normally be printed;\n\n\n-s sep\n causes it to separate the output arguments by the contents of the string \nsep\n instead of the default single space.\n\n\n\n\ngopl.io/ch2/echo4/main.go\n\n\n// Echo4 prints its command-line arguments.\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nflag\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nvar\n \nn\n \n=\n \nflag\n.\nBool\n(\nn\n,\n \nfalse\n,\n \nomit trailing newline\n)\n\n\nvar\n \nsep\n \n=\n \nflag\n.\nString\n(\ns\n,\n \n \n,\n \nseparator\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nflag\n.\nParse\n()\n\n    \nfmt\n.\nPrint\n(\nstrings\n.\nJoin\n(\nflag\n.\nArgs\n(),\n \n*\nsep\n))\n\n    \nif\n \n!\n*\nn\n \n{\n\n        \nfmt\n.\nPrintln\n()\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe function \nflag.Bool\n creates a new flag variable of type \nbool\n. It takes three arguments:\n\n\n\n\nThe name of the flag (\n\"n\"\n),\n\n\nThe variable\u2019s default value (\nfalse\n),\n\n\nA message that will be printed if the user provides an invalid argument, an invalid flag, or \n-h\n or \n-help\n.\n\n\n\n\nThis is similar to \nflag.String\n.\n\n\nThe variables \nsep\n and \nn\n are pointers to the flag variables, which must be accessed indirectly as \n*sep\n and \n*n\n.\n\n\nWhen the program is run, it must call \nflag.Parse\n before the flags are used, to update the flag variables from their default values. The non-flag arguments are available from \nflag.Args()\n as a slice of strings. If \nflag.Parse\n encounters an error, it prints a usage message and calls \nos.Exit(2)\n to terminate the program.\n\n\nThe following are some test results:\n\n\n$ go build gopl.io/ch2/echo4\n\n\n$ ./echo4 a bc def\n\n\na bc def\n\n\n$ ./echo4 -s / a bc def\n\n\na/bc/def\n\n\n$ ./echo4 -n a bc def\n\n\na bc def$\n\n\n$ ./echo4 -help\n\n\nUsage of ./echo4:\n\n\n  -n    omit trailing newline\n\n\n  -s string\n\n\n        separator (default \n \n)\n\n\n\n\n\n\nThe \nnew\n Function\n\n\nAnother way to create a variable is to use the built-in function \nnew\n. The expression \nnew(T)\n creates an \nunnamed variable\n (\nanonymous variable\n) of type \nT\n, initializes it to the zero value of \nT\n, and returns its address, which is a value of type \n*T\n.\n\n\np\n \n:=\n \nnew\n(\nint\n)\n    \n// p, of type *int, points to an unnamed int variable\n\n\nfmt\n.\nPrintln\n(\n*\np\n)\n  \n// \n0\n\n\n*\np\n \n=\n \n2\n           \n// sets the unnamed int to 2\n\n\nfmt\n.\nPrintln\n(\n*\np\n)\n  \n// \n2\n\n\n\n\n\n\nA variable created with \nnew\n is no different from an ordinary local variable whose address is taken, except that there\u2019s no need to invent (and declare) a dummy name, and we can use \nnew(T)\n in an expression. \nThus \nnew\n is only a syntactic convenience, not a fundamental notion.\n\n\nThe two \nnewInt\n functions below have identical behaviors:\n\n\nfunc\n \nnewInt\n()\n \n*\nint\n \n{\n\n    \nreturn\n \nnew\n(\nint\n)\n\n\n}\n\n\n\n\n\n\nfunc\n \nnewInt\n()\n \n*\nint\n \n{\n\n    \nvar\n \ndummy\n \nint\n\n    \nreturn\n \ndummy\n\n\n}\n\n\n\n\n\n\nEach call to new returns a distinct variable with a unique address:\n\n\np\n \n:=\n \nnew\n(\nint\n)\n\n\nq\n \n:=\n \nnew\n(\nint\n)\n\n\nfmt\n.\nPrintln\n(\np\n \n==\n \nq\n)\n \n// \nfalse\n\n\n\n\n\n\nThere is one exception to this rule: two variables whose type carries no information and is therefore of size zero, such as \nstruct{}\n or \n[0]int\n, may have the same address (depending on the implementation).\n\n\nThe \nnew\n function is relatively rarely used because the most common unnamed variables are of struct types, for which the struct literal syntax (\nSection 4.4.1\n) is more flexible.\n\n\nSince new is a predeclared function, not a keyword, it\u2019s possible to redefine the name for something else within a function, for example:\n\n\nfunc\n \ndelta\n(\nold\n,\n \nnew\n \nint\n)\n \nint\n \n{\n \nreturn\n \nnew\n \n-\n \nold\n \n}\n\n\n\n\n\n\nWithin \ndelta\n, the built-in \nnew\n function is unavailable.\n\n\nLifetime of Variables\n\n\nThe lifetime of a variable is the interval of time during which it exists as the program executes.\n\n\n\n\nThe lifetime of a package-level variable is the entire execution of the program.\n\n\nLocal variables have dynamic lifetimes: a new instance is created each time the declaration statement is executed, and the variable lives on until it becomes \nunreachable\n, at which point its storage may be recycled.\n\n\nFunction parameters and results are also local variables; they are created each time their enclosing function is called.\n\n\n\n\nFor example, in this excerpt from the Lissajous program of \nSection 1.4\n:\n\n\nfor\n \nt\n \n:=\n \n0.0\n;\n \nt\n \n \ncycles\n*\n2\n*\nmath\n.\nPi\n;\n \nt\n \n+=\n \nres\n \n{\n\n    \nx\n \n:=\n \nmath\n.\nSin\n(\nt\n)\n\n    \ny\n \n:=\n \nmath\n.\nSin\n(\nt\n*\nfreq\n \n+\n \nphase\n)\n\n    \nimg\n.\nSetColorIndex\n(\nsize\n+\nint\n(\nx\n*\nsize\n+\n0.5\n),\n \nsize\n+\nint\n(\ny\n*\nsize\n+\n0.5\n),\n\n        \nblackIndex\n)\n\n\n}\n\n\n\n\n\n\n\n\nThe variable \nt\n is created each time the for loop begins.\n\n\nNew variables \nx\n and \ny\n are created on each iteration of the loop.\n\n\n\n\nHow does the garbage collector know that a variable\u2019s storage can be reclaimed?\n *\n\n\nThe basic idea is that every package-level variable, and every local variable of each currently active function, can potentially be the start or root of a path to the variable in question, following pointers and other kinds of references that ultimately lead to the variable. If no such path exists, the variable has become unreachable, so it can no longer affect the rest of the computation.\n\n\nBecause the lifetime of a variable is determined only by whether or not it is reachable, a local variable may outlive a single iteration of the enclosing loop. It may continue to exist even after its enclosing function has returned.\n\n\nHeap or stack?\n *\n\n\nA compiler may choose to allocate local variables on the heap or on the stack, but this choice is not determined by whether \nvar\n or \nnew\n was used to declare the variable.\n\n\nvar\n \nglobal\n \n*\nint\n\n\n\nfunc\n \nf\n()\n \n{\n\n    \nvar\n \nx\n \nint\n\n    \nx\n \n=\n \n1\n\n    \nglobal\n \n=\n \nx\n\n\n}\n\n\n\nfunc\n \ng\n()\n \n{\n\n    \ny\n \n:=\n \nnew\n(\nint\n)\n\n    \n*\ny\n \n=\n \n1\n\n\n}\n\n\n\n\n\n\nIn the above code:\n\n\n\n\nx\n must be heap-allocated because it is still reachable from the variable \nglobal\n after \nf\n has returned, despite being declared as a local variable; we say \nx\n \nescapes\n from \nf\n.\n\n\nConversely, when \ng\n returns, the variable \n*y\n becomes unreachable and can be recycled. Since \n*y\n does not escape from \ng\n, it\u2019s safe for the compiler to allocate *y on the stack, even though it was allocated with \nnew\n.\n\n\n\n\nIn any case, the notion of escaping is not something that you need to worry about in order to write correct code, though it\u2019s good to keep in mind during performance optimization, since each variable that escapes requires an extra memory allocation.\n\n\nThoughts on garbage collection\n *\n\n\nGarbage collection is a tremendous help in writing correct programs, but it does not relieve you of the burden of thinking about memory. You don\u2019t need to explicitly allocate and free memory, but to write efficient programs you still need to be aware of the lifetime of variables.  For example, keeping unnecessary pointers to short-lived objects within long-lived objects, especially global variables, will prevent the garbage collector from reclaiming the short-lived objects.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np32 on short variable declaration.\n\n\n\n\nA short variable declaration acts like an assignment only to variables that were already declared in the same lexical block; declarations in an outer block are ignored.\n\n\n\n\nWhat does \"declarations in an outer block are ignored\" mean?", 
            "title": "Chapter 2. Program Structure"
        }, 
        {
            "location": "/gopl/ch3/", 
            "text": "Chapter 3. Basic Data Types\n\n\nComputers operate fundamentally on fixed-size numbers called \nwords\n, which are interpreted as integers, floating-point numbers, bit sets, or memory addresses, then combined into larger aggregates.\n\n\nGo\u2019s types fall into four categories:\n\n\n\n\nBasic types: numbers, strings, and booleans.\n\n\nAggregate types: arrays and structs.\n\n\nReference types: pointers, slices, maps, functions, and channels .\n\n\nInterface types\n\n\n\n\nBasic types (discussed in this chapter) include numbers, strings, and booleans.\n\n\nIntegers\n\n\nGo provides both signed and unsigned integer arithmetic. There are four distinct sizes of\nsigned integers: 8, 16, 32, and 64 bits. They represented by:\n\n\n\n\nSigned: \nint8\n, \nint16\n, \nint32\n, and \nint64\n;\n\n\nUnsigned: \nuint8\n, \nuint16\n, \nuint32\n, and \nuint64\n.\n\n\n\n\nThere are also two types \nint\n and \nuint\n that are the natural or most efficient size for signed and unsigned integers on a particular platform: \nint\n is by far the most widely used numeric type. Both these types have the same size, either 32 or 64 bits, but one must not make assumptions about which; different compilers may make different choices even on identical hardware.\n\n\n\n\nThe type \nrune\n is an synonym for \nint32\n and conventionally indicates that a value is a Unicode\ncode point. The two names may be used interchangeably.\n\n\nThe type \nbyte\n is an synonym for \nuint8\n, and emphasizes that the value is a piece of raw data rather than a small numeric quantity.\n\n\nuintptr\n is an unsigned integer type, whose width is not specified but is sufficient to hold all the bits of a pointer value. The \nuintptr\n type is used only for low-level programming, such as at the boundary of a Go program with a C library or an operating system (discussed with the \nunsafe\n package in \nChapter 13\n).\n\n\n\n\nRegardless of their size, \nint\n, \nuint\n, and \nuintptr\n are different types from their explicitly sized siblings. Thus \nint\n is not the same type as \nint32\n, even if the natural size of integers is 32 bits, and an explicit conversion is required to use an \nint\n value where an \nint32\n is needed, and vice versa.\n\n\nSignedness *\n\n\nSigned numbers are represented in \n2\u2019s-complement\n form, in which the high-order bit is reserved for the sign of the number and the range of values of an n-bit number is from \u22122\nn\n\u22121\n to 2\nn\n\u22121\n\u22121. Unsigned integers use the full range of bits for non-negative values and thus have the range 0 to 2\nn\n\u22121\n. For instance, the range of \nint8\n is \u2212128 to 127, whereas the range of \nuint8\n is 0 to 255.\n\n\nBinary operators *\n\n\nGo\u2019s binary operators for arithmetic, logic, and comparison are listed here in order of decreasing precedence:\n\n\n* / % \n \n \n \n^\n+ - | ^\n== != \n \n= \n \n=\n\n\n||\n\n\n\n\n\nThere are only five levels of precedence for binary operators. Operators at the same level associate to the left; parentheses may be required for clarity, or to make the operators evaluate in the intended order in an expression like \nmask \n (1 \n 28)\n.\n\n\nEach operator in the first two lines of the table above, has a corresponding assignment operator. For instance, \n+\n has \n+=\n that may be used to abbreviate an assignment statement.\n\n\nArithmetic operators\n *\n\n\nThe integer \narithmetic operators\n \n+\n, \n-\n, \n*\n, and \n/\n may be applied to integer, floating-point, and complex numbers, but the remainder operator \n%\n applies only to integers.\n\n\n\n\nThe behavior of \n%\n for negative numbers varies across programming languages. In Go, the sign of the remainder is always the same as the sign of the \ndividend\n, so \n-5%3\n and \n-5%-3\n are both \n-2\n.\n\n\nThe behavior of \n/\n depends on whether its operands are integers, so \n5.0/4.0\n is \n1.25\n, but \n5/4\n is \n1\n because integer division truncates the result toward zero.\n\n\n\n\nInteger overflow\n *\n\n\nIf the result of an arithmetic operation, whether signed or unsigned, has more bits than can be represented in the result type, it is said to \noverflow\n. The high-order bits that do not fit are silently discarded. If the original number is a signed type, the result could be negative if the leftmost bit is a 1, as in the \nint8\n example here:\n\n\nvar\n \nu\n \nuint8\n \n=\n \n255\n\n\nfmt\n.\nPrintln\n(\nu\n,\n \nu\n+\n1\n,\n \nu\n*\nu\n)\n \n// \n255 0 1\n\n\n\nvar\n \ni\n \nint8\n \n=\n \n127\n\n\nfmt\n.\nPrintln\n(\ni\n,\n \ni\n+\n1\n,\n \ni\n*\ni\n)\n \n// \n127 -128 1\n\n\n\n\n\n\n[p53]\n\n\nAll values of basic type (booleans, numbers, and strings) are comparable. This means two values of the same type may be compared using the \n==\n and \n!=\n operators. Furthermore, integers, floating-point numbers, and strings are ordered by the comparison operators.", 
            "title": "Chapter 3. Basic Data Types"
        }, 
        {
            "location": "/gopl/ch4/", 
            "text": "Chapter 4. Composite Types", 
            "title": "Chapter 4. Composite Types"
        }, 
        {
            "location": "/gopl/ch5/", 
            "text": "Chapter 5. Functions", 
            "title": "Chapter 5. Functions"
        }, 
        {
            "location": "/gopl/ch6/", 
            "text": "Chapter 6. Methods", 
            "title": "Chapter 6. Methods"
        }, 
        {
            "location": "/gopl/ch7/", 
            "text": "Chapter 7. Interfaces", 
            "title": "Chapter 7. Interfaces"
        }, 
        {
            "location": "/twgr/", 
            "text": "TWGR\n\n\n\n\nChapter 1. Bootstrapping your Ruby literacy\n\n\nChapter 2. Objects, methods, and local variables", 
            "title": "Contents"
        }, 
        {
            "location": "/twgr/ch1/", 
            "text": "Chapter 1. Bootstrapping your Ruby literacy\n\n\nThis chapter discusses basic Ruby syntax and techniques and how Ruby works, including three fundamental levels:\n\n\n\n\nCore language: design principles, syntax, and semantics\n\n\nExtensions and libraries that ship with Ruby, and the facilities for adding extensions of your own\n\n\nCommand-line tools that come with Ruby, with which you run the interpreter and some other important utilities\n\n\n\n\nBasic Ruby language literacy\n\n\nThe examples in this book use Ruby 2.1.0. The \nirb\n utility ships with Ruby and is the most widely used Ruby command-line tool other than the interpreter itself. The irb examples in this book will use a command-line option that makes irb output easier to read:\n\n\nirb --simple-prompt", 
            "title": "Chapter 1. Bootstrapping your Ruby literacy"
        }, 
        {
            "location": "/twgr/ch2/", 
            "text": "Chapter 2. Objects, methods, and local variables\n\n\nEvery line of Ruby code involves the concept of the object. What you do with objects, broadly speaking, is send them messages, most of which correspond to names of methods that you\u2019re asking the object to execute. This chapter details the combined processes of message sending and method calling.\n\n\nTalking to objects\n\n\nIn any Ruby program, the bulk of the design, logic, and action revolves around objects. When you write Ruby programs, your main activities are creating objects, endowing them with abilities, and asking them to perform actions. When you want something done, you ask an object to do it. For example, rather than ask in the abstract whether \na\n equals \nb\n, you ask a whether it considers itself equal to \nb\n. Generally, writing a Ruby program is largely a matter of engineering your objects so that each object plays a clear role and can perform actions related to that role.\n\n\nRuby and object orientation\n\n\nRuby comes to the idea of manipulating data through objects via the program language design principle \nobject orientation\n. In object-oriented programming (OOP), you perform calculations, data manipulation, and input/output operations by creating objects and asking them to perform actions and provide you with information.\n\n\nDesigning object-oriented software is largely a matter of figuring out what you want your objects to be:\n\n\n\n\nWhat they should do,\n\n\nHow they\u2019ll interact with each other,\n\n\nHow many of each there should be (for example, many students, one registrar),\n\n\nOther such questions.\n\n\n\n\nRuby provides a complete set of tools for:\n\n\n\n\nNaming, creating, addressing, and manipulating objects,\n\n\nThe data they operate on through the manipulation of those objects.\n\n\n\n\nCreating a generic object\n\n\n[p36]\n\n\nThe following code creates a generic object, which does not represent or model anything specific:\n\n\nobj\n \n=\n \nObject\n.\nnew\n\n\n\n\n\n\nNow you have an object and a variable through which you can address it.\n\n\nAll Ruby objects are created with certain methods that they know how to execute because they\u2019re Ruby objects.\n\n\nDefining an object\u2019s behavior\n\n\nSpecifically, and more technically, you have to define a method for your object. You do this using a special term, the keyword \ndef\n. The following code defines method \ntalk\n for the object \nobj\n:\n\n\ndef\n \nobj\n.\ntalk\n\n  \nputs\n \nI am an object.\n\n  \nputs\n \n(Do you object?)\n\n\nend\n\n\n\n\n\n\nThe following figure shows analysis of the above code:\n\n\n\n\nSending messages to objects\n\n\nUse the message-sending or method-calling syntax:\n\n\nobj\n.\ntalk\n\n\n\n\n\n\nThe output is:\n\n\nI am an object.\n(Do you object?)\n\n\n\n\n\nThe object \nobj\n \nresponds to\n the message \ntalk\n. \nAn object is said to respond to a message if the object has a method defined whose name corresponds to the message.\n\n\nA few things to consider about the dot-based message-sending syntax:\n\n\n\n\nThe dot (\n.\n) is the message-sending operator. The message on the right is sent to the object (or \nreceiver\n) on the left.\n\n\nThe receiver can be often represented by a variable that stands in for an object; it can also be a literal object construct, e.g. a string in quotation marks.\n\n\nIn practice, the message being sent is almost always the name of a method. The object always tries to act on the assumption that the message is the name of a method. If there\u2019s no method by that name, error-handling measures are taken.\n\n\n\n\nMethods that take arguments\n\n\nIn a method definition, you indicate the arguments by means of a list of variables in parentheses after the method name. Arguments can be required or optional. More precisely:\n\n\n\n\nThe variables listed in the method definition are the method\u2019s \nformal parameters\n.\n\n\nThe values you supply to the method when you call it are the corresponding \narguments\n.\n\n\n\n\nHowever, it\u2019s common to use the word \narguments\n, informally, to refer to a method\u2019s parameters as well as a method call\u2019s arguments.\n\n\nFor example, define a method:\n\n\ndef\n \nobj\n.\nc2f\n(\nc\n)\n\n  \nc\n \n*\n \n9\n.\n0\n \n/\n \n5\n \n+\n \n32\n\n\nend\n\n\n\n\n\n\nThe method \nobj.c2f\n has one formal parameter, which means it takes one argument. When you call the method, you provide an argument:\n\n\nputs\n \nobj\n.\nc2f\n(\n100\n)\n\n\n\n\n\n\nThe result is:\n\n\n212.0\n\n\n\n\n\nThe parentheses are optional in both cases, you can also do this:\n\n\ndef\n \nobj\n.\nc2f\n \nc\n\n\n\n\n\n\nand this:\n\n\nobj\n.\nc2f\n \n100\n\n\n\n\n\n\nHowever, parentheses are not always optional, particularly when you\u2019re stringing multiple\nmethod calls together, so it\u2019s good to lean toward using them rather than leaving them\nout. You can make an exception for common or conventional cases where parentheses\nare usually excluded, like calls to \nputs\n. But when in doubt, use the parentheses.\n\n\nAt the other end of the process, every method call \nreturns\n a value.\n\n\nThe return value of a method\n\n\nRuby code is made up of expressions, each of which evaluates to a particular value.  The following table shows some examples of expressions and their values:\n\n\n\n\n\n\n\n\nExpression\n\n\nValue\n\n\nComments\n\n\n\n\n\n\n\n\n\n\n2 + 2\n\n\n4\n\n\nArithmetic expressions evaluate to their results.\n\n\n\n\n\n\n\"Hello\"\n\n\n\"Hello\"\n\n\nA simple, literal string (in quotation marks) evaluates to itself.\n\n\n\n\n\n\n\"Hello\" + \" there\"\n\n\n\"Hello there\"\n\n\nStrings can be \"added\" to each other (concatenated) with the plus sign.\n\n\n\n\n\n\nc = 100\n\n\n100\n\n\nWhen you assign to a variable, the whole assignment evaluates to the value you\u2019ve assigned.\n\n\n\n\n\n\nc * 9/5 + 32\n\n\n212\n\n\nThe usual rules of precedence apply: multiplication and division bind more tightly than addition and are performed first.\n\n\n\n\n\n\nobj.c2f(100)\n\n\n212\n\n\nA method call is an expression.\n\n\n\n\n\n\n\n\nEvery method call is an expression.  When you call a method, the method call evaluates to something. This result of calling a method is the method\u2019s return value.\n\n\nThe return value of any method is the same as the value of the last expression evaluated during execution of the method. In the case of the temperature-conversion method (i.e. \nobj.c2f\n), the last expression evaluated is the only line of the method body.\n\n\nRuby gives you a keyword for making return values explicit: \nreturn\n. The use of this keyword is usually optional, but many programmers like to use it because it makes explicit what is otherwise implicit:\n\n\ndef\n \nobj\n.\nc2f\n(\nc\n)\n\n  \nreturn\n \nc\n \n*\n \n9\n.\n0\n \n/\n \n5\n \n+\n \n32\n\n\nend\n\n\n\n\n\n\nThis is equivalent to the earlier version of the method, but it\u2019s more expressive about what it\u2019s doing.\n\n\nIn some cases, the \nreturn\n is required:\n\n\n\n\nYou have to use it if you return multiple values, which will be automatically wrapped up in an array: \nreturn a,b,c\n rather than just \na,b,c\n (though you can also return multiple values in an explicit array, like \n[a,b,c]\n, without return).\n\n\nYou also have to use \nreturn\n if you want to return from somewhere in the middle of a method.\n\n\n\n\nWhether you use return or not, something will be returned from every method call. Even a call to an empty method body, consisting of just the \ndef\n and \nend\n statements, returns \nnil\n.\n\n\nAt this point, the object is doing what we need it to do: listening to messages and acting on them. [p40]\n\n\nCrafting an object: The behavior of a ticket\n\n\nThe ticket object, behavior first\n\n\nA ticket object should be able to provide data about itself. It should field requests for information about the event it\u2019s for: when, where, name of event, performer, which seat, and cost.\n\n\n01/02/03\nTown Hall\nAuthor\ns reading\nMark Twain\nSecond Balcony, row J, seat 12\n$5.50\n\n\n\n\n\nCreating the ticket object\n\n\nch2/ticket.rb\n\n\nticket\n \n=\n \nObject\n.\nnew\n\n\n\ndef\n \nticket\n.\ndate\n\n  \n01/02/03\n\n\nend\n\n\n\ndef\n \nticket\n.\nvenue\n\n  \nTown Hall\n\n\nend\n\n\n\ndef\n \nticket\n.\nevent\n\n  \nAuthor\ns reading\n\n\nend\n\n\n\ndef\n \nticket\n.\nperformer\n\n  \nMark Twain\n\n\nend\n\n\n\ndef\n \nticket\n.\nseat\n\n  \nSecond Balcony, row J, seat 12\n\n\nend\n\n\n\ndef\n \nticket\n.\nprice\n\n  \n5\n.\n50\n\n\nend\n\n\n\n\n\n\nThe majority of the methods defined here return string values. The \nprice\n method returns a floating-point number.\n\n\nQuerying the ticket object\n\n\nThe use of \nprint\n and \nputs\n can help get the information:\n\n\nprint\n \nThis ticket is for: \n\n\nprint\n \nticket\n.\nevent\n \n+\n \n, at \n\n\nprint\n \nticket\n.\nvenue\n \n+\n \n, on \n\n\nputs\n \nticket\n.\ndate\n \n+\n \n.\n\n\nprint\n \nThe performer is \n\n\nputs\n \nticket\n.\nperformer\n \n+\n \n.\n\n\nprint\n \nThe seat is \n\n\nprint\n \nticket\n.\nseat\n \n+\n \n, \n\n\nprint\n \nand it costs $\n\n\nputs\n \n%.2f.\n \n%\n \nticket\n.\nprice\n\n\n\n\n\n\nShortening the ticket code via string interpolation\n\n\nOne of the most useful programming techniques available in Ruby is \nstring interpolation\n.  The string-interpolation operator gives you a way to drop anything into a string: a variable, for example, or the return value of a method. This can save you a lot of back-and-forth between \nprint\n and \nputs\n.\n\n\nStrings can also be concatenated with the plus sign (\n+\n). The following code is an example of using string interpolation to insert the values of expressions into the string and using string addition to consolidate multiple \nputs\n calls into one:\n\n\nputs\n \nThis ticket is for: \n#{\nticket\n.\nevent\n}\n, at \n#{\nticket\n.\nvenue\n}\n.\n \n+\n\n  \nThe performer is \n#{\nticket\n.\nperformer\n}\n.\n \n+\n\n  \nThe seat is \n#{\nticket\n.\nseat\n}\n, \n \n+\n\n  \nand it costs $\n#{\n%.2f.\n \n%\n \nticket\n.\nprice\n}", 
            "title": "Chapter 2. Objects, methods, and local variables"
        }, 
        {
            "location": "/icnd1/", 
            "text": "ICND1\n\n\n\n\nICND1 Part I: Networking Fundamentals", 
            "title": "Contents"
        }, 
        {
            "location": "/icnd1/part1/", 
            "text": "Part I: Networking Fundamentals\n\n\nChapter 1. Introduction to Computer Networking\n\n\nChapter 2. The TCP/IP and OSI Networking Models\n\n\nTCP/IP Networking Model\n\n\nA \nnetworking model\n (\nnetworking architecture\n or \nnetworking blueprint\n), refers to a comprehensive set of documents that define everything that should happen for a computer network to work.\n\n\nThe TCP/IP model both defines and references a large collection of protocols that allow computers to communicate. TCP/IP uses documents called \nRequests for Comments\n (RFC).\n\n\nData Encapsulation Terminology\n\n\n\n\n\n\nCreate and encapsulate the application data with any required application layer headers.\n\n\nEncapsulate the data supplied by the application layer inside a transport layer header.\n\n\nEncapsulate the data supplied by the transport layer inside an Internet layer (IP) header.\n\n\nEncapsulate the data supplied by the Internet layer inside a data link layer header and trailer. This is the only layer that uses both a \nheader\n and a \ntrailer\n.\n\n\nTransmit the bits.\n\n\n\n\nOSI Networking Model\n\n\n\n\nDescribing Protocols by Referencing the OSI Layers\n\n\nNetworking documents often describe TCP/IP protocols and standards by referencing OSI layers, both by layer number and layer name. For instance, a common description of a LAN switch is \u201clayer 2 switch,\u201d with \u201clayer 2\u201d referring to OSI layer 2.\n\n\n\n\n\n\n\n\nLayer Name\n\n\nProtocols and Specifications\n\n\nDevices\n\n\n\n\n\n\n\n\n\n\nApplication, presentation, session (Layers 5\u20137)\n\n\nTelnet, HTTP, FTP, SMTP, POP3, VoIP, SNMP\n\n\nFirewall, intrusion detection systems, hosts\n\n\n\n\n\n\nTransport (Layer 4)\n\n\nTCP, UDP\n\n\nHosts, firewalls\n\n\n\n\n\n\nNetwork (Layer 3)\n\n\nIP\n\n\nRouter\n\n\n\n\n\n\nData link (Layer 2)\n\n\nEthernet (IEEE 802.3), HDLC, Frame Relay, PPP\n\n\nLAN switch, wireless access point, cable modem, DSL modem\n\n\n\n\n\n\nPhysical (Layer 1)\n\n\nRJ-45, EIA/TIA-232, V.35, Ethernet (IEEE 802.3)\n\n\nLAN hub, LAN repeater, cables\n\n\n\n\n\n\n\n\nOSI Layering Concepts and Benefits\n\n\n[p41]\n\n\n\n\nLess complex\n\n\nStandard interfaces\n\n\nEasier to learn\n\n\nEasier to develop\n\n\nMultivendor interoperability\n\n\nModular engineering\n\n\n\n\nOSI Encapsulation Terminology\n\n\n\n\nThe TCP/IP model uses terms such as \nsegment\n, \npacket\n, and \nframe\n to refer to various layers and their respective encapsulated data. OSI uses a more generic term: \nprotocol data unit\n (PDU).\n\n\nChapter 3. Fundamentals of LANs\n\n\nAn Overview of Modern Ethernet LANs\n\n\nTypes of cabling:\n\n\n\n\nUnshielded Twisted-Pair\n (UTP)\n\n\nFiber-optic\n\n\n\n\nMost IEEE standards define a different variation of Ethernet at the physical layer.\nFor the data link layer:\n\n\n\n\n802.3 Media Access Control (MAC) sublayer\n\n\n802.2 Logical Link Control (LLC) sublayer\n\n\n\n\n[p52]\n\n\n\n\n\n\n\n\nCommon Name\n\n\nSpeed\n\n\nAlternative Name\n\n\nName of IEEE Standard\n\n\nCable Type, Maximum Length\n\n\n\n\n\n\n\n\n\n\nEthernet\n\n\n10 Mbps\n\n\n10BASE-T\n\n\nIEEE 802.3\n\n\nCopper, 100 m\n\n\n\n\n\n\nFast Ethernet\n\n\n100 Mbps\n\n\n100BASE-TX\n\n\nIEEE 802.3u\n\n\nCopper, 100 m\n\n\n\n\n\n\nGigabit Ethernet\n\n\n1000 Mbps\n\n\n1000BASE-LX, 1000BASE-SX\n\n\nIEEE 802.3z\n\n\nFiber, 550 m (SX) 5 km (LX)\n\n\n\n\n\n\nGigabit Ethernet\n\n\n1000 Mbps\n\n\n1000BASE-T\n\n\nIEEE 802.3ab\n\n\n100 m\n\n\n\n\n\n\n\n\nThe term Ethernet is often used to mean \"all types of Ethernet\", but in some cases it is used to mean \"10BASE-T Ethernet\"\n\n\nA Brief History of Ethernet\n\n\n\n\nCarrier sense multiple access with collision detection (CSMA/CD) algorithm\n\n\n\n\nRepeaters\n\n\nRepeaters\n extended the length of LANs by cleaning up the electrical signal and repeating it (a Layer 1 function) but without interpreting the meaning of the electrical signal. [p56]\n\n\nBuilding 10BASE-T Networks with Hubs\n\n\nHubs\n are essentially repeaters with multiple physical ports. It simply regenerates the electrical signal that comes in one port and sends the same signal out every other port.\n\n\nEthernet UTP Cabling\n\n\nTransmitting Data Using Twisted Pairs\n\n\nUTP cabling consists of matched pairs of wires that are indeed twisted together, with current on the two wires in opposite directions.\n\n\nUTP Cabling Pinouts for \n10BASE-T and 100BASE-TX\n\n\n10BASE-T and 100BASE-TX Ethernet define that one pair should be used to send data in one direction, with the other pair used to send data in the other direction.\n\n\nThe wires in the UTP cable must be connected to the correct \npin positions\n in the RJ-45 connectors in order for communication to work correctly.\n\n\n[p62-64]\n\n\nThe following applies to 10BASE-T and 100BASE-TX only:\n\n\n\n\nEthernet \nstraight-through cable\n: both ends of the cable use the same EIA/TIA pinout standard on each end of the cable. A straight-through cable is used when the devices on the ends of the cable use opposite pins when they transmit data.\n\n\nEthernet \ncrossover cable\n:  two devices both use the same pins to transmit and the pinouts of the cable are set up to swap the wire pair\n\n\n\n\n\n\n\n\n\n\nDevices That Transmit on 1,2 and Receive on 3,6\n\n\nDevices That Transmit on 3,6 and Receive on 1,2\n\n\n\n\n\n\n\n\n\n\nPC NICs\n\n\nHubs\n\n\n\n\n\n\nRouters\n\n\nSwitches\n\n\n\n\n\n\nWireless Access Point (Ethernet interface)\n\n\n\u2014\n\n\n\n\n\n\nNetworked printers (printers that connect directly to the LAN)\n\n\n\u2014\n\n\n\n\n\n\n\n\n1000BASE-T Cabling\n\n\n1000BASE-T differs from 10BASE-T and 100BASE-TX as far as the cabling and pinouts:\n\n\n\n\nReequires four wire pairs\n\n\nTransmits and receives on each of the four wire pairs simultaneously\n\n\nHas no concept of straight-through and crossover cables\n\n\n\n\nImproving Performance by Using Switches Instead of Hubs\n\n\nCSMA/CD logic helps prevent collisions and also defines how to act when a collision does occur:\n\n\n\n\nA device with a frame to send listens until the Ethernet is not busy.\n\n\nWhen the Ethernet is not busy, the sender(s) begin(s) sending the frame.\n\n\nThe sender(s) listen(s) to make sure that no collision occurred.\n\n\nIf a collision occurs, the devices that had been sending a frame each send a jamming signal to ensure that all stations recognize the collision.\n\n\nAfter the jamming is complete, each sender randomizes a timer and waits that long before trying to resend the collided frame. When each random timer expires, the process starts over with Step 1.\n\n\n\n\nIncreasing Available Bandwidth Using Switches\n\n\nThe term \ncollision domain\n defines the set of devices whose frames could collide. For example, all devices connected to the hub are in the same collision domain. To avoid collisions, and to recover when they occur, devices in the same collision domain use CSMA/CD.\n\n\nSwitches\n significantly reduce, or even eliminate, the number of collisions on a LAN:\n\n\n\n\nSwitches interpret the bits in the received frame so that they can typically send the frame out the one required port, rather than all other ports\n\n\nIf a switch needs to forward multiple frames out the same port, the switch buffers the frames in memory, sending one at a time, thereby avoiding collisions\n\n\n\n\nThe switch\u2019s logic requires that the switch look at the Ethernet header, which is considered a Layer 2 feature. As a result, switches are considered to operate as a Layer 2 device, whereas hubs are Layer 1 devices.\n\n\nBuffering (temporarily holds the frame in memory) also helps prevent collisions.\n\n\nSwitch features provide significant performance improvements:\n\n\n\n\nIf only one device is cabled to each port of a switch, no collisions can occur.\n\n\nDevices connected to one switch port do not share their bandwidth with devices connected to another switch port. Each has its own separate bandwidth, meaning that a switch with 100-Mbps ports has 100 Mbps of bandwidth \nper port\n.\n\n\n\n\nShared Ethernet vs. Switched Ethernet\n\n\n\n\nShared Ethernet\n: bandwidth is shared among the devices on the LAN because they must take turns using the LAN because of the CSMA/CD algorithm. A hub with 24 100-Mbps Ethernet devices connected to it allows for a theoretical maximum of 100 Mbps of bandwidth\n\n\nSwitched Ethernet\n: bandwidth does not have to be shared, allowing for far greater performance. A switch with 24 100-Mbps Ethernet devices connected to it supports 100 Mbps for each port, or 2400 Mbps (2.4 Gbps) theoretical maximum bandwidth.\n\n\n\n\nDoubling Performance by Using Full-Duplex Ethernet\n\n\nIn an Ethernet network using hubs, CSMA/CD imposes \nhalf-duplex\n logic on each device, meaning that only one device can send at a time. LAN switches with only one device cabled to each port of the switch allow the use of \nfull-duplex\n operation; Ethernet card can send and receive concurrently.\n\n\nEthernet Data-Link Protocols\n\n\nEthernet Addressing\n\n\n\n\n\n\n\n\nLAN Addressing Term or Feature\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nMAC\n\n\nMedia Access Control. 802.3 (Ethernet) defines the MAC sublayer of IEEE Ethernet.\n\n\n\n\n\n\nEthernet address, NIC address, LAN address\n\n\nOther names often used instead of MAC address. These terms describe the 6-byte address of the LAN interface card.\n\n\n\n\n\n\nBurned-in address\n\n\nThe 6-byte address assigned by the vendor making the card.\n\n\n\n\n\n\nUnicast address\n\n\nA term for a MAC that represents a single LAN interface.\n\n\n\n\n\n\nBroadcast address\n\n\nAn address that means \u201call devices that reside on this LAN right now.\u201d (FFFF.FFFF.FFFF)\n\n\n\n\n\n\nMulticast address\n\n\nOn Ethernet, a multicast address implies some subset of all devices currently on the Ethernet LAN. (0100.5exx.xxxx, any value can be used in the last half)\n\n\n\n\n\n\n\n\nEthernet Framing\n\n\nFraming\n defines the meaning of the bits transmitted and received over a network.\n\n\n\n\n\n\nData\n field holds Layer 3 packets (L3 PDU)\n\n\nMaximum transmission unit\n (MTU) defines the maximum Layer 3 packet that can be sent over a medium. 1500 bytes is the largest IP MTU allowed over an Ethernet.\n\n\n\n\nIdentifying the Data Inside an Ethernet Frame\n\n\nType/Length\n filed:\n\n\n\n\nLength\n field: with a value less than hex 0600 (decimal 1536); another field is needed to identify the type of L3 PDU inside the frame.\n\n\nType\n field: value of hexadecimal 0800 (decimal 2048) implies an IP packet\n\n\n\n\nError Detection\n\n\nErrors (bit changes) occur due to electrical interference. Trailer containing a \nFrame Check Sequence\n (FCS) field used for error detection.\n\n\nChapter 4. Fundamentals of WANs\n\n\nThe WAN topics in this chapter describe mainly how enterprise networks use WANs to connect remote sites.\n\n\nOSI Layer 1 for Point-to-Point WANs\n\n\n\n\nLeased line\n or \nleased circuit\n: WAN cable, line or point-to-point connection that is paid for use\n\n\nTelephone company (telco), or public telephone and telegraph (PTT)\n\n\nService provider\n: a company that provides any form of WAN connectivity, including Internet services.\n\n\n\n\nRouters provide the capability to connect many different types of OSI Layer 1 and Layer 2 technologies. A router is connected to each end of a WAN connection.\n\n\n\n\n\n\nCentral Office (CO): a building where the telco locates the devices used to create its own network\n\n\nChannel service unit/data service (\nCSU/DSU\n)\n\n\ndemarc\n (\ndemarcation point\n): he point at which the telco\u2019s responsibility is on one side and the customer\u2019s responsibility is on the other\n\n\nCustomer premises equipment\n (CPE): devices that are at the customer site\n\n\n\n\nWAN Cabling Standards\n\n\n[p84]\n\n\nClock Rates, Synchronization, DCE, and DTE\n\n\n[p86]\n\n\n\n\nSynchronization: various devices need to synchronize their clocks so that they run at exactly the same speed to make a link work\n\n\nData communications equipment (DCE): device that provides clocking, typically the CSU/DSU\n\n\nData terminal equipment (DTE): device receiving clocking, typically the router\n\n\n\n\nLink Speeds\n\n\n\n\n\n\n\n\nName(s) of Line\n\n\nBit Rate\n\n\n\n\n\n\n\n\n\n\nDS0\n\n\n64 kbps\n\n\n\n\n\n\nDS1 (T1)\n\n\n1.544 Mbps (24 DS0s, plus 8 kbps overhead)\n\n\n\n\n\n\nDS3 (T3)\n\n\n44.736 Mbps (28 DS1s, plus management overhead)\n\n\n\n\n\n\nE1\n\n\n2.048 Mbps (32 DS0s)\n\n\n\n\n\n\nE3\n\n\n34.368 Mbps (16 E1s, plus management overhead)\n\n\n\n\n\n\nJ1 (Y1)\n\n\n2.048 Mbps (32 DS0s; Japanese standard)\n\n\n\n\n\n\n\n\nOSI Layer 2 for Point-to-Point WANs\n\n\nHDLC\n\n\n\n\nHigh-Level Data Link Control\n (HDLC) defines framing to:\n\n\n\n\nDelivers data across the link\n\n\nCheck for errors\n\n\nIdentify the packet type\n\n\n\n\nPoint-to-Point Protocol\n\n\nPoint-to-Point Protocol (PPP) behaves much like HDLC. The framing looks identical to the Cisco proprietary HDLC framing. PPP has become the most popular and feature-rich of WAN data link layer protocols. [p91]\n\n\nPoint-to-Point WAN Summary\n\n\nWAN Terminology [p91-92]\n\n\n\n\nSynchronous: The imposition of time ordering on a bit stream\n\n\nClock source: The device to which the other devices on the link adjust their speed when using synchronous links\n\n\nCSU/DSU: Used on digital links as an interface to the telephone company in the United States. Routers typically use a short cable from a serial interface to a CSU/DSU, which is attached to the line from the telco\n\n\nTelco\n\n\nFour-wire circuit: A line from the telco with four wires, composed of two twisted-pair wires. Each pair is used to send in one direction, so a four-wire circuit allows full-duplex communication.\n\n\nT1\n\n\nE1\n\n\n\n\nAll the following terms may be used to refer to a point-to-point leased line:\n\n\n\n\nleased line\n\n\nleased circuit\n\n\nlink\n\n\nserial link\n\n\nserial line\n\n\npoint-to-point link\n\n\ncircuit\n\n\n\n\nFrame Relay and Packet-Switching Services\n\n\nPacket-switching service\n: a company can connect a large number of routers using a single serial link from each router into the packet-switching service. Once connected, each router can send packets to all the other routers\u2014much like all the devices connected to an Ethernet hub or switch can send data directly to each other.\n\n\nTwo types of packet-switching service are very popular today:\n\n\n\n\nFrame Relay: much more common\n\n\nAsynchronous Transfer Mode (ATM)\n\n\n\n\nChapter 5. Fundamentals of IPv4 Addressing and Routing\n\n\n\n\nRouting: the process of forwarding packets (Layer 3 PDUs).\n\n\nLogical addressing: enables the routing process to identify a packet\u2019s source and destination.\n\n\nRouting protocol: aids routers by dynamically learning about the groups of addresses in the network, which in turn allows the routing (forwarding) process to work well.\n\n\nOther utilities: The network layer also relies on other utilities: Domain Name System (DNS), Dynamic Host Configuration Protocol (DHCP), Address Resolution Protocol (ARP), and ping.\n\n\n\n\nPath selection\n sometimes is used to mean:\n\n\n\n\nRouting protocol\n\n\nRouting (forwarding) of packets\n\n\n\n\nOverview of Network Layer Functions\n\n\nToday, the only Layer 3 protocol that is used widely is the TCP/IP network layer protocol, specifically, IP.  IP does not require any overhead agreements or messages before sending a packet, making IP a connectionless protocol, with no error recovery.\n\n\nRouting (Forwarding)\n\n\nRouting focuses on the end-to-end logic of forwarding data.\n\n\nThe routing table for any particular network layer protocol contains a list of network layer address groupings. Instead of a single entry in the routing table per individual destination network layer address, there is one routing table entry per group.\n\n\nNetwork Layer Interaction with the Data Link Layer\n\n\nThe routing process forwards the packet, and only the packet, end-to-end through the network, discarding data-link headers and trailers along the way.\n\n\nRouters build new data-link headers and trailers and because the new headers contain data-link addresses, the PCs and routers must decide what data-link addresses to use. The Address Resolution Protocol (ARP) is used to dynamically learn the data-link address of an IP host connected to a LAN.\n\n\nRouting as covered so far has two main concepts:\n\n\n\n\nThe process of routing forwards Layer 3 packets, also called Layer 3 protocol data units (L3 PDU), based on the destination Layer 3 address in the packet.\n\n\nThe routing process uses the data link layer to encapsulate the Layer 3 packets into Layer 2 frames for transmission across each successive data link.", 
            "title": "ICND1 Part I: Networking Fundamentals"
        }, 
        {
            "location": "/icnd1/part1/#chapter-1-introduction-to-computer-networking", 
            "text": "", 
            "title": "Chapter 1. Introduction to Computer Networking"
        }, 
        {
            "location": "/icnd1/part1/#chapter-2-the-tcpip-and-osi-networking-models", 
            "text": "TCP/IP Networking Model  A  networking model  ( networking architecture  or  networking blueprint ), refers to a comprehensive set of documents that define everything that should happen for a computer network to work.  The TCP/IP model both defines and references a large collection of protocols that allow computers to communicate. TCP/IP uses documents called  Requests for Comments  (RFC).  Data Encapsulation Terminology    Create and encapsulate the application data with any required application layer headers.  Encapsulate the data supplied by the application layer inside a transport layer header.  Encapsulate the data supplied by the transport layer inside an Internet layer (IP) header.  Encapsulate the data supplied by the Internet layer inside a data link layer header and trailer. This is the only layer that uses both a  header  and a  trailer .  Transmit the bits.   OSI Networking Model   Describing Protocols by Referencing the OSI Layers  Networking documents often describe TCP/IP protocols and standards by referencing OSI layers, both by layer number and layer name. For instance, a common description of a LAN switch is \u201clayer 2 switch,\u201d with \u201clayer 2\u201d referring to OSI layer 2.     Layer Name  Protocols and Specifications  Devices      Application, presentation, session (Layers 5\u20137)  Telnet, HTTP, FTP, SMTP, POP3, VoIP, SNMP  Firewall, intrusion detection systems, hosts    Transport (Layer 4)  TCP, UDP  Hosts, firewalls    Network (Layer 3)  IP  Router    Data link (Layer 2)  Ethernet (IEEE 802.3), HDLC, Frame Relay, PPP  LAN switch, wireless access point, cable modem, DSL modem    Physical (Layer 1)  RJ-45, EIA/TIA-232, V.35, Ethernet (IEEE 802.3)  LAN hub, LAN repeater, cables     OSI Layering Concepts and Benefits  [p41]   Less complex  Standard interfaces  Easier to learn  Easier to develop  Multivendor interoperability  Modular engineering   OSI Encapsulation Terminology   The TCP/IP model uses terms such as  segment ,  packet , and  frame  to refer to various layers and their respective encapsulated data. OSI uses a more generic term:  protocol data unit  (PDU).", 
            "title": "Chapter 2. The TCP/IP and OSI Networking Models"
        }, 
        {
            "location": "/icnd1/part1/#chapter-3-fundamentals-of-lans", 
            "text": "An Overview of Modern Ethernet LANs  Types of cabling:   Unshielded Twisted-Pair  (UTP)  Fiber-optic   Most IEEE standards define a different variation of Ethernet at the physical layer.\nFor the data link layer:   802.3 Media Access Control (MAC) sublayer  802.2 Logical Link Control (LLC) sublayer   [p52]     Common Name  Speed  Alternative Name  Name of IEEE Standard  Cable Type, Maximum Length      Ethernet  10 Mbps  10BASE-T  IEEE 802.3  Copper, 100 m    Fast Ethernet  100 Mbps  100BASE-TX  IEEE 802.3u  Copper, 100 m    Gigabit Ethernet  1000 Mbps  1000BASE-LX, 1000BASE-SX  IEEE 802.3z  Fiber, 550 m (SX) 5 km (LX)    Gigabit Ethernet  1000 Mbps  1000BASE-T  IEEE 802.3ab  100 m     The term Ethernet is often used to mean \"all types of Ethernet\", but in some cases it is used to mean \"10BASE-T Ethernet\"  A Brief History of Ethernet   Carrier sense multiple access with collision detection (CSMA/CD) algorithm   Repeaters  Repeaters  extended the length of LANs by cleaning up the electrical signal and repeating it (a Layer 1 function) but without interpreting the meaning of the electrical signal. [p56]  Building 10BASE-T Networks with Hubs  Hubs  are essentially repeaters with multiple physical ports. It simply regenerates the electrical signal that comes in one port and sends the same signal out every other port.  Ethernet UTP Cabling  Transmitting Data Using Twisted Pairs  UTP cabling consists of matched pairs of wires that are indeed twisted together, with current on the two wires in opposite directions.  UTP Cabling Pinouts for  10BASE-T and 100BASE-TX  10BASE-T and 100BASE-TX Ethernet define that one pair should be used to send data in one direction, with the other pair used to send data in the other direction.  The wires in the UTP cable must be connected to the correct  pin positions  in the RJ-45 connectors in order for communication to work correctly.  [p62-64]  The following applies to 10BASE-T and 100BASE-TX only:   Ethernet  straight-through cable : both ends of the cable use the same EIA/TIA pinout standard on each end of the cable. A straight-through cable is used when the devices on the ends of the cable use opposite pins when they transmit data.  Ethernet  crossover cable :  two devices both use the same pins to transmit and the pinouts of the cable are set up to swap the wire pair      Devices That Transmit on 1,2 and Receive on 3,6  Devices That Transmit on 3,6 and Receive on 1,2      PC NICs  Hubs    Routers  Switches    Wireless Access Point (Ethernet interface)  \u2014    Networked printers (printers that connect directly to the LAN)  \u2014     1000BASE-T Cabling  1000BASE-T differs from 10BASE-T and 100BASE-TX as far as the cabling and pinouts:   Reequires four wire pairs  Transmits and receives on each of the four wire pairs simultaneously  Has no concept of straight-through and crossover cables   Improving Performance by Using Switches Instead of Hubs  CSMA/CD logic helps prevent collisions and also defines how to act when a collision does occur:   A device with a frame to send listens until the Ethernet is not busy.  When the Ethernet is not busy, the sender(s) begin(s) sending the frame.  The sender(s) listen(s) to make sure that no collision occurred.  If a collision occurs, the devices that had been sending a frame each send a jamming signal to ensure that all stations recognize the collision.  After the jamming is complete, each sender randomizes a timer and waits that long before trying to resend the collided frame. When each random timer expires, the process starts over with Step 1.   Increasing Available Bandwidth Using Switches  The term  collision domain  defines the set of devices whose frames could collide. For example, all devices connected to the hub are in the same collision domain. To avoid collisions, and to recover when they occur, devices in the same collision domain use CSMA/CD.  Switches  significantly reduce, or even eliminate, the number of collisions on a LAN:   Switches interpret the bits in the received frame so that they can typically send the frame out the one required port, rather than all other ports  If a switch needs to forward multiple frames out the same port, the switch buffers the frames in memory, sending one at a time, thereby avoiding collisions   The switch\u2019s logic requires that the switch look at the Ethernet header, which is considered a Layer 2 feature. As a result, switches are considered to operate as a Layer 2 device, whereas hubs are Layer 1 devices.  Buffering (temporarily holds the frame in memory) also helps prevent collisions.  Switch features provide significant performance improvements:   If only one device is cabled to each port of a switch, no collisions can occur.  Devices connected to one switch port do not share their bandwidth with devices connected to another switch port. Each has its own separate bandwidth, meaning that a switch with 100-Mbps ports has 100 Mbps of bandwidth  per port .   Shared Ethernet vs. Switched Ethernet   Shared Ethernet : bandwidth is shared among the devices on the LAN because they must take turns using the LAN because of the CSMA/CD algorithm. A hub with 24 100-Mbps Ethernet devices connected to it allows for a theoretical maximum of 100 Mbps of bandwidth  Switched Ethernet : bandwidth does not have to be shared, allowing for far greater performance. A switch with 24 100-Mbps Ethernet devices connected to it supports 100 Mbps for each port, or 2400 Mbps (2.4 Gbps) theoretical maximum bandwidth.   Doubling Performance by Using Full-Duplex Ethernet  In an Ethernet network using hubs, CSMA/CD imposes  half-duplex  logic on each device, meaning that only one device can send at a time. LAN switches with only one device cabled to each port of the switch allow the use of  full-duplex  operation; Ethernet card can send and receive concurrently.  Ethernet Data-Link Protocols  Ethernet Addressing     LAN Addressing Term or Feature  Description      MAC  Media Access Control. 802.3 (Ethernet) defines the MAC sublayer of IEEE Ethernet.    Ethernet address, NIC address, LAN address  Other names often used instead of MAC address. These terms describe the 6-byte address of the LAN interface card.    Burned-in address  The 6-byte address assigned by the vendor making the card.    Unicast address  A term for a MAC that represents a single LAN interface.    Broadcast address  An address that means \u201call devices that reside on this LAN right now.\u201d (FFFF.FFFF.FFFF)    Multicast address  On Ethernet, a multicast address implies some subset of all devices currently on the Ethernet LAN. (0100.5exx.xxxx, any value can be used in the last half)     Ethernet Framing  Framing  defines the meaning of the bits transmitted and received over a network.    Data  field holds Layer 3 packets (L3 PDU)  Maximum transmission unit  (MTU) defines the maximum Layer 3 packet that can be sent over a medium. 1500 bytes is the largest IP MTU allowed over an Ethernet.   Identifying the Data Inside an Ethernet Frame  Type/Length  filed:   Length  field: with a value less than hex 0600 (decimal 1536); another field is needed to identify the type of L3 PDU inside the frame.  Type  field: value of hexadecimal 0800 (decimal 2048) implies an IP packet   Error Detection  Errors (bit changes) occur due to electrical interference. Trailer containing a  Frame Check Sequence  (FCS) field used for error detection.", 
            "title": "Chapter 3. Fundamentals of LANs"
        }, 
        {
            "location": "/icnd1/part1/#chapter-4-fundamentals-of-wans", 
            "text": "The WAN topics in this chapter describe mainly how enterprise networks use WANs to connect remote sites.  OSI Layer 1 for Point-to-Point WANs   Leased line  or  leased circuit : WAN cable, line or point-to-point connection that is paid for use  Telephone company (telco), or public telephone and telegraph (PTT)  Service provider : a company that provides any form of WAN connectivity, including Internet services.   Routers provide the capability to connect many different types of OSI Layer 1 and Layer 2 technologies. A router is connected to each end of a WAN connection.    Central Office (CO): a building where the telco locates the devices used to create its own network  Channel service unit/data service ( CSU/DSU )  demarc  ( demarcation point ): he point at which the telco\u2019s responsibility is on one side and the customer\u2019s responsibility is on the other  Customer premises equipment  (CPE): devices that are at the customer site   WAN Cabling Standards  [p84]  Clock Rates, Synchronization, DCE, and DTE  [p86]   Synchronization: various devices need to synchronize their clocks so that they run at exactly the same speed to make a link work  Data communications equipment (DCE): device that provides clocking, typically the CSU/DSU  Data terminal equipment (DTE): device receiving clocking, typically the router   Link Speeds     Name(s) of Line  Bit Rate      DS0  64 kbps    DS1 (T1)  1.544 Mbps (24 DS0s, plus 8 kbps overhead)    DS3 (T3)  44.736 Mbps (28 DS1s, plus management overhead)    E1  2.048 Mbps (32 DS0s)    E3  34.368 Mbps (16 E1s, plus management overhead)    J1 (Y1)  2.048 Mbps (32 DS0s; Japanese standard)     OSI Layer 2 for Point-to-Point WANs  HDLC   High-Level Data Link Control  (HDLC) defines framing to:   Delivers data across the link  Check for errors  Identify the packet type   Point-to-Point Protocol  Point-to-Point Protocol (PPP) behaves much like HDLC. The framing looks identical to the Cisco proprietary HDLC framing. PPP has become the most popular and feature-rich of WAN data link layer protocols. [p91]  Point-to-Point WAN Summary  WAN Terminology [p91-92]   Synchronous: The imposition of time ordering on a bit stream  Clock source: The device to which the other devices on the link adjust their speed when using synchronous links  CSU/DSU: Used on digital links as an interface to the telephone company in the United States. Routers typically use a short cable from a serial interface to a CSU/DSU, which is attached to the line from the telco  Telco  Four-wire circuit: A line from the telco with four wires, composed of two twisted-pair wires. Each pair is used to send in one direction, so a four-wire circuit allows full-duplex communication.  T1  E1   All the following terms may be used to refer to a point-to-point leased line:   leased line  leased circuit  link  serial link  serial line  point-to-point link  circuit   Frame Relay and Packet-Switching Services  Packet-switching service : a company can connect a large number of routers using a single serial link from each router into the packet-switching service. Once connected, each router can send packets to all the other routers\u2014much like all the devices connected to an Ethernet hub or switch can send data directly to each other.  Two types of packet-switching service are very popular today:   Frame Relay: much more common  Asynchronous Transfer Mode (ATM)", 
            "title": "Chapter 4. Fundamentals of WANs"
        }, 
        {
            "location": "/icnd1/part1/#chapter-5-fundamentals-of-ipv4-addressing-and-routing", 
            "text": "Routing: the process of forwarding packets (Layer 3 PDUs).  Logical addressing: enables the routing process to identify a packet\u2019s source and destination.  Routing protocol: aids routers by dynamically learning about the groups of addresses in the network, which in turn allows the routing (forwarding) process to work well.  Other utilities: The network layer also relies on other utilities: Domain Name System (DNS), Dynamic Host Configuration Protocol (DHCP), Address Resolution Protocol (ARP), and ping.   Path selection  sometimes is used to mean:   Routing protocol  Routing (forwarding) of packets   Overview of Network Layer Functions  Today, the only Layer 3 protocol that is used widely is the TCP/IP network layer protocol, specifically, IP.  IP does not require any overhead agreements or messages before sending a packet, making IP a connectionless protocol, with no error recovery.  Routing (Forwarding)  Routing focuses on the end-to-end logic of forwarding data.  The routing table for any particular network layer protocol contains a list of network layer address groupings. Instead of a single entry in the routing table per individual destination network layer address, there is one routing table entry per group.  Network Layer Interaction with the Data Link Layer  The routing process forwards the packet, and only the packet, end-to-end through the network, discarding data-link headers and trailers along the way.  Routers build new data-link headers and trailers and because the new headers contain data-link addresses, the PCs and routers must decide what data-link addresses to use. The Address Resolution Protocol (ARP) is used to dynamically learn the data-link address of an IP host connected to a LAN.  Routing as covered so far has two main concepts:   The process of routing forwards Layer 3 packets, also called Layer 3 protocol data units (L3 PDU), based on the destination Layer 3 address in the packet.  The routing process uses the data link layer to encapsulate the Layer 3 packets into Layer 2 frames for transmission across each successive data link.", 
            "title": "Chapter 5. Fundamentals of IPv4 Addressing and Routing"
        }, 
        {
            "location": "/icnd2/", 
            "text": "ICND2\n\n\n\n\nICND2 Part I: LAN Switching", 
            "title": "Contents"
        }, 
        {
            "location": "/icnd2/part1/", 
            "text": "Part I: LAN Switching\n\n\nChapter 1. Virtual LANs", 
            "title": "ICND2 Part I: LAN Switching"
        }, 
        {
            "location": "/icnd2/part1/#chapter-1-virtual-lans", 
            "text": "", 
            "title": "Chapter 1. Virtual LANs"
        }, 
        {
            "location": "/devops/", 
            "text": "DevOps\n\n\n\n\nChapter 1. What Is DevOps?\n\n\nChapter 2. The Cloud as a Platform\n\n\nChapter 3. Operations\n\n\nChapter 4. Overall Architecture\n\n\nChapter 5. Building and Testing\n\n\nChapter 6. Deployment\n\n\nChapter 7. Monitoring\n\n\nChapter 8. Security and Security Audits\n\n\nChapter 9. Other Ilities\n\n\nChapter 10. Business Considerations\n\n\nChapter 11. Supporting Multiple Datacenters\n\n\nChapter 12. Implementing a Continuous Deploy\n\n\nChapter 13. Migrating to Microservices\n\n\nChapter 14. Operations as a Process\n\n\nChapter 15. The Future of DevOps", 
            "title": "Contents"
        }, 
        {
            "location": "/devops/ch1/", 
            "text": "Chapter 1. What Is DevOps?\n\n\nIntroduction\n\n\nDefining DevOps\n\n\nThe definition of DevOps focuses on the goals, rather than the means:\n\n\n\n\nDevOps is a set of practices intended to reduce the time between committing a change to a system and the change being placed into normal production, while ensuring high quality.\n\n\n\n\nDevOps Practices\n\n\n\n\nWhy DevOps?\n\n\nDevOps Perspective\n\n\nDevOps and Agile\n\n\nTeam Structure\n\n\n[p16]\n\n\n\n\nCoordination\n\n\nBarriers\n\n\nSummary", 
            "title": "Chapter 1. What Is DevOps?"
        }, 
        {
            "location": "/devops/ch2/", 
            "text": "Chapter 2. The Cloud as a Platform\n\n\nThe \nNational Institute of Standards and Technology\n (NIST) has provided a characterization of the cloud with the following elements:\n\n\n\n\nOn-demand self-service\n\n\nBroad network access\n\n\nResource pooling\n\n\nRapid elasticity\n\n\nMeasured service\n\n\n\n\nNIST also characterizes the various types of services available from cloud providers, as shown in the table below:\n\n\n\n\n\n\n\n\nService Model\n\n\nExamples\n\n\n\n\n\n\n\n\n\n\nSaaS\n: Software as a Service\n\n\nE-mail, online games, Customer Relationship Management, virtual desktops, etc.\n\n\n\n\n\n\nPaaS\n: Platform as a Service\n\n\nWeb servers, database, execution runtime, development tools, etc.\n\n\n\n\n\n\nIaaS\n: Infrastructure as a Service\n\n\nVirtual machines, storage, load balancers, networks, etc.\n\n\n\n\n\n\n\n\nFeatures of the Cloud\n\n\nVirtualization\n\n\n[p29]\n\n\nCreating a Virtual Machine\n\n\n[p30]\n\n\nLoading a Virtual Machine\n\n\n[p30]\n\n\nThe process of creating a VM image is called \nbaking\n the image:\n\n\n\n\nA \nheavily baked\n image contains all of the software required to run an application,\n\n\nA \nlightly baked\n image contains only a portion of the software required, such as an operating system and a middleware container.\n\n\n\n\nVirtualization introduces several types of uncertainty should be aware of.\n\n\n\n\nBecause a VM shares resources with other VMs on a single physical machine, there may be some performance interference among the VMs. This situation may be particularly difficult for cloud consumers as they usually have no visibility into the co-located VMs owned by other consumers.\n\n\nThere are also time and dependability uncertainties when loading a VM, depending on the underlying physical infrastructure and the additional software that needs to be dynamically loaded. DevOps operations often create and destroy VMs frequently for setting up different environments or deploying new versions of software.\n\n\n\n\nIP and Domain Name System Management\n\n\nDNS\n\n\nPersistence of IP Addresses with Respect to VMs\n\n\nThe IP address assigned to a virtual machine on its creation persists as long as that VM is active. A VM becomes inactive when it is terminated, paused, or stopped. In these cases, the IP address is returned to the cloud provider\u2019s pool for reassignment.\n\n\nPlatform as a Service\n\n\nThe additional abstraction of PaaS over IaaS means that you can focus on the important bits of your system\u2014the application:\n\n\n\n\nPros: You do not have to deal with the network configuration, load balancers, operating systems, security patches on the lower layers, and so on.\n\n\nCons: It also means you give up visibility into and control over the underlying layers. Where this is acceptable, it might be well worthwhile to use a PaaS solution. However, when you end up needing the additional control at a later stage, the migration might be increasingly hard.\n\n\n\n\nDistributed Environment\n\n\nThis section explores some of the implications of having hundreds of thousands of servers within a cloud provider\u2019s environment. These implications concern the time involved for various operations, the probability of failure, and the consequences of these two aspects on the consistency of data.\n\n\nTime\n\n\n\n\nAccessing 1MB (roughly one million bytes) sequentially from main memory takes on the order of 12\u00b5s (microseconds).\n\n\nAccessing an item from a spinning disk requires on the order of 4ms (milliseconds) to move the disk head to the correct location.\n\n\n\n\nThen, reading 1MB takes approximately 2ms.\n\n\nIn a distributed environment where messages are the means of communication between the various processes involved in an application:\n\n\n\n\nA round trip within the same datacenter takes approximately 500\u00b5.\n\n\nA round trip between California and the Netherlands takes around 150ms.\n\n\n\n\nConsequences:\n\n\n\n\nDetermining what data to maintain in memory or on the disk is a critical performance decision. Caching allows for maintaining some data in both places but introduces the problem of keeping the data consistent.\n\n\nWhere persistent data is physically located will also have a large impact on performance.\n\n\n\n\nCombining these two consequences with the possibility of failure, discussed in the next section, leads to a discussion of keeping data consistent using different styles of database management systems.\n\n\nFailure\n\n\nAlthough any particular cloud provider may guarantee high availability, these guarantees are typically for large segments of their cloud as a whole and do not refer to the components.  Individual component failure can thus still impact your application.\n\n\nThe possibilities for individual element failure are significant. Amazon released some data stating that in a datacenter with ~64,000 servers with 2 disks each, on average more than 5 servers and 17 disks fail each day.\n\n\nBelow is a list of problems arising in a datacenter in its first year of operation (from a presentation by \nJeff Dean\n, Google):\n\n\n\n\n~0.5 overheating (power down most machines in \n5 minutes, ~1\u20132 days to recover)\n\n\n~1 PDU failure (~500\u20131,000 machines suddenly disappear, ~6 hours to come back)\n\n\n~1 rack-move (plenty of warning, ~500\u20131,000 machines powered down, ~6 hours)\n\n\n~1 network rewiring (rolling ~5% of machines down over 2-day span)\n\n\n~20 rack failures (40\u201380 machines instantly disappear, 1\u20136 hours to get back)\n\n\n~5 racks go wonky (40\u201380 machines see 50% packet loss)\n\n\n~8 network maintenances (4 might cause ~30-minute random connectivity losses)\n\n\n~12 router reloads (takes out DNS for a couple minutes)\n\n\n~3 router failures (have to immediately pull traffic for an hour)\n\n\n~dozens of minor 30-second blips for DNS\n\n\n~1,000 individual machine failures\n\n\n~thousands of hard drive failures\n\n\nslow disks, bad memory, misconfigured machines, flaky machines, etc.\n\n\nlong-distance links: wild dogs, sharks, dead horses, drunken hunters, etc.\n\n\n\n\nWhat do these failure statistics mean from an application or operations perspective?\n\n\n\n\nFirst, any particular VM or portion of a network may fail. This VM or network may be performing application or operation functionality.\n\n\nSecond, since the probability of failure of serial use of components is related to the product of the failure rate of the individual components, the more components involved in a request, the higher the probability of failure.\n\n\n\n\nFailure of a VM\n\n\nOne of the major decisions the architect of a distributed system makes is how to divide state among the various pieces of an application. If a stateless component fails, it can be replaced without concern for state. On the other hand, state must be maintained somewhere accessible to the application, and getting state and computation together in the same VM will involve some level of overhead. We distinguish three main cases:\n\n\n\n\nA stateless component\n. If a VM is stateless, then failure of a VM is recovered by creating another instance of the same VM image and ensuring that messages are correctly routed to it. This is the most desirable situation from the perspective of recovering from failure.\n\n\nClient state\n. A session is a dialogue between two or more components or devices. Typically, each session is given an ID to provide continuity within the dialogue.\n\n\nFor example, you may log in to a website through one interaction between your browser and a server. Session state allows your browser to inform the server in successive messages that you have been successfully logged in and that you are who you purport to be. Sometimes the client will add additional state for security or application purposes. Since client state must be sent with a message to inform the server of the context or a set of parameters, it should be kept to a minimum.\n\n\n\n\n\n\nApplication state\n contains the information specific to an application or a particular user of an application. It may be extensive, such as a knowledge base or the results of a web crawler, or it may be small, such as the current position of a user when watching a streaming video. We identify three categories of application states:\n\n\nSmall amounts of persistent state.\n The persistent state must be maintained across multiple sessions or across failure of either servers or clients. The application can maintain this state either per user or for the whole application. Small amounts of persistent state can be:\n\n\nMaintained in a flat file or other structure on a file system.\n\n\nCached using a tool that maintains a persistent state across VM instances such as ZooKeeper or Memcached.\n\n\n\n\n\n\nModerate amounts of persistent or semi-persistent state\n. It is advantageous to cache those portions of persistent state that are used frequently in computations and to maintain state across different instances of a VM that allows the sharing of this state. In some sense, this is equivalent to shared memory at the hardware level except that it is done across different VMs across a network. Tools such as Memcached are intended to manage moderate amounts of shared state that represent cached database entries or generated pages. Memcached automatically presents a consistent view of the data to its clients, and by sharing the data across servers, it provides resilience in the case of failure of a VM.\n\n\nLarge amounts of persistent state\n. Large amounts of persistent state can be kept in either of the following: [p37]\n\n\nA database managed by a database management system,\n\n\nA distributed file system such as Hadoop Distributed File System (HDFS).\n\n\n\n\n\n\n\n\n\n\n\n\nThe Long Tail\n\n\n[p37-39]\n\n\nIn the cloud, many phenomena such as response time to requests show a long-tail distribution.  This result is often due to the increased probability of failure with more entities involved, and the failure of one component causes response time to be an order slower than usual (e.g., until a network packet is routed through a different link, after the main network link broke and the error has been detected).\n\n\nSimple requests such as computation, reading a file, or receiving a local message will have a distribution closer to normal. Complicated requests such as extensive map-reduce jobs, searches across a large database, or launching virtual instances will have a skewed distribution such as a long tail.\n\n\nA request that takes an exceedingly long time to respond should be treated as a failure. However, one problem with such a request is that there is no way of knowing whether the request has failed altogether or is going to eventually complete. One mechanism to combat the long tail is to cancel a request that takes too long.\n\n\nConsistency\n\n\n[p39]\n\n\nConsistency is maintained in a distributed system by introducing locks that control the sequence of access to individual data items. Locking data items introduces delays in accessing those data items; consequently, there are a variety of different schemes for maintaining consistency and reducing the delay caused by locks. Regardless of the scheme used, the availability of data items will be impacted by the delays caused by the introduction of locks.\n\n\nIn addition, in the cloud persistent data may be partitioned among different locales to reduce access time, especially if there is a large amount of data. Per a theoretical result called the \nCAP\n (Consistency, Availability, Partition Tolerance) theorem, it is not possible to simultaneously have fully available, consistent, and partitioned data.\n\n\nEventual consistency\n means that distributed, partitioned, and replicated data will be consistent after a period of time even if not immediately upon a change to a data item; the replicas will become consistent eventually.\n\n\nNoSQL Databases\n\n\nFor a variety of reasons, including the CAP theorem and the overhead involved in setting up a relational database system, a collection of database systems have been introduced that go under the name NoSQL. Originally the name literally meant \nNo\n SQL, but since some of the systems now support SQL, it now stands for \nNot Only\n SQL.\n\n\nNoSQL systems use a different data model than relational systems. Relational systems are based on presenting data as tables. NoSQL systems use data models ranging from key-value pairs to graphs. The rise of NoSQL systems has had several consequences:\n\n\n\n\nNoSQL systems are not as mature as relational systems, and many features of relational systems such as transactions, schemas, and triggers are not supported by these systems. The application programmer must implement these features if they are needed in the application.\n\n\nThe application programmer must decide which data model(s) are most appropriate for their use. Different applications have different needs with respect to their persistent data, and these needs must be understood prior to choosing a database system.\n\n\n\n\nApplications may use multiple database systems for different needs.\n\n\n\n\nKey-value stores\n can deal with large amounts of semistructured data efficiently.\n\n\nGraph database\n systems can maintain connections among data items efficiently.\n\n\n\n\nThe virtue of using multiple different database systems is that you can better match a system with your needs.\n\n\n\n\n\n\nElasticity\n\n\nRapid elasticity and provisioning is one of the characteristics of the cloud identified by NIST. Elasticity means that the number of resources such as VMs used to service an application can grow and shrink according to the load.  Monitoring the utilization of the existing resources is one method for measuring the load.\n\n\nThe following figure clients accessing VMs through a load balancer and a monitor determining CPU and I/O utilization of the various VMs, grouped together in a scaling group. The monitor sends its information to the scaling controller, which has a collection of rules that determine when to add or remove the server in the scaling group.\n\n\n\n\nDevOps Consequences of the Unique Cloud Features\n\n\nThree of the unique aspects of the cloud that impact DevOps are:\n\n\n\n\nThe ability to create and switch environments simply,\n\n\nThe ability to create VMs easily,\n\n\nThe management of databases.\n\n\n\n\nEnvironments\n\n\nAn environment in our context is a set of computing resources sufficient to execute a software system, including all of the supporting software, data sets, network communications, and defined external entities necessary to execute the software system.\n\n\nThe essence of this definition is that an environment is self-contained except for explicitly defined external entities. An environment is typically isolated from other environments. Chapter 5 covers a number of environments such as the Dev, integration, user testing, and production environments. In the case study in Chapter 12, the life cycle of an environment is explicitly a portion of their deployment pipeline. [p41]\n\n\nThe isolation of one environment from another is enforced by having no modifiable shared resources. \nResources that are read-only, such as feeds of one type or another, can be shared without a problem. Since an environment communicates with the outside world only through defined external entities, these entities can be accessed by URLs and, hence, managed separately.\n Writing to or altering the state of these external entities should only be done by the production environment, and separate external entities must be created (e.g., as dummies or test clones) for all other environments.\n\n\nThe following figure shows two variants of two different environments: a testing environment and a production environment: Each contains slightly different versions of the same system. The two load balancers, responsible for their respective environments, have different IP addresses.\n\n\n\n\na. Testing can be done by forking the input stream to the production environment and sending a copy to the testing environment as shown in part (a) in the figure. \nIn this case, it is important that the test database be isolated from the production database.\n\n\nb. Part b shows an alternative situation. In this case, some subset of actual production messages is sent to the test environment that performs live testing. Canary testing and other methods of live testing are discussed in \nChapter 6\n.\n\n\n\n\n\n\n\n\nMoving between environments can be accomplished in a single script that can be tested for correctness prior to utilizing it. Chapter 6 also discusses other techniques for moving between testing and production environments.\n\n\nA consequence of easily switching production from one environment to another is that achieving business continuity becomes easier. Business continuity means that businesses can continue to operate in the event of a disaster occurring either in or to their main datacenter. \nChapter 11\n dicusses a case study about managing multiple datacenters, but for now observe that there is no requirement that the two environments be co-located in the same datacenter. There is a requirement that the two databases be synchronized if the goal is quickly moving from one environment to a backup environment.\n\n\nCreating Virtual Machines Easily\n\n\nOne of the problems that occurs in administering the cloud from a consumer\u2019s perspective arises because it is so easy to allocate new VMs, which may lead to:\n\n\n\n\nSecurity risk\n. Virtual machines need to have the latest patches applied, just as physical machines, and need to be accounted for. Unpatched machines constitute a security risk.\n\n\nCost\n. In a public cloud, the consumer pays for the use of VMs.\n\n\n\n\nThe term \nVM sprawl\n is used to describe the complexity in managing too many VMs. Similarly, the challenges of having too many VM images is called \nimage sprawl\n. Developing and enforcing a policy on the allocation of machines and archiving of VM images is one of the activities necessary when utilizing the cloud as a platform.\n\n\nData Considerations\n\n\nThe economic viability of the cloud coincided with the advent of NoSQL database systems. Many systems utilize multiple different database systems, both relational and NoSQL. Furthermore, large amounts of data are being gathered from a variety of sources for various business intelligence or operational purposes. Just as computational resources can be added in the cloud by scaling, storage resources can also be added.\n\n\nHDFS\n\n\nHDFS provides storage for applications in a cluster. HDFS also provides the file system for many NoSQL database systems. HDFS suppors commands such as open, create, read, write, close through a normal file system interface.\n\n\nSince the storage provided by HDFS is shared by multiple applications, a manager controls the name space of file names and allocates space when an application wishes to write a new block. This manager also provides information so that applications can perform direct access to particular blocks.\n\n\nIn HDFS, the manager is called the NameNode, and each element of the storage pool is called a DataNode. There is one NameNode with provision for a hot backup. Each DataNode is a separate physical computer or VM.  Applications are restricted to write a fixed-size block (typically 64MB). When an application wishes to write a new block to a file, it contacts the NameNode and asks for the DataNodes where this block will be stored. Each block is replicated some number of times, typically three. The NameNode responds to a request for a write with a list of the DataNodes where the block to be written will be stored, and the application then writes its block to each of these DataNodes.\n\n\nMany features of HDFS are designed to guard against failure of the individual DataNodes and to improve the performance of HDFS. For our purposes, the essential element is that HDFS provides a pool of storage sites that are shared across applications.\n\n\nOperational Considerations\n\n\nThe operational considerations associated with a shared file system such as HDFS are twofold.\n\n\n\n\nWho manages the HDFS installation?\n HDFS can be either a shared system among multiple applications, or it can be instantiated for a single application.  In case of a single application, its management will be the responsibility of the development team for that application. In the shared case, the management of the system must be assigned somewhere within the organization.\n\n\nHow is the data stored within HDFS protected in the case of a disaster?\n HDFS itself replicates data across multiple DataNodes, but a general failure of a datacenter may cause HDFS to become unavailable or the data being managed by HDFS to become corrupted or lost. Consequently, business continuity for those portions of the business dependent on the continued execution of HDFS and access to the data stored within HDFS is an issue that must be addressed.\n\n\n\n\nSummary\n\n\n[p44-45]", 
            "title": "Chapter 2. The Cloud as a Platform"
        }, 
        {
            "location": "/devops/ch3/", 
            "text": "Chapter 3. Operations\n\n\nIntroduction\n\n\n[p47]\n\n\nDevOps does not subsume Dev and does not subsume Ops. To understand DevOps, however, it is important to be aware of the context that people in Ops or Dev come from.\n\n\nOne characterization of Ops is given in the Information Technology Infrastructure Library (ITIL). ITIL acts as a kind of coarse-grained job description for the operations staff. ITIL is based on the concept of \"services\", and the job of Ops is to support the design, implementation, operation, and improvement of these services within the context of an overall strategy.\n\n\nOperations Services\n\n\nAn operations service can be the provisioning of hardware, the provisioning of software, or supporting various IT functions. Services provided by operations also include the specification and monitoring of \nservice level agreements\n (SLAs), capacity planning, business continuity, and information security.\n\n\nProvisioning of Hardware\n\n\nProvisioning of Software\n\n\nIT Functions\n\n\nOps supports a variety of functions. These include:\n\n\n\n\nService desk operations\n. The service desk staff is responsible for handling all incidents and service requests and acts as first-level support for all problems.\n\n\nTechnology experts\n. Ops typically has experts for networks, information security, storage, databases, internal servers, web servers and applications, and telephony.\n\n\nDay-to-day provisioning of IT services\n. These include periodic and repetitive maintenance operations, monitoring, backup, and facilities management.\n\n\n\n\nService Level Agreements\n\n\n[p50]\n\n\nAn organization has a variety of SLAs with external providers of services. For example, a cloud provider will guarantee a certain level of availability. Ops traditionally is responsible for monitoring and ensuring that the SLAs are adhered to.\n\n\nCapacity Planning\n\n\n[p51]\n\n\nOps is responsible for ensuring that adequate computational resources are available for the organization.\n\n\nBusiness Continuity and Security\n\n\nIn the event a disaster occurs, an organization needs to keep vital services operational so that both internal and external customers can continue to do their business. Two key parameters enable an organization to perform a cost/benefit analysis of various alternatives to maintain business continuity:\n\n\n\n\nRecovery point objective\n (RPO). When a disaster occurs, what is the maximum period for which data loss is tolerable? If backups are taken every hour then the RPO would be 1 hour, since the data that would be lost is that which accumulated since the last backup.\n\n\nRecovery time objective\n (RTO). When a disaster occurs, what is the maximum tolerable period for service to be unavailable? For instance, if a recovery solution takes 10 minutes to access the backup in a separate datacenter and another 5 minutes to instantiate new servers using the backed-up data, the RTO is 15 minutes.\n\n\n\n\nThe two values are independent since some loss of data may be tolerable, but being without service is not. It is also possible that being without service is tolerable but losing data is not.\n\n\nThe following figure (Figure 3.2) shows three alternative backup strategies with different RPOs. [p52]\n\n\n\n\n\n\nFigure 3.2a shows an external agent (the backup process) copying the database periodically. No application support is required but the backup process should copy a consistent version of the database, which means no updates are currently being applied. If the backup process is external to the database management system, then transactions may be in process and so the activation of the backup should be carefully performed. In this case, the RPO is the period between two backups. That is, if a disaster occurs just prior to the backup process being activated, all changes in the period from the last backup will be lost.\n\n\nFigure 3.2b shows an alternative without an external agent. In this case, the database management system creates a copy periodically. The difference between 3.2a and 3.2b is that in 3.2b, guaranteeing consistency is done by the database management system, whereas in 3.2a, consistency is guaranteed by some mechanism that governs the activation of the backup process.  If the database is a relational database management system (RDBMS) offering some level of replication (i.e., a transaction only completes a commit when the replica database has executed the transaction as well), then transactions lost in the event of a disaster will be those not yet committed to the replicating database. The cost, however, is increased overhead per transaction.\n\n\nFigure 3.2c modifies Figure 3.2b by having the database management system log every write. \nThen the data can be re-created by beginning with the backup database and replaying the entries in the log.\n If both the log and the backup database are available during recovery, the RPO is 0 since all data is either in the backup database or in the log. The protocol for committing a transaction to the production database is that no transaction is committed until the respective log entry has been written. It is possible in this scheme that some transactions have not been completed, but no data from a completed transaction will be lost. This scheme is used by high-reliability relational database management systems. It is also used by distributed file systems such as Hadoop Distributed File System (HDFS).\n\n\n\n\nWhen considering RTO (how quickly you can get your application up and running after an outage or disaster), alternatives include: using multiple datacenters as discussed in the case study in \nChapter 11\n or using distinct availability zones or regions offered by a cloud provider, or even using several cloud providers.\n\n\nBy considering RTO and RPO, the business can perform a cost/benefit analysis of a variety of different disaster recovery techniques. Some of these techniques will involve application systems architecture such as replication and maintaining state consistency in the different replicas. Other techniques such as periodic backups can be performed with any application architecture. Using stateless servers on the application tier and different regions within a cloud provider results in a short RTO but does not address RPO.\n\n\nTraditionally, Ops is responsible for the overall security of computer systems.  Securing the network, detecting intruders, and patching operating systems are all activities performed by Ops. \nChapter 8\n discusses security and its maintenance in some depth.\n\n\nService Strategy\n\n\nService Design\n\n\nService Transition\n\n\nService Operation\n\n\nService Operation Concepts\n\n\nService Operation Functions\n\n\nMonitoring is of central importance during operations, as it allows collecting events, detecting incidents, and measuring to determine if SLAs are being fulfilled; it provides the basis for service improvement. SLAs can also be defined and monitored for operations activities,\n\n\nMonitoring can be combined with some \ncontrol\n (for example, as done in autoscaling for cloud resources, where an average CPU load among the pool of web servers of 70% triggers a rule to start another web server).\n\n\nControl can be \nopen-loop\n or \nclosed-loop\n:\n\n\n\n\nOpen-loop control (monitoring feedback is not taken into account) can be used for regular backups at predefined times.\n\n\nIn closed-loop control, monitoring information is taken into account when deciding on an action, such as in the autoscaling example.\n\n\n\n\n[p57]\n\n\nContinual Service Improvement\n\n\nAll of the Ops services: the provisioning of hardware and software, IT support functions, specification and monitoring of SLAs, capacity planning, business continuity, and information security\u2014are organizational processes. They should be monitored and evaluated from the perspective of the questions we have identified.\n\n\nOrganizationally, each of these services should have an owner, and the owner of a service is the individual responsible for overseeing its monitoring, evaluation, and improvement.\n\n\nThe figure below depicts the seven-step process for improvement, as suggested by ITIL.\n\n\n\n\nOperations and DevOps", 
            "title": "Chapter 3. Operations"
        }, 
        {
            "location": "/devops/ch4/", 
            "text": "Chapter 4. Overall Architecture\n\n\nDevOps achieves its goals partially by replacing explicit coordination with implicit and often less coordination. [p65]\n\n\nDo DevOps Practices Require Architectural Change?\n\n\nOverall Architecture Structure\n\n\n\n\nA \nmodule\n is a code unit with coherent functionality.\n\n\nA \ncomponent\n is an executable unit.\n\n\n\n\nA compiler or interpreter turns modules into binaries, and a builder turns the binaries into components. The development team directly develops modules. Components are results of the modules developed by development teams.\n\n\nDevelopment teams using DevOps processes are usually small and have limited inter-team coordination. \nWhen a team deploys a component, it cannot go into production unless the component is compatible with other components with which it interacts.\n Ensuring this compatibility require either of the following:\n\n\n\n\nExplicit multi-team coordination,\n\n\nImplicitly definition of the architecture.\n\n\n\n\nAn organization can introduce continuous deployment without major architectural modifications. However, dramatically reducing the time required to place a component into production requires architectural support:\n\n\n\n\nDeploying without explicit coordination\n with other teams reduces the time required to place a component into production.\n\n\n Allowing for different versions of the same service\n to be simultaneously in production leads to different team members deploying without coordination with other members of their team.\n\n\nRolling back a deployment\n in the event of errors allows for various forms of live testing.\n\n\n\n\nMicroservice architecture\n is an architectural style that satisfies these requirements. It is a good general basis for projects that are adopting DevOps practices. By definition, a microservice architecture consists of a collection of services where each service provides a small amount of functionality and the total functionality of the system is derived from composing multiple services.\n\n\nThe following figure describes a microservice architecture. A user interacts with a single consumer-facing service, which in turn utilizes a collection of other services. We use the terminology \nservice\n to refer to a component that provides a service and \nclient\n to refer to a component that requests a service. A single component can be a client in one interaction and a service in another. In a system such as LinkedIn, the service depth may reach as much as 70 for a single user request.\n\n\n\n\nTo minimize inter-team coordination, there are three categories of design decisions that can be made globally as a portion of the architecture design, thus removing the need for inter-team coordination: the coordination model, management of resources, and mapping among architectural elements.\n\n\nCoordination Model\n\n\nIf two services interact, there are two details of the coordination:\n\n\n\n\nHow a client discovers a service that it wishes to use,\n\n\nHow the individual services communicate.\n\n\n\n\nThe following figure gives an overview of the interaction between a service and its client:\n\n\n\n\nThe service registers with a registry. The registration includes a name for the service as well as information on how to invoke it (e.g. an endpoint location as a URL or an IP address),\n\n\nA client can retrieve the information about the service from the registry and invoke the service using this information. If the registry provides IP addresses, it acts as a local DNS server, because typically the registry is not open to the general Internet but is within the environment of the application.\n\n\n\n\n\n\nNetflix Eureka\n is an example of a cloud service registry that acts as a DNS server and serves as a catalogue of available services, and can further be used to track aspects such as versioning, ownership, service level agreements (SLAs) for the set of services in an organization. Extensions to the registry are further discussed in \nChapter 6\n\n\nManagement of Resources\n\n\nTwo types of resource management decisions can be made globally and incorporated in the architecture: provisioning/deprovisioning VMs and managing variation in demand.\n\n\nProvisioning and Deprovisioning VMs\n\n\n[p70]\n\n\nDetermining which component controls the provisioning and deprovisioning of a new instance for a service is another important aspect. Three possibilities exist for the controlling component:\n\n\n\n\nA service itself can be responsible for (de)provisioning additional instances.\n\n\nA client or a component in the client chain can be responsible for (de) provisioning instances of a service\n\n\nAn external component monitors the performance of service instances (e.g., their CPU load) and (de)provisions an instance when the load reaches a given threshold. Amazon\u2019s autoscaling groups provide this capability, in collaboration with the CloudWatch monitoring system.\n\n\n\n\nManaging Demand\n\n\nThe number of instances of an individual service that exist should reflect the demand on the service from client requests. We just discussed several different methods for provisioning and deprovisioning instances, and these methods make different assumptions about how demand is managed.\n\n\n[p71]\n\n\n\n\nOne method for managing demand is to monitor performance.\n\n\nAnother possible technique is to use SLAs to control the number of instances.\n\n\n\n\nMapping Among Architectural Elements\n\n\nWe discuss two different types of mappings: work assignments and allocation. Both of these are decisions that are made globally.\n\n\n\n\nWork assignments\n. A single team may work on multiple modules, but having multiple development teams work on the same module requires a great deal of coordination among those development teams.\n\n\nSince coordination takes time, an easier structure is to package the work of a single team into modules and develop interfaces among the modules to allow modules developed by different teams to interoperate. In fact, the original definition of a module by David Parnas in the 1970s was as a work assignment of a team.\n\n\nAlthough not required, it is reasonable that each component (i.e., microservice) is the responsibility of a single development team. That is, the set of modules that, when linked, constitute a component are the output of a single development team. This does not preclude a single development team from being responsible for multiple components but it means that any coordination involving a component is settled within a single development team, and that any coordination involving multiple development teams goes across components. Given the set of constraints on the architecture we are describing, cross-team coordination requirements are limited.\n\n\n\n\n\n\nAllocation\n. Allocation. Each component (i.e., microservice) will exist as an independent deployable unit. This allows each component to be allocated to a single (virtual) machine or container, or it allows multiple components to be allocated to a single (virtual) machine. The redeployment or upgrade of one microservice will not affect any other microservices. This choice is explored in \nChapter 6\n\n\n\n\nQuality Discussion of Microservice Architecture", 
            "title": "Chapter 4. Overall Architecture"
        }, 
        {
            "location": "/devops/ch5/", 
            "text": "Chapter 5. Building and Testing\n\n\nIntroduction\n\n\nThe infrastructure used to support the development and deployment process should support the following requirements (some ignored):\n\n\n\n\nThe code produced by one team can be easily integrated with code produced by other teams.\n\n\nAn integrated version of the system can be easily deployed into various environments (e.g., testing, staging, and production).\n\n\nAn integrated version of the system can be easily and fully tested without affecting the production version of the system.\n\n\nA recently deployed new version of the system can be closely supervised.\n\n\nOlder versions of the code are available in case a problem develops once the code has been placed into production.\n\n\nCode can be rolled back in the case of a problem.\n\n\n\n\nA \ndeployment pipeline\n (as shown in the figure below) consists of the steps that are taken between a developer committing code and the code actually being promoted into normal production, while ensuring high quality.\n\n\n\n\nThe deployment pipeline has following steps:\n\n\n\n\nPre-commit tests\n. The developer performs a series of pre-commit tests on their local environment\n\n\nCommit\n. The developer commits code to the joint versioning system\n\n\nIntegration tests\n. A commit then triggers an integration build of the service being developed. This build is tested by integration tests.\n\n\nStaging tests\n. If these tests are successful, the build is promoted to a quasi-production environment, the staging environment, where it is tested once more.\n\n\nProduction\n. Then, it is promoted to production under close supervision for another period of close supervision\n\n\nNormal production\n. It is promoted to normal production.\n\n\n\n\nThe specific tasks may vary a bit for different organizations. For example, a small company may not have a staging environment or special supervision for a recently deployed version. A larger company may have several different production environments for different purposes. Some of these different production environments are described in \nChapter 6\n.\n\n\nSome definitions:\n\n\n\n\nContinuous integration\n is to have automatic triggers between one phase and the next, up to \nintegration tests\n.\n\n\nIf the build is successful then integration tests are triggered. If not, the developer responsible for the failure is notified.\n\n\n\n\n\n\nContinuous delivery\n is having automated triggers as far as the \nstaging system\n.\n\n\nContinuous deployment\n means that the next to last step (deployment into the production system) is automated as well.\n\n\n\n\nOnce a service is deployed into production it is closely monitored for a period and then it is promoted into normal production. At this final stage, monitoring and testing still exist but the service is no different from other services in this regard. In this chapter, we are concerned with the building and testing aspects of this pipeline.\n\n\nChapter 6\n describes deployment practices, and \nChapter 7\n discusses monitoring methods.\n\n\nMoving a System Through the Deployment Pipeline\n\n\nCommitted code moves through the steps shown in \nFigure 5.1\n. It is moved by tools, which are controlled by their programs (called \nscripts\n in this context) or by developer/operator commands. Two aspects of this movement are of interest in this section:\n\n\n\n\nTraceability\n\n\nThe environment associated with each step of the pipeline\n\n\n\n\nTraceability\n\n\nTraceability means that, for any system in production, it is possible to determine exactly how it came to be in production. This means keeping track not only of source code but also of all the commands to all the tools that acted on the elements of the system.\n\n\nA movement called \nInfrastructure as Code\n uses the rationale that:\n\n\n\n\nThe scripts and associated configuration parameters should be kept under version control, just as the application code.\n\n\nTests are also maintained in version control.\n\n\nConfiguration parameters can be kept as files that are stored in version control or handled through dedicated configuration management systems.\n\n\n\n\nTreating infrastructure-as-code means that this code should be subject to the same quality control as application source code.\n\n\nA complication to the requirement to keep everything in version control is the treatment of third-party software such as Java libraries. Software project management tools like Apache Maven can go a long way to managing the complexities of library usage. [p82]\n\n\nThe Environment\n\n\nAn executing system can be viewed as a collection of executing code, an environment, configuration, systems outside of the environment with which the primary system interacts, and data.\n\n\n\n\nAs the system moves through the deployment pipeline, these items work together to generate the desired behavior or information:\n\n\n\n\nPre-commit\n. The environment is typically a laptop or a desktop, the external systems are stubbed out or mocked, and only limited data is used for testing. Read-only external systems (e.g. RSS feed) can be accessed during the pre-commit stage. Configuration parameters should reflect the environment and also control the debugging level.\n\n\nBuild and integration testing\n. The environment is usually a continuous integration server.\n\n\nThe code is compiled, and the component is built and baked into a VM image. The image can be either heavily or lightly baked (see the later section on \npackaging\n).\n\n\nDuring integration testing, a set of test data forms a test database (not production), which consists of a sufficient amount of data to perform the automated tests associated with integration.\n\n\nThe configuration parameters connect the built system with an integration testing environment\n\n\n\n\n\n\nUAT/staging/performance testing\n. The environment is as close to production as possible.\n\n\nAutomated acceptance tests are run, and stress testing is performed through the use of artificially generated workloads.\n\n\nThe database should have some subset of actual production data in it. The subset should be large enough to enable the tests to be run in a realistic setting.\n\n\nConfiguration parameters connect the tested system with the larger test environment. Access to the production database should not be allowed from the staging environment.\n\n\n\n\n\n\nProduction\n. The production environment should access the live database and have sufficient resources to adequately handle its workload. Configuration parameters connect the system with the production environment.\n\n\n\n\nThe configuration for each of these environments will be different, for example:\n\n\n\n\nLogging. Logging in development environment is usually in much detailed fashion to help debugging, since the performance overhead created does not matter as much.\n\n\nCredentials. The credentials for accessing production resources (e.g. the live customer database), should not be made available to developers.\n\n\n\n\nWhile some changes in configuration are unavoidable, it is important to keep these changes to a minimum to prevent affecting the behavior of the system. As such, testing with a vastly different configuration from the production system will not be helpful.\n\n\nWikipedia has a longer list of environments:\n\n\n\n\nLocal: Developer\u2019s laptop/desktop/workstation\n\n\nDevelopment: Development server, a.k.a. sandbox\n\n\nIntegration: Continuous integration (CI) build target, or for developer testing of side effects\n\n\nTest/QA: For functional, performance testing, quality assurance, etc.\n\n\nUAT: User acceptance testing\n\n\nStage/Pre-production: Mirror of production environment\n\n\nProduction/Live: Serves end-users/clients\n\n\n\n\nCrosscutting Aspects\n\n\nThis section discusses various crosscutting aspects of a deployment pipeline:\n\n\n\n\nTest harnesses\n. A test harness is a collection of software and test data configured to test a program unit by running it under varying conditions and monitoring its behavior and output.\n\n\nTest harnesses are essential in order to automate tests.\n\n\nA critical feature of a test harness is that it generates a report. It should, at a minimum, identify which tests failed.\n\n\nMost of the types of tests discussed in this chapter should be able to be automated and driven by the test harness.\n\n\n\n\n\n\nNegative tests\n. It is also important to test if the system behaves in a defined way without the assumptions, which are about the environment hold and the user performs actions expectedly (in the right order with the right inputs).\n\n\nExamples are users performing actions in the wrong order (clicking buttons, calling commands) or simulated connectivity issues(external services becoming unavailable, connections being dropped at unexpected points in time).\n\n\nThe common expectation is that:\n\n\nThe application should degrade or fail gracefully\n\n\nIf failure is unavoidable, provide meaningful error messages and exit in a controlled manner.\n\n\n\n\n\n\n\n\n\n\nRegression testing\n.\n\n\nRegression testing seeks to uncover new software bugs, or regressions, in existing functional and non-functional areas of a system after changes such as enhancements, patches or configuration changes, have been made to them.\n\n\nAnother use of regression testing is to ensure that any fixed bugs are not reintroduced later on.\n\n\nIt is possible to automate the regression test creation: Failures detected at later points in the deployment pipeline (during staging testing) can be automatically recorded and added as new tests into unit or integration testing.\n\n\n\n\n\n\nTraceability of errors\n (also referred to as lineage or a form of provenance).\n\n\n\n\nDevelopment and Pre-commit Testing\n\n\nVersion Control and Branching\n\n\nCore features of version control are: the ability to identify distinct versions of the source code, sharing code revisions between developers, recording who made a change from one version to the next, and recording the scope of a change.\n\n\n\n\nCVS and SVN are centralized solutions, where each developer checks out code from a central server and commits changes back to that server.\n\n\nGit is a distributed version control system: Every developer has a local clone (or copy) of a Git repository that holds all contents.\n\n\nCommits are done to the local repository.\n\n\nA set of changes can be synchronized against a central server, where changes from the server are synchronized with the local repository (using the \npull\n command) and local changes can be forwarded to the server (using the \npush\n command).\n\n\nPush can only be executed if the local repository is up-to-date, hence a push is usually preceded by a pull.\n\n\nDuring the pull, changes to the same files are merged automatically. However, this merge can fail, in which case the developer has to resolve any conflicts locally. The resulting changes from an (automatic or semi-manual) merge are committed locally and then pushed to the server.\n\n\n\n\n\n\n\n\nAlmost all version control systems support the creation of new branches. A branch is essentially a copy of a repository (or a portion) and allows independent evolution of two or more streams of work.\n\n\nFor example, if part of the development team is working on a set of new features while a previous version is in production and a critical error is discovered in the production system, the version currently in production must be fixed. This can be done by creating a branch for the fix based on the version of the code that was released into production.  After the error has been fixed and the fixed version has been released into production, the branch with the fix is typically merged back into the main branch (also called the trunk, mainline, or master branch).\n\n\nThis example is useful in highlighting the need for traceability that we discussed previously. In order to fix the error, the code that was executing needs to be determined (traceability of the code). The error may be due to a problem with the configuration (traceability of the configuration) or with the tool suite used to promote it into production (traceability of the infrastructure).\n\n\nAlthough the branch structure is useful and important, two problems exist in using branches.\n\n\n\n\nYou may have too many branches and lose track of which branch you should be working on for a particular task. For this reason, short-lived tasks should not create a new branch.\n\n\nMerging two branches can be difficult. Different branches evolve concurrently, and often developers touch many different parts of the code.\n\n\n\n\nAn alternative to branching is to have all developers working on the trunk directly. Instead of reintegrating a big branch, a developer deals with integration issues at each commit, which is a simpler solution, but requires more frequent action than using branches.\n\n\nThe problem with doing all of the development on one trunk is that a developer may be working on several different tasks within the same module simultaneously.  When one task is finished, the module cannot be committed until the other tasks are completed. To do so would introduce incomplete and untested code for the new feature into the deployment pipeline. Solving this problem is the rationale for feature toggles.\n\n\nFeature Toggles\n\n\nA \nfeature toggle\n (also called a \nfeature flag\n or a \nfeature switch\n) is an \"if\" statement around immature code. A new feature that is not ready for testing or production is disabled in the source code itself, for example, by setting a global Boolean variable.\n\n\nHowever, there are certain dangers in feature toggles.\n\n\n\n\nLesson 1: Do not reuse toggle names.\n\n\nLesson 2: Integrate the feature and get rid of the toggle tests as soon as is timely.\n\n\n\n\nWhen there are many feature toggles, managing them becomes complicated. It would be useful to have a specialized tool or library that knows about all of the feature toggles in the system, is aware of their current state, can change their state, and can eventually remove the feature toggle from your code base.\n\n\nConfiguration Parameters\n\n\nA configuration parameter is an externally settable variable that changes the behavior of a system. A configuration setting may be: the language you wish to expose to the user, the location of a data file, the thread pool size, the color of the background on the screen, or the feature toggle settings.\n\n\nIn this book, we are interested in configuration settings that either control the relation of the system to its environment or control behavior related to the stage in the deployment pipeline in which the system is currently run.\n\n\n[p90]\n\n\nOne decision to make about configuration parameters is whether the values should be the same in the different steps of the deployment pipeline. If the production system\u2019s values are different, you must also decide whether they must be kept confidential. These decisions yield three categories.\n\n\n\n\nValues are the same in multiple environments. Feature toggles and performance-related values (e.g., database connection pool size) should be the same in performance testing/UAT/staging and production, but may be different on local developer machines.\n\n\nValues are different depending on the environment. The number of virtual machines (VMs) running in production is likely bigger than that number for the testing environments.\n\n\nValues must be kept confidential. The credentials for accessing the production database or changing the production infrastructure must be kept confidential and only shared with those who need access to them: no sizeable organization can take the risk that a development intern walks away with the customer data.\n\n\n\n\nKeeping values of configuration parameters confidential introduces some complications to the deployment pipeline. The overall goal is to make these values be the current ones in production but keep them confidential.\n\n\n\n\nOne technique is to give meta-rights to the deployment pipeline and restrict access to the pipeline.  When, for instance, a new VM is deployed into production, the deployment pipeline can give it rights to access a key store with the credentials required to operate in production.\n\n\nAnother technique is for the deployment pipeline to set the network configuration in a virtual environment for a machine such that it gets to access the production database servers, the production configuration server, and so forth, if the machine is to be part of the production environment. In this case, only the deployment pipeline should have the right to create machines in the production portion of the network.\n\n\n\n\nTesting During Development and Pre-commit Tests\n\n\n[p91]\n\n\n\n\nTest-driven development\n. When following this philosophy, before writing the actual code for a piece of functionality, you develop an automated test for it. Then the functionality is developed, with the goal of fulfilling the test. Once the test passes, the code can be refactored to meet higher-quality standards.\n\n\nUnit tests\n. Unit tests are code-level tests, each of which is testing individual classes and methods.\n\n\n\n\nWhile these tests can be run by the developer at any point, a modern practice is to enforce \npre-commit tests\n. These tests are run automatically before a commit is executed. Typically they include a relevant set of unit tests, as well as a few smoke tests. \nSmoke tests are specific tests that check in a fast (and incomplete) manner that the overall functionality of the service can still be performed.\n The goal is that any bugs that pass unit tests but break the overall system can be found long before integration testing. Once the pre-commit tests succeed, the commit is executed.\n\n\nBuild and Integration Testing\n\n\nBuild is the process of creating an executable artifact from input such as source code and configuration. It primarily consists of compiling source code and packaging all files that are required for execution. Once the build is complete, a set of automated tests are executed that test whether the integration with other parts of the system uncovers any errors. The unit tests can be repeated here to generate a history available more broadly than to a single developer.\n\n\nBuild Scripts\n\n\n[p91-92]\n\n\nThe build and integration tests are performed by a continuous integration (CI) server. The input to this server should be scripts that can be invoked by a single command. This practice ensures that the build is repeatable and traceable.\n\n\nPackaging\n\n\nThe goal of building is to create something suitable for deployment. There are several standard methods of packaging the elements of a system for deployment.  The appropriate method of packaging will depend on the production environment.  Some packaging options are:\n\n\n\n\nRuntime-specific packages\n, such as Java archives, web application archives, and federal acquisition regulation archives in Java, or .NET assemblies.\n\n\nOperating system packages\n. If the application is packaged into software packages of the target OS (such as the Debian or Red Hat package system),\na variety of well-proven tools can be used for deployment.\n\n\nVM images\n can be created from a template image, to include the changes from the latest revision.\n\n\nLightweight containers\n\n\n\n\nThere are two dominant strategies for applying changes in an application when using VM images or lightweight containers: \nheavily baked\n versus \nlightly baked images.\n Heavily baked images cannot be changed at runtime. This concept is also termed \nimmutable servers\n: Once a VM has been started, no changes (other than configuration values) are applied to it.\n\n\n[p93]\n\n\nContinuous Integration and Build Status\n\n\n[p93-94]\n\n\nIntegration Testing\n\n\nIntegration testing is the step in which the built executable artifact is tested.  The environment includes connections to external services, such as a surrogate database. Including other services requires mechanisms to distinguish between production and test requests, so that running a test does not trigger any actual transactions, such as production, shipment, or payment.\n\n\n[p94-95]\n\n\nUAT/Staging/Performance Testing\n\n\n[p95]\n\n\nStaging is the last step of the deployment pipeline prior to deploying the system into production. The staging environment mirrors, as much as possible, the production environment. The types of tests that occur at this step are the following:\n\n\n\n\nUser acceptance tests\n (UATs) are tests where prospective users work with a current revision of the system through its UI and test it, either according to a test script or in an exploratory fashion.\n\n\nAutomated acceptance tests\n are the automated version of repetitive UATs. Such tests control the application through the UI, trying to closely mirror what a human user would do. Automation takes some load off the UATs, while ensuring that the interaction is done in exactly the same way each time. As such, automated acceptance tests enable a higher rate of repetition than is possible with relatively expensive human testers.\n\n\nSmoke tests\n are a subset of the automated acceptance tests that are used to quickly analyze if a new commit breaks some of the core functions of the application.\n\n\nNonfunctional tests\n test aspects such as performance, security, capacity, and availability.\n\n\n\n\nProduction\n\n\nEarly Release Testing\n\n\nThis subsection focuses on the testing method. \nChapter 6\n discusses how to release the application to achieve early release testing.\n\n\n\n\nBeta release\n is the most traditional approach. A selected few users, often subscribed to a beta program, are given access to a prerelease (beta) version of the application. Beta testing is primarily used for \non-premises use of software\n.\n\n\nCanary testing\n is a method of deploying the new version to a few servers first, to see how they perform. It is the cloud equivalent of beta testing.\n\n\nOne or a few of the application servers are upgraded from the current version to a stable, well-tested release candidate version of the application. Load balancers direct a small portion of the user requests to the candidate version, while monitoring is ongoing. If the candidate servers are acceptable in terms of some metrics (e.g., performance, scalability, number of errors) the candidate version is rolled out to all servers.\n\n\n\n\n\n\nA/B testing\n is similar to canary testing, except that the tests are intended\nto determine which version performs better in terms of certain business-level key performance indicators. For example, a new algorithm for recommending products may increase revenue, or UI changes may lead to more click-throughs.\n\n\n\n\nError Detection\n\n\nEven systems that have passed all of their tests may still have errors. \nThese errors can be either functional or nonfunctional.\n Techniques used to determine nonfunctional errors include monitoring of the system for indications of poor behavior.  This can consist of monitoring the timing of the response to user requests, the queue lengths, and so forth.\n\n\nOnce an alert has been raised, tracking and finding its source can be quite difficult. Logs produced by the system are important in enabling this tracking (\nChapter 7\n). It is important that the provenance of the software causing the alert and the user requests that triggered the alert all can be easily obtained. Enabling the diagnosis of errors is one of the reasons for the emphasis on using automated tools that maintain histories of their activities.\n\n\nIn any case, once the error is diagnosed and repaired, the cause of the error can be made one of the regression tests for future releases.\n\n\nLive Testing\n\n\nMonitoring is a passive form of testing: the systems run in their normal fashion and data is gathered about their behavior and performance. Another form of testing after the system has been placed in production is to actually perturb the running system. This form is called \nlive testing\n. Netflix has a set of test tools called the Simian Army. The elements of the Simian Army are both passive and active. The passive elements examine running instances to determine unused resources, expired certificates, health checks on instances, and adherence to best practices.\n\n\nIncidents\n\n\nNo matter how well you test or organize a deployment, errors will exist once a system gets into production. Understanding potential causes of post-deployment errors helps to more quickly diagnose problems. Here are several anecdotes we have heard from IT professionals:\n\n\n\n\nA developer connected test code to a production database.\n\n\nVersion dependencies existing among the components. When dependencies exist among components, the order of deployment becomes important and it is possible if the order is incorrect that errors will result.\n\n\nA change in a dependent system coincided with a deployment. For instance, a dependent system removed a service on which an application depended, and this removal happened after all of the staging tests had been passed.\n\n\nParameters for dependent systems were set incorrectly. For example, queues overflowed or resources were exhausted in dependent systems. Adjusting the configurations for the dependent systems and adding monitoring rules were the fixes adopted by the affected organization.\n\n\n\n\nSummary\n\n\nHaving an appropriate deployment pipeline is essential for rapidly creating and deploying systems. The pipeline has at least five major step: pre-commit, build and integration testing, UAT/staging/performance tests, production, and promoting to normal production.\n\n\nEach step operates within a different environment and with a set of different configuration parameter values\u2014although this set should be limited in size as much as possible. As the system moves through the pipeline, you can have progressively more confidence in its correctness. Even systems promoted to normal production, however, can have errors and can be improved from the perspective of performance or reliability. Live testing is a mechanism to continue to test even after placing a system in production or promoting it to normal production.\n\n\nFeature toggles are used to make code inaccessible during production. They allow incomplete code to be contained in a committed module. They should be removed when no longer necessary because otherwise they clutter the code base; also, repurposed feature toggles can cause errors.\n\n\nTests should be automated, run by a test harness, and report results back to the development team and other interested parties. Many incidents after placing a system in production are caused by either developer or configuration errors.\n\n\nAn architect involved in a DevOps project should ensure the following:\n\n\n\n\nThe various tools and environments are set up to enable their activities to be traceable and repeatable.\n\n\nConfiguration parameters should be organized based on whether they will change for different environments and on their confidentiality.\n\n\nEach step in the deployment pipeline has a collection of automated tests with an appropriate test harness.\n\n\nFeature toggles are removed when the code they toggle has been placed into production and been judged to be successfully deployed.", 
            "title": "Chapter 5. Building and Testing"
        }, 
        {
            "location": "/devops/ch6/", 
            "text": "Chapter 6. Deployment\n\n\nIntroduction\n\n\nDeployment\n is the process of placing a version of a service into production. The initial deployment of a service can be viewed as going from no version of the service to the initial version of the service. Because an initial deployment happens only once for most systems and new versions happen frequently, this chapter discuss upgrading a service.\n\n\nThe overall goal of a deployment is to place an upgraded version of the service into production with minimal impact to the users of the system, whether it is through failures or downtime.\n\n\nThere are three reasons for changing a service:\n\n\n\n\nTo fix an error\n\n\nTo improve some quality of the service\n\n\nTo add a new feature\n\n\n\n\nThe initial discussion assumes that deployment is an all-or-nothing process: at the end of the deployment either all of the virtual machines (VMs) running a service have had the upgraded version deployed or none of them have. Later this chapter, partial deployments are discussed.\n\n\n\n\nIn the figure above, Microservice 3 is being upgraded (shown in dark gray). Microservice 3 depends on microservices 4 and 5, and microservices 1 and 2 (clients of microservice 3) depend on it. For now, assume that any VM runs exactly one service. Other options are discussed later in this chapter.\n\n\nThe goal of a deployment is to move from the current state that has N VMs of the old version, A, of a service executing, to a new state where there are N VMs of the new version, B, of the same service in execution.\n\n\nStrategies for Managing a Deployment\n\n\nThere are two popular strategies for managing a deployment: \nblue/green deployment\n and \nrolling upgrade\n. They differ in terms of costs and complexity.\n\n\nBefore discussing these strategies in more detail, we need to make the following two assumptions:\n\n\n\n\nService to the clients should be maintained while the new version is being deployed.\n\n\nMaintaining service to the clients with no downtime is essential for many Internet e-commerce businesses.\n\n\nOrganizations that have customers primarily localized in one geographic area can afford scheduled downtime, but scheduled off-hours during downtime requires system administrators and op operators to work in the off-hours.\n\n\n\n\n\n\nAny development team should be able to deploy a new version of their service at any time without coordinating with other teams.\n\n\nThis may have an impact on client services developed by other teams, but removes one cause for \nsynchronous coordination\n.\n\n\n\n\n\n\n\n\nThe placement of a new VM with a version into production takes time. In order to place an upgraded VM of a service into production, the new version must be loaded onto a VM and be initialized and integrated into the environment, sometimes with dependency on placements of some other services first. This can take on the order of minutes. Consequently, depending on how parallel some actions can be and their impact on the system still serving clients, the upgrade of hundreds or thousands of VMs can take hours or, in extreme cases, even days.\n\n\nBlue/Green Deployment\n\n\nA \nblue/green deployment\n (sometimes called \nbig flip\n or \nred/black deployment\n) consists of maintaining the N VMs containing version A in service while provisioning N VMs of virtual machines containing version B.\n\n\nOnce N VMs have been provisioned with version B and are ready to service requests, then client requests can be routed to version B. This is a matter of instructing the domain name server (DNS) or load balancer to change the routing of messages. This routing switch can be done in a single stroke for all requests. After a supervisory period, the N VMs provisioned with version A are removed from the system. If anything goes wrong during the supervisory period, the routing is switched back, so that the requests go to the VMs running version A again.\n\n\nThis strategy is conceptually simple, but has some disadvantage:\n\n\n\n\nIt is expensive in terms of both VM and software licensing costs.\n\n\nThe provisioning of the N VMs containing version B prior to terminating all version A VMs is the source of the cost. For this period of time, the VM-based cost doubles.\n\n\nThe provisioning of the hundred (or more) new VMs (even if it can be done in parallel) hundreds of VMs can be time-consuming.\n\n\n\n\n\n\nLong-running requests and stateful data during the switch-over and rollback require special care.\n\n\n\n\nA variation of this model is to do the traffic switching gradually. A small percentage of requests are first routed to version B, effectively conducting a canary test.\n Canary testing is mentioned in Chapter 5 and discuss it in more detail in the section \nCanary Testing\n. If everything goes well for a while, more version B VMs can be provisioned and more requests can be routed to this pool of VMs, until all requests are routed to version B.  This increases confidence in your deployment, but also introduces a number of consistency issues (discussed in \nSection 6.3\n).\n\n\nRolling Upgrade\n\n\nA \nrolling upgrade\n consists of deploying a small number of version B VMs at a time directly to the current production environment, while switching off the same number of VMs running version A. For example, we deploy one version B VM at a time. Once an additional version B VM has been deployed and is receiving requests, one version A VM is removed from the system. Repeating this process N times results in a complete deployment of version B.\n\n\nThis strategy is inexpensive but more complicated. It may cost a small number of additional VMs for the duration of the deployment, but again introduces a number of issues of consistency and more risks in disturbing the current production environment.\n\n\nThe following figure provides a representation of a rolling upgrade within the Amazon cloud:\n\n\n\n\n\n\nEach VM (containing one service) is \ndecommissioned\n (removed, deregistered from the elastic load balancer (ELB), and terminated)\n\n\nThen, a new VM is started and registered with the ELB.\n\n\nThis process continues until all of the VMs containing version A have been replaced with VMs containing version B.\n\n\n\n\nThe additional cost of a rolling upgrade can be low if you conduct your rolling upgrade when your VMs are not fully utilized, and your killing of one or a small number of VMs at a time still maintains your expected service level. It may cost a bit if you add a small number of VMs before you start the rolling upgrade to mitigate the performance impact and risk of your rolling upgrade.\n\n\nDuring a rolling upgrade, one subset of the VMs is providing service with version A, and the remainder of the VMs are providing service with version B.  This creates the possibility of failures as a result of mixed versions. This type of failure is discussed in the \nnext section\n.\n\n\nLogical Consistency\n\n\nThere are some types of logical consistency:\n\n\n\n\nMixed versions in deployment\n. The deployment using a rolling upgrade introduces one type of logical inconsistency (multiple versions of the same service will be simultaneously active). This may also happen with those variants of the blue/green deployment that put new versions into service prior to the completion of the deployment.\n\n\nInconsistency in functionality between a service and its clients\n. Revisiting \nFigure 6.1\n, A service being deployed without synchronous coordination with its client or dependent services may introduce a possible source of logical inconsistency.\n\n\nInconsistency between a service and data kept in a database.\n\n\n\n\nMultiple Versions of the Same Service Simultaneously Active\n\n\nThe following figure shows an instance of an inconsistency because of two active versions of the same service. Two components are shown: the client and two versions (versions A and B) of a service.\n\n\n\n\nThe client sends a message that is routed to version B.\n\n\nVersion B performs its actions and returns some state to the client.\n\n\nThe client then includes that state in its next request to the service.\n\n\nThe second request is routed to version A, and this version does not know what to make of the state, because the state assumes version B. Therefore, an error occurs.\n\n\n\n\nThis problem is called a \nmixed-version race condition\n.\n\n\n\n\nSeveral techniques can prevent this situation:\n\n\n\n\nMake the client version aware\n so that it knows that its initial request was serviced by a version B VM. Then it can require its second request to be serviced by a version B VM.\n\n\nChapter 4\n describes how a service is registered with a registry/load balancer. This registration can contain the version number. The client can then request a specific version of the service.  Response messages from the service should contain a tag so that the client is aware of the version of the service with which it has just interacted.\n\n\n\n\n\n\nToggle the new features\n contained in version B and the client so that only one version is offering the service at any given time.\n\n\nMake the services forward and backward compatible\n, and enable the clients to recognize when a particular request has not been satisfied.\n\n\n\n\nThese options are not mutually exclusive (some of these options can be used together). For example, you can use feature toggles within a backward compatible setting. Within a rolling upgrade you will have installed some VMs of the new version while still not having activated the new features. This requires the new version to be backward compatible.\n\n\nFeature Toggling\n\n\n[p107]\n\n\nTo coordinate the activation of the feature in two directions:\n\n\n\n\nAll of the VMs for the service you just deployed must have the service\u2019s portion of the feature activated.\n\n\nAll of the services involved in implementing the feature must have their portion of the feature activated.\n\n\n\n\nFeature toggles (described in \nChapter 5\n) can be used to control whether a feature is activated. A feature toggle is a piece of code within an \nif\n statement where the \nif\n condition is based on an externally settable feature variable. Using this technique means that the problems associated with activating a feature are:\n\n\n\n\nDetermining that all services involved in implementing a feature have been sufficiently upgraded,\n\n\nActivating the feature in all of the VMs of these services at the same time.\n\n\n\n\nBoth of these problems are examples of synchronizing across the elements of a distributed system. The primary modern methods for performing such synchronization are based on the Paxos or ZAB algorithms, which are difficult to implement correctly. However, standard implementations are available in systems such as ZooKeeper.\n\n\nExample of feature toggling with ZooKeeper\n\n\nAssume the service being deployed implements a portion of a single feature, \nFeature X\n. When a VM of the service is deployed, it registers itself as being interested in \nFeatureXActivationFlag\n. If the flag is false, then the feature is toggled off; if the flag is true, the feature is toggled on. If the state of the \nFeatureXActivationFlag\n changes, then the VM is informed of this and reacts accordingly.\n\n\nAn agent (which can human or automated) external to any of the services in the system being upgraded is responsible for setting \nFeatureXActivationFlag\n. The flag is maintained in ZooKeeper and thus kept consistent across the VMs involved. As long as all of the VMs are informed simultaneously of the toggling, then the feature is activated simultaneously and there is no version inconsistency that could lead to failures. The simultaneous information broadcast is performed by ZooKeeper. This particular use of ZooKeeper for feature toggling is often implemented in other tools. For example, Netflix\u2019s \nArchaius\n tool provides configuration management for distributed systems. The configuration being managed can be feature toggles or any other property.\n\n\nThe agent is aware of the various services implementing \nFeature X\n and does not activate the feature until all of these services have been upgraded. \n\n\nOne complication comes from deciding when the VMs have been \"sufficiently upgraded\". VMs may fail or become unavailable. Waiting for these VMs to be upgraded before activating the feature is not desirable. The use of a registry/ load balancer as described in \nChapter 4\n enables the activation agent to avoid these problems. Recall that each VM must renew its registration periodically to indicate that it is still active. The activation agent examines the relevant VMs that are registered to determine when all VMs of the relevant services have been upgraded to the appropriate versions.\n\n\nBackward and Forward Compatibility\n\n\n\n\nBackward compatibility\n means the new version of the service behaves as the old version. For requests that are known to the old version of a service, the new version provides the same behavior. In other words, the external interfaces provided by version B of a service are a superset of the external interfaces provided by version A of that service.\n\n\nForward compatibility\n means that a client deals gracefully with error responses indicating an incorrect method call. Suppose a client wishes to utilize a method that will be available in version B of a service but the method is not present in version A. Then if the service returns an error code indicating it does not recognize the method call, the client can infer that it has reached version A of the service.\n\n\n\n\nMaintaining backward compatibility can be done using the pattern depicted in the figure below:\n\n\n\n\nThe service being upgraded makes a distinction between internal and external interfaces:\n\n\n\n\nExternal interfaces\n include all of the existing interfaces from prior versions as well as, possibly, new ones added with this version.\n\n\nInternal interfaces\n can be restructured with every version.\n\n\nIn-between the external interfaces and the internal interfaces is a \ntranslation layer\n that maps the old interfaces to the new ones.\n\n\n\n\nAs far as a client is concerned, the old interfaces are still available for the new version. If a client wishes to use a new feature, then a new interface is available for that feature.\n\n\nOne consequence of using this pattern is that obsolete interfaces may be maintained beyond the point where any clients use them. Determining which clients use which interfaces can be done through monitoring and recording all service invocations. Once there are no usages for a sufficiently long time, the interface can be deprecated. The deprecating of an interface may result in additional maintenance work, so it should not be done lightly.\n\n\nForward and backward compatibility allows for independent upgrade for services under your control. Not all services will be under your control. In particular, third-party services, libraries, or legacy services may not be backward compatible. In this case, there are several techniques you can use, although none of them are foolproof:\n\n\n\n\nDiscovery\n.\n\n\nExploration\n.\n\n\nPortability layer\n. The following figure shows the concept of a portability layer. A portability layer provides a single interface that can be translated into the interfaces for a variety of similar systems. This technique has been used to port applications to different operating systems, to allow multiple different devices to look identical from the application perspective, or to allow for the substitution of different database systems.\n\n\n\n\n\n\nCompatibility with Data Kept in a Database\n\n\nBesides the compatibility of services, some services must also be able to read and write to a database in consistently. For example, that the data schema changes: In the old version of the schema, there is one field for customer address; in the new version, the address is broken into street, city, postal code, and country. Inconsistency, in this case, means that a service intends to write the address as a single field using the schema that has the address broken into portions.\n\n\nInconsistencies are triggered by a change in the database schema. A schema can be either explicit such as in relational database management systems (RDBMSs) or implicit such as in various NoSQL database management systems.\n\n\nThe most basic solution to such a schema change is \nnot to modify existing fields but only to add new fields or tables\n, which can be done without affecting existing code. The use of the new fields or tables can be integrated into the application incrementally. \nOne method for accomplishing this is to treat new fields or tables as new features in a release\n. That is, either the use of the new field or table is under the control of a feature toggle or the services are forward and backward compatible with respect to database fields and tables.\n\n\nIf a change to the schema is absolutely required you have two options:\n\n\n\n\nConvert the persistent data from the old schema to the new one.\n\n\nConvert data into the appropriate form during reads and writes. This could be done either by the service or by the database management system.\n\n\n\n\nThese options are not mutually exclusive. You might perform the conversion in the background and convert data on the fly while the conversion is ongoing.  Modern RDBMSs provide the ability to reorganize data from one schema to another online while satisfying requests, although at a storage and performance cost. Database systems typically do not provide this capability, and so, if you use them, you have to engineer a solution for your particular situation. [p111]\n\n\nPackaging\n\n\nThis section discusses consistency of the build process in terms of getting the latest versions into the services. Deciding that components package services and that each service is packaged as exactly one component (discussed in \nChapter 4\n), does not end your packaging decisions. You must decide on the binding time among components residing on the same VM and a strategy for placing services into VMs. Packaging components onto a VM image is called \nbaking\n and the options range from \nlightly baked\n to \nheavily baked\n (discussed in \nChapter 5\n). What we add to that discussion here is the number of processes loaded into each VM.\n\n\nA VM is an image that is running on top of a hypervisor that enables sharing a single bare metal processor, memory, and network among multiple tenants or VMs. The image of the VM is loaded onto the hypervisor from which it is scheduled.\n\n\nA VM image could include multiple independent processes, each a service. The question is: \nShould multiple services be placed in a single VM image?\n The following figure shows two options:\n\n\n\n\nIn the top option, a developer commits a service for deployment, which is embedded into a single VM image. For example, Netflix claims they package one service per VM.\n\n\nIn the bottom option, different developers commit different services into a single VM image. \nThe emergence of lightweight containers often assumes one service per container, but with the possibility to have multiple containers per VM.\n\n\n\n\n\n\nOne minor difference in these two options is the number of times that a VM image must be baked:\n\n\n\n\nIf there is one service per VM, then that VM image is created when a change in its service is committed.\n\n\nIf there are two services per VM, then the VM image must be rebaked whenever a change to either the first or second service is committed.\n\n\n\n\nA more important difference occurs when service 1 sends a message to service 2:\n\n\n\n\nIf the two are in the same VM, then the message does not need to leave the VM to be delivered.\n\n\nIf they are in different VMs, then more handling and network communication are involved.\n\n\n\n\nThis means the latency for messages will be higher when each service is packaged into a single VM.\n\n\nHowever, packaging multiple services into the same VM image opens up the possibility of deployment race conditions, because different development teams do not coordinate over their deployment schedules and they may be deploying their upgrades at (roughly) the same time.\n\n\nThe examples below assume the upgraded services are included in the deployed portion of the VM (heavily baked) and not loaded later by the deployed software.\n\n\n\n\nIn Figure 6.7 (below), development team 1 creates a new image with a new version (v\nm+1\n) of service 1 (S1) and an old version of service 2 (S2). Development team 2 creates a new image with an old version of service 1 and a new version (v\nn+1\n) of service 2. The provisioning processes of the two teams overlap, which causes a deployment race condition.\n\n\n\n\n\n\n\n\nIn Figure 6.8 (below), development team 1 builds their image after development team 2 has committed their changes. The result is similar in that the final version that is deployed does not have the latest version of both service 1 and service 2.\n\n\n\n\n\n\nThe tradeoff for including multiple services into the same VM is between reduced latency and the possibility of deployment race conditions.\n\n\nDeploying to Multiple Environments\n\n\nAs long as services are independent and communicate only through messages, deployment to multiple environments (e.g. VMware and Amazon EC2) is possible basically with the design we have presented. The registry/load balancer discussed in \nChapter 4\n needs to be able to direct messages to different environments.\n\n\nBusiness Continuity\n\n\nIntroduced in \nChapter 2\n, \nbusiness continuity\n is the ability for a business to maintain service when facing a disaster or serious outages. It is achieved by deploying to sites that are physically and logically separated from each other. This section differentiates between deploying to a public cloud and a private cloud, although the essential element, the management of state, is the same. Disaster recovery is discussed in \nChapter 10\n and case study in \nChapter 11\n.\n\n\nPublic Cloud\n\n\nPublic clouds are extremely reliable in the aggregate. They consist of hundreds of thousands of physical servers and provide extensive replication and failover services. Failures do occur, which can be to particular VMs of your system or to other cloud services.\n\n\n\n\nA failure to a VM is not a rare occurrence.\n\n\nCloud providers achieve economies of scale partially by purchasing commodity hardware. Any element of the hardware can fail: memory, disk, motherboard, network, or CPU.\n\n\nFailures may be total or partial. A partial failure in the underlying hardware can make your VM run slowly although it is still executing. In either case, you must architect your system to detect VM failures and respond to them. This is outside the scope of this chapter.\n\n\n\n\n\n\nA failure to the cloud infrastructure is a rare but not impossible occurrence.\n\n\nA quick search on \"public cloud outages\" can give you information about the latest high-profile outages that have occurred.\n\n\nOther outages are lower-profile but do still occur. You can survive many outages by choosing how you deploy your VMs.\n\n\n\n\n\n\n\n\nAmazon EC2 has multiple regions (nine as of this writing) scattered around the globe. Each region has multiple availability zones. Each availability zone is housed in a location that is physically distinct from other availability zones and that has its own power supply, physical security, and so forth:\n\n\n\n\nIf you deploy VMs of your system to different availability zones within the same region, you have some measure of protection against a cloud outage.\n\n\nIf you deploy VMs of your system to different regions, then you have much more protection against outages, since some of the services such as elastic load balancing are per-region.\n\n\n\n\nTwo considerations to keep in mind when you deploy to different availability zones or regions are state management and latency:\n\n\n\n\nState management\n. Making services stateless has several advantages, as discussed in \nChapter 4\n.\n\n\nIf a service is stateless then additional VMs can be created at any time to handle increased workload. Additional VMs can also be created in the event of a VM failure.\n\n\nThe disadvantages of stateless services are that state must be maintained somewhere in the system and latency may increase when the service needs to obtain or change this state.\n\n\n\n\n\n\nLatency\n. Sending messages from one availability zone to another adds a bit of latency; messages sent from one region to another adds more latency to your system.\n\n\n\n\nPrivate Cloud\n\n\n[p116]\n\n\nPartial Deployment\n\n\nUp to this point the discussion has been focused on all-or-nothing deployments.  Now we discuss two types of partial deployments: canary testing and A/B testing.\n\n\nCanary Testing\n\n\nA new version is deployed into production after having been tested in a staging environment, which is as close to a production environment as possible. There is still a possibility of errors existing in the new version. \nThese errors can be either functional or have a quality impact. Performing an additional step of testing in a real production environment is the purpose of canary testing.\n A canary test is conceptually similar to a beta test in the shrink-wrapped software world.\n\n\nOne question is to whom to expose the canary servers. This can be a random sample of users. An alternative is to decide the question based on the organization a user belongs to, for example, the employees of the developing organization, or particular customers. The question could also be answered based on geography, for example, such that all requests that are routed to a particular datacenter are served by canary versions.\n\n\nThe mechanism for performing the canary tests depends on whether features are activated with feature toggles or whether services are assumed to be forward or backward compatible. In either case, a new feature cannot be fully tested in production until all of the services involved in delivering the feature have been partially deployed.\n\n\nMessages can be routed to the canaries by making the registry/load balancer canary-aware and having it route messages from the designated testers to the canary versions. More and more messages can be routed until a desired level of performance has been exhibited.\n\n\n\n\nIf new features are under the control of feature toggles, then turning on the toggle for the features on the canary versions activates these features and enables the tests to proceed.\n\n\nIf the services use forward and backward compatibility, then the tests will be accomplished once all of the services involved in a new feature have been upgraded to the new version.\n\n\n\n\nIn either case, you should carefully monitor the canaries, and they should be rolled back in the event an error is detected.\n\n\nA/B Testing\n\n\nA/B testing is introduced in \nChapter 5\n. It is another form of testing that occurs in the production environment through partial deployment. The \"A\" and \"B\" refer to two different versions of a service that present either different user interfaces or different behavior. In this case, it is the behavior of the user when presented with these two different versions that is being tested.\n\n\nIf either A or B shows preferable behavior in terms of some business metric such as orders placed, then that version becomes the production version and the other version is retired.\n\n\nImplementing A/B testing is similar to implementing canaries. The registry/ load balancer must be made aware of A/B testing and ensure that a single customer is served by VMs with either the A behavior or the B behavior but not both. The choice of users that are presented with version B (or A) may be randomized, or it may be deliberate. If deliberate, factors such as geographic location, age group (for registered users), or customer level (e.g., \"gold\" frequent flyers), may be taken into account.\n\n\nRollback\n\n\nThe new version of a service is on probation for some period after deployment. It has gone through testing of a variety of forms but it still is not fully trusted.\n\n\nRolling back\n means reverting to a prior release. It is also possible to roll forward, to correct the error and generate a new release with the error fixed. Rolling forward is essentially just an instance of upgrading.\n\n\nBecause of the sensitivity of a rollback and the possibility of rolling forward, rollbacks are rarely triggered automatically. \nA human should be in the loop who decides whether the error is serious enough to justify discontinuing the current deployment.\n The human then must decide whether to roll back or roll forward.\n\n\nRollback for blue/green deployment\n\n\nIf you still have VMs with version A available, as in the blue/green deployment model before decommissioning all version A VMs, rolling back can be done by simply redirecting the traffic back to these. \nOne way of dealing with the persistent state problem is to keep version A VMs receiving a replicated copy of the requests version B has been receiving during the probation period.\n\n\nRollback for rolling upgrade deployment\n\n\nWith a rolling upgrade model or you cannot simply replace version B by version A as a whole, you have to replace a version B VM with a version A VM in more complicated ways. The new version B can be in one of four states during its lifetime:\n\n\n\n\nUninstalled\n: cannot be rolled back.\n\n\nPartially installed\n: have rollback possibilities (see below).\n\n\nFully installed but on probation\n: rollback possibilities (see below).\n\n\nCommitted into production\n: cannot be rolled back, although the old version could be treated as a new deployment and be redeployed.\n\n\nAs in \nChapter 5\n, if version B has been committed then removal of all of the feature toggles that have been activated within version B should be put on the development teams\u2019 list of activities to perform.\n\n\n\n\n\n\n\n\nThe strategy for rolling back (version B is partially installed or fully installed but on probation) depends on whether feature toggles are being used and have been activated. This pertains to both of the remaining two states:\n\n\n\n\nNot using feature toggles\n. Rolling back VMs in this case is a matter of disabling those VMs and reinstalling VMs running version A of the service.\n\n\nUsing feature toggles\n.\n\n\nIf the features have not been activated, then we have the prior version. Disable VMs running version B and reinstall version A.\n\n\nIf the feature toggles have been activated, then deactivate them. If this prevents further errors, then no further action is required. If it does not, then we have the situation as if feature toggles were not present.\n\n\n\n\n\n\n\n\nThe remaining case deals with persistent data and is the most complicated. \nSuppose all of the version B VMs have been installed and version B\u2019s features activated, but a rollback is necessary. Rolling back to the state where version B is installed but no features activated is a matter of toggling off the new features, which is a simple action.\n The complications come from consideration of persistent data.\n\n\nA concern when an error is detected is that incorrect values have been written into the database. Dealing with erroneous database values is a delicate operation with significant business implications.\n\n\n[p119-120]\n\n\nIdentifying and correcting incorrect values in the database is a delicate and complicated operation requiring the collection of much metadata.\n\n\nTools\n\n\nOne method for categorizing tools is to determine whether they directly affect the internals of the entity being deployed. As in \nChapter 5\n, if a VM image contains all the required software including the new version, you can replace a whole VM of the old version with a whole VM of the new version. This is called using a \nheavily baked\n deployment approach.\n\n\nAlternatively, you can use tools to change the internals of a VM, so as to deploy the new version by replacing the old version without terminating the VM. Even if you terminate the VM with the old version, you can start a new \nlightly baked\n VM but then access the machine from the inside to deploy the new version at a later stage of the deployment process.\n\n\n\n\nNetflix Asgard\n is an open source, web-based tool for managing cloud-based applications and infrastructure. Asgard is not interested in the contents of these VMs. It uses a VM image that contains the new version and creates VMs for these images. One of the features of Asgard is that it understands deployment processes such as rolling upgrade. It allows specification of the number of VMs to be upgraded in a single cycle.\n\n\nInfrastructure-as-a-Service (IaaS) vendors also provide specific tools for coordinated VM provisioning, which is used as a part of a deployment. For example, Amazon allows users to use \nCloudFormation\n scripts as a parameterized, declarative approach for deployment of VMs. CloudFormation scripts understand dependencies and rollback.\n\n\nChef\n and \nPuppet\n are two examples of tools that manage the items inside a virtual machine. They can replace a version of a piece of software inside a VM and ensure that configuration settings conform to a specification.\n\n\nOne emerging trend is the use of lightweight container tools, such as \nDocker\n, in deployment. A lightweight container is an OS-level virtualization technique for running multiple isolated OSs on a single host (VM or physical machine). They are like VMs, but they are smaller and start much faster.\n\n\nImage management and testing tools such as \nVagrant\n and \nTest Kitchen\n help control both VMs and items inside the VMs. A developer can spin up production-like environments for pre-commit testing and integration testing to reveal issues that would only surface in production.\n\n\n\n\nSummary\n\n\nStrategies for deploying multiple VMs of a service include blue/green deployment and rolling upgrade:\n\n\n\n\nA blue/green deployment does not introduce any logical problems but requires allocating twice the number of VMs required to provide a service.\n\n\nA rolling upgrade is more efficient in how it uses resources but introduces a number of logical consistency problems:\n\n\nMultiple different versions of a single service can be simultaneously active. These multiple versions may provide inconsistent versions of the service.\n\n\nA client may assume one version of a dependent service and actually be served by a different version.\n\n\nRace conditions can exist because of the choice of packing multiple and dependent services and multiple development teams performing concurrent deployment. Choosing the number of services to be packed into a single VM is often a tradeoff among resource utilization, performance, and complexity of deployment.\n\n\n\n\n\n\n\n\nSolutions to the problems of logical consistency involve using some combination of feature toggles, forward and backward compatibility, and version awareness.\n\n\nDeployments must occasionally be rolled back. Feature toggles support rolling back features, but the treatment of persistent data is especially sensitive when rolling back a deployment.\n\n\nDeployment also plays an important role for achieving business continuity. Deploying into distinct sites provides one measure of continuity. Having an architecture that includes replication allows for a shorter time to repair and to resume processing in the event of an unexpected outage.\n\n\nA variety of tools exist for managing deployment. The emergence of lightweight containers and image management tools is helping developers to deploy into small-scale production-like environments more easily for testing.", 
            "title": "Chapter 6. Deployment"
        }, 
        {
            "location": "/devops/ch7/", 
            "text": "Chapter 7. Monitoring\n\n\nIntroduction\n\n\nThis chapter focuses on software monitoring. Software monitoring comprises myriad types of monitoring and the considerations that come with them. Activities as varied as collecting metrics at various levels (resources/OS/middleware/application-level), graphing and analyzing metrics, logging, generating alerts concerning system health status, and measuring user interactions all are a portion of what is meant by monitoring.\n\n\nThe insights available from monitoring fall into five different categories:\n\n\n\n\nIdentifying failures and the associated faults both at runtime and during postmortems held after a failure has occurred.\n\n\nIdentifying performance problems of both individual systems and collections of interacting systems.\n\n\nCharacterizing workload for both short-term and long-term capacity planning and billing purposes.\n\n\nMeasuring user reactions to various types of interfaces or business offerings. A/B testing is disucssed in \nChapters 5\n and \nChapter 6\n.\n\n\nDetecting intruders who are attempting to break into the system.\n\n\n\n\nThe term \nmonitoring\n refers to the process of observing and recording system state changes and data flows:\n\n\n\n\nState changes\n can be expressed by direct measurement of the state or by logs recording updates that impact part of the state.\n\n\nData flows\n can be captured by logging requests and responses between both internal components and external systems.\n\n\n\n\nThe software supporting such a process is called a \nmonitoring system\n.\n\n\nMonitoring a workload include the tools and infrastructure associated with operations activities. All of the activities in an environment contribute to a datacenter\u2019s workload, and this includes both operations-centric and monitoring tools.\n\n\nDevOps\u2019 continuous delivery/ deployment practices and strong reliance on automation mean that changes to the system happen at a much higher frequency. Use of a microservice architecture also makes monitoring of data flows more challenging.\n\n\nSome examples of the new challenges are:\n\n\n\n\nMonitoring under continuous changes is difficult.\n\n\nTraditional monitoring relies heavily on anomaly detection. You know the profile of your system during normal operation. You set thresholds on metrics and monitor to detect abnormal behavior. If your system changes, you may have to readjust them. This approach becomes less effective if your system is constantly changing due to continuous deployment practices and cloud elasticity.\n\n\nSetting thresholds based on normal operation will trigger multiple false alarms during a deployment. Disabling alarms during deployments will, potentially, miss critical errors when a system is already in a fairly unstable state. Multiple deployments can simultaneously occur as we discussed in Chapter 6, and these deployments further complicate the setting of thresholds.\n\n\n\n\n\n\nThe cloud environment introduces different levels from application programming interface (API) calls to VM resource usage.\n Choosing between a top-down approach and a bottom-up approach for different scenarios and balancing the tradeoffs is not easy.\n\n\nMonitoring requires attention to more moving parts\n (when adopting the microservice architecture as introduced in \nChapter 4\n).\n\n\nIt also requires logging more inter-service communication to ensure a user request traversing through a dozen services still meets your service level agreements. If anything goes wrong, you need to determine the cause through analysis of large volumes of (distributed) data.\n\n\n\n\n\n\nManaging logs becomes a challenge in large-scale distributed systems.\n\n\nWhen you have hundreds or thousands of nodes, collecting all logs centrally becomes difficult or prohibitively expensive. Performing analysis on huge collections of logs is challenging as well, because of the sheer volume of logs, noise, and inconsistencies in logs from multiple independent sources.\n\n\n\n\n\n\n\n\nMonitoring solutions must be tested and validated just as other portions of the infrastructure. Testing a monitoring solution in your various environments is one portion of the testing, but the scale of your non-production environments may not approach the scale of your production\u2014which implies that your monitoring environments may be only partially tested prior to being placed into production\n\n\nWhat to Monitor\n\n\nThe following table lists the insights you might gain from the monitoring data and the portions of the stack where such data can be collected: [p129]\n\n\n\n\n\n\n\n\nGoal of Monitoring\n\n\nSource of Data\n\n\n\n\n\n\n\n\n\n\nFailure detection\n\n\nApplication and infrastructure\n\n\n\n\n\n\nPerformance degradation detection\n\n\nApplication and infrastructure\n\n\n\n\n\n\nCapacity planning\n\n\nApplication and infrastructure\n\n\n\n\n\n\nUser reaction to business offerings\n\n\nApplication\n\n\n\n\n\n\nIntruder detection\n\n\nApplication and infrastructure\n\n\n\n\n\n\n\n\nThe fundamental items to be monitored consist of inputs, resources, and outcomes:\n\n\n\n\nThe resources can be hard resources such as CPU, memory, disk, and network (even if virtualized).\n\n\nThey can also be soft resources such as queues, thread pools, or configuration specifications.\n\n\nThe outcomes include items such as transactions and business-oriented activities.\n\n\n\n\nFailure Detection\n\n\nAny element of the physical infrastructure can fail. Total failures are relatively easy to detect: No data is flowing where data used to flow. It is the partial failures that are difficult to detect, for instance: a cable is not firmly seated and degrades performance; before a machine totally fails because of overheating it experiences intermittent failure; and so forth.\n\n\nDetecting failure of the physical infrastructure is the datacenter provider\u2019s problem. Instrumenting the operating system or its virtual equivalent will provide the data for the datacenter.\n\n\nSoftware can also fail, either totally or partially. Total failure is relatively easy to detect. Partial software failures have myriad causes (similar to partial hardware failures):\n\n\n\n\nThe underlying hardware may have a partial failure;\n\n\nA downstream service may have failed;\n\n\nThe software (or its supporting software) may have been misconfigured.\n\n\n\n\nDetecting software failures can be done in one of three fashions:\n\n\n\n\nThe monitoring software performs \nhealth checks\n on the system from an external point.\n\n\nA \nspecial agent inside the system\n performs the monitoring.\n\n\nThe \nsystem itself\n detects problems and reports them.\n\n\n\n\nPartial failures may also manifest as performance problems (discussed in the following subsection).\n\n\nPerformance Degradation Detection\n\n\nDetecting performance degradations is the most common use of monitoring data. Degraded performance can be observed by comparing current performance to historical data, or by complaints from clients or end users. Ideally, the monitoring system catches performance degradation before users are impacted at a notable strength.\n\n\nPerformance measures include \nlatency\n, \nthroughput\n, and \nutilization\n.\n\n\nLatency\n\n\nLatency is the time from the initiation of an activity to its completion, which can be measured at various levels of granularity:\n\n\n\n\nAt a coarse grain, latency can refer to the period from a user request to the satisfaction of that request.\n\n\nAt a fine grain, latency can refer to the period from placing a message on a network to the receipt of that message.\n\n\n\n\nLatency can also be measured at either the infrastructure or the application level. Measuring latency across different physical computers is more problematic because of the difficulty of synchronizing clocks.\n\n\nLatency is cumulative in the sense that the latency of responding to a user request is the sum of the latency of all of the activities that occur until the request is satisfied, adjusted for parallelism. It is useful when diagnosing the cause of a latency problem to know the latency of the various subactivities performed in the satisfaction of the original request. [p131]\n\n\nThroughput\n\n\nThroughput is the number of operations of a particular type in a unit time. Although throughput could refer to infrastructure activities (e.g., the number of disk reads per minute), it is more commonly used at the application level. For example, the number of transactions per second is a common reporting measure.\n\n\nThroughput provides a system-wide measure involving all of the users, whereas latency has a single-user or client focus.\n High throughput may or may not be related to low latency. The relation will depend on the number of users and their pattern of use.\n\n\nA reduction in throughput is not, by itself, a problem. The reduction in throughput may be caused by a reduction in the number of users. Problems are indicated through the coupling of throughput and user numbers.\n\n\nUtilization\n\n\nUtilization is the relative amount of use of a resource and is typically measured by inserting probes on the resources of interest. For example, the CPU utilization may be 80%. High utilization can be used as either of the following:\n\n\n\n\nAn early warning indicator of problems with latency or throughput,\n\n\nA diagnostic tool used to find the cause of problems with latency or throughput.\n\n\n\n\nThe resources can either be at the infrastructure or application level:\n\n\n\n\nHard resources such as CPU, memory, disk, or network are best measured by the infrastructure.\n\n\nSoft resources such as queues or thread pools can be measured either by the application or the infrastructure depending on where the resource lives.\n\n\n\n\nMaking sense of utilization frequently requires attributing usage to activities or applications. For example, \napp1\n is using 20% of the CPU, disk compression is using 30%, and so on. Thus, connecting the measurements with applications or activities is an important portion of data collection.\n\n\nCapacity Planning\n\n\nThere two types of capacity planning:\n\n\n\n\nLong-term capacity planning\n involves humans and has a time frame on the order of days,\n\n\nShort-term capacity planning\n is performed automatically and has a time frame on the order of minutes.\n\n\n\n\nLong-Term Capacity Planning\n\n\nLong-term capacity planning is intended to match hardware needs (whether real or virtualized) with workload requirements.\n\n\n\n\nIn a physical datacenter, it involves ordering hardware.\n\n\nIn a virtualized public datacenter, it involves deciding on the number and characteristics of the virtual resources that are to be allocated.\n\n\n\n\nIn both cases, the input to the capacity planning process is a characterization of the current workload gathered from monitoring data and a projection of the future workload based on business considerations and the current workload. \nBased on the future workload, the desired throughput and latency for the future workload, and the costs of various provisioning options, the organization will decide on one option and provide the budget for it.\n\n\nShort-Term Capacity Planning\n\n\nIn the cloud, short-term capacity planning means creating a new virtual machine (VM) for an application or deleting an existing VM.\n\n\n\n\nA common method of making and executing these decisions (creating and deleting VMs) is based on monitoring information collected by the infrastructure.\n\n\nChapter 4\n discusses various options for controlling the allocation of VM instances based on the current load.\n\n\nMonitoring the usage of the current VM instances was an important portion of each option.\n\n\n\n\n\n\nMonitoring data is also used for billing in public clouds. In order to charge for use, the use must be determined, and this is accomplished through monitoring by the cloud provider.\n\n\n\n\nUser Interaction\n\n\nUser satisfaction is an important element of a business. It depends on four elements that can be monitored:\n\n\n\n\nThe latency of a user request.\n Users expect decent response times. Depending on the application, seemingly trivial variations in response can have a large impact.\n\n\nThe reliability of the system with which the user is interacting.\n Failure and failure detection are discussed earlier.\n\n\nThe effect of a particular business offering or user interface modification.\n A/B testing is discussed in \nChapters 5\n and \nChapter 6\n. The measurements collected from A/B testing must be meaningful for the goal of the test, and the data must be associated with variant A or B of the system.\n\n\nThe organization\u2019s particular set of metrics.\n These metrics should be important indicators either of the following:\n\n\nUser satisfaction,\n\n\nThe effectiveness of the organization\u2019s computer-based services.\n\n\n\n\n\n\n\n\nThere are generally two types of user interaction monitoring.\n\n\n\n\nReal user monitoring\n (RUM). RUM essentially records all user interactions with an application.\n\n\nRUM data is used to assess the real service level a user experiences and whether server side changes are being propagated to users correctly.\n\n\nRUM is usually passive in terms of not affecting the application payload without exerting load or changing the server-side application.\n\n\n\n\n\n\nSynthetic monitoring\n. It is similar to developers performing stress testing on an application.\n\n\nExpected user behaviors are scripted either using some emulation system or using actual client software (such as a browser). However, the goal is often not to stress test with heavy loads, but to monitor the user experience.\n\n\nSynthetic monitoring allows you to monitor user experience in a systematic and repeatable fashion, not dependent on how users are using the system right now.\n\n\nSynthetic monitoring may be a portion of the automated user acceptance tests discussed in \nChapter 5\n.\n\n\n\n\n\n\n\n\nIntrusion Detection\n\n\nIntruders can break into a system by subverting an application (for example, through incorrect authorization or a man-in-the-middle attack). Applications can monitor users and their activities to determine whether the activities are consistent with the users\u2019 role in the organization or their past behavior.\n\n\nFor instance, if user John has a mobile phone using the application, and the phone is currently in Australia, any log-in attempts from, say, Nigeria should be seen as suspicious.\n\n\nIntrusion detector\n *\n\n\nAn \nintrusion detector\n is a software application that monitors network traffic by looking for abnormalities. These abnormalities can be caused by:\n\n\n\n\nAttempts to compromise a system by unauthorized users,\n\n\nViolations of an organization\u2019s security policies.\n\n\n\n\nIntrusion detectors use a variety of different techniques to identify attacks. They frequently use historical data from an organization\u2019s network to understand what is normal. They also use libraries that contain the network traffic patterns observed during various attacks. Current traffic on a network is compared to the expected (from an organization\u2019s history) and the abnormal (from the attack history) to decide whether an attack is currently under way.\n\n\nIntrusion detectors can also monitor traffic to determine whether an organization\u2019s security policies are being violated without malicious intent.\n\n\nIntrusion detectors generate alerts and alarms as discussed in \nSection 7.5\n. Problems with false positives and false negatives exist with intrusion detectors as they do with all monitoring systems.\n\n\nHow to Monitor\n\n\nMonitoring systems interact with the elements being monitored, as shown in the figure below.\n\n\n\n\nThe system to be monitored can be as broad as a collection of independent applications or services, or as narrow as a single application:\n\n\n\n\nAgentless monitoring\n. If the system is actively contributing to the data being monitored (the arrow labeled \"agentless\") then the monitoring is intrusive and affects the system design.\n\n\nAgent-based monitoring\n. If the system is not actively contributing to the data being monitored (the arrow labeled \"agent-based\") then the monitoring is nonintrusive and does not affect the system design.\n\n\nHealth checks\n. A third source of data is indicted by the arrow labeled \"health checks\". External systems can also monitor system or application-level states through health checks, performance-related requests, or transaction monitoring\n\n\n\n\nThe data collected either through agents or through agentless means is eventually sent to a central repository (\"Monitoring data storage\" in \nFigure 7.1\n). The central repository is typically distributed (logically but not physically central). Each step from the initial collection to the central repository can do filtering and aggregation.\n\n\nThe considerations in determining the amount of filtering and aggregation are:\n\n\n\n\nThe volume of data being generated,\n\n\nThe potential failure of local nodes,\n\n\nThe granularity of the necessary communication.\n\n\n\n\nRetrieving the data from local nodes is important because the local node may fail and the data become unavailable. Sending all of the data directly to a central repository may introduce congestion to the network. Thus, selecting the intermediate steps from the local nodes to the central repository and the filtering and aggregation done at each step are important architectural decisions when setting up a monitoring framework.\n\n\nOnce monitoring data is collected, you can do many things:\n\n\n\n\nAlarms can be configured to trigger alerts that notify operators or other systems about major state changes.\n\n\nGraphing and dashboards can be used to visualize system state changes for human operators.\n\n\nA monitoring system also allows operators to drill down into detailed monitoring data and logs, which is important for error diagnosis, root cause analysis, and deciding on the best reaction to a problem.\n\n\n\n\nThe traditional view of the monitoring system (as discussed so far) is increasingly being challenged by new interactions between the monitoring system and other systems, which are shown outside of the dotted areas in \nFigure 7.1\n.\n\n\nYou can perform stream processing and (big) data analytics on monitoring data streams and historical data. Not only can you gain insights into system characteristics using system-level monitoring data, you may also gain insights into user behaviors and intentions using application- and user-level monitoring data.\n\n\nBecause of these growing different uses of monitoring data, many companies are starting to use a unified log and metrics-centric publish-subscribe architecture for both the monitoring system and the overall application system. More and more types of data, including nontraditional log and metrics data, are being put into a unified storage, where various other systems (whether monitoring-related or not) can subscribe to the data of interest. Several implications of the unified view are:\n\n\n\n\nIt significantly reduces the coupling of any two systems. \nSystems interact with the unified log in a publish-subscribe fashion that makes publishers ignorant of the specific identity of the subscriber and vice versa.\n\n\nIt simplifies the integration of multiple sources of data. \nUsing a central log store allows data to be correlated based on attributes such as time stamps rather than their source.\n [p136]\n\n\n\n\nThe line between the monitoring system and the system to be monitored is getting blurred when application and user monitoring data are treated the same as system-level monitoring data: data from anywhere and at any level could contribute to insights about both systems and users.\n\n\nThe following sections discuss the method of retrieving monitoring data, monitoring operations, and data collection and storage:\n\n\nAgent-Based and Agentless Monitoring\n\n\nIn some situations, the system to be monitored already has internal monitoring facilities that can be accessed through a defined protocol. For example:\n\n\n\n\nThe \nSimple Network Management Protocol\n (SNMP) is a common mechanism for gathering metrics from servers and network equipment. It is especially useful on network equipment because that equipment often comes as a closed system and you cannot install monitoring agents.\n\n\nYou can use protocols like Secure Shell (SSH) to remotely access a system and retrieve available data.\n\n\nApplication Response Measurement\n (ARM) is an industry standard that provides ways for an application to trigger actions such as requesting an external ARMsupported system to start or stop tracking a transaction and correlating times spent in different systems for a single transaction.\n\n\n\n\nAgentless monitoring is particularly useful when you cannot install agents, and it can simplify the deployment of your monitoring system.\n\n\nThe agent-based and agentless approaches both have their strengths and weaknesses:\n\n\n\n\nAgentless\n. \nThe \nagentless\n approach is better in terms of deployment and maintenance effort.\n However, it is less secure if the collection repository is outside of your network because more ports need to be opened and firewall rules relaxed to allow different layers of a system to communicate its data to the external world.\n\n\nAgent-based\n. In contrast, an \nagent\n on a host can communicate with the OS and applications locally and send all collected information over a single channel. \nThis also allows an agent-based approach to optimize network traffic and processing overhead.\n\n\nExternal\n. In addition to collecting monitoring data from inside a system, you can collect information from an external viewpoint. You can set up \nhealth checks\n to periodically check a system or conduct performance monitoring from an external user\u2019s point of view\n\n\n\n\nQuestions to be considered when designing a system include:\n\n\n\n\nWhere does this information come from?\n\n\nHow does this information fit into the application and monitoring architecture?\n\n\nWhat are the quality implications?\n\n\n\n\nMonitoring Operation Activities\n\n\nSome operations tools (such as Chef) monitor resources such as configuration settings to determine whether they conform to prespecified settings. We also mentioned monitoring resource specification files to identify changes. Both of these types of monitoring are best done by agents that periodically sample the actual values and the files that specify those values.\n\n\nTreating infrastructure-as-code implies that infrastructure should contribute monitoring information in the same fashion as other applications, which can be through any of the means discussed: agents, agentless, or external.\n\n\nChapter 14\n discusses how to perform fine-grained monitoring of the behavior of operations tools and scripts. This can include assertions over monitoring data. \nFor instance, during a rolling upgrade a number of VMs are taken out of service to be replaced with VMs running a newer version of the application. Then you can expect the average CPU utilization of the remaining machines to increase by a certain factor.\n\n\nCollection and Storage\n\n\nThe core of monitoring is recoding and analyzing time series data (a sequence of time-stamped data points):\n\n\n\n\nThese data points are acquired at successive intervals in time and represent certain aspects of states and state changes.\n\n\nThe system being monitored will generate time-stamped event notifications at various levels of severity. These notifications are typically output as logs.\n\n\n\n\nThe monitoring system can conduct direct measurement or collect existing data, statistics, or logs and then turn them into metrics (with time and space). The data is then transferred to a repository. The incoming data streams need to be processed into a time series and stored in a time series database.\n\n\nThree key challenges are: [p138]\n\n\n\n\nCollating related items by time.\n Time stamps in a distributed system are not going to be consistent.\n\n\nDifferent nodes in a single cluster may differ in their clocks by several microseconds.\n\n\nDifferent nodes across multiple clusters may differ by much more.\n\n\n\n\n\n\nCollating related items by context.\n\n\nThe volume of monitoring data.\n You may need a retention policy to cope with the volume of data collected.\n\n\n\n\nThe \nRound-Robin Database\n (RRD) is a popular time series database, which is designed for storing and displaying time series data with good retention policy configuration capabilities. Big data storage and processing solutions are increasingly used for monitoring data. You can treat your monitoring data as data streams feeding into streaming systems for real-time processing, combined with (big) historical data. You can load all your data into big data storage systems such as Hadoop Distributed File System (HDFS) or archive it in relatively inexpensive online storage systems such as \nAmazon Glacier\n.\n\n\nWhen to Change the Monitoring Configuration\n\n\nMonitoring is either time-based or event-based. Timing frequency and generation of events should all be configurable and changed in response to events occurring in the datacenter.\n\n\nSome examples of events that could change the monitoring configuration are:\n\n\n\n\nAn alert.\n One consequence of an alert could be that the frequency of sampling is increased.  The frequency could be decreased if the alert does not turn into an alarm.\n\n\nDeployment.\n Any of the deployment scenarios can trigger changes to monitoring:\n\n\nCanary deployment. The new versions under test should be monitored more closely\n\n\nRolling upgrade. Closer monitoring will help detect the occurrence of a race condition more quickly.\n\n\nFeature activation or deactivation. Feature changes should trigger changes in the monitoring configuration.\n\n\n\n\n\n\nChanges to any infrastructure software including DevOps tools.\n\n\nChanges to any configuration parameters.\n One of the major sources of errors in modern distributed systems is incorrect parameters.\n\n\n\n\nInterpreting Monitoring Data\n\n\nAssume that the monitoring data (both time-based and event-based) has been collected in a central repository. This data is being added and examined continually, by both other systems and humans.\n\n\nLogs\n\n\nA log is a time series of events. Records are typically appended to the end of the log. Logs usually record the actions performed that may result in a state change of the system.\n\n\n[p140]\n\n\nLogs are used:\n\n\n\n\nDuring operations to detect and diagnose problems.\n\n\nDuring debugging to detect errors.\n\n\nDuring post-problem forensics to understand the sequence that led to a particular problem.\n\n\n\n\nSome general rules about writing logs are:\n\n\n\n\nLogs should have a consistent format.\n\n\nLogs should include an explanation for why this particular log message was produced.\n\n\nLog entries should include context information. Besides date and time, it also includes information to support tracking the log entry such as:\n\n\nSource of the log entry within the code\n\n\nProcess ID for the process executing when the log entry was produced\n\n\nRequest ID for the request that caused that process to execute this log producer\n\n\nVM ID for the VM that produced this message\n\n\n\n\n\n\nLogs should provide screening information. Log messages are collected in a repository that is accessed through queries. Severity levels are an example of screening information, alert levels are another.\n\n\n\n\nGraphing and Display\n\n\nOnce you have all relevant data, it is useful to visualize it:\n\n\n\n\nSome monitoring systems have strong visualization capabilities embedded.\n\n\nThere are also specialized systems just for visualization and querying, such as \nGraphite\n, which support real-time graphing of large amounts of data.\n\n\n\n\nYou can set up a dashboard showing important real-time aspects of your system and its components at an aggregated level. You can also dive into the details interactively or navigate through history when you detect an issue. An experienced operator will use visual patterns of graphs to discern problems.\n\n\n[p141]\n\n\nAlarms and Alerts\n\n\nMonitoring systems inform the operator of significant events. This information can be in the form of either an alarm or an alert:\n\n\n\n\nAlerts\n are raised for purposes of informing and may be in advance of an alarm (e.g., the datacenter temperature is rising);\n\n\nAlarms\n require action by the operator or another system (e.g., the datacenter is on fire).\n\n\n\n\nAlarms and alerts can be triggered by any of the following:\n\n\n\n\nEvents (e.g., a particular physical machine is not responding),\n\n\nValues crossing a threshold (e.g., the response time for a particular disk is greater than an acceptable value),\n\n\nSophisticated combinations of values and trends.\n\n\n\n\n[p141]\n\n\nThe typical issues are:\n\n\n\n\nHow do you configure your monitoring system to reduce \nfalse positives\n (alarms without the necessity for action) and \nfalse negatives\n (the necessity for action without an alarm being raised)?\n\n\nHow do you configure your monitoring system so that the alerts provide necessary information to diagnose an alarm?\n\n\n\n\nA problem for operators is receiving false positive alarms or a flood of alerts from different channels about the same event. Under such conditions, operators will quickly get \"alert fatigue\" and start ignoring alerts or simply turn some of them off. On the other hand, if you try to reduce false positives, you may risk missing important events, which increases false negatives.\n\n\nIf your alarms are very specific in their triggering conditions, you may be informed about some subtle errors early in their occurrence. However, you may risk rendering your alarms less effective when the system undergoes changes over time, or when the system momentarily exhibits interference of legitimate but previously unknown operations. [p142]\n\n\nSome general rules to improve the usefulness of alerts and alarms are:\n\n\n\n\nIntroduce context to your alarms.\n\n\nThis could be as simple as disabling certain alerts during specific times or actions; for example, when replacing a physical computer it does not make sense to raise alarms about the computer\u2019s health.\n\n\nOther more complex contexts could be related to external events or interfering operations.\n\n\n\n\n\n\nAlarms can not only go off if something happens, they can also be set to go off if an expected event did not happen\n. This helps with drills and testing of your alarms since you can set an alarm to go off when an event that you know is not going to happen does not, in fact, happen.\n\n\nAggregate different alerts that are likely referring to the same events.\n\n\nSet clear severity levels and urgency levels so people or systems receiving the alerts can act accordingly.\n\n\n\n\nDiagnosis and Reaction\n\n\nOperators often use monitoring systems to diagnose the causes and observe the progress of mitigation and recovery. However, monitoring systems are not designed for interactive or automated diagnosis. Thus, operators, in ad hoc ways, will try to correlate events, dive into details and execute queries, and examine logs. Concurrently, they manually trigger more diagnostic tests and recovery actions (such as restarting processes or isolating problematic components) and observe their effects from the monitoring system.\n\n\nThe essence of the skill of a reliability engineer is the ability to diagnose a problem in the presence of uncertainty. Once the problem has been diagnosed, frequently the reaction is clear although, at times, possible reactions have different business consequences. [p142-143]\n\n\nMonitoring DevOps Processes\n\n\nDevOps processes should be monitored so that they can be improved and problems can be detected.\n\n\nFive things that are important to monitor:\n\n\n\n\nA business metric\n\n\nCycle time\n\n\nMean time to detect errors\n\n\nMean time to report errors\n\n\nAmount of scrap (rework)\n\n\n\n\nChallenges\n\n\nChallenge 1: Monitoring Under Continuous Changes\n\n\nChallenge 2: Bottom-Up vs. Top-Down and Monitoring in the Cloud\n\n\nChallenge 3: Monitoring a Microservice Architecture\n\n\nChallenge 4: Dealing with Large Volumes of Distributed (Log) Data\n\n\nTools", 
            "title": "Chapter 7. Monitoring"
        }, 
        {
            "location": "/devops/ch8/", 
            "text": "Chapter 8. Security and Security Audits\n\n\nWhat Is Security?\n\n\nSecurity is easily remembered by the acronym CIA, which stands for \nconfidentiality\n, \nintegrity\n, and \navailability\n:\n\n\n\n\nConfidentiality\n means that no unauthorized people are able to access information;\n\n\nIntegrity\n means that no unauthorized people are able to modify information;\n\n\nAvailability\n means that authorized people are able to access information.\n\n\n\n\nThe case study in \nChapter 12\n discusses an approach that advocates integrating the security team into the adoption process. Other DevOps activities that are candidates for the discussion of security are:\n\n\n\n\nSecurity audits.\n When a security audit is imminent, coordination between Dev and Ops becomes quite important.\n\n\nSecuring the deployment pipeline.\n The deployment pipeline itself is an attractive target for malicious attackers.\n\n\nMicroservice architectures.\n The adoption of a microservice architecture introduces new security challenges.\n\n\n\n\n[p155]\n\n\nOne of the catchphrases in DevOps is \"infrastructure-as-code\", which means treating scripts and DevOps process specifications as code, and applying the same quality control practices as you do with code. Security policies, governance rules, and configurations can be naturally embedded in the infrastructure code and automation for easier auditing.\n\n\nThreats\n\n\nThe point of view of an attacker provides one perspective for you to take when designing your system or subsystem. Microsoft has introduced the acronym \nSTRIDE\n for a threat model.\n\n\n\n\nSpoofing identity\n. An example of identity spoofing is illegally accessing and then using another user\u2019s authentication information, such as username and password.\n\n\nTampering with data\n. Data tampering involves the malicious modification of data.\n\n\nRepudiation\n. Repudiation threats are associated with users who deny performing an action without other parties having a way to prove otherwise.\n\n\nInformation disclosure\n. Information disclosure threats involve the exposure of information to individuals who are not supposed to have access to it.\n\n\nDenial of service\n. Denial of service (DoS) attacks target the service availability to valid users, for example, by making a web server temporarily unavailable or unusable.\n\n\nElevation of privilege\n. In this type of threat, an unprivileged user gains privileged access and thereby has sufficient access to compromise or destroy the entire system.\n\n\n\n\nResources to Be Protected\n\n\nSecurity Roles and Activities\n\n\nIdentity Management\n\n\nAccess Control\n\n\nDetection, Auditing, and Denial of Service\n\n\nDevelopment\n\n\nAuditors\n\n\nApplication Design Considerations\n\n\nDeployment Pipeline Design Considerations", 
            "title": "Chapter 8. Security and Security Audits"
        }, 
        {
            "location": "/devops/ch9/", 
            "text": "Chapter 9. Other Ilities\n\n\nIntroduction\n\n\n[p181]\n\n\nThis chapter uses the word DevOps pipeline to represent all aspects of DevOps.\n\n\nIn software architecture, the word \"ility\" is used to describe quality concerns other than those that focus on the basic functionalities and their correctness. In terms of DevOps, ilities correspond to questions such as:\n\n\n\n\nHow well are these functionalities in your pipeline performing?\n\n\nCan you precisely repeat your DevOps operations when needed?\n\n\nHow much time has passed between a business concept and its final release?\n\n\nHow can different tools in your pipeline interoperate?\n\n\n\n\nPrevious chapters discuss some major concerns such as monitoring and security. This chapter covers additional concerns. The following table is a list of the ilities and their primary quality concerns:\n\n\n\n\n\n\n\n\nIlities\n\n\nQuality Concerns\n\n\n\n\n\n\n\n\n\n\nRepeatability\n\n\nThe degree to which repeating the same operation is possible\n\n\n\n\n\n\nPerformance\n\n\nThe time and resources required to execute a DevOps operation\n\n\n\n\n\n\nReliability\n\n\nThe degree to which the DevOps pipeline and individual pieces of software within it maintain their services for defined periods of time\n\n\n\n\n\n\nRecoverability\n\n\nThe degree to which a failed DevOps operation can be brought back to a desired state with minimal impacts to the application being operated on\n\n\n\n\n\n\nInteroperability\n\n\nThe degree to which different DevOps tools can usefully exchange information via interfaces in a particular context\n\n\n\n\n\n\nTestability\n\n\nThe ease with which the DevOps operation software can be made to demonstrate its faults through testing\n\n\n\n\n\n\nModifiability\n\n\nThe amount of effort required to change the DevOps software, processes, or the operation environment of an application\n\n\n\n\n\n\n\n\nWe focus on the ilities of the DevOps pipeline itself rather than the application the pipeline produces and operates on. There are certainly strong connections between the pipeline and the application. For example, the performance and recoverability of an upgrade operation may have significant impacts on the performance and recoverability of the application being upgraded\u2014but we do not explore these connections here. We consider the ility issues of the DevOps pipeline from two different perspectives: product and process.", 
            "title": "Chapter 9. Other Ilities"
        }, 
        {
            "location": "/devops/ch10/", 
            "text": "Chapter 10. Business Considerations", 
            "title": "Chapter 10. Business Considerations"
        }, 
        {
            "location": "/devops/ch11/", 
            "text": "Chapter 11. Supporting Multiple Datacenters\n\n\nIntroduction\n\n\nCurrent State\n\n\nBusiness Logic and Web Tiers\n\n\nDatabase Tier\n\n\nOther Infrastructure Tools\n\n\nDatacenter Switch\n\n\nTesting", 
            "title": "Chapter 11. Supporting Multiple Datacenters"
        }, 
        {
            "location": "/devops/ch12/", 
            "text": "", 
            "title": "Chapter 12. Implementing a Continuous Deploy"
        }, 
        {
            "location": "/devops/ch13/", 
            "text": "", 
            "title": "Chapter 13. Migrating to Microservices"
        }, 
        {
            "location": "/devops/ch14/", 
            "text": "", 
            "title": "Chapter 14. Operations as a Process"
        }, 
        {
            "location": "/devops/ch15/", 
            "text": "", 
            "title": "Chapter 15. The Future of DevOps"
        }, 
        {
            "location": "/spec/", 
            "text": "SPEC\n\n\n\n\nChapter 1. Introduction\n\n\nChapter 2. Methodology\n\n\nChapter 3. Operating Systems", 
            "title": "Contents"
        }, 
        {
            "location": "/spec/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nThis chapter introduces systems performance, describing roles, activities, perspectives, and challenges, along with latency, an essential performance metric, and some newer developments in computing: \ndynamic tracing\n and cloud computing.\n\n\nSystems Performance\n\n\nSystems performance is the study of the entire system, including all physical components and the full software stack. Anything in the data path (software or hardware) can affect performance. For distributed systems, this means multiple servers and applications. A diagram of an environment showing the data path help you understand the relationships between components and help ensure that you don\u2019t overlook whole areas.\n\n\nThe following figure shows a generic system software stack on a single server.  The term \nentire stack\n sometimes refers only the application environment (including databases, applications, and web servers). In terms of systems performance, we use \nentire stack\n to mean everything, including system libraries and the kernel.\n\n\n\n\nRoles\n\n\n[p2]\n\n\nUsually, performance is a part-time activity, and there may be a tendency to explore performance only within the role\u2019s area of responsibility (the network team checks the network, the database team checks the database, etc.). However, some performance issues requires a cooperative effort to find the root cause.\n\n\nPerformance engineers\n work with multiple teams and perform a holistic study of the environment, which is vital in resolving complex performance issues. They can also identify opportunities to develop better tooling and metrics for system-wide analysis and capacity planning across the environment.\n\n\nThere are also specialty application-specific occupations in the field of performance, for example, for Java performance and MySQL performance. These often begin with a limited check of system performance before moving to applicationspecific tools.\n\n\nActivities\n\n\nThe field of performance includes the following activities, listed in an ideal order of execution:\n\n\n\n\nSetting performance objectives and performance modeling\n\n\nPerformance characterization of prototype software or hardware\n\n\nPerformance analysis of development code, pre-integration\n\n\nPerforming non-regression testing of software builds, pre- or post-release\n\n\nBenchmarking/\nbenchmarketing\n for software releases\n\n\nProof-of-concept\n testing in the target environment\n\n\nConfiguration optimization for production deployment\n\n\nMonitoring of running production software\n\n\nPerformance analysis of issues\n\n\n\n\nPerspectives", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/spec/ch2/", 
            "text": "Chapter 2. Methodology\n\n\nPerformance issues can arise from software, hardware, and any component along the data path. Methodologies help us approach complex systems by showing where to start and what steps to take to locate and analyze performance issues. [p15]\n\n\nTerminology\n\n\nThe following are key terms for systems performance. Later chapters provide additional terms and describe some of these in different contexts.\n\n\n\n\nIOPS\n: Input/output operations per second is a measure of the rate of data transfer operations.\n\n\nFor disk I/O, IOPS refers to reads and writes per second.\n\n\n\n\n\n\nThroughput\n: the rate of work performed. Especially in communications, the term is used to refer to the \ndata rate\n (bytes per second or bits per second).\n\n\nIn some contexts (e.g., databases), throughput can refer to the operation rate (operations per second or transactions per second).\n\n\n\n\n\n\nResponse time\n: the time for an operation to complete. This includes any time spent waiting and time spent being serviced (service time), including the time to transfer the result.\n\n\nLatency\n: Latency is a measure of time an operation spends waiting to be serviced.\n\n\nIn some contexts, it can refer to the entire time for an operation, equivalent to response time (\nSection 2.3\n).\n\n\n\n\n\n\nUtilization\n:\n\n\nFor resources that service requests, utilization is a measure of how busy a resource is, based on how much time in a given interval it was actively performing work.\n\n\nFor resources that provide storage, utilization may refer to the capacity that is consumed (e.g., memory utilization).\n\n\n\n\n\n\nSaturation\n: the degree to which a resource has queued work it cannot service.\n\n\nBottleneck\n: In system performance, a bottleneck is a resource that limits the performance of the system. Identifying and removing systemic bottlenecks is a key activity of systems performance.\n\n\nWorkload\n: The input to the system or the load applied is the workload. For a database, the workload consists of the database queries and commands sent by the clients.\n\n\nCache\n: a fast storage area that can duplicate or buffer a limited amount of data, to avoid communicating directly with a slower tier of storage, thereby improving performance. For economic reasons, a cache is smaller than the slower tier.\n\n\n\n\nModels\n\n\nSystem under Test\n\n\nThe performance of a \nsystem under test\n (SUT) is shown below:\n\n\n\n\nPerturbations\n (interference) can affect results, including those caused by:\n\n\n\n\nScheduled system activity,\n\n\nOther users of the system,\n\n\nOher workloads.\n\n\n\n\nThe origin of the perturbations may not be clear and determining it can be particularly difficult in some cloud environments, where other activity (by guest tenants) on the physical host system is not observable from within a guest SUT.\n\n\nAnother difficulty is that modern environments may be composed of several networked components needed to service the input workload, including load balancers, web servers, database servers, application servers, and storage systems. The mere act of mapping the environment may help to reveal previously overlooked sources of perturbations. The environment may also be modeled as a network of queueing systems, for analytical study.\n\n\nQueueing System\n\n\nSome components and resources can be modeled as a queueing system. The following figure shows a simple queueing system.\n\n\n\n\nConcepts\n\n\nLatency\n\n\nThe \nlatency\n is the time spent waiting before an operation is performed.  The following figure, as an example of latency, shows a network transfer (e.g. HTTP GET request):\n\n\n\n\nIn this example, the operation is a network service request to transfer data. Before this operation can take place, the system must wait for a network connection to be established, which is latency for this operation. The response time spans this latency and the operation time.\n\n\nDepending on the target, the latency can be measured differently. For example, the load time for a website may be composed of three different times:\n\n\n\n\nDNS latency, which refers to the entire DNS operation.\n\n\nTCP connection latency, which refers to the initialization only (TCP handshake).\n\n\nTCP data transfer time.\n\n\n\n\nAt a higher level, the response time may be termed latency. [p19]\n\n\nTime orders of magnitude and their abbreviations are listed in the following table:\n\n\n\n\n\n\n\n\nUnit\n\n\nAbbreviation\n\n\nFraction of 1 s\n\n\n\n\n\n\n\n\n\n\nMinute\n\n\nm\n\n\n60\n\n\n\n\n\n\nSecond\n\n\ns\n\n\n1\n\n\n\n\n\n\nMillisecond\n\n\nms\n\n\n0.001 or 1/1000 or 1 x 10\n-3\n\n\n\n\n\n\nMicrosecond\n\n\n\u03bcs\n\n\n0.000001 or 1/1000000 or 1 x 10\n-6\n\n\n\n\n\n\nNanosecond\n\n\nns\n\n\n0.000000001 or 1/1000000000 or 1 x 10\n-9\n\n\n\n\n\n\nPicosecond\n\n\nps\n\n\n0.000000000001 or 1/1000000000000 or 1 x 10\n-12\n\n\n\n\n\n\n\n\nWhen possible, other metric types can be converted to latency or time so that they can be compared. For example:\n\n\n\n\nChoosing the better performance between 100 network I/O or 50 disk I/O be a complicated choice, involving many factors: network hops, rate of network drops and retransmits, I/O size, random or sequential I/O, disk types, etc..\n\n\nComparing 100 ms of total network I/O and 50 ms of total disk I/O is easier.\n\n\n\n\nTime Scales\n\n\nSystem components operate over vastly different time scales (orders of magnitude).\n\n\nThe following table is an example Time Scale of System Latencies (3.3 GHz processor):\n\n\n\n\n\n\n\n\nEvent\n\n\nLatency\n\n\nScaled\n\n\n\n\n\n\n\n\n\n\n1 CPU cycle\n\n\n0.3 ns\n\n\n1 s\n\n\n\n\n\n\nLevel 1 cache access\n\n\n0.9 ns\n\n\n3 s\n\n\n\n\n\n\nLevel 2 cache access\n\n\n2.8 ns\n\n\n9 s\n\n\n\n\n\n\nLevel 3 cache access\n\n\n12.9 ns\n\n\n43 s\n\n\n\n\n\n\nMain memory access (DRAM, from CPU)\n\n\n120 ns\n\n\n6 min\n\n\n\n\n\n\nSolid-state disk I/O (flash memory)\n\n\n50\u2013150 \u03bcs\n\n\n2\u20136 days\n\n\n\n\n\n\nRotational disk I/O\n\n\n1\u201310 ms\n\n\n1\u201312 months\n\n\n\n\n\n\nInternet: San Francisco to New York\n\n\n40 ms\n\n\n4 years\n\n\n\n\n\n\nInternet: San Francisco to United Kingdom\n\n\n81 ms\n\n\n8 years\n\n\n\n\n\n\nInternet: San Francisco to Australia\n\n\n183 ms\n\n\n19 years\n\n\n\n\n\n\nTCP packet retransmit\n\n\n1\u20133 s\n\n\n105\u2013317 years\n\n\n\n\n\n\nOS virtualization system reboot\n\n\n4 s\n\n\n423 years\n\n\n\n\n\n\nSCSI command time-out\n\n\n30 s\n\n\n3 millennia\n\n\n\n\n\n\nHardware (HW) virtualization system reboot\n\n\n40 s\n\n\n4 millennia\n\n\n\n\n\n\nPhysical system reboot\n\n\n5 m\n\n\n32 millennia\n\n\n\n\n\n\n\n\nTrade-offs\n\n\nBe aware of some common performance trade-offs. The figure below shows the good/fast/cheap \"pick two\" trade-off on the left alongside the terminology adjusted for IT projects on the right.\n\n\n\n\nA common trade-off in performance tuning is that between CPU and memory:\n\n\n\n\nMemory can be used to cache results, reducing CPU usage.\n\n\nCPU may be spent to compress data to reduce memory usage. (On modern systems with an abundance of CPU)\n\n\n\n\n[p21]\n\n\nTunable parameters often come with trade-offs. For examples:\n\n\n\n\nFile system record size\n (or block size):\n\n\nSmall record sizes, close to the application I/O size, will perform better for random I/O workloads and make more efficient use of the file system cache while the application is running.\n\n\nLarge record sizes will improve streaming workloads, including file system backups.\n\n\n\n\n\n\nNetwork buffer size\n:\n\n\nSmall buffer sizes will reduce the memory overhead per connection, helping the system scale.\n\n\nLarge sizes will improve network throughput.\n\n\n\n\n\n\n\n\nTuning Efforts\n\n\nPerformance tuning is most effective when done closest to where the work is performed (e.g. within application itself)).\n The following table shows an example of software stack, with tuning possibilities.\n\n\n\n\n\n\n\n\nLayer\n\n\nTuning Targets\n\n\n\n\n\n\n\n\n\n\nApplication\n\n\ndatabase queries performed\n\n\n\n\n\n\nDatabase\n\n\ndatabase table layout, indexes, buffering\n\n\n\n\n\n\nSystem calls\n\n\nmemory-mapped or read/write, sync or async I/O flags\n\n\n\n\n\n\nFile system\n\n\nrecord size, cache size, file system tunables\n\n\n\n\n\n\nStorage\n\n\nRAID level, number and type of disks, storage tunables\n\n\n\n\n\n\n\n\nApplication Level\n *\n\n\nTuning at the application level may improve performance significantly due to the following reasons:\n\n\n\n\nIt may be possible to eliminate or reduce database queries and improve performance by a large factor (e.g., 20x).\n\n\nTuning down to the storage device level may eliminate or improve storage I/O, but tuning efforts have already been made executing higher-level OS stack code, so this may improve resulting application performance by only percentages (e.g., 20%).\n\n\n\n\n\n\nSince many of today\u2019s environments target rapid deployment for features and functionality, application development and testing tend to focus on correctness, leaving little or no time for performance measurement or optimization before production deployment. These activities are conducted later, when performance becomes a problem.\n\n\n\n\nThe application isn\u2019t necessarily the most effective level from which to base observation. Slow queries may be best understood from their time spent on-CPU, or from the file system and disk I/O that they perform. These are observable from operating system tools.\n\n\nIn many environments (especially cloud computing), the application level is under constant development, pushing software changes into production weekly or daily. Large performance improvment (including fixes for regressions) are frequently found as the application code changes. In these environments, tuning for the operating system and observability from the operating system can be easy to overlook. Remember that operating system performance analysis can also identify application-level issues, not just OS-level issues, in some cases more easily than from the application alone.\n\n\nLevel of Appropriateness\n\n\nDifferent organizations and environments have different requirements for performance [p22]. This doesn\u2019t necessarily mean that some organizations are doing it right and some wrong. It depends on the \nreturn on investment\n (ROI) for performance expertise:\n\n\n\n\nOrganizations with large data centers or cloud environments may need a team of performance engineers who analyze everything, including kernel internals and CPU performance counters, and frequently use dynamic tracing. They may also formally model performance and develop accurate predictions for future growth.\n\n\nSmall start-ups may have time only for superficial checks, trusting third-party monitoring solutions to check their performance and provide alerts.\n\n\n\n\nPoint-in-Time Recommendations\n\n\nThe performance characteristics of environments change over time, due to the addition of more users, newer hardware, and updated software or firmware.\n\n\n[p23]\n\n\nPerformance recommendations, especially the values of tunable parameters, are valid only at a specific \npoint in time\n. What may have been the best advice from a performance expert one week may become invalid a week later after a software or hardware upgrade, or after adding more users.\n\n\nLoad versus Architecture\n\n\nAn application can perform badly due to an issue with the software configuration and hardware on which it is running: its architecture. However, an application can also perform badly simply due to too much load applied, resulting in queueing and long latencies. Load and architecture are pictured in the figure below:\n\n\n\n\nIf analysis of the architecture shows queueing of work but no problems with how the work is performed, the issue may be one of too much load applied. In a cloud computing environment, this is the point where more nodes can be introduced to handle the work.\n\n\nSingle-threaded and multithreaded application\n *\n\n\nFor example,\n\n\n\n\nAn \nissue of architecture\n may be a single-threaded application that is busy on-CPU, with requests queueing while other CPUs are available and idle. In this case, performance is limited by the application\u2019s single-threaded architecture.\n\n\nAn \nissue of load\n may be a multithreaded application that is busy on all available CPUs, with requests still queueing. In this case, performance is limited by the available CPU capacity, or put differently, by more load than the CPUs can handle.\n\n\n\n\nScalability\n\n\nThe performance of the system under increasing load is its \nscalability\n. The following figure shows a typical throughput profile as a system\u2019s load increases:\n\n\n\n\nFor some period, linear scalability is observed. A point is then reached, marked with a dotted line, where contention for a resource begins to affect performance. This point can be described as a \nknee point\n, as it is the boundary between two pro files. Beyond this point, the throughput profile departs from linear scalability, as contention for the resource increases. Eventually the overheads for increased contention and coherency cause less work to be completed and throughput to decrease.\n\n\nThis point may occur when a component reaches 100% utilization: the \nsaturation point\n. It may also occur when a component approaches 100% utilization, and queueing begins to be frequent and significant. This point may occur when a component reaches 100% utilization: the saturation\npoint. It may also occur when a component approaches 100% utilization, and\nqueueing begins to be frequent and significant.\n\n\nAn example system that may exhibit this profile is an application that performs heavy compute, with more load added as threads. As the CPUs approach 100% utilization, performance begins to degrade as CPU scheduler latency increases. After peak performance, at 100% utilization, throughput begins to decrease as more threads are added, causing more context switches, which consume CPU resources and cause less actual work to be completed.\n\n\nThe same curve can be seen if you replace \"load\" on the \nx\n axis with a resource such as CPU cores (detailed in \nModeling\n)\n\n\nThe degradation of performance for nonlinear scalability, in terms of average response time or latency, is graphed in the following figure:\n\n\n\n\n\n\nThe \"fast\" degradation profile may occur for memory load, when the system begins to page (or swap) to supplement main memory.\n\n\nThe \"slow\" degradation profile may occur for CPU load.\n\n\nAnother \"fast\" profile example is disk I/O. As load (and the resulting disk utilization) increases, I/O becomes more likely to queue behind other I/O. An idle rotational disk may serve I/O with a response time of about 1 ms, but when load increases, this can approach 10 ms.\n\n\n\n\nLinear scalability of response time could occur if the application begins to return errors when resources are unavailable, instead of queueing work. For example, a web server may return 503 \"Service Unavailable\" instead of adding requests to a queue, so that those requests that are served can be performed with a consistent response time.\n\n\nKnown-Unknowns\n\n\nThe following notions are important:\n\n\n\n\nKnown-knowns\n: These are things you know. You know you should be checking a performance metric, and you know its current value. For example, you know you should be checking CPU utilization, and you also know that the value is 10% on average.\n\n\nKnown-unknowns\n: These are things you know that you do not know. You know you can check a metric or the existence of a subsystem, but you haven\u2019t yet observed it. For example, you know you could be checking what is making the CPUs busy by the use of profiling but have yet to do so.\n\n\nUnknown-unknowns\n: These are things you do not know you do not know.  For example, you may not know that device interrupts can become heavy CPU consumers, so you are not checking them.\n\n\n\n\nPerformance is a field where \"the more you know, the more you don\u2019t know\". It\u2019s the same principle: the more you learn about systems, the more unknownunknowns you become aware of, which are then known-unknowns that you can check on.\n\n\nMetrics\n\n\nPerformance metrics are statistics generated by the system, applications, or additional tools that measure activity of interest. They are studied for performance analysis and monitoring, either numerically at the command line or graphically using visualizations.\n\n\nCommon types of systems performance metrics include:\n\n\n\n\nIOPS\n: I/O operations per second\n\n\nThroughput\n: either operations or volume per second, depending on its context:\n\n\nDatabase throughput is usually a measure of queries or requests (operations) per second.\n\n\nNetwork throughput is a measure of bits or bytes (volume) per second.\n\n\n\n\n\n\nUtilization\n\n\nLatency\n\n\n\n\nOverhead\n\n\nSince CPU cycles must be spent to gather and store the metrics. This causes overhead, which can negatively affect the performance of the target of measurement. This is called the \nobserver effect\n.\n\n\nIssues\n\n\nThe temptation is to assume that the software vendor has provided metrics that are well chosen, are bug-free, and provide complete visibility. In reality, metrics can be confusing, complicated, unreliable, inaccurate, and even plain wrong (due to bugs). Sometimes a metric was correct on one software version but did not get updated to reflect the addition of new code and code paths.\n\n\nUtilization\n\n\nThe term \nutilization\n is often used for operating systems to describe device usage, such as for the CPU and disk devices. Utilization can be time-based or capacitybased.\n\n\nTime-Based\n\n\nTime-based utilization is the average amount of time the server or resource was busy, as defined in \nqueueing theory\n, along with the ratio:\n\n\n\n\nU\n = \nB\n/\nT\n\n\n\n\nwhere:\n\n\n\n\nU\n = utilization\n\n\nB\n = total time the system was busy during \nT\n, the observation period\n\n\n\n\nThe \"utilization\" is also available from operating system performance tools. The disk monitoring tool \niostat(1)\n calls this metric \n%b\n for percent busy, a term that better conveys the underlying metric: \nB\n/\nT\n.\n\n\nThis utilization metric means how busy a component is: when a component approaches 100% utilization, performance can seriously degrade when there is contention for the resource. Other metrics can be checked to confirm and to see if the component has therefore become a system bottleneck.\n\n\nSome components can service multiple operations in parallel. Performance may not degrade much at 100% utilization, as they can accept more work. [p28]\n\n\n\n\nA disk that is 100% busy may also be able to accept and process more work, for example, by buffering writes in the on-disk cache to be completed later.\n\n\nStorage arrays frequently run at 100% utilization because some disk is busy 100% of the time, but the array has plenty of idle disks and can accept much more work.\n\n\n\n\nCapacity-Based\n\n\nThe other definition of utilization in the context of capacity planning is:\n\n\n\n\nA system or component (such as a disk drive) is able to deliver a certain amount of throughput. At any level of performance, the system or component is working at some proportion of its capacity. That proportion is called the utilization.\n\n\n\n\nThis defines utilization in terms of capacity instead of time. It implies that a disk at 100% utilization cannot accept any more work. With the time-based definition, 100% utilization only means it is busy 100% of the time. Therefore, \n100% busy does not mean 100% capacity.\n\n\nTime-Based vs. Capacity-Based\n *\n\n\nUse elevator as an example:\n\n\n\n\nTime-Based Utilization: the elevator may be considered utilized when it is moving between floors, and not utilized when it is idle waiting. However, the elevator may be able to accept more passengers even when it is busy 100% of the time responding to calls.\n\n\nCapacity-Based Utilization: 100% capacity may mean the elevator is at its maximum payload capacity and cannot accept more passengers.\n\n\n\n\nIn an ideal world, we would be able to measure both types of utilization for a device, which usually isn't possible. [p29]\n\n\nIn this book, \nutilization\n usually refers to the time-based version.\n The capacity version is used for some volume-based metrics, such as memory usage.\n\n\nNon-Idle Time\n\n\nNon-idle time\n is a more accurate term to define utilization, but not yet in common usage. [p29]\n\n\nSaturation\n\n\nSaturation\n is the degree to which more work is requested of a resource than it can process. Saturation begins to occur at 100% utilization (capacity-based), as extra work cannot be processed and begins to queue. This is pictured in the following figure:\n\n\n\n\nAny degree of saturation is a performance issue, as time is spent waiting (latency). For time-based utilization (percent busy), saturation may not begin at the 100% utilization mark, depending on the degree to which the resource can operate on work in parallel. [p30]\n\n\nProfiling\n\n\nProfiling\n is typically performed by \nsampling\n the state of the system at timed intervals, and then studying the set of samples.\n\n\nUnlike the previous metrics covered, including IOPS and throughput, the use of sampling provides a \ncoarse\n view of the target\u2019s activity, depending on the rate of sampling.\n\n\nFor example, CPU usage can be understood in reasonable detail by sampling the CPU program counter or stack backtrace at frequent intervals to gather statistics on the code paths that are consuming CPU resources, which is detailed in \nChapter 6\n.\n\n\nCaching\n\n\nFrequently used to improve performance, a cache stores results from a slower storage tier in a faster storage tier for reference. An example is caching disk blocks in main memory (RAM).\n\n\n\n\nMultiple tiers of caches may be used. CPUs commonly employ multiple hardware caches for main memory (Levels 1, 2, and 3), beginning with a very fast but small cache (Level 1) and increasing in both storage size and access latency. This is an economic trade-off between density and latency:level; and sizes are chosen for the best performance for the on-chip space available.\n\n\nThere are many other caches present in a system, many of them implemented in software using main memory for storage.\n\n\n\n\nCaching is detailed in \nSection 3.2.11\n.\n\n\nCache metrics\n *\n\n\nHit ratio\n is a metric of cache performance. It represents the number of times the needed data was found in the cache (hits) versus the number of times it was not (misses). The higher, the better, as a higher ratio reflects more data successfully accessed from faster media. The following figure shows the expected performance improvement for increasing cache hit ratios.\n\n\n\n\nThis is a nonlinear profile because of the difference in speed between cache hits and misses (the two storage tiers). The performance difference between 98% and 99% is much greater than that between 10% and 11%. The greater the difference, the steeper the slope becomes.\n\n\nMiss rate\n is another metric, in terms of misses per second. This is proportional (linear) to the performance penalty of each miss.\n\n\nThe total runtime for each workload can be calculated as:\n\n\n\n\nruntime = (hit rate x hit latency) + (miss rate x miss latency)\n\n\n\n\nThis calculation uses the average hit and miss latencies and assumes the work is serialized.\n\n\nAlgorithms\n\n\nCache management algorithms and policies determine what to store in the limited space available for a cache:\n\n\n\n\nMost recently used\n (MRU) refers to a cache \nretention policy\n, which decides what to favor keeping in the cache: the objects that have been used most recently.\n\n\nLeast recently used\n (LRU) can refer to an equivalent cache \neviction policy\n, deciding what objects to remove from the cache when more space is needed.\n\n\nMost frequently used\n (MFU)\n\n\nLeast frequently used\n (LFU)\n\n\nNot frequently used\n (NFU): an inexpensive but less thorough version of LRU.\n\n\n\n\nHot, Cold, and Warm Caches\n\n\nThe following words describe the state of the cache:\n\n\n\n\nCold: A \ncold cache\n is empty, or populated with unwanted data. The hit ratio for a cold cache is zero (or near zero as it begins to warm up).\n\n\nHot: A \nhot cache\n is populated with commonly requested data and has a high hit ratio, for example, over 99%.\n\n\nWarm: A \nwarm cache\n is one that is populated with useful data but doesn\u2019t have a high enough hit ratio to be considered hot.\n\n\nWarmth: Cache warmth describes how hot or cold a cache is. An activity that improves cache warmth is one that aims to improve the cache hit ratio.\n\n\n\n\nWhen caches are first initialized, they begin cold and then warm up over time.  When the cache is large or the next-level storage is slow (or both), the cache can take a long time to become populated and warm.\n\n\n[p32]\n\n\nPerspectives\n\n\nThere are two common perspectives for performance analysis: \nworkload analysis\n and \nresource analysis\n, which can be thought of as either top-down or bottom-up analysis of the operating system software stack, as show in the figure below:\n\n\n\n\nResource Analysis\n\n\nResource analysis begins with analysis of the system resources: CPUs, memory, disks, network interfaces, busses, and interconnects. It is most likely performed by system administrators, who are responsible for the physical environment resources.\n\n\nActivities\n *\n\n\n\n\nPerformance issue investigations:\n to see if a particular type of resource is responsible\n\n\nCapacity planning\n: for information to help size new systems, and to see when existing system resources may become exhausted\n\n\n\n\nMetrics with utilization as a focus\n *\n\n\nResource analysis focuses on utilization to identify when resources are at or approaching their limit.\n\n\n\n\nSome resource types, such as CPUs, have utilization metrics readily available.\n\n\nUtilization for other resources can be estimated based on available metrics, for example, estimating network interface utilization by comparing the send and receive megabits per second (throughput) with the known maximum bandwidth.\n\n\n\n\nMetrics\n best suited for resource analysis include:\n\n\n\n\nIOPS\n\n\nThroughput\n\n\nUtilization\n\n\nSaturation\n\n\n\n\nThese metrics measure the following:\n\n\n\n\nWhat the resource is being asked to do\n\n\nHow utilized or saturated\nit is for a given load. Ot\n\n\n\n\nOther types of metrics, including latency, are also of use to see how well the resource is responding for the given workload.\n\n\nDocumentation on \"stat\" tools\n *\n\n\nResource analysis is a common approach to performance analysis, in part because of the widely available documentation on the topic. Such documentation focuses on the operating system \"stat\" tools: \nvmstat(1)\n, \niostat(1)\n, \nmpstat(1)\n. Resource analysis is a perspective, but not the only perspective.\n\n\nWorkload Analysis\n\n\nWorkload analysis, as seen in the figure below, examines the performance of the applications, including the workload applied and how the application is responding. It is most commonly used by application developers and support staff, who are responsible for the application software and configuration.\n\n\n\n\nTargets for workload analysis\n *\n\n\n\n\nRequests\n: the workload applied\n\n\nLatency\n: the response time of the application\n\n\nCompletion\n: looking for errors\n\n\n\n\nStudying workload requests involves checking and summarizing their attributes: the process of \nworkload characterization\n (detailed in \nSection 2.5\n). For databases, these attributes may include the client host, database name, tables, and query string. This data may help identify unnecessary work or unbalanced work. Examining these attributes may identify ways to reduce or eliminate the work applied. (The fastest query is the one you don\u2019t do at all.)\n\n\nLatency (response time) is the most important metric for expressing application performance. For instance: for a MySQL database, it\u2019s query latency; for Apache, it\u2019s HTTP request latency. In these contexts, the term \nlatency\n is used to mean the same as response time (\nSection 2.3.1\n).\n\n\nIdentifying issues\n\n\nThe tasks of workload analysis are identifying and confirming issues. Latency, for example, can be done by:\n\n\n\n\nLooking for latency beyond an acceptable threshold,\n\n\nFinding the source of the latency (drill-down analysis),\n\n\nConfirming that the latency is improved after applying a fix.\n\n\n\n\nNote that the starting point is the application. To investigate latency usually involves drilling down deeper into the application, libraries, and the operating system (kernel).\n\n\nSystem issues may be identified by studying characteristics related to the completion of an event, including its error status. While a request may complete quickly, it may do so with an error status that causes the request to be retried, accumulating latency.\n\n\nMetrics for workload analysis\n *\n\n\n\n\nThroughput (transactions per second)\n\n\nLatency\n\n\n\n\nThese measure the rate of requests and the resulting performance.\n\n\nMethodology\n\n\nModeling\n\n\nCapacity Planning\n\n\nStatistics\n\n\nMonitoring\n\n\nVisualizations\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np17 on System under Test:\n\n\n\n\nThe mere act of mapping the environment may help to reveal previously overlooked sources of perturbations. The environment may also be modeled as a network of queueing systems, for analytical study.\n\n\n\n\nWTF?\n\n\np21 on Trade-offs:\n\n\n\n\nFile system record size and network buffer size: small vs large\n\n\n\n\nFurther reading may be required to understand these trade-offs.", 
            "title": "Chapter 2. Methodology"
        }, 
        {
            "location": "/spec/ch3/", 
            "text": "Chapter 3. Operating Systems\n\n\nAn understanding of the operating system and its kernel is essential for systems\nperformance analysis, such as:\n\n\n\n\nHow system calls are being performed,\n\n\nHow CPUs are scheduling threads,\n\n\nHow limited memory could be affecting performance,\n\n\nHow a file system processes I/O.\n\n\n\n\nThis chapter has two parts:\n\n\n\n\nBackground\n introduces terminology and operating system fundamentals.\n\n\nKernels\n summarizes Linux and Solaris-based kernels.\n\n\n\n\nTerminology\n\n\nThe following is the core operating system terminology in this book:\n\n\n\n\nOperating system\n: This refers to the software and files that are installed on a system so that it can boot and execute programs. It includes the kernel, administration tools, and system libraries.\n\n\nKernel\n: the program that manages the system, including devices (hardware), memory, and CPU scheduling. It runs in a privileged CPU mode that allows direct access to hardware, called \nkernel mode\n.\n\n\nProcess\n: an OS abstraction and environment for executing a program. The program normally runs in \nuser mode\n, with access to kernel mode (e.g., for performing device I/O) via \nsystem calls\n or \ntraps\n.\n\n\nThread\n: an executable context that can be scheduled to run on a CPU. The kernel has multiple threads, and a process contains one or more.\n\n\nTask\n: a Linux runnable entity, which can refer to a process (with a single thread), a thread from a multithreaded process, or kernel threads.\n\n\nKernel-space\n: the memory address space for the kernel.\n\n\nUser-space\n: the memory address space for processes.\n\n\nUser-land\n: user-level programs and libraries (/usr/bin, /usr/lib, . . .).\n\n\nContext switch\n: a kernel routine that switches a CPU to operate in a different address space (context).\n\n\nSystem call (syscall)\n: a well-defined protocol for user programs to request the kernel to perform privileged operations, including device I/O.\n\n\nProcessor\n: a physical chip containing one or more CPUs.\n\n\nTrap\n: a signal sent to the kernel, requesting a system routine (privileged action). Trap types include system calls, processor exceptions, and interrupts.\n\n\nInterrupt\n: a signal sent by physical devices to the kernel, usually to request servicing of I/O. An interrupt is a type of trap.", 
            "title": "Chapter 3. Operating Systems"
        }, 
        {
            "location": "/cnapp/", 
            "text": "CNAPP\n\n\n\n\nChapter 1. Introduction", 
            "title": "Contents"
        }, 
        {
            "location": "/cnapp/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nOver the last decade, the Internet has been used more as a mechanism for information dissemination and broadcasting, mainly driven by the World Wide Web (WWW or the Web). The Web forms a universe of information accessible via networked computers, offering content in the form of Web pages, images, text, animations, or audio and video streams. This book examines the technical concepts and the challenges of distributing, delivering, and servicing content over the Internet. The focus is on fundamental principles and concepts rather than providing a reference for specific communication protocols or implementation details.", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/bd/", 
            "text": "BD\n\n\n\n\nChapter 1. A new paradigm for Big Data\n\n\nChapter 2. Data model for Big Data\n\n\nChapter 3. Data model for Big Data: Illustration", 
            "title": "Contents"
        }, 
        {
            "location": "/bd/ch1/", 
            "text": "Chapter 1. A new paradigm for Big Data\n\n\n[p1-2]\n\n\nTraditional systems, and the data management techniques associated with them, have failed to scale to Big Data.\n\n\nTo tackle the challenges of Big Data, a lof of new technologies has emerged, many of which have been grouped under the term \nNoSQL\n. In some ways, these new technologies are more complex than traditional databases, and in other ways they\u2019re simpler. These systems can scale to vastly larger sets of data, but using these technologies effectively requires a fundamentally new set of techniques.  They aren\u2019t one-size-fits-all solutions.\n\n\nMany of these Big Data systems were pioneered by Google, including:\n\n\n\n\nDistributed filesystems,\n\n\nThe  MapReduce computation framework,\n\n\nDistributed locking services.\n\n\n\n\nAnother notable pioneer in the space was Amazon, which created an innovative distributed key/value store called Dynamo. The open source community responded in the years following with Hadoop, HBase, MongoDB, Cassandra, RabbitMQ, and countless other projects.\n\n\nThis book is about complexity as much as it is about scalability. Some of the most basic ways people manage data in traditional systems like relational database management systems (RDBMSs) are too complex for Big Data systems.The simpler, alternative approach is the new paradigm for Big Data. This approach is dubbed the \nLambda Architecture\n.\n\n\nHow this book is structured\n\n\nThis book is a theory book, focusing on how to approach building a solution to any Big Data problem. It is structured into theory and illustration chapters.\n\n\nScaling with a traditional database\n\n\nThe example in this section is a simple web analytics application, which tracks the number of pageviews for any URL a customer wishes to track. The customer\u2019s web page pings the application\u2019s web server with its URL every time a pageview is received. Additionally, the application should be able to tell you at any point what the top 100 URLs are by number of pageviews.\n\n\nYou start with a traditional relational schema for the pageviews similiar to the table below:\n\n\n\n\n\n\n\n\nColumn name\n\n\nType\n\n\n\n\n\n\n\n\n\n\nid\n\n\ninteger\n\n\n\n\n\n\nuser_id\n\n\ninteger\n\n\n\n\n\n\nurl\n\n\nvarchar(255)\n\n\n\n\n\n\npageviews\n\n\nbigint\n\n\n\n\n\n\n\n\nYour back end consists of an RDBMS with a table of that schema and a web server. Whenever someone loads a web page being tracked by your application, the web page pings your web server with the pageview, and your web server increments the corresponding row in the database.\n\n\nThe following subsections discuss what problems emerge as you evolve the application: you\u2019ll run into problems with both scalability and complexity.\n\n\nScaling with a queue\n\n\nAs the traffic to your application is growing, you got a lot of \"Timeout error on inserting to the database\" error, sincet the database can\u2019t keep up with the load, so write requests to increment pageviews are timing out.\n\n\nInstead of having the web server hit the database directly, you insert a queue between the web server and the database. Whenever you receive a new pageview, that event is added to the queue. You then create a worker process that reads 100 events at a time off the queue, and batches them into a single database update. This is illustrated in the figure below:\n\n\n\n\nThis scheme resolves the timeout issues you were getting. If the database ever gets overloaded again, the queue will just get bigger instead of timing out to the web server and potentially losing data.\n\n\nScaling by sharding the database\n\n\nAs your application continues to get more and more popular, and again the database gets overloaded. Your worker can\u2019t keep up with the writes; adding more workers to parallelize the updates doesn\u2019t help; the database is clearly the bottleneck.\n\n\nThe approach is to use multiple database servers and spread the table across all the servers. Each server will have a subset of the data for the table. This is known as \nhorizontal partitioning\n or \nsharding\n. This technique spreads the write load across multiple machines.\n\n\nThe sharding technique you use is to choose the shard for each key by taking the hash of the key modded by the number of shards. Mapping keys to shards using a hash function causes the keys to be uniformly distributed across the shards. You do the following:\n\n\n\n\nWrite a script to map over all the rows in your single database instance, and split the data into four shards. Since it takes a while to run this script, you turn off the worker that increments pageviews to avoid losing increments during the transition.\n\n\nWrap a library around database-handling code that reads the number of shards from a configuration file, and redeploy all of your application code, since all application code needs to know how to find the shard for each key. You have to modify your top-100-URLs query to get the top 100 URLs from each shard and merge those together for the global top 100 URLs.\n\n\n\n\nAs the application gets more popular, you keep having to reshard the database into more shards to keep up with the write load:\n\n\n\n\nEach time gets more and more painful because there\u2019s so much more work to coordinate. You can\u2019t just run one script to do the resharding, as that would be too slow. You have to do all the resharding in parallel and manage many active worker scripts at once.\n\n\nIf you forget to update the application code with the new number of shards, it causes many of the increments to be written to the wrong shards. So you have to write a one-off script to manually go through the data and move whatever was misplaced.\n\n\n\n\nFault-tolerance issues begin\n\n\nWith so many shards, it becomes a frequent occurrence for the disk on one of the database machines to go bad. That portion of the data is unavailable while that machine is down. You do a couple of things to address this:\n\n\n\n\nYou update your queue/worker system to put increments for unavailable shards on a separate \u201cpending\u201d queue that you attempt to flush once every five minutes.\n\n\nYou use the database\u2019s replication capabilities to add a slave to each shard so you have a backup in case the master goes down. You don\u2019t write to the slave, but at least customers can still view the stats in the application.\n\n\n\n\nCorruption issues\n\n\nYou accidentally deploy a bug to production that increments the number of pageviews by two, instead of by one, for every URL and you don\u2019t notice until 24 hours later, but by then the damage is done. Your weekly backups don\u2019t help because there\u2019s no way of knowing which data got corrupted.  After all this work trying to make your system scalable and tolerant of machine failures, your system has no resilience to a human making a mistake.\n\n\nWhat went wrong?\n\n\nAs the application evolved, the system continued to get more and more complex: queues, shards, replicas, resharding scripts, etc. Developing applications on the data requires a lot more than just knowing the database schema; your code needs to know how to talk to the right shards, and if you make a mistake, there\u2019s nothing preventing you from reading from or writing to the wrong shard.\n\n\nOne problem is that your database is not self-aware of its distributed nature, so it can\u2019t help you deal with shards, replication, and distributed queries. All that complexity got pushed to you both in operating the database and developing the application code.\n\n\nHowever, the worst problem is that the system is not engineered for human mistakes.  As the system keeps getting more complex, it is more likely that a mistake will be made:\n\n\n\n\nMistakes in software are inevitable. If you\u2019re not engineering for it, you might as well be writing scripts that randomly corrupt data.\n\n\nBackups are not enough; the system must be carefully thought out to limit the damage a human mistake can cause.\n\n\nHuman-fault tolerance is not optional. It\u2019s essential, especially when Big Data adds so many more complexities to building applications.\n\n\n\n\nHow will Big Data techniques help?\n\n\nThe Big Data techniques to be discussed address these scalability and complexity issues in dramatically:\n\n\n\n\nThe databases and computation systems for Big Data are aware of their distributed nature. Sharding and replication are handled for you.\n\n\nShading: the logic is internalized in the database, preventing situations where you accidentally query the wrong shard.\n\n\nScaling: just add new nodes and the systems will automatically rebalance onto the new nodes.\n\n\n\n\n\n\nMake data immutable. Instead of storing the pageview counts as your core dataset, which you continuously mutate as new pageviews come in, you store the raw pageview information, which is never modified. \nWhen you make a mistake, you might write bad data, but at least you won\u2019t destroy good data.\n This is a much stronger human-fault tolerance guarantee than in a traditional system based on mutation. [p6]\n\n\n\n\nNoSQL is not a panacea\n\n\nInnovation in scalable data systems in the past decades include:\n\n\n\n\nLarge-scale computation systems: such as \nHadoop\n\n\nDatabases: such as \nCassandra\n and \nRiak\n.\n\n\n\n\nThese systems can handle very large amounts of data, but with serious trade-offs:\n\n\n\n\nHadoop can parallelize large-scale batch computations on very large amounts of data, but the computations have high latency. You don\u2019t use Hadoop for anything where you need low-latency results.\n\n\nNoSQL databases like Cassandra achieve their scalability by offering you a much more limited data model than you\u2019re used to with something like SQL.\n\n\nSqueezing your application into these limited data models can be very complex.\n\n\nThey are not human-fault tolerant, because the databases are mutable.\n\n\n\n\n\n\n\n\nThese tools on their own are not a panacea. But when intelligently used in conjunction with one another, you can produce scalable systems for arbitrary data problems with human-fault tolerance and a minimum of complexity. This is the Lambda Architecture discussed throughout the book.\n\n\nFirst principles\n\n\nWhat does a data system do? An intuitive definition is:\n\n\n\n\nA data system answers questions based on information that was acquired in the past up to the present.\n\n\n\n\n\n\nData systems don\u2019t just memorize and regurgitate information. They combine bits and pieces together to produce their answers.\n\n\nAll bits of information are equal. Some information is derived from other pieces of information.\n\n\nWhen you keep tracing back where information is derived from, you eventually end up at information that\u2019s not derived from anything. This is the rawest information you have: information you hold to be true simply because it exists. This information is called \ndata\n.\n\n\n\n\nData is often used interchangeably with the word \ninformation\n. But for the remainder of this book, when we use the word data, we\u2019re referring to that special information from which everything else is derived.\n\n\nThe most general-purpose data system answers questions by looking at the entire dataset, which has the definition:\n\n\n\n\nquery = function(all data)\n\n\n\n\n[p7]\n\n\nThe Lambda Architecture provides a general-purpose approach to implementing an arbitrary function on an arbitrary dataset and having the function return its results with low latency. This does not mean always using the same technologies to implement a database system; the Lambda Architecture defines a consistent approach to choosing those technologies and to wiring them together to meet your requirements.\n\n\nDesired properties of a Big Data system\n\n\nNot only must a Big Data system perform well and be resource-efficient, it must be easy to reason about as well.\n\n\nRobustness and fault tolerance\n\n\nSystems need to behave correctly despite any of the following situations:\n\n\n\n\nMachines going down randomly\n\n\nThe complex semantics of consistency in distributed databases\n\n\nDuplicated data\n\n\nConcurrency\n\n\n\n\nThese challenges make it difficult even to reason about a system is doing. Part of making a Big Data system robust is avoiding these complexities so that you can easily reason about the system\n\n\nIt\u2019s imperative for systems to be \nhuman-fault tolerant\n, which is an oft-overlooked property. In a production system, it\u2019s inevitable that someone will make a mistake, such as by deploying incorrect code that corrupts values in a database. If you build immutability and recomputation into the core of a Big Data system, the system will be innately resilient to human error by providing a clear and simple mechanism for recovery.\n\n\nLow latency reads and updates\n\n\n\n\nMost applications require reads to be satisfied with very low latency, typically\nbetween a few milliseconds to a few hundred milliseconds.\n\n\nThe update latency requirements vary a great deal between applications. Some applications require updates to propagate immediately, but in other applications a latency of a few hours is fine.\n\n\n\n\nYou need to be able to:\n\n\n\n\nAchieve low latency updates when you need them in your Big Data systems,\n\n\nAchieve low latency reads and updates without compromising the robustness of the system.\n\n\n\n\nScalability\n\n\nScalability is the ability to maintain performance in the face of increasing data or load by adding resources to the system.\n The Lambda Architecture is horizontally scalable across all layers of the system stack: scaling is accomplished by adding more machines.\n\n\nGeneralization\n\n\nA general system can support a wide range of applications. Because the Lambda Architecture is based on functions of all data, it generalizes to all applications.\n\n\nExtensibility\n\n\nYExtensible systems allow functionality to be added with a minimal development cost, without having to reinvent the wheel each time you add a related feature or make a change to how your system works.\n\n\nOftentimes a new feature or a change to an existing feature requires a migration of old data into a new format. Part of making a system extensible is making it easy to do large-scale migrations. Being able to do big migrations quickly and easily is core to the approach under discussion.\n\n\nAd hoc queries\n\n\nEvery large dataset has unanticipated value within it. Being able to mine a dataset arbitrarily gives opportunities for business optimization and new applications. Ultimately, you can\u2019t discover interesting things to do with your data unless you can ask arbitrary questions of it.\n\n\nMinimal maintenance\n\n\nMaintenance is the work required to keep a system running smoothly. This includes:\n\n\n\n\nAnticipating when to add machines to scale,\n\n\nKeeping processes up and running,\n\n\nDebugging anything that goes wrong in production.\n\n\n\n\nAn important part of minimizing maintenance is choosing components that have as little implementation complexity as possible. You want to rely on components that have simple mechanisms underlying them. In particular, distributed databases tend to have very complicated internals. The more complex a system, the more likely something will go wrong, and the more you need to understand about the system to debug and tune it.\n\n\nYou combat implementation complexity by relying on simple algorithms and simple components.\n A trick employed in the Lambda Architecture is to push complexity out of the core components and into pieces of the system whose outputs are discardable after a few hours. The most complex components used, like read/write distributed databases, are in this layer where outputs are eventually discardable.\n\n\nDebuggability\n\n\nA Big Data system must provide the information necessary to debug the system when things go wrong. The key is to be able to trace, for each value in the system, exactly what caused it to have that value.\n\n\nDebuggability is accomplished in the Lambda Architecture through the functional nature of the batch layer and by preferring to use recomputation algorithms when possible.\n\n\nThe problems with fully incremental architectures\n\n\nTraditional architectures look like the figure below:\n\n\n\n\nWhat characterizes these architectures is the use of read/write databases and maintaining the state in those databases incrementally as new data is seen. For example, an incremental approach to counting pageviews would be to process a new pageview by adding one to the counter for its URL. The vast majority of both relational and non-relational database deployments are done as fully incremental architectures. This has been true for many decades.\n\n\nFully incremental architectures are so widespread that many people don\u2019t realize it\u2019s possible to avoid their problems with a different architecture.  This is called \nfamiliar complexity\n (complexity that\u2019s so ingrained, you don\u2019t even think to find a way to avoid it).\n\n\nThe problems with fully incremental architectures are significant. This section discusses:\n\n\n\n\nGeneral complexities brought on by any fully incremental architecture.\n\n\nTwo contrasting solutions for the same problem: one using the best possible fully incremental solution, and one using a Lambda Architecture.\n\n\n\n\nYou\u2019ll see that the fully incremental version is significantly worse in every respect.\n\n\nOperational complexity\n\n\nWith many complexities inherent in fully incremental architectures that create difficulties in operating production infrastructure, this section focuses on one: the need for read/write databases to perform online compaction, and what you have to do operationally to keep things running smoothly.\n\n\nIn a read/write database, as a disk index is incrementally added to and modified, parts of the index become unused. These unused parts take up space and eventually need to be reclaimed to prevent the disk from filling up. Reclaiming space as soon as it becomes unused is too expensive, so the space is occasionally reclaimed in bulk in a process called \ncompaction\n.\n\n\nCompaction is an intensive operation. The server places substantially higher demand on the CPU and disks during compaction, which dramatically lowers the performance of that machine during that time period. Databases such as HBase and Cassandra are well-known for requiring careful configuration and management to avoid problems or server lockups during compaction. The performance loss during compaction is a complexity that can even cause cascading failure: if too many machines compact at the same time, the load they were supporting will have to be handled by other machines in the cluster. This can potentially overload the rest of your cluster, causing total failure.\n\n\nTo manage compaction correctly, you have to:\n\n\n\n\nSchedule compactions on each node so that not too many nodes are affected at once.\n\n\nBe aware of how long a compaction takes to avoid having more nodes undergoing compaction than you intended.\n\n\nMake sure you have enough disk capacity on your nodes to last them between compactions.\n\n\nMake sure you have enough capacity on your cluster so that it doesn\u2019t become overloaded when resources are lost during compactions.\n\n\n\n\nThe best way to deal with complexity is to get rid of that complexity altogether. The fewer failure modes you have in your system, the less likely it is that you\u2019ll suffer unexpected downtime. Dealing with online compaction is a complexity inherent to fully incremental architectures, but in a Lambda Architecture the primary databases don\u2019t require any online compaction.\n\n\nExtreme complexity of achieving eventual consistency\n\n\nIncremental architectures have another complexity when trying to make the system highly available.  A highly available system allows for queries and updates even in the presence of machine or partial network failure.\n\n\nAchieving high availability competes directly with another important property called \nconsistency\n. A consistent system returns results that take into account all previous writes. The \nCAP theorem\n has shown that it\u2019s impossible to achieve both high availability and consistency in the same system in the presence of network partitions. Therefore, a highly available system sometimes returns stale results during a network partition.\n\n\nIn order for a highly available system to return to consistency once a network partition ends (known as \neventual consistency\n), a lot of help is required from your application. [p11] Distributed databases achieve high availability by keeping multiple replicas of all information stored. When you keep many copies of the same information, that information is still available even if a machine goes down or the network gets partitioned, as shown in the figure below. During a network partition, a system that chooses to be highly available has clients update whatever replicas are reachable to them. This causes replicas to diverge and receive different sets of updates. Only when the partition goes away can the replicas be merged together into a common value.\n\n\n\n\nExample: highly available counting\n *\n\n\nFor example, suppose you have two replicas with a count of 10 when a network partition begins. Suppose the first replica gets two increments and the second gets one increment.  When it comes time to merge these replicas together, with values of 12 and 11, what should the merged value be? Although the correct answer is 13, there\u2019s no way to know just by looking at the numbers 12 and 11. They could have diverged at 11 (in which case the answer would be 12), or they could have diverged at 0 (in which case the answer would be 23).\n\n\nTo do highly available counting correctly, it\u2019s not enough to just store a count:\n\n\n\n\nYou need a data structure that\u2019s amenable to merging when values diverge,\n\n\nYou need to implement the code that will repair values once partitions end.\n\n\n\n\nThis is an amazing amount of complexity you have to deal with just to maintain a simple count.\n\n\nIn general, handling eventual consistency in incremental, highly available systems is unintuitive and prone to error. This complexity is innate to highly available, fully incremental systems. However, the Lambda Architecture structures itself in a different way that greatly lessens the burdens of achieving highly available, eventually consistent systems.\n\n\nLack of human-fault tolerance\n\n\nThe last problem with fully incremental architectures is their inherent lack of human-fault tolerance. \nAn incremental system is constantly modifying the state it keeps in the database, which means a mistake can also modify the state in the database. Because mistakes are inevitable, the database in a fully incremental architecture is guaranteed to be corrupted.\n\n\nThis is one of the few complexities of fully incremental architectures that can be resolved without a complete rethinking of the architecture. Consider the two architectures shown in the following figure:\n\n\n\n\nSynchronous architecture, where the application makes updates directly to the database.\n\n\nAsynchronous architecture, where events go to a queue before updating the database in the background.\n\n\n\n\n\n\nIn both cases, every event is permanently logged to an events datastore. By keeping every event, if a human mistake causes database corruption, you can go back to the events store and reconstruct the proper state for the database. Because the events store is immutable and constantly growing, redundant checks, like permissions, can be put in to make it highly unlikely for a mistake to trample over the events store. This technique is also core to the Lambda Architecture and is discussed in depth in \nChapter 2\n and \nChapter 3\n.\n\n\nAlthough fully incremental architectures with logging can overcome the human-fault tolerance deficiencies of those without logging, the logging cannot handle the other complexities that have been discussed.\n\n\nFully incremental solution vs. Lambda Architecture solution\n\n\nOne of the example queries implemented throughout the book serves as a great contrast between fully incremental and Lambda architectures. The query has to do with pageview analytics and is done on two kinds of data coming in:\n\n\n\n\nPageviews\n, which contain a user ID, URL, and timestamp.\n\n\nEquivs\n, which contain two user IDs. An equiv indicates the two user IDs refer to the same person.\n\n\n\n\nThe goal of the query is to compute the number of unique visitors to a URL over a\nrange of time. Queries should be up to date with all data and respond with minimal\nlatency (less than 100 milliseconds). Below is the interface for the query:\n\n\nlong\n \nuniquesOverTime\n(\nString\n \nurl\n,\n \nint\n \nstartHour\n,\n \nint\n \nendHour\n)\n\n\n\n\n\n\nIf a person visits the same URL in a time range with two user IDs connected via equivs (even transitively), that should only count as one visit. A new equiv coming in can change the results for any query over any time range for any URL.\n\n\nInstead of showing details of the solutions which require covering many concepts such as indexing, distributed databases, batch processing, \nHyperLogLog\n, we\u2019ll focus on the characteristics of the solutions and the striking differences between them. The best possible fully incremental solution is shown in detail in Chapter 10, and the Lambda Architecture solution is built up in Chapter 8, 9, 14, and 15.\n\n\nThe two solutions can be compared on three axes: accuracy, latency, and throughput. [p14] The Lambda Architecture solution is significantly better in all respects. Lambda Architecture can produce solutions with higher performance in every respect, while also avoiding the complexity that plagues fully incremental architectures.\n\n\nLambda Architecture\n\n\nComputing arbitrary functions on an arbitrary dataset in real time is not a simple problem. There\u2019s no single tool that provides a complete solution. Instead, you have to use a variety of tools and techniques to build a complete Big Data system.\n\n\nThe main idea of the Lambda Architecture is to build Big Data systems as a series of layers, as shown in the following figure.\n\n\n\n\nEach layer satisfies a subset of the properties and builds upon the functionality provided by the layers beneath it. Each layer requires a lot of work to design, implement, and deploy, but the high-level ideas of the whole system are easy to understand.\n\n\nStarting everything from the \nquery\n = \nfunction\n(\nall data\n) equation, you could ideally run the functions on the fly to get the results.  However, this would take a huge amount of resources to do and would be unreasonably expensive. This is similar to having to read a petabyte dataset every time you wanted to answer the query of someone\u2019s current location.\n\n\nThe most obvious alternative approach is to precompute the query function, which is called the \nbatch view\n. Instead of computing the query on the fly, you read the results from the precomputed view. The precomputed view is indexed so that it can be accessed with random reads:\n\n\n\n\nbatch view = function(all data)\n\n\nquery = function(batch view)\n\n\n\n\nThis system works as follows:\n\n\n\n\nRun a function on all the data to get the batch view.\n\n\nWhen you want to know the value for a query, run a function on that batch view.\n\n\nThe batch view makes it possible to get the values you need from it very quickly, without having to scan everything in it.\n\n\n\n\nFor example, you\u2019re building a web analytics application, and you want to query the number of pageviews for a URL on any range of days. If you were computing the query as a function of all the data, you\u2019d scan the dataset for pageviews for that URL within that time range, and return the count of those results.\n\n\nInstead, the batch view approach (as show in the figure below) works as follows:\n\n\n\n\nRun a function on all the pageviews to precompute an index from a key of \n[url, day]\n to the count of the number of pageviews for that URL for that day.\n\n\nTo resolve the query, retrieve all values from that view for all days within that time range, and sum up the counts to get the result.\n\n\n\n\n\n\nCreating the batch view (with this approach described so far) is a high-latency operation, because it\u2019s running a function on all the data you have. By the time it finishes, a lot of new data will have collected that\u2019s not represented in the batch views, and the queries will be out of date by many hours. We will ignore this issue for the moment (because we'll be able to fix it) and assume it\u2019s fine for queries to be out of date by a few hours and continue exploring this idea of precomputing a batch view by running a function on the complete dataset.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np10 on Operational complexity\n\n\n\n\nIn a read/write database, as a disk index is incrementally added to and modified, parts of the index become unused. These unused parts take up space and eventually need to be reclaimed to prevent the disk from filling up. Reclaiming space as soon as it becomes unused is too expensive, so the space is occasionally reclaimed in bulk in a process called \ncompaction\n.\n\n\n\n\nWhat is a disk index?", 
            "title": "Chapter 1. A new paradigm for Big Data"
        }, 
        {
            "location": "/bd/ch2/", 
            "text": "Chapter 2. Data model for Big Data", 
            "title": "Chapter 2. Data model for Big Data"
        }, 
        {
            "location": "/bd/ch3/", 
            "text": "Chapter 3. Data model for Big Data: Illustration", 
            "title": "Chapter 3. Data model for Big Data: Illustration"
        }, 
        {
            "location": "/htae/", 
            "text": "HTAE\n\n\n\n\n0x200 Programming", 
            "title": "Contents"
        }, 
        {
            "location": "/htae/ch2/", 
            "text": "0x200 Programming", 
            "title": "0x200 Programming"
        }, 
        {
            "location": "/bash/", 
            "text": "Bash\n\n\nIntroduction\n\n\nWhat is Bash?\n\n\nBash is the shell, or command language interpreter, for the GNU operating system. The name is an acronym for the \"\nB\nourne-\nA\ngain \nSH\nell\", a pun on \nStephen Bourne\n, the author of the direct ancestor of the current Unix shell \nsh\n.\n\n\nWhat is a shell?\n\n\nA shell is simply a macro processor that executes commands. The term \"macro processor\" means functionality where text and symbols are expanded to create larger expressions.\n\n\nA Unix shell is both a command interpreter and a programming language:\n\n\n\n\nAs a command interpreter, the shell provides the user interface to the rich set of GNU utilities.\n\n\nThe programming language features allow these utilities to be combined. Files containing commands can be created, and become commands themselves. These new commands have the same status as system commands in directories such as \n/bin\n, allowing users or groups to establish custom environments to automate their common tasks.\n\n\n\n\nShells may be used interactively or non-interactively:\n\n\n\n\nIn interactive mode, they accept input typed from the keyboard.\n\n\nWhen executing non-interactively, shells execute commands read from a file.\n\n\n\n\nA shell allows execution of GNU commands, both synchronously and asynchronously:\n\n\n\n\nThe shell waits for synchronous commands to complete before accepting more input;\n\n\nAsynchronous commands continue to execute in parallel with the shell while it reads and executes additional commands.\n\n\nThe redirection constructs permit fine-grained control of the input and output of those commands. Moreover, the shell allows control over the contents of commands\u2019 environments.\n\n\n\n\nShells also provide a small set of built-in commands (builtins) implementing functionality impossible or inconvenient to obtain via separate utilities. For example:\n\n\n\n\ncd\n, \nbreak\n, \ncontinue\n, and \nexec\n cannot be implemented outside of the shell because they directly manipulate the shell itself.\n\n\nThe \nhistory\n, \ngetopts\n, \nkill\n, or \npwd\n builtins, among others, could be implemented in separate utilities, but they are more convenient to use as builtin commands.\n\n\n\n\nWhile executing commands is essential, most of the power (and complexity) of shells is due to their embedded programming languages. Like any high-level language, the shell provides variables, flow control constructs, quoting, and functions.\n\n\nShells offer features geared specifically for interactive use rather than to augment the programming language. These interactive features include job control, command line editing, command history and aliases.\n\n\nDefinitions\n\n\n\n\n\n\nPOSIX\n: A family of open system standards based on Unix. Bash is primarily concerned with the Shell and Utilities portion of the POSIX 1003.1 standard.\n\n\n\n\n\n\nblank\n: A space or tab character.\n\n\n\n\n\n\nbuiltin\n: A command that is implemented internally by the shell itself, rather than by an executable program somewhere in the file system.\n\n\n\n\n\n\ncontrol operator\n: A token that performs a control function. It is a newline or one of the following: \u2018||\u2019, \u2018\n\u2019, \u2018\n\u2019, \u2018;\u2019, \u2018;;\u2019, \u2018|\u2019, \u2018|\n\u2019, \u2018(\u2019, or \u2018)\u2019.\n\n\n\n\n\n\nexit status\n: The value returned by a command to its caller. The value is restricted to eight bits, so the maximum value is 255.\n\n\n\n\n\n\nfield\n: A unit of text that is the result of one of the shell expansions. After expansion, when executing a command, the resulting fields are used as the command name and arguments.\n\n\n\n\n\n\nfilename\n: A string of characters used to identify a file.\n\n\n\n\n\n\njob\n: A set of processes comprising a pipeline, and any processes descended from it, that are all in the same process group.\n\n\n\n\n\n\njob control\n: A mechanism by which users can selectively stop (suspend) and restart (resume) execution of processes.\n\n\n\n\n\n\nmetacharacter\n: A character that, when unquoted, separates words. A metacharacter is a \nblank\n or one of the following characters: \u2018|\u2019, \u2018\n\u2019, \u2018;\u2019, \u2018(\u2019, \u2018)\u2019, \u2018\n\u2019, or \u2018\n\u2019.\n\n\n\n\n\n\nname\n: A \nword\n consisting solely of letters, numbers, and underscores, and beginning with a letter or underscore. Names are used as shell variable and function names. Also referred to as an \nidentifier\n.\n\n\n\n\n\n\noperator\n: A \ncontrol operator\n or a \nredirection operator\n. See \nRedirections\n, for a list of redirection operators. Operators contain at least one unquoted \nmetacharacter\n.\n\n\n\n\n\n\nprocess group\n: A collection of related processes each having the same \nprocess group ID\n.\n\n\n\n\n\n\nprocess group ID\n: A unique identifier that represents a \nprocess group\n during its lifetime.\n\n\n\n\n\n\nreserved word\n: A word that has a special meaning to the shell. Most reserved words introduce shell flow control constructs, such as \nfor\n and \nwhile\n.\n\n\n\n\n\n\nreturn status\n: A synonym for \nexit status\n.\n\n\n\n\n\n\nsignal\n: A mechanism by which a process may be notified by the kernel of an event occurring in the system.\n\n\n\n\n\n\nspecial builtin\n: A shell builtin command that has been classified as special by the POSIX standard.\n\n\n\n\n\n\ntoken\n: A sequence of characters considered a single unit by the shell. It is either a \nword\n or an \noperator\n.\n\n\n\n\n\n\nword\n: A sequence of characters treated as a unit by the shell. Words may not include unquoted \nmetacharacters\n.\n\n\n\n\n\n\nRelationships of some definitions *\n\n\n\n\ntoken\n\n\nword\n\n\nname\n\n\nreserved word\n\n\n\n\n\n\noperator\n\n\ncontrol operator\n\n\nredirection operator\n\n\n\n\n\n\n\n\n\n\nmetacharacter\n\n\nblank\n\n\n\u2018|\u2019, \u2018\n\u2019, \u2018;\u2019, \u2018(\u2019, \u2018)\u2019, \u2018\n\u2019, or \u2018\n\u2019\n\n\n\n\n\n\nbuiltin\n\n\nspecial bulitin\n\n\n\n\n\n\n\n\nBasic Shell Features\n\n\nAll of the Bourne shell builtin commands are available in Bash, The rules for evaluation and quoting are taken from the POSIX specification for the \"standard\" Unix shell.\n\n\nThis chapter briefly summarizes the shell\u2019s \"building blocks\": commands, control structures, shell functions, shell parameters, shell expansions, redirections, which are a way to direct input and output from and to named files, and how the shell executes commands.\n\n\nShell Syntax\n\n\n\n\nIf the input indicates the beginning of a comment, the shell ignores the comment symbol (\u2018#\u2019), and the rest of that line.\n\n\nOtherwise, \nthe shell reads its input and divides the input into words and operators\n, employing the quoting rules to select which meanings to assign various words and characters.\n\n\n\n\n[\ns3.1\n]\n\n\nShell Operation\n\n\nBasically, the shell does the following:\n\n\n\n\nReads its input in one of the following way:\n\n\nfrom a file (see \nShell Scripts\n),\n\n\nfrom a string supplied as an argument to the \n-c\n invocation option (see \nInvoking Bash\n),\n\n\nfrom the user\u2019s terminal.\n\n\n\n\n\n\nBreaks the input into words and operators, obeying the quoting rules described in \nQuoting\n. These tokens are separated by \nmetacharacters\n. Alias expansion is performed by this step (see \nAliases\n).\n\n\nParses the tokens into simple and compound commands (see \nShell Commands\n).\n\n\nPerforms the various shell expansions (see \nShell Expansions\n), breaking the expanded tokens into lists of filenames (see \nFilename Expansion\n) and commands and arguments.\n\n\nPerforms any necessary redirections (see \nRedirections\n) and removes the redirection operators and their operands from the argument list.\n\n\nExecutes the command (see \nExecuting Commands\n).\n\n\nOptionally waits for the command to complete and collects its exit status (see \nExit Status\n).\n\n\n\n\nQuoting\n\n\nQuoting is used to remove the special meaning of certain characters or words to the shell. It is used to:\n\n\n\n\nDisable special treatment for special characters,\n\n\nPrevent reserved words from being recognized as such,\n\n\nPrevent parameter expansion.\n\n\n\n\nThere are three quoting mechanisms: the \nescape character\n, single quotes, and double quotes.\n\n\nEscape Character\n\n\nA non-quoted backslash \u2018\\\u2019 is the Bash escape character. It preserves the literal value of the next character that follows, with the exception of newline. If a \\newline pair appears, and the backslash itself is not quoted, the \\newline is treated as a line continuation.\n\n\nSingle Quotes\n\n\nEnclosing characters in single quotes (\u2018'\u2019) preserves the literal value of each character within the quotes. A single quote may not occur between single quotes, even when preceded by a backslash.\n\n\nDouble Quotes\n\n\nEnclosing characters in double quotes (\u2018\"\u2019) preserves the literal value of all characters within the quotes, with the exception of \u2018$\u2019, \u2018`\u2019, \u2018\\\u2019, and, when history expansion is enabled, \u2018!\u2019.\n\n\n\n\n\u2018$\u2019 and \u2018`\u2019 retain their special meaning within double quotes (see \nShell Expansions\n).\n\n\nThe backslash retains its special meaning only when followed by one of the following characters: \u2018$\u2019, \u2018`\u2019, \u2018\"\u2019, \u2018\\\u2019, or newline. Within double quotes, backslashes that are followed by one of these characters are removed. Backslashes preceding characters without a special meaning are left unmodified.\n\n\nA double quote may be quoted within double quotes by preceding it with a backslash.\n\n\nHistory expansion (if enabled) will be performed unless an \u2018!\u2019 appearing in double quotes is escaped using a backslash.\n\n\nThe backslash preceding the \u2018!\u2019 is not removed.\n\n\n\n\nExamples on history expansion and \u2018!\u2019 (history expansion enabled):\n\n\n$ foo\n\n\n-bash: foo: command not found\n\n\n$ echo \n!!\n\n\necho \nfoo\n\n\nfoo\n\n\n$ echo \n\\!!\n\n\n\\!!\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\nThe GNU Bash Reference Manual\n\n\nBash Hackers Wiki", 
            "title": "Bash"
        }, 
        {
            "location": "/c/", 
            "text": "C\n\n\n\n\nIf you think like a computer, writing C actually makes sense.\n\n Linus Torvalds \n\n\n\n\nFirst-class ADT\n\n\nBad:\n\n\n/* Include guards and include files omitted. */\n\n\n\n#define MAX_NO_OF_ORDERS 42\n\n\n\n/* Internal representation of a customer. */\n\n\n\ntypedef\n \nstruct\n\n\n\n{\n\n    \nconst\n \nchar\n*\n \nname\n;\n\n    \nAddress\n \naddress\n;\n\n    \nsize_t\n \nnoOfOrders\n;\n\n    \nOrder\n \norders\n[\nMAX_NO_OF_ORDERS\n];\n\n\n}\n \nCustomer\n;\n\n\n\nvoid\n \ninitCustomer\n(\nCustomer\n*\n \ntheCustomer\n,\n\n                  \nconst\n \nchar\n*\n \nname\n,\n\n                  \nconst\n \nAddress\n*\n \naddress\n);\n\n\n\nvoid\n \nplaceOrder\n(\nCustomer\n \n*\ncustomer\n,\n \nconst\n \nOrder\n*\n \norder\n);\n\n\n\n/* A lot of other related functions... */\n\n\n\n\n\n\nGood:\n\n\n\n\n1_FirstClassADT\n\n\n\n\nInformation hiding\n\n\nThe First-class ADT pattern will eliminate dependency problems. Thuis pattern provides a method that separates interface from implementation.\n\n\nIncomplete Types\n\n\nThe C standard (C99) allows us to declare objects of incomplete types in a context where their sizes aren\u2019t needed.\n\n\nIn the following code:\n\n\n/* Pointer to an incomplete type */\n\n\ntypedef\n \nstruct\n \nCustomer\n*\n \nCustomerPtr\n;\n\n\n\n\n\n\nInstances of this pointer will serve as a handle for the clients of a first-class ADT. This mechanism enforces the constraint on clients to use the provided interface functions (\nCustomer.h\n) because there is no way a client can access a field in the \nCustomer\n structure (the C language \ndoes not allow an incomplete type to be de-referenced\n). The type is considered complete as soon as the compiler detects a subsequent specifier (\nCustomer.c\n), with the same tag, and a declaration list containing the members.\n\n\nCopy Semantics\n\n\nClients only use a handle, which is declared as a pointer, to the ADT. Copies of a handle are simply pointer assignment.\n\n\nDependencies managed\n\n\nInternals of the data structure are encapsulated in the implementation and clients cannot access them.\n\n\nConsequences\n\n\nPros:\n\n\n\n\nImproved encapsulation\n\n\nLoose coupling\n\n\nControlled construction and destruction\n\n\n\n\nCons:\n\n\n\n\nExtra level of indirection\n\n\nIncreased dynamic memory usage\n\n\n\n\n\n\nReferences\n\n\n\n\n[PIC]: \nPatterns in C", 
            "title": "C"
        }, 
        {
            "location": "/golang/", 
            "text": "Go\n\n\nHow to Write Go Code\n\n\n\n\nHow to Write Go Code\n\n\n\n\nBasic constructs and elementary data types\n\n\nFilenames, Keywords and Identifiers\n\n\n\n\nFilenames\n consist of lowercase-letters (that may separated by underscores _), like \nscanner.go\n and \nscanner_test.go\n.  Filenames may not contain spaces or any other special characters.\n\n\nIdentifiers\n begin with a letter (a \nletter\n is every letter in Unicode UTF-8 or _) and followed by 0 or more letters or Unicode digits, like: \nX56\n, \ngroup1\n, \n_x23\n, \ni\n, \n\u04e9\u051112\n.\n\n\nThe \n_\n itself is a special identifier, called the \nblank identifier\n. It can be used in declarations or variable assignments like any other identifier (and any type can be assigned to it), but its value is discarded, so it cannot be used anymore in the code that follows.\n\n\n\n\n\n\nKeywords\n or reserved words are: \nbreak\n, \ndefault\n, \nfunc\n, \ninterface\n, \nselect\n, \ncase\n, \ndefer\n, \ngo\n, \nmap\n, \nstruct\n, \nchan\n, \nelse\n, \ngoto\n, \npackage\n, \nswitch\n, \nconst\n, \nfallthrough\n, \nif\n, \nrange\n, \ntype\n, \ncontinue\n, \nfor\n, \nimport\n, \nreturn\n, \nvar\n.\n\n\nPredeclared identifiers\n (names of elementary types and some basic built-in functions): \nappend\n, \nbool\n, \nbyte\n, \ncap\n, \nclose\n, \ncomplex\n, \ncomplex64\n, \ncomplex128\n, \nuint16\n, \ncopy\n, \nfalse\n, \nfloat32\n, \nfloat64\n, \nimag\n, \nint\n, \nint8\n, \nint16\n, \nuint32\n, \nint32\n, \nint64\n, \niota\n, \nlen\n, \nmake\n, \nnew\n, \nnil\n, \npanic\n, \nuint64\n, \nprint\n, \nprintln\n, \nreal\n, \nrecover\n, \nstring\n, \ntrue\n, \nuint\n, \nuint8\n, \nuintptr\n,\n\n\nPrograms consist out of keywords, constants, variables, operators, types and functions.\n\n\nDelimiters: parentheses \n( )\n, brackets \n[ ]\n and braces \n{ }\n.\n\n\nPunctuation characters: \n.\n, \n;\n, \n...\n.\n\n\nCode is structured in \nstatements\n. A statement doesn\u2019t need to end with a \n;\n. The Go compiler automatically inserts semicolons at the end of statements. However, if multiple statements are written on one line (which is not encouraged for readability reasons), they must be separated by \n;\n.\n\n\n\n\nPackages, import and visibility\n\n\nhello_world.go\n\n\nEvery go file belongs to one and only one \npackage\n (like a library or namespace in other languages). Many different .go files can belong to one package, so the filename(s) and package name are generally not the same.\n\n\n\n\nThe package to which the code-file belongs must be indicated on the first line, e.g. \npackage main\n.\n\n\nA standalone executable belongs to package \nmain\n and each Go application contains one package \nmain\n.\n\n\nA package name is written in lowercase letters.\n\n\n\n\nAn application can consist of different packages. Even if you use only package \nmain\n, you don\u2019t have to stuff all code in one big file: you can make a number of smaller files each having \npackage main\n as the first codeline. If you compile a source file with a package name other than \nmain\n, like \npack1\n, the object file is stored in \npack1.a\n.\n\n\nThe \nstandard library\n contains ready-to-use packages of the Go installation.\n\n\nPackage compilation\n\n\n\n\nTo build a program, the packages, and the files within them, must be compiled in the correct order.  Package dependencies determine the order in which to build packages.\n\n\nWithin a package, the source files must all be compiled together. The package is compiled as a unit, and by convention each directory contains one package.\n\n\nIf a package is changed and recompiled, all the client programs that use this package must be recompiled.\n\n\nThe package model uses \nexplicit dependencies\n to enable faster builds. [TWTG p52]\n\n\n\n\nImport\n\n\nA Go program is created by linking together a set of packages through the \nimport\n keyword. For example, \nimport \"fmt\"\n tells Go that this program needs (functions, or other elements, from) the package \nfmt\n.\n\n\n\n\nThe package names are enclosed within \"\"\n\n\nImport loads the public declarations from the compiled package; it does not insert the source code.\n\n\n\n\nIf multiple packages are needed, they can each be imported by a separate statement:\n\n\nimport\n \nfmt\n\n\nimport\n \nos\n\n\n\n\n\n\nThe shorter and more elegant way (called \nfactoring the keyword\n, also applicable to \nconst\n, \nvar\n and \ntype\n) is available (\nit is also clearer to list the package names in alphabetical order\n):\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nos\n\n\n)\n\n\n\n\n\n\n\n\nIf the name of a package does not start with . or /, like \"fmt\" or \"container/list\", Go looks for it in the global Go tree.\n\n\nIf it starts with ./ the package is searched in the actual directory\n\n\nIf it starts with /, the package is searched for in the (absolute) path indicated.\n\n\n\n\nApart from \n_\n, identifiers of code-objects have to be unique in a package: there can be no naming conflicts. But the same identifier can be used in different packages: the package name qualifies it to be different.\n\n\nVisibility rule\n\n\nPackages expose their code-objects to code outside of the package according to the following rule:\n\n\n\n\nWhen the identifier (of a constant, variable, type, function, struct field, etc.) starts with an uppercase letter, like \nGroup1\n, then the \"object\" with this identifier is visible in code outside the package (thus available to client-programs, \"importers\" of the package), it is said to be exported (like public in OO languages).\n\n\nIdentifiers which start with a lowercase letter are not visible outside the package, but they are visible and usable in the whole package (like private).\n\n\n\n\nSome notes on this rule:\n\n\n\n\nUppercase letters can come from the entire Unicode-range, like Greek; not only ASCII letters are allowed.\n\n\nImporting a package gives (only) access to the exported objects in that package.\n\n\nPackages also serve as namespaces and can help to avoid name-clashes (name-conflicts): variables with the same name in two packages are differentiated by their package name. For example, \npack1.Thing\n and \npack2.Thing\n.\n\n\n\n\nA package can also be given another name (an \nalias\n), for example:\n\n\npackage\n \nmain\n\n\n\nimport\n \nfm\n \nfmt\n  \n// alias\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nfm\n.\nPrintln\n(\nhello, world\n)\n\n\n}\n\n\n\n\n\n\nImporting a package which is not used in the rest of the code is a build-error.\n\n\nPackage level declarations and initializations\n\n\nAfter the import statement, zero or more constants (\nconst\n), variables (\nvar)\n, and types (\ntype\n) can be declared; these are \nglobal\n (have package scope) and are known in all functions in the code (like \nc\n and \nv\n in \ngotemplate.go\n below), and they are followed by one or more functions (\nfunc\n).\n\n\n\n\ngotemplate.go\n\n\n\n\nFunctions\n\n\nThe simplest function declaration has the format:\n\n\nfunc\n \nfunctionName\n()\n\n\n\n\n\n\nA \nmain\n function as starting is required. The \nmain\n function must have no arguments and no return values results.\n\n\nWhen the program executes, after initializations the first function called (the entry-point of the application) will be \nmain.main()\n. The program exits immediately and successfully when \nmain.main\n returns.\n\n\nThe code in functions (the body) is enclosed between braces: \n{ }\n.\n\n\n\n\nThe first \n{\n must be on the same line as the function declaration: this is imposed by the compiler and \ngofmt\n.\n\n\nThe last \n}\n is positioned after the function code beneath function.\n\n\nFor small functions it is allowed that everything is written on one line, like for example: \nfunc Sum(a, b int) int { return a + b }\n.\n\n\nThe same rule applies wherever \n{ }\n are used (for example: \nif\n, etc.).\n\n\n\n\nSchematically, a general function looks like:\n\n\nfunc\n \nfunctionName\n(\nparam1\n \ntype1\n,\n \nparam2\n \ntype2\n,\n \n...\n)\n \n(\nret1\n \ntype1\n,\n \nret2\n \ntype2\n,\n \n...\n)\n \n{\n\n    \n// ...\n\n\n}\n\n\n\n\n\n\nFunction names\n\n\n\n\nPascalCasing\n (exported): function names only start with a capital letter when the function has to be used outside the package.\n\n\ncamelCasing\n (private): every new word in the name starts with a capital letter.\n\n\n\n\nfmt.Print\n and \nfmt.Println\n\n\n\n\nThe line \nfmt.Println(\"hello, world\")\n calls the function \nPrintln\n from the package \nfmt\n, which prints the string-parameter to the console, followed by a newline-character \n\\n\n.\n\n\nThe same result can be obtained with \nfmt.Print(\"hello, world\\n\")\n.\n\n\nPrint\n and \nPrintln\n can also be applied to variables, like in: \nfmt.Println(arr)\n; they use the default output-format for the variable \narr\n.\n\n\n\n\nprint\n and \nprintln\n\n\nPrinting a string or a variable can be done even simpler with the predefined functions \nprint\n and \nprintln\n. For example,\n\n\nprint\n(\nABC\n)\n\n\nprintln\n(\nABC\n)\n\n\nprintln\n(\ni\n)\n\n\n\n\n\n\nThese are only to be used in the debugging phase; when deploying a program replace them with their \nfmt\n relatives.\n\n\nComments\n\n\nComments are not compiled. They are used by \ngodoc\n.\n\n\n\n\nA one-line comment starts with \n//\n, at the beginning or somewhere in a line; this is mostly used.\n\n\nA multi-line or block-comment starts with \n/*\n and ends with \n*/\n, nesting is not allowed; this is used for making package documentation and commenting out code.\n\n\n\n\n[TWTG p56]\n\n\nEvery package should have a package comment, a block comment immediately preceding the package statement. A package can be spread over many files, but the comment needs to be in only one of them. This comment is shown when a developer demands info of the package with \ngodoc\n.\n\n\nTypes\n\n\nA declaration of a variable with \nvar\n automatically initializes it to the zero-value defined for its type. A type defines the set of values and the set of operations that can take place on those values.\n\n\nTypes can be:\n\n\n\n\nElementary\n (or \nprimitive\n): int, float, bool, string,\n\n\nStructured\n (or \ncomposite\n): struct, array, slice, map, channel,\n\n\nInterfaces\n only describe the behavior of a type.\n\n\n\n\nA structured type which has no real value (yet) has the value \nnil\n, which is also the default value for these types (in C anc C++ it is NULL).\n\n\nUse the keyword \ntype\n for defining your own type (usually a struct type). It is also possible to define an \nalias\n for an existing type, for example:\n\n\ntype\n \n(\n\n    \nIZ\n \nint\n\n    \nFZ\n \nfloat\n\n    \nSTR\n \nstring\n\n\n)\n\n\n\n\n\n\nProgram structure\n\n\ngotemplate.go\n is an example of the general structure of a Go program. This structure is not necessary, the compiler does not mind if \nmain()\n or the variable declarations come last, but a uniform structure makes Go code better readable from top to bottom:\n\n\n\n\nAfter import: declare constants, variables and the types\n\n\nThen comes the \ninit()\n function if there is any: this is a special function that every package can contain and that is executed first.\n\n\nThen comes the \nmain()\n function (only in the package \nmain\n)\n\n\nThen come the rest of the functions:\n\n\nThe methods on the types first, or;\n\n\nThe functions in order as they are called from \nmain()\n onwards, or;\n\n\nThe methods and functions alphabetically if the number of functions is high.\n\n\n\n\n\n\n\n\nOrder of execution\n\n\n\n\nAll packages in package \nmain\n are imported in the order as indicated.\n\n\nIn every package, if it imports packages, Step 1 is called for this package (recursively) but a certain package is imported only once.\n\n\nFor every package (in reverse order of dependencies) all constants and variables are evaluated, and the \ninit()\n if it contains this function.\n\n\nIn package \nmain\n the same happens, and then \nmain()\n starts executing.\n\n\n\n\nConversions\n\n\nA value can be \nconverted\n (\ncast\n, \ncoerced\n) into a value of another type. Go never does \nimplicit\n (automatic) conversion, it must be done explicitly with the syntax like a function call, as in \nvalueOfTypeB = typeB(valueOfTypeA)\n. For example:\n\n\na\n \n:=\n \n5.0\n\n\nb\n \n:=\n \nint\n(\na\n)\n\n\n\n\n\n\nThis can only succeed in certain well defined cases (from a narrower type to a broader type, for example: \nint16\n to \nint32\n). When converting from a broader type to a narrower type (for example: \nint32\n to \nint16\n, or \nfloat32\n to \nint\n) loss of value (\ntruncation\n) can occur. When the conversion is impossible and the compiler detects this, a compile-error is given, otherwise a runtime-error occurs.\n\n\nVariables with the same underlying type can be converted into one another:\n\n\nvar\n \na\n \nIZ\n \n=\n \n5\n\n\nc\n \n:=\n \nint\n(\na\n)\n\n\nd\n \n:=\n \nIZ\n(\nc\n)\n\n\n\n\n\n\nNaming\n\n\n[TWTG p60]\n\n\n\n\nNames - Effective Go\n\n\n\n\nConstants\n\n\nA constant (\nconst\n) contains data which does not change. This data can only be of type boolean, number (integer, float or complex) or string. It is defined with the format \nconst identifier [type] = value\n (type specifier \n[type]\n is optional, the compiler can implicitly derive the type from the value). For example:\n\n\nconst\n \nb\n \nstring\n \n=\n \nabc\n\n\nconst\n \nPi\n \n=\n \n3.14159\n\n\n\n\n\n\nA value derived from an untyped constant becomes typed when it is used within a context that requires a typed value. For example:\n\n\nvar\n \nn\n \nint\n\n\nf\n(\nn\n \n+\n \n5\n)\n \n// untyped numeric constant 5 becomes typed as int\n\n\n\n\n\n\nConstants must be evaluated at compile time; a const can be defined as a calculation, but all the values necessary for the calculation must be available at compile time. For example:\n\n\nconst\n \nc1\n \n=\n \n2\n/\n3\n \n// ok\n\n\nconst\n \nc2\n \n=\n \ngetNumber\n()\n \n// gives the build error: getNumber() used as value\n\n\n\n\n\n\nConstants can be used for \nenumerations\n:\n\n\nconst\n \n(\n\n    \nUnknown\n \n=\n \n0\n\n    \nFemale\n \n=\n \n1\n\n    \nMale\n \n=\n \n2\n\n\n)\n\n\n\n\n\n\nIn such cases, the value \niota\n can be used to enumerate the values:\n\n\nconst\n \n(\n  \n// iota is reset to 0\n\n    \nc0\n \n=\n \niota\n  \n// c0 == 0\n\n    \nc1\n \n=\n \niota\n  \n// c1 == 1\n\n    \nc2\n \n=\n \niota\n  \n// c2 == 2\n\n\n)\n\n\n\n\n\n\nThis can be shortened to:\n\n\nconst\n \n(\n\n    \nc0\n \n=\n \niota\n\n    \nc1\n\n    \nc2\n\n\n)\n\n\n\n\n\n\n[TWTG p62-63]\n\n\nSee \nConstant declarations\n and \niota\n.\n\n\nVariables\n\n\nThe general form for declaring a variable is \nvar identifier type\n. The type is written after the identifier of the variable, contrary to almost any other programming language. Why did the Go designers chose for this convention? It removes some ambiguity which can exist in C declarations, for example, in \nint* a, b;\n, only \na\n is a pointer and \nb\n is not; in Go, they can both be declared pointers as follows: \nvar a, b *int\n.\n\n\nVariables can be declared using the following format:\n\n\nvar\n \na\n \nint\n\n\nvar\n \nb\n \nbool\n\n\nvar\n \nstr\n \nstring\n\n\n\n\n\n\nThis can be also written as (\nmainly used to declare variables globally\n):\n\n\nvar\n \n(\n\n    \na\n \nint\n\n    \nb\n \nbool\n\n    \nstr\n \nstring\n\n\n)\n\n\n\n\n\n\nWhen a variable is declared it contains automatically the default \nzero value\n for its type: \nfalse\n for booleans, 0 for integers, 0.0 for floats, \"\" for strings, and \nnil\n for pointers, functions, interfaces, slices, channels, and maps. \nAll memory in Go is initialized.\n\n\nA variable (constant, type, function) is only known in a certain range of the program, called the \nscope\n:\n\n\n\n\nVariables declared outside of any function (at the top level) have \nglobal scope\n (or \npackage scope\n): they are visible and available in all source files of the package.\n\n\nVariables declared in a function have \nlocal scope\n: they are only known in that function, the same goes for parameters and return-variables.\n\n\nVariables defined inside such a construct (e.g. \nif\n, \nfor\n) are only known within that construct (\nconstruct scope\n). Mostly you can think of a scope as the codeblock ( surrounded by \n{ }\n ) in which the variable is declared.\n\n\n\n\nAlthough identifiers have to be unique, an identifier declared in a block may be redeclared in an inner block: in this block (but only there) the redeclared variable takes priority and \nshadows\n the outer variable with the same name; if used, care must be taken to avoid subtle errors.\n\n\nVariables can get their value (which is called \nassigning\n and uses the assignment operator \n=\n) at compile time, but a value can also be computed or changed during runtime. For example:\n\n\na\n \n=\n \n15\n\n\nb\n \n=\n \nfalse\n\n\n\n\n\n\nIn general, \na\n variable \nb\n can only be assigned to a variable \na\n as in \na = b\n, when \na\n and \nb\n are of the same type.\n\n\nDeclaration and assignment (initialization) can be combined, in the general format \nvar identifier [type] = value\n. For example:\n\n\nvar\n \na\n \nint\n \n=\n \n15\n\n\nvar\n \nb\n \nbool\n \n=\n \nfalse\n\n\n\n\n\n\nHowever, the Go compiler is intelligent enough to derive the type of a variable from its value (dynamically, also called \nautomatic type inference\n, similar to Python and Ruby, but there it happens in run time), so the following forms (omitting the type) are also correct:\n\n\nvar\n \na\n \n=\n \n15\n\n\nvar\n \nb\n \n=\n \nfalse\n\n\n// Or, equivalently:\n\n\nvar\n \n(\n\n    \na\n \n=\n \n15\n\n    \nb\n \n=\n \nfalse\n\n\n)\n\n\n\n\n\n\nIt can still be useful to include the type information in the case where you want the variable to be typed something different than what would be inferred, such as in: \nvar n int64 = 2\n.\n\n\nHowever, an expression (declaration) like \nvar a\n is not correct, because the compiler has no clue about the type of \na\n.\n\n\nVariables could also be expressions computed at runtime, like:\n\n\nvar\n \n(\n\n    \nHOME\n \n=\n \nos\n.\nGetenv\n(\nHOME\n)\n\n    \nUSER\n \n=\n \nos\n.\nGetenv\n(\nUSER\n)\n\n\n)\n\n\n\n\n\n\nThe \nvar\n syntax is mainly used at a global, package level; in functions it is replaced by the short declaration syntax \n:=\n.\n\n\nValue types and reference types\n\n\nMemory in a computer is used in programs as a enormous number of \nwords\n:\n\n\n\n\nAll words have the same length of 32 bits (4 bytes) or 64 bits (8 bytes), according to the processor and the operating system.\n\n\nAll words are identified by their memory address (represented as a hexadecimal number).\n\n\n\n\nAll variables of elementary (primitive) types like int, float, bool, string are \nvalue types\n. They point directly to their value contained in memory.\n\n\nComposite types like arrays and structs are also value types.\n\n\nWhen assigning the value of a value type to another variable: \nj = i\n, a copy of the original value \ni\n is made in memory, as illustrated in the figure below:\n\n\n\n\nThe memory address of the word where variable \ni\n is stored is given by \ni\n.\n\n\nA \nreference type\n variable \nr1\n contains the address of the memory location where the value of \nr1\n is stored (or at least the first word of it). This address, called a \npointer\n, is also contained in a word.\n\n\nThe different words a reference type points to could be sequential memory addresses (the memory layout is said to be contiguously) which is the most efficient storage for computation, or the words could be spread around, each pointing to the next.\n\n\nWhen assigning \nr2 = r1\n, only the reference (the address) is copied, as illustrated in the figure below:\n\n\n\n\nIf the value of \nr1\n is modified, all references of that value (like \nr1\n and \nr2\n) then point to the modified content.\n\n\nIn Go, pointers are reference types, as well as slices, maps and channels. The variables that are referenced are stored in the heap, which is garbage collected and which is a much larger memory space than the stack.\n\n\nPrinting\n\n\n\n\nThe function \nfmt.Printf\n is visible outside the \nfmt\n package because it starts with a \nP\n, and is used to print output to the console. It generally uses a format string as its first argument.\n\n\nThis format string can contain one or more format-specifiers \n%..\n, where \n..\n denotes the type of the value to be inserted, e.g. \n%s\n stands for a string value, \n%v\n is the general default format specifier.\n\n\n\n\n\n\nThe function \nfmt.Sprintf\n behaves in exactly the same way as Printf, but simply returns the formatted string.\n\n\nThe functions \nfmt.Print\n and \nfmt.Println\n perform fully automatic formatting of their arguments using the format-specifier \n%v\n, adding spaces between arguments and the latter a newline at the end. For example:\n\n\nfmt.Print(\"Hello:\", 23)\n produces as output: \nHello: 23\n.\n\n\n\n\n\n\n\n\nShort forms of declaration and assignment\n\n\nInitializing declaration with \n:=\n\n\nWith the type omitted, the keyword \nvar\n is pretty superfluous (e.g. \nvar a = 50\n), so it may be written as \na: = 50\n, and the types of is inferred by the compiler.\n\n\na := 50\n is the preferred form, but \nit can only be used inside functions, not in package scope.\n The \n:=\n operator effectively makes a new variable; it is also called an \ninitializing declaration\n.\n\n\nIf after the lines above in the same codeblock we declare \na := 20\n, this is not allowed: the compiler gives the error \"no new variables on left side of \n:=\n\"; however \na = 20\n is ok because then the same variable only gets a new value.\n\n\nUndeclared and unused variables\n\n\n\n\nA variable a which is used, but not declared, gives a compiler error: \"undefined: a\".\n\n\nDeclaring a \nlocal\n variable, but not using it, is a compiler error: \"a declared and not used\". However, for global variables, this is allowed. [TWTG p69]\n\n\n\n\nMultiple declaration and assignment\n\n\n\n\nMultiple declarations of variables of the same type on a single line, like: \nvar a, b, c int\n. This is an important reason why the type is written after the identifier(s).\n\n\nMultiple assignments of variables (parallel or simultaneous assignment):\n\n\nFor already-declared variables: \na, b, c = 5, 7, \"abc\"\n\n\nFor undeclared variables: \na, b, c := 5, 7, \"abc\"\n\n\n\n\n\n\n\n\nWith two variables it can be used to perform a \nswap\n of the values: \na, b = b, a\n.\n\n\nThe blank identifier \n_\n can also be used to throw away values, like the value 5 in: \n_, b = 5, 7\n\n\n_\n is in effect a write-only variable, you cannot ask for its value. \nIt exists because a declared variable in Go must also be used, and sometimes you don\u2019t need to use all return values from a function.\n\n\nThe multiple assignment is also used when a function returns more than 1 value, for example: \nval, err = func1(var1)\n.\n\n\nStructs\n\n\nVisibility\n\n\nThe naming of the struct type and its fields adheres to the visibility rule. It is possible that an exported struct type has a mix of fields: some exported, others not.\n\n\nFactory methods\n\n\nForce using factory methods on a private type [TWTG p233]:\n\n\nwrong\n \n:=\n \nnew\n(\nmatrix\n.\nmatrix\n)\n    \n// will NOT compile (matrix is private)\n\n\nright\n \n:=\n \nmatrix\n.\nNewMatrix\n(\n...\n)\n   \n// the ONLY way to instantiate a matrix\n\n\n\n\n\n\nStructs with tags\n\n\nOnly the package \nreflect\n can access tag content. \nreflect.TypeOf()\n on a variable gives the right type; if this is a struct type, it can be indexed by \nField\n, and then the \nTag\n property can be used. For example:\n\n\n\n\nstruct_tag.go\n\n\n\n\nAnonymous fields and embedded structs\n\n\nConflicting names [TWTG p239]\n\n\n\n\nAn outer name hides an inner name. This provides a way to override a field or method.\n\n\nIf the same name appears twice at the same level, it is an error if the name is used by the program.\n\n\n\n\nMethods\n\n\n\n\nReceiver type\n\n\nMethod set: collection of all the methods on a given type \nT\n (or \n*T\n)\n\n\nNo method overloading\n\n\nA method and the type on which it acts must be defined in the same package\n\n\nPointer or value as receiver: if for a type \nT\n a method \nMeth()\n exists on \n*T\n and \nt\n is a variable of type \nT\n, then \nt.Meth()\n is automatically translated to \n(\nt).Meth()\n [TWTG p246]\n\n\n\n\nMethods on embedded types and inheritance\n\n\n\n\nOverriding: \nmethod4.go\n [TWTG p250]\n\n\nEmbedding multiple anonymous types: \nmult_inheritance.go\n [TWTG p253-254]\n\n\n\n\nEmbed functionality in a type\n\n\n\n\nAggregation (or composition): include a named field of the type of the wanted functionality, \nembed_func1.go\n\n\nEmbedding: \nembed_func2.go\n\n\n\n\nFormat specifiers\n\n\nString()\n-method on a type [TWTG p259]:\n\n\n\n\n%T\n: complete type specification\n\n\n%#v\n complete output of the instance with its fields\n\n\n\n\nInterfaces\n\n\nInterfaces in Go provide a way to specify the behavior of an object: if something can do this, then it can be used here.\n\n\n\n\nA type doesn\u2019t have to state explicitly that it implements an interface: interfaces are satisfied implicitly. Multiple types can implement the same interface.\n\n\nA type that implements an interface can also have other functions.\n\n\nA type can implement many interfaces.\n\n\nAn interface type can contain a reference to an instance of any of the types that implement the interface (an interface has what is called a dynamic type)\n\n\n\n\nThe interface variable both contains the value of the receiver instance and a pointer to the appropriate method in a method table.\n\n\n\n\ninterfaces_poly.go\n\n\n\n\nInterface embedding interfaces\n\n\nAn interface can contain the name of one or more other interface(s), which is equivalent to explicitly enumerating the methods of the embedded interface in the containing interface. [TWTG p270]\n\n\nDetect and convert the type of an interface variable: type assertions\n\n\nWe can test if \nvarI\n (interface variable) contains at a certain moment a variable of type \nT\n with the type assertion test [TWTG p271]:\n\n\nif\n \nv\n,\n \nok\n \n:=\n \nvarI\n.(\nT\n);\n \nok\n \n{\n\n    \n// checked type assertion\n\n\n}\n\n\n\n\n\n\n\n\ntype_interfaces.go\n\n\n\n\nThe type switch\n\n\n\n\nType switch\n\n\n\n\ntype_switch.go\n\n\n\n\n\nTesting if a value implements an interface\n\n\nv\n is a value and we want to test whether it implements the \nStringer\n interface:\n\n\nif\n \nsv\n,\n \nok\n \n:=\n \nv\n.(\nStringer\n);\n \nok\n \n{\n\n    \nfmt\n.\nPrintf\n(\nv implements String(): %s\\n\n,\n \nsv\n.\nString\n());\n \n// note: sv, not v\n\n\n}\n\n\n\n\n\n\nWriting functions so that they accept an interface variable as a parameter makes them more general. Use interfaces to make code more generally applicable.\n\n\nVariables of interface type\n\n\nA variable of interface type stores a pair: the concrete value assigned to the variable, and that value's type descriptor.\n\n\n\n\nThe representation of an interface\n\n\n\n\nUsing method sets with interfaces\n\n\n\n\nPointer methods can be called with pointers.\n\n\nValue methods can be called with values.\n\n\nValue-receiver methods can be called with pointer values because they can be dereferenced first.\n\n\nPointer-receiver methods \ncannot\n be called with values, however, because the value stored inside an interface has no address.\n\n\n\n\nExamples:\n\n\n\n\nmethodset2.go\n\n\nsort.go\n\n\nsortmain.go\n\n\n\n\nEmpty Interface\n\n\nA variable of empty interface type \ninterface{}\n can through assignment receive a variable of any type.\n\n\nInterface Slice\n\n\n\n\nInterface slice\n\n\n\n\nInterface to interface\n\n\nAn interface value can also be assigned to another interface value, as long as the underlying value implements the necessary methods.\n\n\ntwtg_11.9.5.go\n\n\n\n\n\nReflection\n\n\nReflection is the ability of a program to examine its own structure, particularly through the types; it\u2019s a form of \nmetaprogramming\n. \nreflect\n can be used to investigate types and variables at runtime, e.g. its size, its methods, and it can also call these methods \"dynamically\".\n\n\n\n\nreflect.TypeOf\n\n\nreflect.ValueOf\n\n\n\n\ntwtg_11.10.1.go\n\n\n\n\n\n\n\nv.Kind()\n: returns a constant indicating the type\n\n\nv.Interface()\n: recovers the (interface) value\n\n\n\n\nExample:\n\n\n\n\nreflect1.go\n\n\n\n\nSetting a value through reflection\n\n\n\n\nSettability\n: a \nValue\n can be changed only if it is addressable and was not obtained by the use of unexported struct fields, \nreflect2.go\n\n\n\n\nReflection on structs\n\n\n\n\nreflect_struct.go\n\n\n\n\nPrintf\n and reflection\n\n\nPrintf\n uses the reflection package to unpack it and discover the argument list, \nprint.go\n\n\nInterfaces and dynamic typing\n\n\n\n\nIn Go there are no classes: data (structures, or more general types) and methods are treated \northogonally\n, they are much more \nloosely coupled\n.\n\n\nThere is no requirement for explicitly declaring that a type satisfies an interface. This allows interfaces to be defined and used without having to modify existing code.\n\n\nTypes implementing an interface can be passed to any function which takes that interface as an argument. This resembles much more the \nduck typing\n in dynamic languages.\n\n\nExtraction of an interface reduces thereby the number of types and methods needed [TWTG p301]: \nmulti_interfaces_poly.go\n\n\nIf a type must implement a new interface, the type itself doesn\u2019t have to be changed, you must only make the new method(s) on the type. [TWTG p303]\n\n\n\n\n\n\nEmpty interface and function overloading [TWTG p304]\n\n\nInheritance of interfaces:\n\n\nA type includes (embeds) another type (which implements one or more interfaces) as a pointer, then the type can use all of the interfaces-methods. [TWTG p304]\n\n\nA type can also inherit from multiple interfaces providing something like \nmultiple inheritance\n. [TWTG p305]\n\n\n\n\n\n\n\n\nSummary of object-orientedness of Go\n\n\n[TWTG p306]\n\n\n\n\nEncapsulation (data hiding): visibility rule\n\n\nPackage scope\n: lowercase\n\n\nExported\n: uppercase\n\n\n\n\n\n\nInheritance: embedding one or multiple types\n\n\nPolymorphism: a variable of a type can be assigned to a variable of any interface it implements. Types and interfaces are loosely coupled; multiple inheritance is possible through implementing multiple interfaces.\n\n\n\n\nHigher order functions\n\n\n[TWTG p306-309]\n\n\n\n\nReferences\n\n\n\n\n[TWTG] \nThe Way To Go: A Thorough Introduction To The Go Programming Language\n\n\n[DOC] \nDocumentation\n\n\n[SPEC] \nThe Go Programming Language Specification\n\n\n[EG] \nEffective Go\n\n\n[TGB] \nThe Go Blog", 
            "title": "Go"
        }, 
        {
            "location": "/python/", 
            "text": "Python\n\n\nA Tutorial Introduction\n\n\nGenerators\n\n\nInstead of returning a single value, a function can generate an entire sequence of results if it uses the \nyield\n statement. For example:\n\n\ndef\n \ncountdown\n(\nn\n):\n\n    \nprint\n \nCounting down!\n\n    \nwhile\n \nn\n \n \n0\n:\n\n        \nyield\n \nn\n \n# Generate a value (n)\n\n        \nn\n \n-=\n \n1\n\n\n\n\n\n\nAny function that uses \nyield\n is known as a \ngenerator\n. Calling a generator function creates an object that produces a sequence of results through successive calls to a \nnext()\n method (or \n__next__()\n in Python 3). For example:\n\n\n \nc\n \n=\n \ncountdown\n(\n5\n)\n\n\n \nc\n.\nnext\n()\n\n\nCounting down!\n\n\n5\n\n\n \nc\n.\nnext\n()\n\n\n4\n\n\n \nc\n.\nnext\n()\n\n\n3\n\n\n\n\n\n\nThe \nnext()\n call makes a generator function run until it reaches the next \nyield\n statement. At this point, the value passed to \nyield\n is returned by \nnext()\n, and the function suspends execution. The function resumes execution on the statement following \nyield\n when \nnext()\n is called again. This process continues until the function returns.\n\n\nNormally you would not manually call next() as shown. Instead, you hook it up to\na for loop like this:\n\n\nNormally you would not manually call \nnext()\n as shown. Instead, you hook it up to a \nfor\n loop like this:\n\n\n \nfor\n \ni\n \nin\n \ncountdown\n(\n5\n):\n\n\n...\n \nprint\n \ni\n,\n\n\nCounting\n \ndown\n!\n\n\n5\n \n4\n \n3\n \n2\n \n1\n\n\n\n\n\n\nGenerators are an extremely powerful way of writing programs based on processing pipelines, streams, or data flow. For example, the following generator function mimics the behavior of the UNIX \ntail -f\n command that\u2019s commonly used to monitor log files:\n\n\n# tail a file (like tail -f)\n\n\nimport\n \ntime\n\n\ndef\n \ntail\n(\nf\n):\n\n    \nf\n.\nseek\n(\n0\n,\n2\n)\n \n# Move to EOF\n\n    \nwhile\n \nTrue\n:\n\n        \nline\n \n=\n \nf\n.\nreadline\n()\n \n# Try reading a new line of text\n\n        \nif\n \nnot\n \nline\n:\n \n# If nothing, sleep briefly and try again\n\n            \ntime\n.\nsleep\n(\n0.1\n)\n\n            \ncontinue\n\n        \nyield\n \nline\n\n\n\n\n\n\nHere\u2019s an example of hooking both of these generators together to create a simple processing pipeline:\n\n\n# A python implementation of Unix \ntail -f | grep python\n\n\nwwwlog\n \n=\n \ntail\n(\nopen\n(\naccess-log\n))\n\n\npylines\n \n=\n \ngrep\n(\nwwwlog\n,\npython\n)\n\n\nfor\n \nline\n \nin\n \npylines\n:\n\n    \nprint\n \nline\n,\n\n\n\n\n\n\nA subtle aspect of generators is that they are often mixed together with other iterable\nobjects such as lists or files. Specifically, when you write a statement such as \nfor item\nin s\n, \ns\n could represent the following:\n\n\n\n\nA list of items,\n\n\nThe lines of a file,\n\n\nThe result of a generator function,\n\n\nAny number of other objects that support iteration.\n\n\n\n\nThe fact that you can just plug different objects in for \ns\n can be a powerful tool for creating extensible programs.\n\n\nCoroutines\n\n\nNormally, functions operate on a single set of input arguments. However, a function can also be written to operate as a task that processes a sequence of inputs sent to it. This type of function is known as a \ncoroutine\n and is created by using the \nyield\n statement as an expression \n(yield)\n as shown in this example:\n\n\ndef\n \nprint_matches\n(\nmatchtext\n):\n\n    \nprint\n \nLooking for\n,\n \nmatchtext\n\n    \nwhile\n \nTrue\n:\n\n        \nline\n \n=\n \n(\nyield\n)\n \n# Get a line of text\n\n        \nif\n \nmatchtext\n \nin\n \nline\n:\n\n            \nprint\n \nline\n\n\n\n\n\n\nTo use this function, you first call it, advance it to the first \n(yield)\n, and then start sending data to it using \nsend()\n. For example:\n\n\n \nmatcher\n \n=\n \nprint_matches\n(\npython\n)\n\n\n \nmatcher\n.\nnext\n()\n \n# Advance to the first (yield)\n\n\nLooking for python\n\n\n \nmatcher\n.\nsend\n(\nHello World\n)\n\n\n \nmatcher\n.\nsend\n(\npython is cool\n)\n\n\npython is cool\n\n\n \nmatcher\n.\nsend\n(\nyow!\n)\n\n\n \nmatcher\n.\nclose\n()\n \n# Done with the matcher function call\n\n\n\n\n\n\n\n\nA coroutine is suspended until a value is sent to it using \nsend()\n. When this happens, that value is returned by the \n(yield)\n expression inside the coroutine and is processed by the statements that follow. Processing continues until the next \n(yield)\n expression is encountered, at which point the function suspends. This continues until the coroutine function returns or \nclose()\n is called on it as shown in the previous example.\n\n\n# A set of matcher coroutines\n\n\nmatchers\n \n=\n \n[\n\n\nprint_matches\n(\npython\n),\n\n\nprint_matches\n(\nguido\n),\n\n\nprint_matches\n(\njython\n)\n\n\n]\n\n\n\n# Prep all of the matchers by calling next()\n\n\nfor\n \nm\n \nin\n \nmatchers\n:\n \nm\n.\nnext\n()\n\n\n\n# Feed an active log file into all matchers. Note for this to work,\n\n\n# a web server must be actively writing data to the log.\n\n\nwwwlog\n \n=\n \ntail\n(\nopen\n(\naccess-log\n))\n\n\nfor\n \nline\n \nin\n \nwwwlog\n:\n\n    \nfor\n \nm\n \nin\n \nmatchers\n:\n\n        \nm\n.\nsend\n(\nline\n)\n \n# Send data into each matcher coroutine\n\n\n\n\n\n\nCoroutines are detailed in \nChapter 6\n.\n\n\nFunctions and Functional Programming\n\n\nDecorators\n\n\nA \ndecorator\n is a function whose primary purpose is to wrap another function or class.  The primary purpose of this wrapping is to transparently alter or enhance the behavior of the object being wrapped. Syntactically, decorators are denoted using the special \n@\n symbol as follows:\n\n\n@trace\n\n\ndef\n \nsquare\n(\nx\n):\n\n    \nreturn\n \nx\n*\nx\n\n\n\n\n\n\nThe preceding code is shorthand for the following:\n\n\ndef\n \nsquare\n(\nx\n):\n\n    \nreturn\n \nx\n*\nx\n\n\nsquare\n \n=\n \ntrace\n(\nsquare\n)\n\n\n\n\n\n\nIn the example, a function \nsquare()\n is defined. However, immediately after its definition, the function object itself is passed to the function \ntrace()\n, which returns an object that replaces the original \nsquare\n.\n\n\n[PER p101]\n\n\nOrder of multiple decorators\n *\n\n\nWhen decorators are used, they must appear on their own line immediately prior to a function or class definition. More than one decorator can also be applied. For example:\n\n\n@foo\n\n\n@bar\n\n\n@spam\n\n\ndef\n \ngrok\n(\nx\n):\n\n    \npass\n\n\n\n\n\n\nIn this case, the decorators are applied in the order listed.The result is the same as this:\n\n\ndef\n \ngrok\n(\nx\n):\n\n    \npass\n\n\ngrok\n \n=\n \nfoo\n(\nbar\n(\nspam\n(\ngrok\n)))\n\n\n\n\n\n\nDecorators with arguments\n *\n\n\nA decorator can also accept arguments. For example:\n\n\n@eventhandler\n(\nBUTTON\n)\n\n\ndef\n \nhandle_button\n(\nmsg\n):\n\n    \n# ...\n\n\n@eventhandler\n(\nRESET\n)\n\n\ndef\n \nhandle_reset\n(\nmsg\n):\n\n    \n# ...\n\n\n\n\n\n\nIf arguments are supplied, the semantics of the decorator are as follows:\n\n\ndef\n \nhandle_button\n(\nmsg\n):\n\n    \n# ...\n\n\ntemp\n \n=\n \neventhandler\n(\nBUTTON\n)\n \n# Call decorator with supplied arguments\n\n\nhandle_button\n \n=\n \ntemp\n(\nhandle_button\n)\n \n# Call the function returned by the decorato\n\n\n\n\n\n\nIn this case, the decorator function only accepts the arguments supplied with the \n@\n specifier. It then returns a function that is called with the function as an argument.\n\n\n# Event handler decorator\n\n\nevent_handlers\n \n=\n \n{\n \n}\n\n\ndef\n \neventhandler\n(\nevent\n):\n\n    \ndef\n \nregister_function\n(\nf\n):\n\n        \nevent_handlers\n[\nevent\n]\n \n=\n \nf\n\n        \nreturn\n \nf\n\n    \nreturn\n \nregister_function\n\n\n\n\n\n\nDecorators can also be applied to class definitions. For example:\n\n\n@foo\n\n\nclass\n \nBar\n(\nobject\n):\n\n    \ndef\n \n__init__\n(\nself\n,\nx\n):\n\n        \nself\n.\nx\n \n=\n \nx\n\n    \ndef\n \nspam\n(\nself\n):\n\n        \n# statements\n\n\n\n\n\n\nFor class decorators, you should always have the decorator function return a class object as a result. Code that expects to work with the original class definition may want to reference members of the class directly such as \nBar.spam\n. This won\u2019t work correctly if the decorator function \nfoo()\n returns a function.\n\n\nDecorators can interact strangely with other aspects of functions such as recursion, documentation strings, and function attributes. These issues are described later in this chapter.\n\n\n\n\nReferences\n\n\n\n\n[PER] \nPython Essential Reference\n (4th Edition)", 
            "title": "Python"
        }, 
        {
            "location": "/ruby/", 
            "text": "Ruby\n\n\nOO Language\n\n\nRuby Is an Object-Oriented Language\n\n\nIn Ruby, you\u2019d define a \nclass\n to represent entities. With classes, you\u2019ll typically want to create a number of \ninstances\n of each. The word \nobject\n is used interchangeably with \nclass instance\n.\n\n\nThese objects are created by calling a \nconstructor\n, a special method associated with a class. The standard constructor is called \nnew\n.\n\n\nsong1\n \n=\n \nSong\n.\nnew\n(\nRuby Tuesday\n)\n\n\nsong2\n \n=\n \nSong\n.\nnew\n(\nEnveloped in Python\n)\n\n\n# and so on\n\n\n\n\n\n\nThese instances are both derived from the same class, but they have unique characteristics:\n\n\n\n\nEvery object has a unique \nobject identifier\n (abbreviated as \nobject ID\n).\n\n\nYou can define instance variables, variables with values that are unique to each instance.\n\n\n\n\nWithin each class, you can define \ninstance methods\n. These instance methods have access to the object\u2019s instance variables and hence to the object\u2019s state.\n\n\nMethods are invoked by sending a message to an object. The message contains the method\u2019s name, along with any parameters the method may need. When an object receives a message, it looks into its own class for a corresponding method (and execute it if it exists).\n\n\nIt\u2019s worth noting here a major difference between Ruby and most other languages. For example, Java, you\u2019d find the absolute value of some number by calling a separate function and passing in that number, like:\n\n\nnum\n \n=\n \nMath\n.\nabs\n(\nnum\n)\n \n// Java code\n\n\n\n\n\n\nIn Ruby, the ability to determine an absolute value is built into numbers: they take care of the details internally. You simply send the message abs to a number object and let it do the work:\n\n\nnum\n \n=\n \n-\n1234\n \n# =\n -1234\n\n\npositive\n \n=\n \nnum\n.\nabs\n \n# =\n 1234\n\n\n\n\n\n\nSome Basic Ruby\n\n\n\n\nMethods are defined with the keyword def, followed by the method name and the method\u2019s parameters between parentheses (parentheses are optional). Ruby doesn\u2019t use braces to delimit the bodies of compound statements and definitions. Instead, you simply finish the body with the keyword \nend\n.\n\n\nThe most common way to create a string is to use \nstring literals\n, which are sequences of characters between single or double quotation marks.\n\n\nSingle-quoted: with a few exceptions, what you enter in the string literal becomes the string\u2019s value.\n\n\nDouble-quoted:\n\n\nSubstitutions: sequences that start with a backslash character are replaced with some binary value.\n\n\nExpression interpolation: the sequence \n#{expression}\n is replaced by the value of \nexpression\n.\n\n\n\n\n\n\n\n\n\n\n\n\nRuby uses a convention for names that may seem strange at first: the first characters of a name indicate\nhow the name is used.\n\n\n\n\nLocal variables, method parameters, and method names should all start with a lowercase letter or an underscore (non-ASCII characters are assumed to be lowercase letters).\n\n\nGlobal variables are prefixed with a dollar sign (\n$\n)\n\n\nInstance variables begin with an \"at\" sign (\n@\n).\n\n\nClass variables start with two \"at\" signs (\n@@\n).\n\n\nClass names, module names, and constants must start with an uppercase letter.\n\n\n\n\nBy convention, multiword instance variables are written with underscores between the words, and multiword class names are written in \nMixedCase\n (with each word capitalized). Method names may end with the characters \n?\n, \n!\n, and \n=\n.\n\n\nThe following table is an example of variable, class, and constant names:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLocal Variable\n\n\nname\n \nfish_and_chips\n \nx_axis\n \nthx1138\n \n_x\n \n_26\n\n\n\n\n\n\nInstance Variable\n\n\n@name\n \n@point_1\n \n@X\n \n@_\n \n@plan9\n\n\n\n\n\n\nClass Variable\n\n\n@@total\n \n@@symtab\n \n@@N\n \n@@x_pos\n \n@@SINGLE\n\n\n\n\n\n\nGlobal Variable\n\n\n$debug\n \n$CUSTOMER\n \n$_\n \n$plan9\n \n$Global\n\n\n\n\n\n\nClass Name\n\n\nString\n \nActiveRecord\n \nMyClass\n\n\n\n\n\n\nConstant Name\n\n\nFEET_PER_MILE\n \nDEBUG\n\n\n\n\n\n\n\n\nArrays and Hashes\n\n\nTwo ways to create and initialize a new array object using an \narray literal\n:\n\n\na\n \n=\n \n[\n \nant\n,\n \nbee\n,\n \ncat\n,\n \ndog\n,\n \nelk\n \n]\n\n\n# this is the same:\n\n\na\n \n=\n \n%w{ ant bee cat dog elk }\n\n\n\n\n\n\nIn many languages, the concept of \nnil\n (or null) means \"no object\". In Ruby, however, \nnil\n is an object that happens to represent nothing.\n\n\nRuby hashes are similar to arrays. A hash literal uses braces rather than square brackets. The literal must supply two objects for every entry: one for the key, the other for the value, separated by \n=\n:\n\n\ninst_section\n \n=\n \n{\n\n  \ncello\n \n=\n \nstring\n,\n\n  \nclarinet\n \n=\n \nwoodwind\n,\n\n  \ndrum\n \n=\n \npercussion\n,\n\n\n}\n\n\n\n\n\n\nA hash by default returns \nnil\n when indexed by a key it doesn\u2019t contain. To specify a default value (for example, 0) when you create a new, empty hash:\n\n\nhistogram\n \n=\n \nHash\n.\nnew\n(\n0\n)\n \n# The default value is zero\n\n\nhistogram\n[\nruby\n]\n \n# =\n 0\n\n\n\n\n\n\nSymbols\n\n\nMost of the time, the actual numeric values of these constants are irrelevant (as long as they are unique). In Ruby, \nsymbols\n are simply constant names that you don\u2019t have to predeclare and that are guaranteed to be unique. A symbol literal starts with a colon and is normally followed by some kind of name, like \n:north\n, \n:east\n. There\u2019s no need to assign some kind of value to a symbol; Ruby takes care of that for you.  Ruby also guarantees that no matter where it appears in your program, a particular symbol will have the same value.\n\n\nSymbols are frequently used as keys in hashes:\n\n\ninst_section\n \n=\n \n{\n\n  \n:cello\n \n=\n \nstring\n,\n\n  \n:clarinet\n \n=\n \nwoodwind\n,\n\n  \n:drum\n \n=\n \npercussion\n\n\n}\n\n\n\n\n\n\nSymbols are so frequently used as hash keys that Ruby has a shortcut syntax (you can use \nname: value\n pairs to create a hash if the keys are symbols):\n\n\ninst_section\n \n=\n \n{\n\n  \ncello\n:\n \nstring\n,\n\n  \nclarinet\n:\n \nwoodwind\n,\n\n  \ndrum\n:\n \npercussion\n\n\n}\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\n[PR12] \nProgramming Ruby 1.9 \n 2.0: The Pragmatic Programmers' Guide\n (4th Edition)\n\n\nThe Ruby Style Guide", 
            "title": "Ruby"
        }, 
        {
            "location": "/asm/", 
            "text": "x86 Assembly\n\n\n\n\nIf you don't assemble the (assembly) code, it's complete gibberish to the computer.\n\nWikibooks\n\n\n\n\nIntroduction\n\n\nIntroduction\n\n\nWhy Learn Assembly?\n\n\n\n\nWith assembly, the programmer can precisely track the flow of data and execution in a program in a mostly human-readable form.\n\n\nDebuggers will frequently only show program code in assembly language.\n\n\n\n\n\n\nAssembly language is also the preferred tool for implementing some low-level tasks, such as bootloaders and low-level kernel components. Code written in assembly has less overhead than code written in high-level languages\n\n\nAs hardware manufacturers such as Intel and AMD add new features and new instructions to their processors, often times the only way to access those features is to use assembly routines, at least until the major compiler vendors add support for those features.\n\n\n\n\n\n\n\n\nBasic FAQ\n\n\nBasic FAQ\n\n\nHow Computer Reads Assembly\n\n\nThe computer cannot read the assembly language that you write. Your assembler will convert the assembly language into a form of binary information called \"machine code\" that your computer uses to perform its operations.\n\n\nPlatform differences\n\n\nThe basic x86 machine code is dependent only on the processor. The x86 versions of Windows and Linux are obviously built on the x86 machine code. There are a few differences between Linux and Windows programming in x86 Assembly:\n\n\n\n\nOn a Linux computer, the most popular assemblers are the GAS assembler, which uses the AT\nT syntax for writing code, and the Netwide Assembler, also known as NASM, which uses a syntax similar to MASM.\n\n\nOn a Windows computer, the most popular assembler is MASM, which uses the Intel syntax.\n\n\nThe available software interrupts, and their functions, are different on Windows and Linux.\n\n\nThe available code libraries are different on Windows and Linux.\n\n\n\n\nx86 Family\n\n\nx86 Family\n\n\nThe term \"x86\" can refer both to an instruction set architecture and to microprocessors which implement it. The name x86 is derived from the fact that many of Intel's early processors had names ending in \"86\".\n\n\nThe x86 instruction set architecture originated at Intel and has evolved over time by the addition of new instructions as well as the expansion to 64-bits. As of 2009, x86 primarily refers to \nIA-32\n (Intel Architecture, 32-bit) and/or \nx86-64\n, the extension to 64-bit computing.\n\n\nVersions of the x86 instruction set architecture have been implemented by Intel, AMD and several other vendors, with each vendor having its own family of x86 processors.\n\n\nx86 Architecture\n\n\nx86 Architecture\n\n\nThe x86 Architecture\n\n\nThe x86 architecture has:\n\n\n\n\n8 General-Purpose Registers (GPR)\n\n\n6 Segment Registers\n\n\n1 Flags Register\n\n\n1 Instruction Pointer\n\n\n\n\n64-bit x86 has additional registers.\n\n\nGeneral-Purpose Registers (GPR) (32-bit naming conventions)\n\n\nThe 8 GPRs are:\n\n\n\n\nAccumulator register (AX). Used in arithmetic operations.\n\n\nCounter register (CX). Used in shift/rotate instructions and loops.\n\n\nData register (DX). Used in arithmetic operations and I/O operations.\n\n\nBase register (BX). Used as a pointer to data (located in segment register DS, when in segmented mode).\n\n\nStack Pointer register (SP). Pointer to the top of the stack.\n\n\nStack Base Pointer register (BP). Used to point to the base of the stack.\n\n\nSource Index register (SI). Used as a pointer to a source in stream operations.\n\n\nDestination Index register (DI). Used as a pointer to a destination in stream operations.\n\n\n\n\nThe order in which they are listed here is for a reason: it is the same order that is used in a push-to-stack operation, which will be covered later.\n\n\nAll registers can be accessed in 16-bit, 32-bit and 64-bit modes:\n\n\n\n\n16-bit: the register is identified by its two-letter abbreviation from the list above. For example, 'AX'.\n\n\n32-bit: the two-letter abbreviation is prefixed with an 'E' (extended). For example, 'EAX'.\n\n\n64-bit: the two-letter abbreviation is prefixed with an 'R'. For example, 'RAX'.\n\n\n\n\nIt is also possible to address the first four registers (AX, CX, DX and BX) in their size of 16-bit as two 8-bit halves:\n\n\n\n\nThe least significant byte (LSB), or low half, is identified by replacing the 'X' with an 'L'.\n\n The most significant byte (MSB), or high half, uses an 'H' instead.\n\n\n\n\nFor example, CL is the LSB of the counter register, whereas CH is its MSB.\n\n\nThe following table summarizes five ways to access the accumulator, counter, data and base registers: 64-bit, 32-bit, 16-bit, 8-bit LSB, and 8-bit MSB:\n\n\n\n\nSegment Registers\n\n\nThe 6 Segment Registers are:\n\n\n\n\nStack Segment (SS). Pointer to the stack.\n\n\nCode Segment (CS). Pointer to the code.\n\n\nData Segment (DS). Pointer to the data.\n\n\nExtra Segment (ES). Pointer to extra data ('E' stands for 'Extra').\n\n\nF Segment (FS). Pointer to more extra data ('F' comes after 'E').\n\n\nG Segment (GS). Pointer to still more extra data ('G' comes after 'F').\n\n\n\n\nMost applications on most modern operating systems (FreeBSD, Linux or Microsoft Windows) use a memory model that points nearly all segment registers to the same place and uses paging instead, effectively disabling their use. Typically the use of FS or GS is an exception to this rule, instead being used to point at thread-specific data.\n\n\nEFLAGS Register\n\n\nThe EFLAGS is a 32-bit register used as a collection of bits representing Boolean values to store the results of operations and the state of the processor.\n\n\n\n\nThe bits named 0 and 1 are reserved bits and shouldn't be modified.\n\n\nThe different use of these flags are:\n\n\n\n\n0 CF : Carry Flag. Set if the last arithmetic operation carried (addition) or borrowed (subtraction) a bit beyond the size of the register. This is then checked when the operation is followed with an add-with-carry or subtract-with-borrow to deal with values too large for just one register to contain.\n\n\n2 PF : Parity Flag. Set if the number of set bits in the least significant byte is a multiple of 2.\n\n\n4 AF : Adjust Flag. Carry of Binary Code Decimal (BCD) numbers arithmetic operations.\n\n\n6 ZF : Zero Flag. Set if the result of an operation is Zero (0).\n\n\n7 SF : Sign Flag. Set if the result of an operation is negative.\n\n\n8 TF : Trap Flag. Set if step by step debugging.\n\n\n9 IF : Interruption Flag. Set if interrupts are enabled.\n\n\n10 DF : Direction Flag. Stream direction. If set, string operations will decrement their pointer rather than incrementing it, reading memory backwards.\n\n\n11 OF : Overflow Flag. Set if signed arithmetic operations result in a value too large for the register to contain.\n\n\n12-13 IOPL : I/O Privilege Level field (2 bits). I/O Privilege Level of the current process.\n\n\n14 NT : Nested Task flag. Controls chaining of interrupts. Set if the current process is linked to the next process.\n\n\n16 RF : Resume Flag. Response to debug exceptions.\n\n\n17 VM : Virtual-8086 Mode. Set if in 8086 compatibility mode.\n\n\n18 AC : Alignment Check. Set if alignment checking of memory references is done.\n\n\n19 VIF : Virtual Interrupt Flag. Virtual image of IF.\n\n\n20 VIP : Virtual Interrupt Pending flag. Set if an interrupt is pending.\n\n\n21 ID : Identification Flag. Support for CPUID instruction if can be set.\n\n\n\n\nInstruction Pointer\n\n\nThe EIP register contains the address of the next instruction to be executed if no branching is done.\n\n\nEIP can only be read through the stack after a \ncall\n instruction.\n\n\nMemory\n\n\nThe x86 architecture is \nlittle-endian\n, meaning that multi-byte values are written least significant byte first. (This refers only to the ordering of the bytes, not to the bits.)\n\n\n\n\nThe 32 bit value B3B2B1B0\n16\n on an x86 would be represented in memory as:\n\n\n+----+----+----+----+\n| B0 | B1 | B2 | B3 |\n+----+----+----+----+\n\n\n\n\n\nThe 32 bits double word 0x1BA583D4 (the 0x denotes hexadecimal) would be written in memory as:\n\n\n+----+----+----+----+\n| D4 | 83 | A5 | 1B |\n+----+----+----+----+\n\n\n\n\n\nThis will be seen as \n0xD4 0x83 0xA5 0x1B\n when doing a memory dump.\n\n\nTwo's Complement Representation\n\n\nTwo's complement is the standard way of representing negative integers in binary. The sign is changed by inverting all of the bits and adding one.\n\n\nFor example,\n\n\n+----------+------+\n| Start:   | 0001 |\n+----------+------+\n| Invert:  | 1110 |\n+----------+------+\n| Add One: | 1111 |\n+----------+------+\n\n\n\n\n\n\n\n0001 represents decimal 1\n\n\n1111 represents decimal -1\n\n\n\n\nAddressing modes\n\n\nThe addressing mode indicates how the operand is presented.\n\n\nRegister Addressing\n\n\nOperand address R is in the address field.\n\n\nmov\n \nax\n,\n \nbx\n  \n; moves contents of register bx into ax\n\n\n\n\n\n\nImmediate\n\n\nAactual value is in the field.\n\n\nmov\n \nax\n,\n \n1\n   \n; moves value of 1 into register ax\n\n\n\n\n\n\nOr:\n\n\nmov\n \nax\n,\n \n010Ch\n \n; moves value of 0x010C into register ax\n\n\n\n\n\n\nDirect memory addressing\n\n\nOperand address is in the address field.\n\n\n.data\n\n\nmy_var\n \ndw\n \n0abcdh\n \n; my_var = 0xabcd\n\n\n.code\n\n\nmov\n \nax\n,\n \n[\nmy_var\n]\n \n; copy my_var content in ax (ax=0xabcd)\n\n\n\n\n\n\nDirect offset addressing\n\n\nUses arithmetics to modify address.\n\n\nbyte_tbl\n \ndb\n \n12\n,\n15\n,\n16\n,\n22\n,\n.....\n \n; Table of bytes\n\n\nmov\n \nal\n,[\nbyte\n_tbl\n+\n2\n]\n\n\nmov\n \nal\n,\nbyte\n_tbl\n[\n2\n]\n \n; same as the former\n\n\n\n\n\n\nRegister Indirect\n\n\nField points to a register that contains the operand address.\n\n\nmov\n \nax\n,[\ndi\n]\n\n\n\n\n\n\nThe registers used for indirect addressing are BX, BP, SI, DI\n\n\nBase-index\n\n\nmov\n \nax\n,[\nbx\n \n+\n \ndi\n]\n\n\n\n\n\n\nFor example, if we are talking about an array, BX contains the address of the beginning of the array, and DI contains the index into the array.\n\n\nBase-index with displacement\n\n\nmov\n \nax\n,[\nbx\n \n+\n \ndi\n \n+\n \n10\n]\n\n\n\n\n\n\nGeneral-Purpose Registers (GPR) (64-bit naming conventions)\n\n\n16 32 and 64 Bits\n\n\n64-bit x86 adds 8 more general-purpose registers, named R8, R9, R10 and so on up to R15. It also introduces a new naming convention that must be used for these new registers and can also be used for the old ones (except that AH, CH, DH and BH have no equivalents). In the new convention:\n\n\n\n\nR0 is RAX.\n\n\nR1 is RCX.\n\n\nR2 is RDX.\n\n\nR3 is RBX.\n\n\nR4 is RSP.\n\n\nR5 is RBP.\n\n\nR6 is RSI.\n\n\nR7 is RDI.\n\n\nR8, R9, R10, R11, R12, R13, R14, R15 are the new registers and have no other names.\n\n\nR0D~R15D are the lowermost 32 bits of each register. For example, R0D is EAX.\n\n\nR0W~R15W are the lowermost 16 bits of each register. For example, R0W is AX.\n\n\nR0L~R15L are the lowermost 8 bits of each register. For example, R0L is AL.\n\n\n\n\nFor 128-bit registers, see \nSSE\n.\n\n\nStack\n\n\nThe stack is a Last In First Out (LIFO) data structure; data is pushed onto it and popped off of it in the reverse order.\n\n\nmov\n \nax\n,\n \n006Ah\n\n\nmov\n \nbx\n,\n \nF79Ah\n\n\nmov\n \ncx\n,\n \n1124h\n\n\n; Push the value in AX, BX, and CX onto the top of the stack\n\n\npush\n \nax\n\n\npush\n \nbx\n\n\npush\n \ncx\n\n\n\n\n\n\nNow the stack has $006A, $F79A, and $1124.\n\n\ncall\n \ndo_stuff\n\n\n\n\n\n\nDo some stuff. The function is not forced to save the registers it uses, hence us saving them.\n\n\npop\n \ncx\n \n;Pop the last element pushed onto the stack into CX, $1124; the stack now has $006A and $F79A.\n\n\npop\n \nbx\n \n;Pop the last element pushed onto the stack into BX, $F79A; the stack now has just $006A.\n\n\npop\n \nax\n \n;Pop the last element pushed onto the stack into AX, $006A; the stack is empty.\n\n\n\n\n\n\nThe stack has two common uses:\n\n\n\n\nPassing arguments to functions or procedures and also keeping track of control flow when the \ncall\n instruction is used.\n\n\nTemporarily saving registers.\n\n\n\n\nCPU Operation Modes\n\n\nCPU Operation Modes\n\n\nReal Mode\n\n\nReal Mode is a holdover from the original Intel 8086. The Intel 8086 accessed memory using 20-bit addresses. But, as the processor itself was 16-bit, Intel invented an addressing scheme that provided a way of mapping a 20-bit addressing space into 16-bit words. Today's x86 processors start in the so-called Real Mode, which is an operating mode that mimics the behavior of the 8086, with some very tiny differences, for backwards compatibility.\n\n\nProtected Mode\n\n\nFlat Memory Model\n\n\nIf programming in a modern operating system (such as Linux, Windows), you are basically programming in flat 32-bit mode. Any register can be used in addressing, and it is generally more efficient to use a full 32-bit register instead of a 16-bit register part. Additionally, segment registers are generally unused in flat mode, and it is generally a bad idea to touch them.\n\n\nMulti-Segmented Memory Model\n\n\nUsing a 32-bit register to address memory, the program can access (almost) all of the memory in a modern computer. For earlier processors (with only 16-bit registers) the segmented memory model was used. The 'CS', 'DS', and 'ES' registers are used to point to the different chunks of memory. For a small program (small model) the CS=DS=ES. For larger memory models, these 'segments' can point to different locations.\n\n\nComments\n\n\nWhen writing code, it is very helpful to use some comments explaining what is going on. A comment is a section of regular text that the assembler ignores when turning the assembly code into the machine code. In assembly comments are usually denoted with a semicolon \";\", although GAS uses \"#\" for single line comments and \"/\n ... \n/\" for multi-line comments.\n\n\nFor example:\n\n\nLabel1:\n\n   \nmov\n \nax\n,\n \nbx\n    \n;move contents of bx into ax\n\n   \nadd\n \nax\n,\n \nbx\n    \n;add the contents of bx into ax\n\n   \n...\n\n\n\n\n\n\n16 32 and 64 Bits\n\n\n16 32 and 64 Bits\n\n\nIntrinsic Data Types\n\n\nStrictly speaking, assembly has no predefined data types like higher-level programming languages. Any general purpose register can hold any sequence of two or four bytes, whether these bytes represent numbers, letters, or other data. In the same way, there are no concrete types assigned to blocks of memory; you can assign to them whatever value you like.\n\n\nThat said, one can group data in assembly into two categories: integer and floating point. While you could load a floating point value into a register and treat it like an integer, the results would be unexpected, so it is best to keep them separate.\n\n\nInteger\n\n\nAn integer represents a whole number, either positive or negative.\n\n\n\n\nUnder the 8086 architecture, it originally came in 8-bit and 16-bit sizes, which served the most basic operations.\n\n\nLater, starting with the 80386, the data bus was expanded to support 32-bit operations and thus allow operations on integers of that size.\n\n\nThe newest systems under the x86 architecture support 64-bit instructions; however, this requires a 64-bit operating system for optimal effect.\n\n\n\n\nSome assembly instructions behave slightly differently in regards to the sign bit; as such, there is a minor distinction between signed and unsigned integers.\n\n\nFloating Point Numbers\n\n\nFloating point numbers are used to approximate the \nreal numbers\n that usually contain digits before and after the decimal point (like \u03c0, 3.14159...). Unlike integers where the decimal point is understood to be after all digits, in floating point numbers the decimal point floats anywhere in the sequence of digits. The precision of floating point numbers is limited and thus a number like \u03c0 can only be represented approximately.\n\n\nOriginally, floating point was not part of the main processor, requiring the use of emulating software. However, there were floating point coprocessors that allowed operations on this data-type, and starting with the 486DX, were integrated directly with the CPU.\n\n\nAs such, floating point operations are not necessarily compatible with all processors. If you need to perform this type of arithmetic, you may want to use a software library as a backup code path.\n\n\nx86 Instructions\n\n\nConventions\n\n\n\n\nGAS Syntax\n\n\nMASM Syntax\n\n\n\n\nInstructions that take no operands:\n\n\n\n\nInstr\n\n\n\n\n\nInstructions that take 1 operand:\n\n\n\n\nInstr\n arg\n\n\n\n\nInstructions that take 2 operands. Notice how the format of the instruction is different for different assemblers.\n\n\n\n\nInstr\n src, dest    # \nGAS Syntax\n\n\nInstr\n dest, src    ; \nIntel syntax\n\n\n\n\n\nInstructions that take 3 operands. Notice how the format of the instruction is different for different assemblers.\n\n\n\n\nInstr\n aux, src, dest   # \nGAS Syntax\n\n\nInstr\n dest, src, aux   ; \nIntel syntax\n\n\n\n\n\nSuffixes\n\n\nOperation Suffixes\n\n\nSome instructions require the use of suffixes to specify the size of the data which will be the subject of the operation, such as:\n\n\n\n\nb (byte) = 8 bits\n\n\nw (word) = 16 bits\n\n\nl (long) = 32 bits\n\n\nq (quad) = 64 bits\n\n\n\n\nAn example of the usage with the \nmov\n instruction on a 32-bit architecture, GAS syntax:\n\n\nmovl\n \n$0x000F\n,\n \n%eax\n          \n# Store the value F into the eax register\n\n\n\n\n\n\nData Transfer Instructions\n\n\nMove: \nmov\n\n\nmov\n \nsrc\n,\n \ndest\n  \n# GAS Synatx\n\n\n\n\n\n\nmov\n \ndest\n,\n \nsrc\n  \n; Intel Syntax\n\n\n\n\n\n\nThe \nmov\n instruction copies the \nsrc\n operand into the \ndest\n operand.\n\n\nOperands\n\n\n\n\nsrc\n:\n\n\nImmediate\n\n\nRegister\n\n\nMemory\n\n\n\n\n\n\ndest\n:\n\n\nRegister\n\n\nMemory\n\n\n\n\n\n\n\n\nModified flags\n: No FLAGS are modified by this instruction.\n\n\nData swap: \nxchg\n and \ncmpxchg\n\n\nxchg\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nxchg\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nThe \nxchg\n instruction swaps the \nsrc\n operand with the dest operand. It's like doing three move operations: from dest to a temporary (another register), then from \nsrc\n to dest, then from the temporary to \nsrc\n, except that no register needs to be reserved for temporary storage.\n\n\nIf one of the operands is a memory address, then the operation has an implicit \nLOCK\n prefix, that is, the exchange operation is atomic. This can have a large performance penalty.\n\n\nIt's also worth noting that the common \nNOP\n (no op) instruction, \n0x90\n, is the opcode for \nxchgl %eax, %eax\n.\n\n\nOperands\n.\n\n\n\n\nsrc\n\n\nRegister\n\n\nMemory\n\n\n\n\n\n\ndest\n\n\nRegister\n\n\nMemory (only one operand can be in memory: the other must be a register)\n\n\n\n\n\n\n\n\nModified flags\n: No FLAGS are modified by this instruction.\n\n\ncmpxchg\n \narg2\n,\n \narg1\n\n\n\n\n\n\ncmpxchg\n \narg1\n,\n \narg2\n\n\n\n\n\n\nCompare and exchange.\n\n\nMove with zero extend\n\n\nmovz\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nmovzx\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nSign Extend\n\n\nmovs\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nmovsx\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nMove String\n\n\nmovsb\n\n\n\n\n\n\nmovsb\n: Move byte\n\n\nmovsw\n\n\n\n\n\n\nmovsw\n: Move word\n\n\nLoad Effective Address\n\n\nlea\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nlea\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nControl Flow Instructions\n\n\nAlmost all programming languages have the ability to change the order in which statements are evaluated, and assembly is no exception. The instruction pointer (EIP) register contains the address of the next instruction to be executed. To change the flow of control, the programmer must be able to modify the value of EIP. This is where control flow functions come in.\n\n\nComparison: \ntest\n and \ncmp\n\n\ntest\n \narg1\n,\n \narg2\n\n\n\n\n\n\ntest\n \narg2\n,\n \narg1\n\n\n\n\n\n\nPerforms a bit-wise logical AND on \narg1\n and \narg2\n the result of which we will refer to as Temp and sets the ZF (zero), SF (sign) and PF (parity) flags based on \nTemp\n. \nTemp\n is then discarded.\n\n\ncmp\n \narg2\n,\n \narg1\n\n\n\n\n\n\ncmp\n \narg1\n,\n \narg2\n\n\n\n\n\n\nJump Instructions\n\n\nUnconditional Jumps\n\n\njmp\n \nloc\n\n\n\n\n\n\nJump on Equality\n\n\nje\n \nloc\n\n\n\n\n\n\nJump on Inequality\n\n\njne\n \nloc\n\n\n\n\n\n\nJump if Greater\n\n\nJump if Less\n\n\nJump on Zero\n\n\nJump on Sign\n\n\nFunction Calls\n\n\ncall\n \nproc\n\n\n\n\n\n\nPushes the address of the next opcode onto the top of the stack, and jumps to the specified location. This is used mostly for subroutines.\n\n\nret\n \n[\nval\n]\n\n\n\n\n\n\nLoads the next value on the stack into EIP, and then pops the specified number of bytes off the stack. If \nval\n is not supplied, the instruction will not pop any values off the stack after returning.\n\n\nLoop Instructions\n\n\nloop\n \narg\n\n\n\n\n\n\nThe loop instruction decrements ECX and jumps to the address specified by arg unless decrementing ECX caused its value to become zero. For example:\n\n\nmov\n \necx\n,\n \n5\n\n\nstart_loop:\n\n\n; the code here would be executed 5 times\n\n\nloop\n \nstart_loop\n\n\n\n\n\n\nEnter and Leave\n\n\nenter\n \narg\n\n\n\n\n\n\nenter\n creates a stack frame with the specified amount of space allocated on the stack.\n\n\nleave\n\n\n\n\n\n\nleave\n destroys the current stack frame, and restores the previous frame. Using Intel syntax this is equivalent to:\n\n\nmov\n \nesp\n,\n \nebp\n\n\npop\n \nebp\n\n\n\n\n\n\nOther Control Instructions\n\n\nhlt\n\n\n\n\n\n\nHalts the processor. Execution will be resumed after processing next hardware interrupt, unless IF is cleared.\n\n\nnop\n\n\n\n\n\n\nNo operation. This instruction doesn't do anything, but wastes an instruction cycle in the processor. This instruction is often represented as an XCHG operation with the operands EAX and EAX.\n\n\nlock\n\n\n\n\n\n\nAsserts #LOCK prefix on next instruction.\n\n\nwait\n\n\n\n\n\n\nWaits for the FPU to finish its last calculation.\n\n\nArithmetic Instructions\n\n\nLogic Instructions\n\n\nShift and Rotate Instructions\n\n\nOther Instructions\n\n\nStack Instructions\n\n\npush\n \narg\n\n\n\n\n\n\nThis instruction decrements the stack pointer and stores the data specified as the argument into the location pointed to by the stack pointer.\n\n\npop\n \narg\n\n\n\n\n\n\nThis instruction loads the data stored in the location pointed to by the stack pointer into the argument specified and then increments the stack pointer.\n\n\nFlags instructions\n\n\nx86 Interrupts\n\n\nInterrupts are special routines that are defined on a per-system basis. This means that the interrupts on one system might be different from the interrupts on another system. Therefore, it is usually a bad idea to rely heavily on interrupts when you are writing code that needs to be portable.\n\n\nInterrupt Instruction\n\n\nint\n \narg\n\n\n\n\n\n\nThis instruction issues the specified interrupt. For instance:\n\n\nint\n \n0x0A\n\n\n\n\n\n\nCalls interrupt 10 (0x0A (hex) = 10 (decimal)).\n\n\nTypes of Interrupts\n\n\nThere are 3 types of interrupts: Hardware Interrupts, Software Interrupts and Exceptions.\n\n\nHardware Interrupts\n\n\nHardware interrupts are triggered by hardware devices. Hardware interrupts are typically asynchronous: their occurrence is unrelated to the instructions being executed at the time they are raised.\n\n\nSoftware Interrupts\n\n\nSoftware interrupts are usually used to transfer control to a function in the operating system kernel. Software interrupts are triggered by the instruction \nint\n. For example, the instruction \nint 14h\n triggers interrupt \n0x14\n. The processor then stops the current program, and jumps to the code to handle interrupt 14. When interrupt handling is complete, the processor returns flow to the original program.\n\n\nExceptions\n\n\nExceptions are caused by exceptional conditions in the code which is executing, for example an attempt to divide by zero or access a protected memory area. The processor will detect this problem, and transfer control to a handler to service the exception. This handler may re-execute the offending code after changing some value (for example, the zero dividend), or if this cannot be done, the program causing the exception may be terminated.\n\n\nx86 Assemblers\n\n\nGAS Syntax\n\n\nMASM Syntax\n\n\nInterfacing with Linux: System Calls\n\n\nInterfacing with Linux\n\n\nSyscalls\n\n\nSyscalls are the interface between user programs and the Linux kernel. They are used to let the kernel perform various system tasks, such as file access, process management and networking. In the C programming language, you would normally call a wrapper function which executes all required steps or even use high-level features such as the standard IO library.\n\n\nOn Linux, there are several ways to make a syscall. This page will focus on making syscalls by calling a software interrupt using \nint $0x80\n (x86 and x86_64) or \nsyscall\n (x86_64). This is an easy and intuitive method of making syscalls in assembly-only programs.\n\n\nMaking a syscalls\n\n\nTo make a syscall using an interrupt, you have to pass all required information to the kernel by copying them into general purpose registers. Each syscall has a fixed number (note the numbers differ between \nint $0x80\n and \nsyscall\n in the following text). You specify the syscall by writing the number into the \neax\n/\nrax\n register and pass the parameters by writing them in the appropriate registers before making the actual calls. Parameters are passed in the order they appear in the function signature of the corresponding C wrapper function.\n\n\nAfter everything is set up correctly, you call the interrupt using \nint $0x80\n or \nsyscall\n and the kernel performs the task.\n\n\nThe return or error value of a syscall is written to \neax\n or \nrax\n.\n\n\nThe kernel uses its own stack to perform the actions. The user stack is not touched in any way.\n\n\nint 0x80\n\n\nOn both Linux x86 and Linux x86_64 systems you can make a syscall by calling interrupt 0x80 using the \nint $0x80\n command. Parameters are passed by setting the general purpose registers as following:\n\n\n\n\n\n\n\n\nSyscall #\n\n\nParam 1\n\n\nParam 2\n\n\nParam 3\n\n\nParam 4\n\n\nParam 5\n\n\nParam 6\n\n\n\n\n\n\n\n\n\n\neax\n\n\nebx\n\n\necx\n\n\nedx\n\n\nesi\n\n\nedi\n\n\nebp\n\n\n\n\n\n\n\n\nThe return value is in the \neax\n register.\n\n\nThe syscall numbers are described in the Linux source file \narch/x86/include/asm/unistd_32.h\n.\n\n\nAll registers are preserved during the syscall.\n\n\nsyscall\n\n\nThe x86_64 architecture introduced a dedicated instruction to make a syscall. It does not access the interrupt descriptor table and is faster. Parameters are passed by setting the general purpose registers as following:\n\n\nThe syscall numbers are described in the Linux source file \narch/x86/include/asm/unistd_64.h\n.\n\n\n\n\n\n\n\n\nSyscall #\n\n\nParam 1\n\n\nParam 2\n\n\nParam 3\n\n\nParam 4\n\n\nParam 5\n\n\nParam 6\n\n\n\n\n\n\n\n\n\n\nrax\n\n\nrdi\n\n\nrsi\n\n\nrdx\n\n\nrcx\n\n\nr8\n\n\nr9\n\n\n\n\n\n\n\n\nThe return value is in the \nrax\n register.\n\n\nAll registers, except \nrcx\n and \nr11\n, are preserved during the syscall.\n\n\nHello World example\n\n\nThis example will write the text \"Hello World\" to stdout using the \nwrite\n syscall and quit the program using the \n_exit\n syscall.\n\n\nSyscall signatures:\n\n\nssize_t\n \nwrite\n(\nint\n \nfd\n,\n \nconst\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \ncount\n);\n\n\nvoid\n \n_exit\n(\nint\n \nstatus\n);\n\n\n\n\n\n\nThe following is the C program of this example:\n\n\n#include \nunistd.h\n\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nwrite\n(\n1\n,\n \nHello World\n\\n\n,\n \n12\n);\n \n/* write \nHello World\n to stdout */\n\n    \n_exit\n(\n0\n);\n                      \n/* exit with error code 0 (no error) */\n\n\n}\n\n\n\n\n\n\nBoth of the assembly examples start alike: a string stored in the data segment and \n_start\n as a global symbol.\n\n\n.data\n\n\nmsg:\n \n.ascii\n \nHello World\\n\n\n\n\n.text\n\n\n.global\n \n_start\n\n\n\n\n\n\nint 0x80\n\n\nAs defined in \narch/x86/include/asm/unistd_32.h\n, the syscall numbers for \nwrite\n and \n_exit\n are:\n\n\n#define __NR_exit 1\n\n\n#define __NR_write 4\n\n\n\n\n\n\nThe parameters are passed exactly as one would in a C program, using the correct registers. After everything is set up, the syscall is made using \nint $0x80\n.\n\n\n_start:\n\n    \nmovl\n \n$4\n,\n \n%eax\n   \n# use the write syscall\n\n    \nmovl\n \n$1\n,\n \n%ebx\n   \n# write to stdout\n\n    \nmovl\n \n$msg\n,\n \n%ecx\n \n# use string \nHello World\n\n    \nmovl\n \n$12\n,\n \n%edx\n  \n# write 12 characters\n\n    \nint\n \n$0x80\n       \n# make syscall\n\n\n    \nmovl\n \n$1\n,\n \n%eax\n   \n# use the _exit syscall\n\n    \nmovl\n \n$0\n,\n \n%ebx\n   \n# error code 0\n\n    \nint\n \n$0x80\n       \n# make syscall\n\n\n\n\n\n\nsyscall\n\n\nIn \narch/x86/include/asm/unistd_64.h\n, the syscall numbers are defined as following:\n\n\n#define __NR_write 1\n\n\n#define __NR_exit 60\n\n\n\n\n\n\nParameters are passed just like in the \nint $0x80\n example, except that the order of the registers is different. The syscall is made using \nsyscall\n.\n\n\n_start:\n\n    \nmovq\n \n$1\n,\n \n%rax\n   \n# use the write syscall\n\n    \nmovq\n \n$1\n,\n \n%rdi\n   \n# write to stdout\n\n    \nmovq\n \n$msg\n,\n \n%rsi\n \n# use string \nHello World\n\n    \nmovq\n \n$12\n,\n \n%rdx\n  \n# write 12 characters\n\n    \nsyscall\n         \n# make syscall\n\n\n    \nmovq\n \n$60\n,\n \n%rax\n  \n# use the _exit syscall\n\n    \nmovq\n \n$0\n,\n \n%rdi\n   \n# error code 0\n\n    \nsyscall\n         \n# make syscall\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\nx86 Assembly\n: \nX86 Assembly/Print Version\n\n\nx86 assembly language", 
            "title": "x86 assembly"
        }, 
        {
            "location": "/roadmap/", 
            "text": "Roadmap\n\n\nThis page summarizes roadmaps of learning focus on the following areas within the next 6 months.\n\n\nProgramming Languages \n(3)\n\n\nC\n\n\n\n\nPatterns in C\n\n\n\n\nGo\n\n\n\n\nGOPL\n\n\n\n\nRuby\n\n\n\n\nTWGR\n\n\n\n\nOperating Systems \n(2)\n\n\n\n\nLKD\n\n\nSPEC\n\n\n\n\nSystem Programming \n(4)\n\n\n\n\nAPUE\n\n\nUNP\n\n\nLSP\n\n\nTLPI\n\n\n\n\nNetworks \n(3)\n\n\n\n\nTCPv1\n\n\nTCPIP\n\n\nCNAPP\n\n\n\n\nSystem Architecture \n(1)\n\n\n\n\nDevOps", 
            "title": "Roadmap"
        }, 
        {
            "location": "/clrs/", 
            "text": "Chapter 22. Elementary Graph Algorithms\n\n\nThis chapter discusses:\n\n\n\n\nRepresenting a graph\n\n\nSearching a graph\n\n\n\n\n22.1 Representations of graphs\n\n\nThere are two standard ways to represent a graph \nG = (V, E)\n:\n\n\n\n\n(A collection of) \nadjacency lists\n\n\nAn \nadjacency matrix\n\n\n\n\nChoices:\n\n\n\n\nThe adjacency-list representation provides a compact way to represent \nsparse\n graphs (where |\nE\n| is much less than |\nV\n|\n2\n); it is usually the method of choice. Most of the graph algorithms presented in this book assume that an input graph is represented in adjacency-list form.\n\n\nThe adjacency-matrix representation is preferred when the graph is \ndense\n (|\nE\n| is close to |\nV\n|\n2\n).\n\n\n\n\nThe following figure shows two representations of an undirected graph. (a) An undirected graph G with 5 vertices and 7 edges. (b) An adjacency-list representation of G. (c) The adjacency-matrix representation of G.\n\n\n\n\nThe following figure shows two representations of a directed graph. (a) A directed graph G with 6 vertices and 8 edges. (b) An adjacency-list representation of G. (c) The adjacency-matrix representation of G.\n\n\n\n\nThe adjacency-list representation of a graph \nG = (V, E)\n consists of an array \nAdj\n of |V| lists, one for each vertex in \nV\n . For each \nu \u2208 V\n , the adjacency list \nAdj[u]\n\" contains all the vertices \nv\n such that there is an edge \n(u, v) \u2208 E\n. That is, \nAdj[u]\n\" consists of all the vertices adjacent to \nu\n in \nG\n.\n\n\n\n\nIf \nG\n is a directed graph, the sum of the lengths of all the adjacency lists is |\nE\n|, since an edge of the form \n(u, v)\n is represented by having \nv\n appear in \nAdj[u]\n.\n\n\nIf \nG\n is an undirected graph, the sum of the lengths of all the adjacency lists is 2|\nE\n|, , since if \n(u, v)\n is an undirected edge, then \nu\n appears in v's adjacency list and vice versa.\n\n\n\n\n[p591]\n\n\nA potential disadvantage of the adjacency-list representation is that it provides no quicker way to determine whether a given edge \n(u, v)\n is present in the graph than to search for \nv\n in the adjacency list \nAdj[u]\n. An adjacency-matrix representation of the graph remedies this disadvantage, but at the cost of using asymptotically more memory.\n\n\nWe can readily adapt adjacency lists to represent \nweighted graphs\n (graphs for which each edge has an associated weight), typically given by a weight function \nw\n. We simply store the weight \nw(u, v)\n of the edge \n(u, v)\n with vertex \nv\n in \nu\n\u2019s adjacency list.\n\n\n[p591-592]\n\n\nRepresenting attributes\n\n\n[p592]\n\n\nFor example, in an object-oriented programming language, vertex attributes might be represented as instance variables within a subclass of a \nVertex\n class\n\n\n22.2 Breadth-first search", 
            "title": "CLRS"
        }, 
        {
            "location": "/iptables/", 
            "text": "iptables\n\n\n\n\nReferences\n\n\n\n\n[ITT]: \nIptables Tutorial 1.2.2", 
            "title": "iptables"
        }, 
        {
            "location": "/nginx/", 
            "text": "Nginx\n\n\n\n\nReferences\n\n\n\n\n[ND]: \nnginx documentation\n\n\n[NTAG]: \nNGINX and NGINX Plus Tutorial and Admin Guide", 
            "title": "Nginx"
        }, 
        {
            "location": "/vim/", 
            "text": "Vim\n\n\n\n\nReferences\n\n\n\n\n[LVVE]: Learning the vi and Vim Editors, 7th Edition\n\n\n[LVHW]: \nLearn Vimscript the Hard Way", 
            "title": "Vim"
        }
    ]
}