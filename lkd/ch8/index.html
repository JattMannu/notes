<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        <link rel="canonical" href="https://notes.shichao.io/lkd/ch8/">
        <link rel="shortcut icon" href="../../toki_32.png">
        

	<title>Chapter 8. Bottom Halves and Deferring Work - Shichao's Notes</title>

        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link rel="stylesheet" href="../../css/highlight.css">
        <link href="../../css/base.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,400italic,500,600" rel="stylesheet">
        <link href="../../custom.css" rel="stylesheet">
        <link href="../../friendly.css" rel="stylesheet">
        <link href="../../theme.css" rel="stylesheet">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        
    </head>

    <body>

        
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            <!-- Main title -->
            <a class="navbar-brand" href="../..">Shichao's Notes</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            <!-- Main navigation -->
            <ul class="nav navbar-nav">
            <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">APUE <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        <li>
                            <a href="../../apue/">Contents</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch1/">Chapter 1. UNIX System Overview</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch2/">Chapter 2. UNIX Standardization and Implementations</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch3/">Chapter 3. File I/O</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch4/">Chapter 4. Files and Directories</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch5/">Chapter 5. Standard I/O Library</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch6/">Chapter 6. System Data Files and Information</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch7/">Chapter 7. Process Environment</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch8/">Chapter 8. Process Control</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch9/">Chapter 9. Process Relationships</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch10/">Chapter 10. Signals</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch11/">Chapter 11. Threads</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch12/">Chapter 12. Thread Control</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch13/">Chapter 13. Daemon Processes</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch14/">Chapter 14. Advanced I/O</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch15/">Chapter 15. Interprocess Communication</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch16/">Chapter 16. Network IPC: Sockets</a>
                        </li>
                      
                        <li>
                            <a href="../../apue/ch17/">Chapter 17. Advanced IPC</a>
                        </li>
                      
                    </ul>
                </li>
            <li class="dropdown active">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">LKD <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        <li>
                            <a href="../">Contents</a>
                        </li>
                      
                        <li>
                            <a href="../ch1/">Chapter 1. Introduction to the Linux Kernel</a>
                        </li>
                      
                        <li>
                            <a href="../ch2/">Chapter 2. Getting Started with the Kernel</a>
                        </li>
                      
                        <li>
                            <a href="../ch3/">Chapter 3. Process Management</a>
                        </li>
                      
                        <li>
                            <a href="../ch4/">Chapter 4. Process Scheduling</a>
                        </li>
                      
                        <li>
                            <a href="../ch5/">Chapter 5. System Calls</a>
                        </li>
                      
                        <li>
                            <a href="../ch6/">Chapter 6. Kernel Data Structures</a>
                        </li>
                      
                        <li>
                            <a href="../ch7/">Chapter 7. Interrupts and Interrupt Handlers</a>
                        </li>
                      
                        <li class="active">
                            <a href="./">Chapter 8. Bottom Halves and Deferring Work</a>
                        </li>
                      
                        <li>
                            <a href="../ch9/">Chapter 9. An Introduction to Kernel Synchronization</a>
                        </li>
                      
                        <li>
                            <a href="../ch10/">Chapter 10. Kernel Synchronization Methods</a>
                        </li>
                      
                        <li>
                            <a href="../ch11/">Chapter 11. Timers and Time Management</a>
                        </li>
                      
                        <li>
                            <a href="../ch12/">Chapter 12. Memory Management</a>
                        </li>
                      
                        <li>
                            <a href="../ch13/">Chapter 13. The Virtual Filesystem</a>
                        </li>
                      
                        <li>
                            <a href="../ch14/">Chapter 14. The Block I/O Layer</a>
                        </li>
                      
                        <li>
                            <a href="../ch15/">Chapter 15. The Process Address Space</a>
                        </li>
                      
                        <li>
                            <a href="../ch16/">Chapter 16. The Page Cache and Page Writeback</a>
                        </li>
                      
                    </ul>
                </li>
            <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">UNP <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        <li>
                            <a href="../../unp/">Contents</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch1/">Chapter 1. Introduction</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch2/">Chapter 2. The Transport Layer: TCP, UDP, and SCTP</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch3/">Chapter 3. Sockets Introduction</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch4/">Chapter 4. Elementary TCP Sockets</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch5/">Chapter 5. TCP Client/Server Example</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch6/">Chapter 6. I/O Multiplexing: The select and poll Functions</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch7/">Chapter 7. Socket Options</a>
                        </li>
                      
                        <li>
                            <a href="../../unp/ch8/">Chapter 8. Elementary UDP Sockets</a>
                        </li>
                      
                    </ul>
                </li>
            <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">TCPv1 <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        <li>
                            <a href="../../tcpv1/">Contents</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch1/">Chapter 1. Introduction</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch2/">Chapter 2. The Internet Address Architecture</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch3/">Chapter 3. Link Layer</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch4/">Chapter 4. ARP: Address Resolution Protocol</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch5/">Chapter 5. The Internet Protocol (IP)</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch6/">Chapter 6. System Configuration: DHCP and Autoconfiguration</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch7/">Chapter 7. Firewalls and Network Address Translation (NAT)</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch8/">Chapter 8. ICMPv4 and ICMPv6: Internet Control Message Protocol</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch9/">Chapter 9. Broadcasting and Local Multicasting (IGMP and MLD)</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch10/">Chapter 10. User Datagram Protocol (UDP) and IP Fragmentation</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch11/">Chapter 11. Name Resolution and the Domain Name System (DNS)</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch12/">Chapter 12. TCP: The Transmission Control Protocol (Preliminaries)</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch13/">Chapter 13. TCP Connection Management</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch14/">Chapter 14. TCP Timeout and Retransmission</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch15/">Chapter 15. TCP Data Flow and Window Management</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch16/">Chapter 16. TCP Congestion Control</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch17/">Chapter 17. TCP Keepalive</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/ch18/">Chapter 18. Security: EAP, IPsec, TLS, DNSSEC, and DKIM</a>
                        </li>
                      
                        <li>
                            <a href="../../tcpv1/headers/">Headers</a>
                        </li>
                      
                    </ul>
                </li>
            <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">GOPL <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        <li>
                            <a href="../../gopl/">Contents</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch1/">Chapter 1. Tutorial</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch2/">Chapter 2. Program Structure</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch3/">Chapter 3. Basic Data Types</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch4/">Chapter 4. Composite Types</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch5/">Chapter 5. Functions</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch6/">Chapter 6. Methods</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch7/">Chapter 7. Interfaces</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch8/">Chapter 8. Goroutines and Channels</a>
                        </li>
                      
                        <li>
                            <a href="../../gopl/ch10/">Chapter 10. Packages and the Go Tool</a>
                        </li>
                      
                    </ul>
                </li>
            <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown">CSN <b class="caret"></b></a>
                    <ul class="dropdown-menu">
                    
                        <li>
                            <a href="../../csn/">Contents</a>
                        </li>
                      
                        <li>
                            <a href="../../csn/part1/">Part 1: Language</a>
                        </li>
                      
                        <li>
                            <a href="../../csn/part2/">Part 2: Advanced</a>
                        </li>
                      
                    </ul>
                </li>
            <li>
                    <a href="../../toc/">TOC</a>
                </li>
            </ul>
            <!-- Search, Navigation and Repo links -->
            <ul class="nav navbar-nav navbar-right">
                
                <li>
                    
                        <a href="https://github.com/shichao-an/notes/blob/master/docs/lkd/ch8.md">
                    
                        
                            <i class="fa fa-github"></i>
                        
                        GitHub
                    </a>
                </li>
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#chapter-8-bottom-halves-and-deferring-work">Chapter 8. Bottom Halves and Deferring Work</a></li>
        
    
        <li class="main "><a href="#bottom-halves">Bottom Halves</a></li>
        
            <li><a href="#why-bottom-halves">Why Bottom Halves?</a></li>
        
            <li><a href="#a-world-of-bottom-halves">A World of Bottom Halves</a></li>
        
    
        <li class="main "><a href="#softirqs">Softirqs</a></li>
        
            <li><a href="#implementing-softirqs">Implementing Softirqs</a></li>
        
            <li><a href="#using-softirqs">Using Softirqs</a></li>
        
    
        <li class="main "><a href="#tasklets">Tasklets</a></li>
        
            <li><a href="#implementing-tasklets">Implementing Tasklets</a></li>
        
            <li><a href="#using-tasklets">Using Tasklets</a></li>
        
            <li><a href="#ksoftirqd">ksoftirqd</a></li>
        
    
        <li class="main "><a href="#doubts-and-solution">Doubts and Solution</a></li>
        
            <li><a href="#verbatim">Verbatim</a></li>
        
    
    </ul>
</div></div>
            <div class="col-md-9" role="main">
              

<h3 id="chapter-8-bottom-halves-and-deferring-work"><strong>Chapter 8. Bottom Halves and Deferring Work</strong></h3>
<p>Interrupt handlers, discussed in the <a href="../ch7/">previous chapter</a>, can form only the first half of any interrupt processing solution, with the following limitations:</p>
<ul>
<li>Interrupt handlers run asynchronously and interrupt other potentially important code, including other interrupt handlers. Therefore, to avoid stalling the interrupted code for too long, interrupt handlers need to run as quickly as possible.</li>
<li>
<p>Interrupt handlers run with one of the following conditions:</p>
<ul>
<li>The current interrupt level is disabled (if <code>IRQF_DISABLED</code> is unset)</li>
<li>All interrupts on the current processor are disabled (if <code>IRQF_DISABLED</code> is set)</li>
</ul>
<p>Disabling interrupts prevents hardware from communicating with the operating systems, so interrupt handlers need to run as quickly as possible.</p>
</li>
<li>
<p>Interrupt handlers are often timing-critical because they deal with hardware.</p>
</li>
<li>Interrupt handlers do not run in process context, so they cannot block, which limits what they can do.</li>
</ul>
<p>Operating systems need a quick, asynchronous, and simple mechanism for immediately responding to hardware and performing any time-critical actions. Interrupt handlers serve this function well. Less critical work can and should be deferred to a later point when interrupts are enabled.</p>
<p>Consequently, managing interrupts is divided into two parts, or <strong>halves</strong>.</p>
<ol>
<li>The first part, interrupt handlers (<strong>top halves</strong>), are executed by the kernel asynchronously in immediate response to a hardware interrupt, as discussed in the previous chapter.</li>
<li>This chapter looks at the second part of the interrupt solution, <strong>bottom halves</strong>.</li>
</ol>
<h3 id="bottom-halves">Bottom Halves</h3>
<p>The job of bottom halves is to perform any interrupt-related work not performed by the interrupt handler. You want the interrupt handler to perform as little work as possible and in turn be as fast as possible. By offloading as much work as possible to the bottom half, the interrupt handler can return control of the system to whatever it interrupted as quickly as possible.</p>
<p>However, the interrupt handler must perform some work; if the work is timing-sensitive, it makes sense to perform it in the interrupt handler. For example, the interrupt handler almost assuredly needs to acknowledge to the hardware the receipt of the interrupt. It may need to copy data to or from the hardware.</p>
<p>Almost anything else can be performed in the bottom half. For example, if you copy data from the hardware into memory in the top half, it makes sense to process it in the bottom half.</p>
<p>No hard and fast rules exist about what work to perform where. The decision is left entirely up to the device-driver author. Although no arrangement is <em>illegal</em>, an arrangement can certainly be <em>suboptimal</em>.</p>
<p>Since interrupt handlers run asynchronously, with at least the current interrupt line disabled, minimizing their duration is important. The following useful tips help decide how to divide the work between the top and bottom half:</p>
<ul>
<li>If the work is time sensitive, perform it in the interrupt handler.</li>
<li>If the work is related to the hardware, perform it in the interrupt handler.</li>
<li>If the work needs to ensure that another interrupt (particularly the same interrupt) does not interrupt it, perform it in the interrupt handler.</li>
<li>For everything else, consider performing the work in the bottom half.</li>
</ul>
<p>When attempting to write your own device driver, looking at other interrupt handlers and their corresponding bottom halves can help. When deciding how to divide your interrupt processing work between the top and bottom half, ask yourself what <em>must</em> be in the top half and what <em>can</em> be in the bottom half. Generally, the quicker the interrupt handler executes, the better.</p>
<h4 id="why-bottom-halves">Why Bottom Halves?</h4>
<p>It is crucial to understand:</p>
<ul>
<li>Why to defer work</li>
<li>When to defer it</li>
</ul>
<p>You want to limit the amount of work you perform in an interrupt handler because:</p>
<ul>
<li>Interrupt handlers run with the current interrupt line disabled on all processors.</li>
<li>Interrupt handlers that register with <code>IRQF_DISABLED</code> run with all interrupt lines disabled on the local processor (plus the current interrupt line disabled on all processors).</li>
</ul>
<p>Thus, minimizing the time spent with interrupts disabled is important for system response and performance.</p>
<p>Besides, interrupt handlers run asynchronously with respect to other code, even other interrupt handlers. Therefore you should work to minimize how long interrupt handlers run. Processing incoming network traffic should not prevent the kernel's receipt of keystrokes.The solution is to defer some of the work until later.</p>
<h5 id="when-is-later"><strong>When is "later"?</strong> *</h5>
<p><em>Later</em> is often simply <em>not now</em>. <u>The point of a bottom half is not to do work at some specific point in the future, but simply to defer work until any point in the future when the system is less busy and interrupts are again enabled.</u> Often, bottom halves run immediately after the interrupt returns. The key is that they run with all interrupts enabled.</p>
<p>Linux is not the only operating systems that separates the processing of hardware interrupts into two parts.</p>
<ul>
<li>The top half is quick and simple and runs with some or all interrupts disabled.</li>
<li>The bottom half (however it is implemented) runs later with all interrupts enabled.</li>
</ul>
<p>This design keeps system latency low by running with interrupts disabled for as little time as necessary.</p>
<h4 id="a-world-of-bottom-halves">A World of Bottom Halves</h4>
<p>While the top half is implemented entirely via the interrupt handler, multiple mechanisms are available for implementing a bottom half. These mechanisms are different interfaces and subsystems that enable you to implement bottom halves. This chapter discusses multiple methods of implementing bottom halves. [p135]</p>
<h5 id="the-original-bottom-half"><strong>The Original "Bottom Half"</strong></h5>
<p>In the beginning, Linux provided only the "bottom half" for implementing bottom halves. This name was logical because at the time that was the only means available for deferring work. The infrastructure was also known as <em>BH</em> to avoid confusion with the generic term <em>bottom half</em>.</p>
<p>The BH interface was simple.</p>
<ul>
<li>It provided a statically created list of 32 bottom halves for the entire system.</li>
<li>The top half could mark whether the bottom half would run by setting a bit in a 32-bit integer.</li>
<li>Each BH was globally synchronized. No two could run at the same time, even on different processors.</li>
</ul>
<p>This was simple and easy to use, but was also inflexible and a bottleneck.</p>
<h5 id="task-queues"><strong>Task Queues</strong></h5>
<p>The kernel developers later introduced <em>task queues</em> both as a method of deferring work and as a replacement for the BH mechanism.</p>
<p>The kernel defined a family of queues.</p>
<ul>
<li>Each queue contained a linked list of functions to call.</li>
<li>The queued functions were run at certain times, depending on which queue they were in.</li>
<li>Drivers could register their bottom halves in the appropriate queue.</li>
</ul>
<p>This worked fairly well, but it was still too inflexible to replace the BH interface entirely. It also was not lightweight enough for performance-critical subsystems, such as networking.</p>
<h5 id="softirqs-and-tasklets"><strong>Softirqs and Tasklets</strong></h5>
<p>The <em>softirqs</em> and <em>tasklets</em> were introduced during the 2.3 development series, to completely replace the BH interface.</p>
<ul>
<li>Softirqs are a set of statically defined bottom halves that can run simultaneously on any processor; even two of the same type can run concurrently.</li>
<li>Tasklets are flexible, dynamically created bottom halves built on top of softirqs.<ul>
<li>Two different tasklets can run concurrently on different processors, but two of the same type of tasklet cannot run simultaneously.</li>
</ul>
</li>
</ul>
<p>Tasklets are a good trade-off between performance and ease of use. For most bottom-half processing, the tasklet is sufficient. Softirqs are useful when performance is critical, such as with networking. Using softirqs requires more care, however, because two of the same softirq can run at the same time. In addition, softirqs must be registered statically at compile time. Conversely, code can dynamically register tasklets.</p>
<p>While developing the 2.5 kernel, all BH users were converted to the other bottom-half interfaces. Additionally, the task queue interface was replaced by the work queue interface. Work queues are a simple yet useful method of queuing work to later be performed in process context.</p>
<p>Consequently, the 2.6 kernel has three bottom-half mechanisms in the kernel:</p>
<ul>
<li>Softirqs</li>
<li>tasklets</li>
<li>Work queues</li>
</ul>
<h5 id="kernel-timers"><strong>Kernel Timers</strong> *</h5>
<p><em>Kernel timers</em> is another mechanism for deferring work. Unlike the mechanisms discussed in the chapter, timers defer work for a specified amount of time. That is, although the tools discussed in this chapter are useful to defer work to any time but now, you use timers to defer work until at least a specific time has elapsed.</p>
<p>Therefore, timers have different uses than the general mechanisms discussed in this chapter.  A full discussion of timers is given in <a href="../ch11/">Chapter 11 Timers and Time Management</a>.</p>
<h5 id="dispelling-the-confusion"><strong>Dispelling the Confusion</strong></h5>
<p><em>Bottom half</em> is a generic operating system term referring to the deferred portion of interrupt processing. All the kernel's mechanisms for deferring work are "bottom halves". Some people also confusingly call all bottom halves "softirqs".</p>
<p>Bottom half also refers to the original deferred work mechanism in Linux. This mechanism is also known as a BH, so we call it by that name now and leave the former as a generic description. The BH mechanism was deprecated a while back and fully removed in the 2.5 development kernel series.</p>
<p>In the current three methods that exist for deferring work, tasklets are built on softirqs and work queues are their own subsystem. The following table presents a history of bottom halves.</p>
<table>
<thead>
<tr>
<th>Bottom Half</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td>BH</td>
<td>Removed in 2.5</td>
</tr>
<tr>
<td>Task queues</td>
<td>Removed in 2.5</td>
</tr>
<tr>
<td>Softirq</td>
<td>Available since 2.3</td>
</tr>
<tr>
<td>Tasklet</td>
<td>Available since 2.3</td>
</tr>
<tr>
<td>Work queues</td>
<td>Available since 2.5</td>
</tr>
</tbody>
</table>
<h3 id="softirqs">Softirqs</h3>
<p>Softirqs are rarely used directly; tasklets, which are built on softirqs are a much more common form of bottom half. The softirq code lives in the file <a href="https://github.com/shichao-an/linux/blob/v2.6.34/kernel/softirq.c">kernel/softirq.c</a> in the kernel source tree.</p>
<h4 id="implementing-softirqs">Implementing Softirqs</h4>
<p>Softirqs are statically allocated at compile time. Unlike tasklets, you cannot dynamically register and destroy softirqs. Softirqs are represented by the <code>softirq_action</code> structure, which is defined in <a href="https://github.com/shichao-an/linux/blob/v2.6.34/include/linux/interrupt.h"><code>&lt;linux/interrupt.h&gt;</code></a>:</p>
<p><small><a href="https://github.com/shichao-an/linux/blob/v2.6.34/include/linux/interrupt.h#L366">include/linux/interrupt.h#L366</a></small></p>
<div class="codehilite"><pre><span class="k">struct</span> <span class="n">softirq_action</span>
<span class="p">{</span>
    <span class="kt">void</span>    <span class="p">(</span><span class="o">*</span><span class="n">action</span><span class="p">)(</span><span class="k">struct</span> <span class="n">softirq_action</span> <span class="o">*</span><span class="p">);</span>
<span class="p">};</span>
</pre></div>


<p>A 32-entry array of this structure is declared in <a href="https://github.com/shichao-an/linux/blob/v2.6.34/kernel/softirq.c">kernel/softirq.c</a>:</p>
<div class="codehilite"><pre><span class="k">static</span> <span class="k">struct</span> <span class="n">softirq_action</span> <span class="n">softirq_vec</span><span class="p">[</span><span class="n">NR_SOFTIRQS</span><span class="p">];</span>
</pre></div>


<p>Each registered softirq consumes one entry in the array. Consequently, there are <code>NR_SOFTIRQS</code> registered softirqs. The number of registered softirqs is statically determined at compile time and cannot be changed dynamically. The kernel enforces a limit of 32 registered softirqs. In the current kernel, only nine exist.</p>
<h5 id="the-softirq-handler"><strong>The Softirq Handler</strong></h5>
<p>The prototype of a softirq handler, <code>action</code>, looks like:</p>
<div class="codehilite"><pre><span class="kt">void</span> <span class="nf">softirq_handler</span><span class="p">(</span><span class="k">struct</span> <span class="n">softirq_action</span> <span class="o">*</span><span class="p">);</span>
</pre></div>


<p>When the kernel runs a softirq handler, it executes this <code>action</code> function with a pointer to the corresponding <code>softirq_action</code> structure as its argument. For example, if <code>my_softirq</code> pointed to an entry in the <code>softirq_vec</code> array, the kernel would invoke the softirq handler function as:</p>
<div class="codehilite"><pre><span class="n">my_softirq</span><span class="o">-&gt;</span><span class="n">action</span><span class="p">(</span><span class="n">my_softirq</span><span class="p">);</span>
</pre></div>


<p>Note that the kernel passes the entire structure to the softirq handler. This trick enables future additions to the structure without requiring a change in every softirq handler.</p>
<p>A softirq never preempts another softirq. The only event that can preempt a softirq is an interrupt handler. Another softirq (even the same one) can run on another processor, however.</p>
<h5 id="executing-softirqs"><strong>Executing Softirqs</strong></h5>
<p>A registered softirq must be marked before it will execute. This is called <em>raising the softirq</em>. Usually, an interrupt handler marks its softirq for execution before returning. Then, at a suitable time, the softirq runs. Pending softirqs are checked for and executed in the following places:</p>
<ul>
<li>In the return from hardware interrupt code path</li>
<li>In the <code>ksoftirqd</code> kernel thread</li>
<li>In any code that explicitly checks for and executes pending softirqs, such as the networking subsystem</li>
</ul>
<p>Regardless of the method of invocation, softirq execution occurs in <a href="https://github.com/shichao-an/linux/blob/v2.6.34/kernel/softirq.c#L191"><code>__do_softirq()</code></a>, which is invoked by <a href="https://github.com/shichao-an/linux/blob/v2.6.34/kernel/softirq.c#L253"><code>do_softirq()</code></a>. The function is quite simple. If there are pending softirqs, <code>__do_softirq()</code> loops over each one, invoking its handler.</p>
<p>The following code is a simplified variant of the important part of <code>__do_softirq()</code>:</p>
<div class="codehilite"><pre><span class="n">u32</span> <span class="n">pending</span><span class="p">;</span>

<span class="n">pending</span> <span class="o">=</span> <span class="n">local_softirq_pending</span><span class="p">();</span>
<span class="k">if</span> <span class="p">(</span><span class="n">pending</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">softirq_action</span> <span class="o">*</span><span class="n">h</span><span class="p">;</span>

    <span class="cm">/* reset the pending bitmask */</span>
    <span class="n">set_softirq_pending</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>

    <span class="n">h</span> <span class="o">=</span> <span class="n">softirq_vec</span><span class="p">;</span>
    <span class="k">do</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">pending</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">h</span><span class="o">-&gt;</span><span class="n">action</span><span class="p">(</span><span class="n">h</span><span class="p">);</span>
        <span class="n">h</span><span class="o">++</span><span class="p">;</span>
        <span class="n">pending</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">while</span> <span class="p">(</span><span class="n">pending</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>


<p>It checks for, and executes, any pending softirqs. It specifically does the following:</p>
<ol>
<li>It sets the <code>pending</code> local variable to the value returned by the <code>local_softirq_pending()</code> macro.<ul>
<li>This is a 32-bit mask of pending softirqs: if bit <code>n</code> is set, the <code>n</code>th softirq is pending.</li>
</ul>
</li>
<li>After the pending bitmask of softirqs is saved, it clears the actual bitmask.</li>
<li>The pointer <code>h</code> is set to the first entry in the <code>softirq_vec</code>.</li>
<li>If the first bit in pending is set, <code>h-&gt;action(h)</code> is called.</li>
<li>The pointer <code>h</code> is incremented by one so that it now points to the second entry in the <code>softirq_vec</code> array.</li>
<li>The bitmask <code>pending</code> is right-shifted by one.<ul>
<li>This discards the first bit and moves all other bits one place to the right.</li>
</ul>
</li>
<li>The pointer <code>h</code> now points to the second entry in the array, and the pending bitmask now has the second bit as the first. Repeat the previous steps.</li>
<li>Continue repeating until pending is zero, at which point there are no more pending softirqs and the work is done.<ul>
<li>This check is sufficient to ensure <code>h</code> always points to a valid entry in <code>softirq_vec</code> because <code>pending</code> has at most 32 set bits and thus this loop executes at most 32 times.</li>
</ul>
</li>
</ol>
<h4 id="using-softirqs">Using Softirqs</h4>
<p>Softirqs are reserved for the most timing-critical and important bottom-half processing on the system.</p>
<p>Currently, only two subsystems directly use softirqs:</p>
<ul>
<li>Networking devices</li>
<li>Block devices</li>
</ul>
<p>Additionally, kernel timers and tasklets are built on top of softirqs.</p>
<p>If you add a new softirq, you normally want to ask yourself why using a tasklet is insufficient. Tasklets are dynamically created and are simpler to use because of their weaker locking requirements, and they still perform quite well. Nonetheless, for timing-critical applications that can do their own locking in an efficient way, softirqs might be the correct solution.</p>
<h5 id="assigning-an-index"><strong>Assigning an Index</strong></h5>
<p>Softirqs are declared statically at compile time via an <a href="https://github.com/shichao-an/linux/blob/v2.6.34/include/linux/interrupt.h#L341"><code>enum</code></a> in <code>&lt;linux/interrupt.h&gt;</code>. The kernel uses this index, which starts at zero, as a relative priority. Softirqs with the lowest numerical priority execute before those with a higher numerical priority.</p>
<p>Creating a new softirq includes adding a new entry to this <code>enum</code>. When adding a new softirq, you might not want to simply add your entry to the end of the list; instead, you need to insert the new entry depending on the priority you want to give it. By convention, <code>HI_SOFTIRQ</code> is always the first and <code>RCU_SOFTIRQ</code> is always the last entry. A new entry likely belongs in between <code>BLOCK_SOFTIRQ</code> and <code>TASKLET_SOFTIRQ</code>.</p>
<p>The following table contains a list of the existing softirq types.</p>
<table>
<thead>
<tr>
<th>Tasklet</th>
<th>Priority</th>
<th>Softirq Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>HI_SOFTIRQ</code></td>
<td>0</td>
<td>High-priority tasklets</td>
</tr>
<tr>
<td><code>TIMER_SOFTIRQ</code></td>
<td>1</td>
<td>Timers</td>
</tr>
<tr>
<td><code>NET_TX_SOFTIRQ</code></td>
<td>2</td>
<td>Send network packets</td>
</tr>
<tr>
<td><code>NET_RX_SOFTIRQ</code></td>
<td>3</td>
<td>Receive network packets</td>
</tr>
<tr>
<td><code>BLOCK_SOFTIRQ</code></td>
<td>4</td>
<td>Block devices</td>
</tr>
<tr>
<td><code>TASKLET_SOFTIRQ</code></td>
<td>5</td>
<td>Normal priority tasklets</td>
</tr>
<tr>
<td><code>SCHED_SOFTIRQ</code></td>
<td>6</td>
<td>Scheduler</td>
</tr>
<tr>
<td><code>HRTIMER_SOFTIRQ</code></td>
<td>7</td>
<td>High-resolution timers</td>
</tr>
<tr>
<td><code>RCU_SOFTIRQ</code></td>
<td>8</td>
<td>RCU locking</td>
</tr>
</tbody>
</table>
<h5 id="registering-your-handler"><strong>Registering Your Handler</strong></h5>
<p>Next, the softirq handler is registered at run-time via <code>open_softirq()</code>, which takes two parameters: the softirq's index and its handler function. For example, the networking subsystem registers its softirqs like this, in <a href="https://github.com/shichao-an/linux/blob/v2.6.34/net/core/dev.c">net/core/dev.c</a>:</p>
<p><small><a href="https://github.com/shichao-an/linux/blob/v2.6.34/net/core/dev.c#L6017">net/core/dev.c#L6017</a></small></p>
<div class="codehilite"><pre><span class="n">open_softirq</span><span class="p">(</span><span class="n">NET_TX_SOFTIRQ</span><span class="p">,</span> <span class="n">net_tx_action</span><span class="p">);</span>
<span class="n">open_softirq</span><span class="p">(</span><span class="n">NET_RX_SOFTIRQ</span><span class="p">,</span> <span class="n">net_rx_action</span><span class="p">);</span>
</pre></div>


<ul>
<li>The softirq handlers run with interrupts enabled and cannot sleep.</li>
<li>While a handler runs, softirqs on the current processor are disabled. However, another processor can execute other softirqs.</li>
<li>If the same softirq is raised again while it is executing, another processor can run it simultaneously. This means that any shared data, even global data used only within the softirq handler, needs proper locking (as discussed in the next two chapters).</li>
</ul>
<p>Here, locking is an important point, and it is the reason tasklets are usually preferred. Simply preventing your softirqs from running concurrently is not ideal. If a softirq obtained a lock to prevent another instance of itself from running simultaneously, there would be no reason to use a softirq. Consequently, most softirq handlers resort to per-processor data (data unique to each processor and thus not requiring locking) and other tricks to avoid explicit locking and provide excellent scalability.</p>
<p>The reason for using softirqs is scalability. If you do not need to scale to infinitely many processors, then use a tasklet. Tasklets are essentially softirqs in which multiple instances of the same handler cannot run concurrently on multiple processors.</p>
<h5 id="raising-your-softirq"><strong>Raising Your Softirq</strong></h5>
<p>After a handler is added to the <code>enum</code> list and registered via <code>open_softirq()</code>, it is ready to run. To mark it pending, so it is run at the next invocation of <code>do_softirq()</code>, call <code>raise_softirq()</code>. For example, the networking subsystem would call:</p>
<div class="codehilite"><pre><span class="n">raise_softirq</span><span class="p">(</span><span class="n">NET_TX_SOFTIRQ</span><span class="p">);</span>
</pre></div>


<p>This raises the <code>NET_TX_SOFTIRQ</code> softirq. Its handler, <a href="https://github.com/shichao-an/linux/blob/v2.6.34/net/core/dev.c#L2252"><code>net_tx_action()</code></a>, runs the next time the kernel executes softirqs. This function (<code>raise_softirq()</code>) disables interrupts prior to actually raising the softirq and then restores them to their previous state. If interrupts are already off, the function <code>raise_softirq_irqoff()</code> can be used as a small optimization. For example:</p>
<div class="codehilite"><pre><span class="cm">/*</span>
<span class="cm"> * interrupts must already be off!</span>
<span class="cm"> */</span>
<span class="n">raise_softirq_irqoff</span><span class="p">(</span><span class="n">NET_TX_SOFTIRQ</span><span class="p">);</span>
</pre></div>


<p>Softirqs are most often raised from within interrupt handlers. In the case of interrupt handlers, the interrupt handler performs the basic hardware-related work, raises the softirq, and then exits. When processing interrupts, the kernel invokes <code>do_softirq()</code>. The softirq then runs and picks up where the interrupt handler left off. In this example, the "top half" and "bottom half" naming should make sense.</p>
<h3 id="tasklets">Tasklets</h3>
<p>Tasklets are a bottom-half mechanism built on top of softirqs. As mentioned, they have nothing to do with tasks. Tasklets are similar in nature and behavior to softirqs, but have a simpler interface and relaxed locking rules.</p>
<p>When writing a device driver, you almost always want to use tasklets. Softirqs are required only for high-frequency and highly threaded uses. Tasklets, on the other hand, work fine for the vast majority of cases and are very easy to use.</p>
<h4 id="implementing-tasklets">Implementing Tasklets</h4>
<p>Because tasklets are implemented on top of softirqs, they are softirqs. As discussed, tasklets are represented by two softirqs:</p>
<ul>
<li><code>HI_SOFTIRQ</code></li>
<li><code>TASKLET_SOFTIRQ</code>.</li>
</ul>
<p>The only difference in these types is that the <code>HI_SOFTIRQ</code>-based tasklets run prior to the <code>TASKLET_SOFTIRQ</code>-based tasklets.</p>
<h5 id="the-tasklet-structure"><strong>The Tasklet Structure</strong></h5>
<p>Tasklets are represented by the <code>tasklet_struct</code> structure. Each structure represents a unique tasklet. The structure is declared in <code>&lt;linux/interrupt.h&gt;</code>:</p>
<p><small><a href="https://github.com/shichao-an/linux/blob/v2.6.34/include/linux/interrupt.h#L420">include/linux/interrupt.h#L420</a></small></p>
<div class="codehilite"><pre><span class="k">struct</span> <span class="n">tasklet_struct</span> <span class="p">{</span>
    <span class="k">struct</span> <span class="n">tasklet_struct</span> <span class="o">*</span><span class="n">next</span><span class="p">;</span>  <span class="cm">/* next tasklet in the list */</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">state</span><span class="p">;</span>          <span class="cm">/* state of the tasklet */</span>
    <span class="n">atomic_t</span> <span class="n">count</span><span class="p">;</span>               <span class="cm">/* reference counter */</span>
    <span class="kt">void</span> <span class="p">(</span><span class="o">*</span><span class="n">func</span><span class="p">)(</span><span class="kt">unsigned</span> <span class="kt">long</span><span class="p">);</span>  <span class="cm">/* tasklet handler function */</span>
    <span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">data</span><span class="p">;</span>           <span class="cm">/* argument to the tasklet function */</span>
<span class="p">};</span>
</pre></div>


<ul>
<li>The <code>func</code> member is the tasklet handler (the equivalent of <code>action</code> to a softirq) and receives <code>data</code> as its sole argument.</li>
<li>The <code>state</code> member can be zero, <code>TASKLET_STATE_SCHED</code>, or <code>TASKLET_STATE_RUN</code>.<ul>
<li><code>TASKLET_STATE_SCHED</code> denotes a tasklet that is scheduled to run.</li>
<li><code>TASKLET_STATE_RUN</code> denotes a tasklet that is running. As an optimization, <code>TASKLET_STATE_RUN</code> is used only on multiprocessor machines because a uniprocessor machine always knows whether the tasklet is running: it is either the currently executing code or not.</li>
</ul>
</li>
<li>The <code>count</code> field is used as a reference count for the tasklet.<ul>
<li>If it is nonzero, the tasklet is disabled and cannot run.</li>
<li>If it is zero, the tasklet is enabled and can run if marked pending.</li>
</ul>
</li>
</ul>
<h5 id="scheduling-tasklets"><strong>Scheduling Tasklets</strong></h5>
<p>Scheduled tasklets (the equivalent of raised softirqs) are stored in two per-processor structures:</p>
<ul>
<li><code>tasklet_vec</code> (for regular tasklets)</li>
<li><code>tasklet_hi_vec</code> (for high-priority tasklets).</li>
</ul>
<p>Both of these structures are linked lists of <code>tasklet_struct</code> structures. Each <code>tasklet_struct</code> structure in the list represents a different tasklet.</p>
<p>Tasklets are scheduled via the following functions:</p>
<ul>
<li><code>tasklet_schedule()</code></li>
<li><code>tasklet_hi_schedule()</code></li>
</ul>
<p>Either of them receives a pointer to the tasklet's <code>tasklet_struct</code> as its lone argument. Each function ensures that the provided tasklet is not yet scheduled and then calls <code>__tasklet_schedule()</code> and <code>__tasklet_hi_schedule()</code> as appropriate. The two functions are similar. The difference is that one uses <code>TASKLET_SOFTIRQ</code> and one uses <code>HI_SOFTIRQ</code>.</p>
<p><code>tasklet_schedule()</code> undertakes the following steps:</p>
<ol>
<li>Check whether the tasklet's state is <code>TASKLET_STATE_SCHED</code>. If it is, the tasklet is already scheduled to run and the function can immediately return.</li>
<li>Call <code>__tasklet_schedule()</code>.</li>
<li>Save the state of the interrupt system, and then disable local interrupts. This ensures that nothing on this processor will mess with the tasklet code while <code>tasklet_schedule()</code> is manipulating the tasklets.</li>
<li>Add the tasklet to be scheduled to the head of the <code>tasklet_vec</code> or <code>tasklet_hi_vec</code> linked list, which is unique to each processor in the system.</li>
<li>Raise the <code>TASKLET_SOFTIRQ</code> or <code>HI_SOFTIRQ</code> softirq, so <code>do_softirq()</code> executes this tasklet in the near future.</li>
<li>Restore interrupts to their previous state and return.</li>
</ol>
<p><code>do_softirq()</code> is run at the next earliest convenience, (as discussed in the previous section). Because most tasklets and softirqs are marked pending in interrupt handlers, <code>do_softirq()</code> most likely runs when the last interrupt returns. Because <code>TASKLET_SOFTIRQ</code> or <code>HI_SOFTIRQ</code> is now raised, <code>do_softirq()</code> executes the associated handlers. These handlers, <a href="https://github.com/shichao-an/linux/blob/v2.6.34/kernel/softirq.c#L399"><code>tasklet_action()</code></a> and <a href="https://github.com/shichao-an/linux/blob/v2.6.34/kernel/softirq.c#L434"><code>tasklet_hi_action()</code></a>, are the heart of tasklet processing; they perform the following steps:</p>
<ol>
<li>Disable local interrupt delivery (there is no need to first save their state because the code here is always called as a softirq handler and interrupts are always enabled) and retrieve the <code>tasklet_vec</code> or <code>tasklet_hi_vec</code> list for this processor.</li>
<li>Clear the list for this processor by setting it equal to <code>NULL</code>.</li>
<li>Enable local interrupt delivery. Again, there is no need to restore them to their previous state because this function knows that they were always originally enabled.</li>
<li>Loop over each pending tasklet in the retrieved list.</li>
<li>If this is a multiprocessing machine, check whether the tasklet is running on another processor by checking the <code>TASKLET_STATE_RUN</code> flag. If it is currently running, do not execute it now and skip to the next pending tasklet. Recall that only one tasklet of a given type may run concurrently.</li>
<li>If the tasklet is not currently running, set the <code>TASKLET_STATE_RUN</code> flag, so another processor will not run it.</li>
<li>Check for a zero <code>count</code> value, to ensure that the tasklet is not disabled. If the tasklet is disabled, skip it and go to the next pending tasklet.</li>
<li>Run the tasklet handler after ensuring the following:<ul>
<li>The tasklet is not running elsewhere</li>
<li>The tasklet is marked as running so it will not start running elsewhere</li>
<li>The tasklet has a zero <code>count</code> value.</li>
</ul>
</li>
<li>After the tasklet runs, clear the <code>TASKLET_STATE_RUN</code> flag in the tasklet's <code>state</code> field.</li>
<li>Repeat for the next pending tasklet, until there are no more scheduled tasklets waiting to run.</li>
</ol>
<p>The implementation of tasklets is simple, but rather clever:</p>
<ol>
<li>All tasklets are multiplexed on top of two softirqs, <code>HI_SOFTIRQ</code> and <code>TASKLET_SOFTIRQ</code>.</li>
<li>When a tasklet is scheduled, the kernel raises one of these softirqs.</li>
<li>These softirqs, in turn, are handled by special functions that then run any scheduled tasklets.</li>
<li>The special functions ensure that only one tasklet of a given type runs at the same time. However, other tasklets can run simultaneously.</li>
</ol>
<p>All this complexity is then hidden behind a clean and simple interface.</p>
<h4 id="using-tasklets">Using Tasklets</h4>
<p>In most cases, tasklets are the preferred mechanism with which to implement your bottom half for a normal hardware device. Tasklets are dynamically created, easy to use, and quick.</p>
<h5 id="declaring-your-tasklet"><strong>Declaring Your Tasklet</strong></h5>
<p>You can create tasklets statically or dynamically, depending on whether you have (or want) a direct or indirect reference to the tasklet. If you are going to statically create the tasklet (and thus have a direct reference to it), use one of two macros in <code>&lt;linux/interrupt.h&gt;</code>:</p>
<div class="codehilite"><pre><span class="n">DECLARE_TASKLET</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">DECLARE_TASKLET_DISABLED</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">data</span><span class="p">);</span>
</pre></div>


<p>Both these macros statically create a <code>struct tasklet_struct</code> with the given name. When the tasklet is scheduled, the given function <code>func</code> is executed and passed the argument <code>data</code>. The difference between the two macros is the initial reference count. The first macro creates the tasklet with a count of zero, and the tasklet is enabled. The second macro sets count to one, and the tasklet is disabled.</p>
<p>For example:</p>
<div class="codehilite"><pre><span class="n">DECLARE_TASKLET</span><span class="p">(</span><span class="n">my_tasklet</span><span class="p">,</span> <span class="n">my_tasklet_handler</span><span class="p">,</span> <span class="n">dev</span><span class="p">);</span>
</pre></div>


<p>This line is equivalent to</p>
<div class="codehilite"><pre><span class="k">struct</span> <span class="n">tasklet_struct</span> <span class="n">my_tasklet</span> <span class="o">=</span> <span class="p">{</span> <span class="nb">NULL</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">ATOMIC_INIT</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                                     <span class="n">my_tasklet_handler</span><span class="p">,</span> <span class="n">dev</span> <span class="p">};</span>
</pre></div>


<p>This creates a tasklet named <code>my_tasklet</code> enabled with <code>my_tasklet_handler</code> as its handler. The value of <code>dev</code> is passed to the handler when it is executed.</p>
<p>To initialize a tasklet given an indirect reference (a pointer) to a dynamically created <code>struct tasklet_struct</code> named <code>t</code>, call <code>tasklet_init()</code> like this:</p>
<div class="codehilite"><pre><span class="n">tasklet_init</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">tasklet_handler</span><span class="p">,</span> <span class="n">dev</span><span class="p">);</span> <span class="cm">/* dynamically as opposed to statically */</span>
</pre></div>


<h5 id="writing-your-tasklet-handler"><strong>Writing Your Tasklet Handler</strong></h5>
<p>The tasklet handler must match the correct prototype:</p>
<div class="codehilite"><pre><span class="kt">void</span> <span class="n">tasklet_handler</span><span class="p">(</span><span class="kt">unsigned</span> <span class="kt">long</span> <span class="n">data</span><span class="p">)</span>
</pre></div>


<ul>
<li>As with softirqs, tasklets cannot sleep. You cannot use semaphores or other blocking functions in a tasklet.</li>
<li>Tasklets also run with all interrupts enabled, so you must take precautions (for example, disable interrupts and obtain a lock) if your tasklet shares data with an interrupt handler.</li>
<li>Unlike softirqs, two of the same tasklets never run concurrently, though two different tasklets can run at the same time on two different processors. If your tasklet shares data with another tasklet or softirq, you need to use proper locking (see <a href="../ch9/">Chapter 9. An Introduction to Kernel Synchronization</a> and <a href="../ch10/">Chapter 10. Kernel Synchronization Methods</a>).</li>
</ul>
<h5 id="scheduling-your-tasklet"><strong>Scheduling Your Tasklet</strong></h5>
<p>To schedule a tasklet for execution, <code>tasklet_schedule()</code> is called and passed a pointer to the relevant <code>tasklet_struct</code>:</p>
<div class="codehilite"><pre><span class="n">tasklet_schedule</span><span class="p">(</span><span class="o">&amp;</span><span class="n">my_tasklet</span><span class="p">);</span> <span class="cm">/* mark my_tasklet as pending */</span>
</pre></div>


<p>After a tasklet is scheduled, it runs once at some time in the near future. If the same tasklet is scheduled again, before it has had a chance to run, it still runs only once. If it is already running, for example on another processor, the tasklet is rescheduled and runs again. As an optimization, a tasklet always runs on the processor that scheduled it, making better use of the processor's cache.</p>
<ul>
<li>You can disable a tasklet via a call to <code>tasklet_disable()</code>, which disables the given tasklet. If the tasklet is currently running, the function will not return until it finishes executing.<ul>
<li>Alternatively, you can use <code>tasklet_disable_nosync()</code>, which disables the given tasklet but does not wait for the tasklet to complete prior to returning. This is usually not safe because you cannot assume the tasklet is not still running.</li>
</ul>
</li>
<li>A call to <code>tasklet_enable()</code> enables the tasklet. This function also must be called before a tasklet created with <code>DECLARE_TASKLET_DISABLED()</code> is usable.</li>
</ul>
<p>For example:</p>
<div class="codehilite"><pre><span class="n">tasklet_disable</span><span class="p">(</span><span class="o">&amp;</span><span class="n">my_tasklet</span><span class="p">);</span> <span class="cm">/* tasklet is now disabled */</span>

<span class="cm">/* we can now do stuff knowing that the tasklet cannot run .. */</span>

<span class="n">tasklet_enable</span><span class="p">(</span><span class="o">&amp;</span><span class="n">my_tasklet</span><span class="p">);</span> <span class="cm">/* tasklet is now enabled */</span>
</pre></div>


<p>You can remove a tasklet from the pending queue via <code>tasklet_kill()</code>. This function receives a pointer as a lone argument to the tasklet's <code>tasklet_struct</code>. Removing a scheduled tasklet from the queue is useful when dealing with a tasklet that often reschedules itself. This function first waits for the tasklet to finish executing and then it removes the tasklet from the queue. Nothing stops some other code from rescheduling the tasklet. This function must not be used from interrupt context because it sleeps.</p>
<h4 id="ksoftirqd">ksoftirqd</h4>
<p>Softirq processing is aided by a set of per-processor kernel threads. These kernel threads help in the processing of softirqs when the system is overwhelmed with softirqs. Because tasklets are implemented using softirqs, the following discussion applies equally to softirqs and tasklets.</p>
<p>As described, the kernel processes softirqs in a number of places, most commonly
on return from handling an interrupt. There are two characteristics with softirqs:</p>
<ul>
<li>Softirqs might be raised at high rates, such as during heavy network traffic.</li>
<li>Softirq functions can reactivate themselves. That is, while running, a softirq can raise itself so that it runs again. For example, the networking subsystem's softirq raises itself.</li>
</ul>
<p>The combination of these two can result in user-space programs being starved of processor time.</p>
<p>Not processing the reactivated softirqs in a timely manner is unacceptable. When softirqs were first designed, this caused a dilemma that needed fixing, and neither of the two obvious solution was a good one, as discussed below:</p>
<h5 id="first-solution-keep-processing"><strong>First solution: keep processing</strong> *</h5>
<p>The first solution is simply to keep processing softirqs as they come in and to recheck and reprocess any pending softirqs before returning. This ensures that the kernel processes softirqs in a timely manner and, most important, that any reactivated softirqs are also immediately processed. The problem lies in high load environments, in which many softirqs continually reactivate themselves. The kernel might continually service softirqs without accomplishing much else. User-space is neglected; nothing but softirqs and interrupt handlers run. This approach might work fine if the system is never under intense load; if the system experiences moderate interrupt levels, this solution is not acceptable. User-space cannot be starved for significant periods.</p>
<h5 id="second-solution-not-handle-reactivated-softirqs"><strong>Second solution: not handle reactivated softirqs</strong> *</h5>
<p>The second solution is not to handle reactivated softirqs. On return from interrupt, the kernel merely looks at all pending softirqs and executes them as normal. If any softirqs reactivate themselves, however, they will not run until the next time the kernel handles pending softirqs. This is most likely not until the next interrupt occurs, which can equate to a lengthy amount of time before any new (or reactivated) softirqs are executed. Worse, on an otherwise idle system, it is beneficial to process the softirqs right away. Unfortunately, this approach is oblivious to which processes are runnable. Therefore, although this method prevents starving user-space, it does starve the softirqs and does not take good advantage of an idle system.</p>
<h5 id="final-solution-compromise"><strong>Final solution: compromise</strong> *</h5>
<p>The solution ultimately implemented in the kernel is to not immediately process reactivated softirqs. Instead, if the number of softirqs grows excessive, the kernel wakes up a family of kernel threads to handle the load. The kernel threads run with the lowest possible priority (nice value of 19), which ensures they do not run in lieu of anything important. The advantage it brings are:</p>
<ul>
<li>The concession prevents heavy softirq activity from completely starving user-space of processor time.</li>
<li>It also ensures that excessive softirqs do run eventually.</li>
<li>On an idle system the softirqs are handled rather quickly because the kernel threads will schedule immediately.</li>
</ul>
<p>There is one thread per processor, each named <code>ksoftirqd/n</code> where <code>n</code> is the processor number. On a two-processor system, they are <code>ksoftirqd/0</code> and <code>ksoftirqd/1</code>. Having a thread on each processor ensures an idle processor, if available, can always service softirqs. After the threads are initialized, they run a tight loop similar to this:</p>
<div class="codehilite"><pre><span class="k">for</span> <span class="p">(;;)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">softirq_pending</span><span class="p">(</span><span class="n">cpu</span><span class="p">))</span>
        <span class="n">schedule</span><span class="p">();</span>

    <span class="n">set_current_state</span><span class="p">(</span><span class="n">TASK_RUNNING</span><span class="p">);</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">softirq_pending</span><span class="p">(</span><span class="n">cpu</span><span class="p">))</span> <span class="p">{</span>
        <span class="n">do_softirq</span><span class="p">();</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">need_resched</span><span class="p">())</span>
            <span class="n">schedule</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="n">set_current_state</span><span class="p">(</span><span class="n">TASK_INTERRUPTIBLE</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>


<p>The above code does this:</p>
<ul>
<li>If any softirqs are pending (as reported by <code>softirq_pending()</code>), <code>ksoftirqd</code> calls <code>do_softirq()</code> to handle them. Note that it does this repeatedly to also handle any reactivated softirqs.</li>
<li>After each iteration, <code>schedule()</code> is called if needed, to enable more important processes to run.</li>
<li>After all processing is complete, the kernel thread sets itself <code>TASK_INTERRUPTIBLE</code> and invokes the scheduler to select a new runnable process.</li>
</ul>
<h3 id="doubts-and-solution">Doubts and Solution</h3>
<h4 id="verbatim">Verbatim</h4>
<h5 id="p141-on-softirq"><strong>p141 on softirq</strong></h5>
<blockquote>
<p>This function (<code>raise_softirq()</code>) disables interrupts prior to actually raising the softirq and then restores them to their previous state.</p>
</blockquote>
<p><span class="text-danger">Question</span>: Why would <code>raise_softirq()</code> disable interrupt?</p>
<h5 id="p145-on-scheduling-tasklets"><strong>p145 on scheduling tasklets</strong></h5>
<blockquote>
<p>After a tasklet is scheduled, it runs once at some time in the near future. If the same tasklet is scheduled again, before it has had a chance to run, it still runs only once. If it is already running, for example on another processor, the tasklet is rescheduled and runs again</p>
</blockquote>
<p><span class="text-danger">Question</span>: I'm confused. What does it mean?</p>
            </div>
        </div>

        <footer class="col-md-12">
            
        </footer>

        <script src="../../js/jquery-1.10.2.min.js"></script>
        <script src="../../js/bootstrap-3.0.3.min.js"></script>
        <script src="../../js/highlight.pack.js"></script>
        <script src="../../js/base.js"></script>
        <script src="../../custom.js"></script>
    </body>
</html>